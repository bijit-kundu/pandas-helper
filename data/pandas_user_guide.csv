url,link_text,content,content_text
https://pandas.pydata.org/docs/user_guide/10min.html,10 minutes to pandas,"<article class=""bd-article"" role=""main"">
<section id=""minutes-to-pandas"">
<span id=""min""></span><h1>10 minutes to pandas<a class=""headerlink"" href=""#minutes-to-pandas"" title=""Link to this heading"">#</a></h1>
<p>This is a short introduction to pandas, geared mainly for new users.
You can see more complex recipes in the <a class=""reference internal"" href=""cookbook.html#cookbook""><span class=""std std-ref"">Cookbook</span></a>.</p>
<p>Customarily, we import as follows:</p>

<section id=""basic-data-structures-in-pandas"">
<h2>Basic data structures in pandas<a class=""headerlink"" href=""#basic-data-structures-in-pandas"" title=""Link to this heading"">#</a></h2>
<p>Pandas provides two types of classes for handling data:</p>
<ol class=""arabic simple"">
<li><dl class=""simple"">
<dt><a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>: a one-dimensional labeled array holding data of any type</dt><dd><p>such as integers, strings, Python objects etc.</p>
</dd>
</dl>
</li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>: a two-dimensional data structure that holds data like
a two-dimension array or a table with rows and columns.</p></li>
</ol>
</section>
<section id=""object-creation"">
<h2>Object creation<a class=""headerlink"" href=""#object-creation"" title=""Link to this heading"">#</a></h2>
<p>See the <a class=""reference internal"" href=""dsintro.html#dsintro""><span class=""std std-ref"">Intro to data structures section</span></a>.</p>
<p>Creating a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> by passing a list of values, letting pandas create
a default <a class=""reference internal"" href=""../reference/api/pandas.RangeIndex.html#pandas.RangeIndex"" title=""pandas.RangeIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">RangeIndex</span></code></a>.</p>

<p>Creating a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> by passing a NumPy array with a datetime index using <a class=""reference internal"" href=""../reference/api/pandas.date_range.html#pandas.date_range"" title=""pandas.date_range""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">date_range()</span></code></a>
and labeled columns:</p>

<p>Creating a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> by passing a dictionary of objects where the keys are the column
labels and the values are the column values.</p>

<p>The columns of the resulting <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> have different
<a class=""reference internal"" href=""basics.html#basics-dtypes""><span class=""std std-ref"">dtypes</span></a>:</p>

<p>If you’re using IPython, tab completion for column names (as well as public
attributes) is automatically enabled. Here’s a subset of the attributes that
will be completed:</p>

<p>As you can see, the columns <code class=""docutils literal notranslate""><span class=""pre"">A</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">B</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">C</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">D</span></code> are automatically
tab completed. <code class=""docutils literal notranslate""><span class=""pre"">E</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">F</span></code> are there as well; the rest of the attributes have been
truncated for brevity.</p>
</section>
<section id=""viewing-data"">
<h2>Viewing data<a class=""headerlink"" href=""#viewing-data"" title=""Link to this heading"">#</a></h2>
<p>See the <a class=""reference internal"" href=""basics.html#basics""><span class=""std std-ref"">Essentially basics functionality section</span></a>.</p>
<p>Use <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.head.html#pandas.DataFrame.head"" title=""pandas.DataFrame.head""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.head()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.tail.html#pandas.DataFrame.tail"" title=""pandas.DataFrame.tail""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.tail()</span></code></a> to view the top and bottom rows of the frame
respectively:</p>

<p>Display the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.index.html#pandas.DataFrame.index"" title=""pandas.DataFrame.index""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">DataFrame.index</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.columns.html#pandas.DataFrame.columns"" title=""pandas.DataFrame.columns""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">DataFrame.columns</span></code></a>:</p>

<p>Return a NumPy representation of the underlying data with <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_numpy.html#pandas.DataFrame.to_numpy"" title=""pandas.DataFrame.to_numpy""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.to_numpy()</span></code></a>
without the index or column labels:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p><strong>NumPy arrays have one dtype for the entire array while pandas DataFrames
have one dtype per column</strong>. When you call <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_numpy.html#pandas.DataFrame.to_numpy"" title=""pandas.DataFrame.to_numpy""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.to_numpy()</span></code></a>, pandas will
find the NumPy dtype that can hold <em>all</em> of the dtypes in the DataFrame.
If the common data type is <code class=""docutils literal notranslate""><span class=""pre"">object</span></code>, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_numpy.html#pandas.DataFrame.to_numpy"" title=""pandas.DataFrame.to_numpy""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.to_numpy()</span></code></a> will require
copying data.</p>

</div>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.describe.html#pandas.DataFrame.describe"" title=""pandas.DataFrame.describe""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">describe()</span></code></a> shows a quick statistic summary of your data:</p>

<p>Transposing your data:</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.sort_index.html#pandas.DataFrame.sort_index"" title=""pandas.DataFrame.sort_index""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.sort_index()</span></code></a> sorts by an axis:</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.sort_values.html#pandas.DataFrame.sort_values"" title=""pandas.DataFrame.sort_values""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.sort_values()</span></code></a> sorts by values:</p>

</section>
<section id=""selection"">
<h2>Selection<a class=""headerlink"" href=""#selection"" title=""Link to this heading"">#</a></h2>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>While standard Python / NumPy expressions for selecting and setting are
intuitive and come in handy for interactive work, for production code, we
recommend the optimized pandas data access methods, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.at.html#pandas.DataFrame.at"" title=""pandas.DataFrame.at""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.at()</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.iat.html#pandas.DataFrame.iat"" title=""pandas.DataFrame.iat""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.iat()</span></code></a>,
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc"" title=""pandas.DataFrame.loc""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.loc()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.iloc.html#pandas.DataFrame.iloc"" title=""pandas.DataFrame.iloc""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.iloc()</span></code></a>.</p>
</div>
<p>See the indexing documentation <a class=""reference internal"" href=""indexing.html#indexing""><span class=""std std-ref"">Indexing and Selecting Data</span></a> and <a class=""reference internal"" href=""advanced.html#advanced""><span class=""std std-ref"">MultiIndex / Advanced Indexing</span></a>.</p>
<section id=""getitem"">
<h3>Getitem (<code class=""docutils literal notranslate""><span class=""pre"">[]</span></code>)<a class=""headerlink"" href=""#getitem"" title=""Link to this heading"">#</a></h3>
<p>For a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>, passing a single label selects a columns and
yields a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> equivalent to <code class=""docutils literal notranslate""><span class=""pre"">df.A</span></code>:</p>

<p>For a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>, passing a slice <code class=""docutils literal notranslate""><span class=""pre"">:</span></code> selects matching rows:</p>

</section>
<section id=""selection-by-label"">
<h3>Selection by label<a class=""headerlink"" href=""#selection-by-label"" title=""Link to this heading"">#</a></h3>
<p>See more in <a class=""reference internal"" href=""indexing.html#indexing-label""><span class=""std std-ref"">Selection by Label</span></a> using <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc"" title=""pandas.DataFrame.loc""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.loc()</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.at.html#pandas.DataFrame.at"" title=""pandas.DataFrame.at""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.at()</span></code></a>.</p>
<p>Selecting a row matching a label:</p>

<p>Selecting all rows (<code class=""docutils literal notranslate""><span class=""pre"">:</span></code>) with a select column labels:</p>

<p>For label slicing, both endpoints are <em>included</em>:</p>

<p>Selecting a single row and column label returns a scalar:</p>

<p>For getting fast access to a scalar (equivalent to the prior method):</p>

</section>
<section id=""selection-by-position"">
<h3>Selection by position<a class=""headerlink"" href=""#selection-by-position"" title=""Link to this heading"">#</a></h3>
<p>See more in <a class=""reference internal"" href=""indexing.html#indexing-integer""><span class=""std std-ref"">Selection by Position</span></a> using <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.iloc.html#pandas.DataFrame.iloc"" title=""pandas.DataFrame.iloc""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.iloc()</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.iat.html#pandas.DataFrame.iat"" title=""pandas.DataFrame.iat""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.iat()</span></code></a>.</p>
<p>Select via the position of the passed integers:</p>

<p>Integer slices acts similar to NumPy/Python:</p>

<p>Lists of integer position locations:</p>

<p>For slicing rows explicitly:</p>

<p>For slicing columns explicitly:</p>

<p>For getting a value explicitly:</p>

<p>For getting fast access to a scalar (equivalent to the prior method):</p>

</section>
<section id=""boolean-indexing"">
<h3>Boolean indexing<a class=""headerlink"" href=""#boolean-indexing"" title=""Link to this heading"">#</a></h3>
<p>Select rows where <code class=""docutils literal notranslate""><span class=""pre"">df.A</span></code> is greater than <code class=""docutils literal notranslate""><span class=""pre"">0</span></code>.</p>

<p>Selecting values from a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> where a boolean condition is met:</p>

<p>Using <a class=""reference internal"" href=""../reference/api/pandas.Series.isin.html#pandas.Series.isin"" title=""pandas.Series.isin""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">isin()</span></code></a> method for filtering:</p>

</section>
<section id=""setting"">
<h3>Setting<a class=""headerlink"" href=""#setting"" title=""Link to this heading"">#</a></h3>
<p>Setting a new column automatically aligns the data by the indexes:</p>

<p>Setting values by label:</p>

<p>Setting values by position:</p>

<p>Setting by assigning with a NumPy array:</p>

<p>The result of the prior setting operations:</p>

<p>A <code class=""docutils literal notranslate""><span class=""pre"">where</span></code> operation with setting:</p>

</section>
</section>
<section id=""missing-data"">
<h2>Missing data<a class=""headerlink"" href=""#missing-data"" title=""Link to this heading"">#</a></h2>
<p>For NumPy data types, <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code> represents missing data. It is by
default not included in computations. See the <a class=""reference internal"" href=""missing_data.html#missing-data""><span class=""std std-ref"">Missing Data section</span></a>.</p>
<p>Reindexing allows you to change/add/delete the index on a specified axis. This
returns a copy of the data:</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.dropna.html#pandas.DataFrame.dropna"" title=""pandas.DataFrame.dropna""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.dropna()</span></code></a> drops any rows that have missing data:</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna"" title=""pandas.DataFrame.fillna""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.fillna()</span></code></a> fills missing data:</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.isna.html#pandas.isna"" title=""pandas.isna""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">isna()</span></code></a> gets the boolean mask where values are <code class=""docutils literal notranslate""><span class=""pre"">nan</span></code>:</p>

</section>
<section id=""operations"">
<h2>Operations<a class=""headerlink"" href=""#operations"" title=""Link to this heading"">#</a></h2>
<p>See the <a class=""reference internal"" href=""basics.html#basics-binop""><span class=""std std-ref"">Basic section on Binary Ops</span></a>.</p>
<section id=""stats"">
<h3>Stats<a class=""headerlink"" href=""#stats"" title=""Link to this heading"">#</a></h3>
<p>Operations in general <em>exclude</em> missing data.</p>
<p>Calculate the mean value for each column:</p>

<p>Calculate the mean value for each row:</p>

<p>Operating with another <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> with a different index or column
will align the result with the union of the index or column labels. In addition, pandas
automatically broadcasts along the specified dimension and will fill unaligned labels with <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code>.</p>

</section>
<section id=""user-defined-functions"">
<h3>User defined functions<a class=""headerlink"" href=""#user-defined-functions"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.agg.html#pandas.DataFrame.agg"" title=""pandas.DataFrame.agg""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.agg()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.transform.html#pandas.DataFrame.transform"" title=""pandas.DataFrame.transform""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.transform()</span></code></a> applies a user defined function
that reduces or broadcasts its result respectively.</p>

</section>
<section id=""value-counts"">
<h3>Value Counts<a class=""headerlink"" href=""#value-counts"" title=""Link to this heading"">#</a></h3>
<p>See more at <a class=""reference internal"" href=""basics.html#basics-discretization""><span class=""std std-ref"">Histogramming and Discretization</span></a>.</p>

</section>
<section id=""string-methods"">
<h3>String Methods<a class=""headerlink"" href=""#string-methods"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> is equipped with a set of string processing methods in the <code class=""docutils literal notranslate""><span class=""pre"">str</span></code>
attribute that make it easy to operate on each element of the array, as in the
code snippet below. See more at <a class=""reference internal"" href=""text.html#text-string-methods""><span class=""std std-ref"">Vectorized String Methods</span></a>.</p>

</section>
</section>
<section id=""merge"">
<h2>Merge<a class=""headerlink"" href=""#merge"" title=""Link to this heading"">#</a></h2>
<section id=""concat"">
<h3>Concat<a class=""headerlink"" href=""#concat"" title=""Link to this heading"">#</a></h3>
<p>pandas provides various facilities for easily combining together <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> and
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> objects with various kinds of set logic for the indexes
and relational algebra functionality in the case of join / merge-type
operations.</p>
<p>See the <a class=""reference internal"" href=""merging.html#merging""><span class=""std std-ref"">Merging section</span></a>.</p>
<p>Concatenating pandas objects together row-wise with <a class=""reference internal"" href=""../reference/api/pandas.concat.html#pandas.concat"" title=""pandas.concat""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">concat()</span></code></a>:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Adding a column to a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> is relatively fast. However, adding
a row requires a copy, and may be expensive. We recommend passing a
pre-built list of records to the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> constructor instead
of building a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> by iteratively appending records to it.</p>
</div>
</section>
<section id=""join"">
<h3>Join<a class=""headerlink"" href=""#join"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.merge.html#pandas.merge"" title=""pandas.merge""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">merge()</span></code></a> enables SQL style join types along specific columns. See the <a class=""reference internal"" href=""merging.html#merging-join""><span class=""std std-ref"">Database style joining</span></a> section.</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.merge.html#pandas.merge"" title=""pandas.merge""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">merge()</span></code></a> on unique keys:</p>

</section>
</section>
<section id=""grouping"">
<h2>Grouping<a class=""headerlink"" href=""#grouping"" title=""Link to this heading"">#</a></h2>
<p>By “group by” we are referring to a process involving one or more of the
following steps:</p>
<ul class=""simple"">
<li><p><strong>Splitting</strong> the data into groups based on some criteria</p></li>
<li><p><strong>Applying</strong> a function to each group independently</p></li>
<li><p><strong>Combining</strong> the results into a data structure</p></li>
</ul>
<p>See the <a class=""reference internal"" href=""groupby.html#groupby""><span class=""std std-ref"">Grouping section</span></a>.</p>

<p>Grouping by a column label, selecting column labels, and then applying the
<a class=""reference internal"" href=""../reference/api/pandas.core.groupby.DataFrameGroupBy.sum.html#pandas.core.groupby.DataFrameGroupBy.sum"" title=""pandas.core.groupby.DataFrameGroupBy.sum""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrameGroupBy.sum()</span></code></a> function to the resulting
groups:</p>

<p>Grouping by multiple columns label forms <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a>.</p>

</section>
<section id=""reshaping"">
<h2>Reshaping<a class=""headerlink"" href=""#reshaping"" title=""Link to this heading"">#</a></h2>
<p>See the sections on <a class=""reference internal"" href=""advanced.html#advanced-hierarchical""><span class=""std std-ref"">Hierarchical Indexing</span></a> and
<a class=""reference internal"" href=""reshaping.html#reshaping-stacking""><span class=""std std-ref"">Reshaping</span></a>.</p>
<section id=""stack"">
<h3>Stack<a class=""headerlink"" href=""#stack"" title=""Link to this heading"">#</a></h3>

<p>The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack"" title=""pandas.DataFrame.stack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">stack()</span></code></a> method “compresses” a level in the DataFrame’s
columns:</p>

<p>With a “stacked” DataFrame or Series (having a <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a> as the
<code class=""docutils literal notranslate""><span class=""pre"">index</span></code>), the inverse operation of <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack"" title=""pandas.DataFrame.stack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">stack()</span></code></a> is
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack"" title=""pandas.DataFrame.unstack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">unstack()</span></code></a>, which by default unstacks the <strong>last level</strong>:</p>

</section>
<section id=""pivot-tables"">
<h3>Pivot tables<a class=""headerlink"" href=""#pivot-tables"" title=""Link to this heading"">#</a></h3>
<p>See the section on <a class=""reference internal"" href=""reshaping.html#reshaping-pivot""><span class=""std std-ref"">Pivot Tables</span></a>.</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.pivot_table.html#pandas.pivot_table"" title=""pandas.pivot_table""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pivot_table()</span></code></a> pivots a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> specifying the <code class=""docutils literal notranslate""><span class=""pre"">values</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">index</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">columns</span></code></p>

</section>
</section>
<section id=""time-series"">
<h2>Time series<a class=""headerlink"" href=""#time-series"" title=""Link to this heading"">#</a></h2>
<p>pandas has simple, powerful, and efficient functionality for performing
resampling operations during frequency conversion (e.g., converting secondly
data into 5-minutely data). This is extremely common in, but not limited to,
financial applications. See the <a class=""reference internal"" href=""timeseries.html#timeseries""><span class=""std std-ref"">Time Series section</span></a>.</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.Series.tz_localize.html#pandas.Series.tz_localize"" title=""pandas.Series.tz_localize""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.tz_localize()</span></code></a> localizes a time series to a time zone:</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.Series.tz_convert.html#pandas.Series.tz_convert"" title=""pandas.Series.tz_convert""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.tz_convert()</span></code></a> converts a timezones aware time series to another time zone:</p>

<p>Adding a non-fixed duration (<a class=""reference internal"" href=""../reference/api/pandas.tseries.offsets.BusinessDay.html#pandas.tseries.offsets.BusinessDay"" title=""pandas.tseries.offsets.BusinessDay""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">BusinessDay</span></code></a>) to a time series:</p>

</section>
<section id=""categoricals"">
<h2>Categoricals<a class=""headerlink"" href=""#categoricals"" title=""Link to this heading"">#</a></h2>
<p>pandas can include categorical data in a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>. For full docs, see the
<a class=""reference internal"" href=""categorical.html#categorical""><span class=""std std-ref"">categorical introduction</span></a> and the <a class=""reference internal"" href=""../reference/arrays.html#api-arrays-categorical""><span class=""std std-ref"">API documentation</span></a>.</p>

<p>Converting the raw grades to a categorical data type:</p>

<p>Rename the categories to more meaningful names:</p>

<p>Reorder the categories and simultaneously add the missing categories (methods under <a class=""reference internal"" href=""../reference/api/pandas.Series.cat.html#pandas.Series.cat"" title=""pandas.Series.cat""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.cat()</span></code></a> return a new <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> by default):</p>

<p>Sorting is per order in the categories, not lexical order:</p>

<p>Grouping by a categorical column with <code class=""docutils literal notranslate""><span class=""pre"">observed=False</span></code> also shows empty categories:</p>

</section>
<section id=""plotting"">
<h2>Plotting<a class=""headerlink"" href=""#plotting"" title=""Link to this heading"">#</a></h2>
<p>See the <a class=""reference internal"" href=""visualization.html#visualization""><span class=""std std-ref"">Plotting</span></a> docs.</p>
<p>We use the standard convention for referencing the matplotlib API:</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">plt.close</span></code> method is used to <a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.close.html"">close</a> a figure window:</p>

<img alt=""../_images/series_plot_basic.png"" src=""../_images/series_plot_basic.png""/>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>When using Jupyter, the plot will appear using <a class=""reference internal"" href=""../reference/api/pandas.Series.plot.html#pandas.Series.plot"" title=""pandas.Series.plot""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">plot()</span></code></a>. Otherwise use
<a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.show.html"">matplotlib.pyplot.show</a> to show it or
<a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.savefig.html"">matplotlib.pyplot.savefig</a> to write it to a file.</p>
</div>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.plot.html#pandas.DataFrame.plot"" title=""pandas.DataFrame.plot""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">plot()</span></code></a> plots all columns:</p>

<img alt=""../_images/frame_plot_basic.png"" src=""../_images/frame_plot_basic.png""/>
</section>
<section id=""importing-and-exporting-data"">
<h2>Importing and exporting data<a class=""headerlink"" href=""#importing-and-exporting-data"" title=""Link to this heading"">#</a></h2>
<p>See the <a class=""reference internal"" href=""io.html#io""><span class=""std std-ref"">IO Tools</span></a> section.</p>
<section id=""csv"">
<h3>CSV<a class=""headerlink"" href=""#csv"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""io.html#io-store-in-csv""><span class=""std std-ref"">Writing to a csv file:</span></a> using <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_csv.html#pandas.DataFrame.to_csv"" title=""pandas.DataFrame.to_csv""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.to_csv()</span></code></a></p>

<p><a class=""reference internal"" href=""io.html#io-read-csv-table""><span class=""std std-ref"">Reading from a csv file:</span></a> using <a class=""reference internal"" href=""../reference/api/pandas.read_csv.html#pandas.read_csv"" title=""pandas.read_csv""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_csv()</span></code></a></p>

</section>
<section id=""parquet"">
<h3>Parquet<a class=""headerlink"" href=""#parquet"" title=""Link to this heading"">#</a></h3>
<p>Writing to a Parquet file:</p>

<p>Reading from a Parquet file Store using <a class=""reference internal"" href=""../reference/api/pandas.read_parquet.html#pandas.read_parquet"" title=""pandas.read_parquet""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_parquet()</span></code></a>:</p>

</section>
<section id=""excel"">
<h3>Excel<a class=""headerlink"" href=""#excel"" title=""Link to this heading"">#</a></h3>
<p>Reading and writing to <a class=""reference internal"" href=""io.html#io-excel""><span class=""std std-ref"">Excel</span></a>.</p>
<p>Writing to an excel file using <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_excel.html#pandas.DataFrame.to_excel"" title=""pandas.DataFrame.to_excel""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.to_excel()</span></code></a>:</p>

<p>Reading from an excel file using <a class=""reference internal"" href=""../reference/api/pandas.read_excel.html#pandas.read_excel"" title=""pandas.read_excel""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_excel()</span></code></a>:</p>

</section>
</section>
<section id=""gotchas"">
<h2>Gotchas<a class=""headerlink"" href=""#gotchas"" title=""Link to this heading"">#</a></h2>
<p>If you are attempting to perform a boolean operation on a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>
you might see an exception like:</p>

<p>See <a class=""reference internal"" href=""basics.html#basics-compare""><span class=""std std-ref"">Comparisons</span></a> and <a class=""reference internal"" href=""gotchas.html#gotchas""><span class=""std std-ref"">Gotchas</span></a> for an explanation and what to do.</p>
</section>
</section>
</article>","10 minutes to pandas # This is a short introduction to pandas, geared mainly for new users. You can see more complex recipes in the Cookbook . Customarily, we import as follows: Basic data structures in pandas # Pandas provides two types of classes for handling data: Series : a one-dimensional labeled array holding data of any type such as integers, strings, Python objects etc. DataFrame : a two-dimensional data structure that holds data like a two-dimension array or a table with rows and columns. Object creation # See the Intro to data structures section . Creating a Series by passing a list of values, letting pandas create a default RangeIndex . Creating a DataFrame by passing a NumPy array with a datetime index using date_range() and labeled columns: Creating a DataFrame by passing a dictionary of objects where the keys are the column labels and the values are the column values. The columns of the resulting DataFrame have different dtypes : If you’re using IPython, tab completion for column names (as well as public attributes) is automatically enabled. Here’s a subset of the attributes that will be completed: As you can see, the columns A , B , C , and D are automatically tab completed. E and F are there as well; the rest of the attributes have been truncated for brevity. Viewing data # See the Essentially basics functionality section . Use DataFrame.head() and DataFrame.tail() to view the top and bottom rows of the frame respectively: Display the DataFrame.index or DataFrame.columns : Return a NumPy representation of the underlying data with DataFrame.to_numpy() without the index or column labels: Note NumPy arrays have one dtype for the entire array while pandas DataFrames have one dtype per column . When you call DataFrame.to_numpy() , pandas will find the NumPy dtype that can hold all of the dtypes in the DataFrame. If the common data type is object , DataFrame.to_numpy() will require copying data. describe() shows a quick statistic summary of your data: Transposing your data: DataFrame.sort_index() sorts by an axis: DataFrame.sort_values() sorts by values: Selection # Note While standard Python / NumPy expressions for selecting and setting are intuitive and come in handy for interactive work, for production code, we recommend the optimized pandas data access methods, DataFrame.at() , DataFrame.iat() , DataFrame.loc() and DataFrame.iloc() . See the indexing documentation Indexing and Selecting Data and MultiIndex / Advanced Indexing . Getitem ( [] ) # For a DataFrame , passing a single label selects a columns and yields a Series equivalent to df.A : For a DataFrame , passing a slice : selects matching rows: Selection by label # See more in Selection by Label using DataFrame.loc() or DataFrame.at() . Selecting a row matching a label: Selecting all rows ( : ) with a select column labels: For label slicing, both endpoints are included : Selecting a single row and column label returns a scalar: For getting fast access to a scalar (equivalent to the prior method): Selection by position # See more in Selection by Position using DataFrame.iloc() or DataFrame.iat() . Select via the position of the passed integers: Integer slices acts similar to NumPy/Python: Lists of integer position locations: For slicing rows explicitly: For slicing columns explicitly: For getting a value explicitly: For getting fast access to a scalar (equivalent to the prior method): Boolean indexing # Select rows where df.A is greater than 0 . Selecting values from a DataFrame where a boolean condition is met: Using isin() method for filtering: Setting # Setting a new column automatically aligns the data by the indexes: Setting values by label: Setting values by position: Setting by assigning with a NumPy array: The result of the prior setting operations: A where operation with setting: Missing data # For NumPy data types, np.nan represents missing data. It is by default not included in computations. See the Missing Data section . Reindexing allows you to change/add/delete the index on a specified axis. This returns a copy of the data: DataFrame.dropna() drops any rows that have missing data: DataFrame.fillna() fills missing data: isna() gets the boolean mask where values are nan : Operations # See the Basic section on Binary Ops . Stats # Operations in general exclude missing data. Calculate the mean value for each column: Calculate the mean value for each row: Operating with another Series or DataFrame with a different index or column will align the result with the union of the index or column labels. In addition, pandas automatically broadcasts along the specified dimension and will fill unaligned labels with np.nan . User defined functions # DataFrame.agg() and DataFrame.transform() applies a user defined function that reduces or broadcasts its result respectively. Value Counts # See more at Histogramming and Discretization . String Methods # Series is equipped with a set of string processing methods in the str attribute that make it easy to operate on each element of the array, as in the code snippet below. See more at Vectorized String Methods . Merge # Concat # pandas provides various facilities for easily combining together Series and DataFrame objects with various kinds of set logic for the indexes and relational algebra functionality in the case of join / merge-type operations. See the Merging section . Concatenating pandas objects together row-wise with concat() : Note Adding a column to a DataFrame is relatively fast. However, adding a row requires a copy, and may be expensive. We recommend passing a pre-built list of records to the DataFrame constructor instead of building a DataFrame by iteratively appending records to it. Join # merge() enables SQL style join types along specific columns. See the Database style joining section. merge() on unique keys: Grouping # By “group by” we are referring to a process involving one or more of the following steps: Splitting the data into groups based on some criteria Applying a function to each group independently Combining the results into a data structure See the Grouping section . Grouping by a column label, selecting column labels, and then applying the DataFrameGroupBy.sum() function to the resulting groups: Grouping by multiple columns label forms MultiIndex . Reshaping # See the sections on Hierarchical Indexing and Reshaping . Stack # The stack() method “compresses” a level in the DataFrame’s columns: With a “stacked” DataFrame or Series (having a MultiIndex as the index ), the inverse operation of stack() is unstack() , which by default unstacks the last level : Pivot tables # See the section on Pivot Tables . pivot_table() pivots a DataFrame specifying the values , index and columns Time series # pandas has simple, powerful, and efficient functionality for performing resampling operations during frequency conversion (e.g., converting secondly data into 5-minutely data). This is extremely common in, but not limited to, financial applications. See the Time Series section . Series.tz_localize() localizes a time series to a time zone: Series.tz_convert() converts a timezones aware time series to another time zone: Adding a non-fixed duration ( BusinessDay ) to a time series: Categoricals # pandas can include categorical data in a DataFrame . For full docs, see the categorical introduction and the API documentation . Converting the raw grades to a categorical data type: Rename the categories to more meaningful names: Reorder the categories and simultaneously add the missing categories (methods under Series.cat() return a new Series by default): Sorting is per order in the categories, not lexical order: Grouping by a categorical column with observed=False also shows empty categories: Plotting # See the Plotting docs. We use the standard convention for referencing the matplotlib API: The plt.close method is used to close a figure window: Note When using Jupyter, the plot will appear using plot() . Otherwise use matplotlib.pyplot.show to show it or matplotlib.pyplot.savefig to write it to a file. plot() plots all columns: Importing and exporting data # See the IO Tools section. CSV # Writing to a csv file: using DataFrame.to_csv() Reading from a csv file: using read_csv() Parquet # Writing to a Parquet file: Reading from a Parquet file Store using read_parquet() : Excel # Reading and writing to Excel . Writing to an excel file using DataFrame.to_excel() : Reading from an excel file using read_excel() : Gotchas # If you are attempting to perform a boolean operation on a Series or DataFrame you might see an exception like: See Comparisons and Gotchas for an explanation and what to do."
https://pandas.pydata.org/docs/user_guide/dsintro.html,Intro to data structures,"<article class=""bd-article"" role=""main"">
<section id=""intro-to-data-structures"">
<span id=""dsintro""></span><h1>Intro to data structures<a class=""headerlink"" href=""#intro-to-data-structures"" title=""Link to this heading"">#</a></h1>
<p>We’ll start with a quick, non-comprehensive overview of the fundamental data
structures in pandas to get you started. The fundamental behavior about data
types, indexing, axis labeling, and alignment apply across all of the
objects. To get started, import NumPy and load pandas into your namespace:</p>

<p>Fundamentally, <strong>data alignment is intrinsic</strong>. The link
between labels and data will not be broken unless done so explicitly by you.</p>
<p>We’ll give a brief intro to the data structures, then consider all of the broad
categories of functionality and methods in separate sections.</p>
<section id=""series"">
<span id=""basics-series""></span><h2>Series<a class=""headerlink"" href=""#series"" title=""Link to this heading"">#</a></h2>
<p><a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> is a one-dimensional labeled array capable of holding any data
type (integers, strings, floating point numbers, Python objects, etc.). The axis
labels are collectively referred to as the <strong>index</strong>. The basic method to create a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> is to call:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">s</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">Series</span><span class=""p"">(</span><span class=""n"">data</span><span class=""p"">,</span> <span class=""n"">index</span><span class=""o"">=</span><span class=""n"">index</span><span class=""p"">)</span>
</pre></div>
</div>
<p>Here, <code class=""docutils literal notranslate""><span class=""pre"">data</span></code> can be many different things:</p>
<ul class=""simple"">
<li><p>a Python dict</p></li>
<li><p>an ndarray</p></li>
<li><p>a scalar value (like 5)</p></li>
</ul>
<p>The passed <strong>index</strong> is a list of axis labels. Thus, this separates into a few
cases depending on what <strong>data is</strong>:</p>
<p><strong>From ndarray</strong></p>
<p>If <code class=""docutils literal notranslate""><span class=""pre"">data</span></code> is an ndarray, <strong>index</strong> must be the same length as <strong>data</strong>. If no
index is passed, one will be created having values <code class=""docutils literal notranslate""><span class=""pre"">[0,</span> <span class=""pre"">...,</span> <span class=""pre"">len(data)</span> <span class=""pre"">-</span> <span class=""pre"">1]</span></code>.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>pandas supports non-unique index values. If an operation
that does not support duplicate index values is attempted, an exception
will be raised at that time.</p>
</div>
<p><strong>From dict</strong></p>
<p><a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> can be instantiated from dicts:</p>

<p>If an index is passed, the values in data corresponding to the labels in the
index will be pulled out.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>NaN (not a number) is the standard missing data marker used in pandas.</p>
</div>
<p><strong>From scalar value</strong></p>
<p>If <code class=""docutils literal notranslate""><span class=""pre"">data</span></code> is a scalar value, an index must be
provided. The value will be repeated to match the length of <strong>index</strong>.</p>

<section id=""series-is-ndarray-like"">
<h3>Series is ndarray-like<a class=""headerlink"" href=""#series-is-ndarray-like"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> acts very similarly to a <code class=""docutils literal notranslate""><span class=""pre"">ndarray</span></code> and is a valid argument to most NumPy functions.
However, operations such as slicing will also slice the index.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>We will address array-based indexing like <code class=""docutils literal notranslate""><span class=""pre"">s.iloc[[4,</span> <span class=""pre"">3,</span> <span class=""pre"">1]]</span></code>
in <a class=""reference internal"" href=""indexing.html#indexing""><span class=""std std-ref"">section on indexing</span></a>.</p>
</div>
<p>Like a NumPy array, a pandas <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> has a single <a class=""reference internal"" href=""../reference/api/pandas.Series.dtype.html#pandas.Series.dtype"" title=""pandas.Series.dtype""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">dtype</span></code></a>.</p>

<p>This is often a NumPy dtype. However, pandas and 3rd-party libraries
extend NumPy’s type system in a few places, in which case the dtype would
be an <a class=""reference internal"" href=""../reference/api/pandas.api.extensions.ExtensionDtype.html#pandas.api.extensions.ExtensionDtype"" title=""pandas.api.extensions.ExtensionDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">ExtensionDtype</span></code></a>. Some examples within
pandas are <a class=""reference internal"" href=""categorical.html#categorical""><span class=""std std-ref"">Categorical data</span></a> and <a class=""reference internal"" href=""integer_na.html#integer-na""><span class=""std std-ref"">Nullable integer data type</span></a>. See <a class=""reference internal"" href=""basics.html#basics-dtypes""><span class=""std std-ref"">dtypes</span></a>
for more.</p>
<p>If you need the actual array backing a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>, use <a class=""reference internal"" href=""../reference/api/pandas.Series.array.html#pandas.Series.array"" title=""pandas.Series.array""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">Series.array</span></code></a>.</p>

<p>Accessing the array can be useful when you need to do some operation without the
index (to disable <a class=""reference internal"" href=""#dsintro-alignment""><span class=""std std-ref"">automatic alignment</span></a>, for example).</p>
<p><a class=""reference internal"" href=""../reference/api/pandas.Series.array.html#pandas.Series.array"" title=""pandas.Series.array""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">Series.array</span></code></a> will always be an <a class=""reference internal"" href=""../reference/api/pandas.api.extensions.ExtensionArray.html#pandas.api.extensions.ExtensionArray"" title=""pandas.api.extensions.ExtensionArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">ExtensionArray</span></code></a>.
Briefly, an ExtensionArray is a thin wrapper around one or more <em>concrete</em> arrays like a
<a class=""reference external"" href=""https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray"" title=""(in NumPy v1.26)""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">numpy.ndarray</span></code></a>. pandas knows how to take an <a class=""reference internal"" href=""../reference/api/pandas.api.extensions.ExtensionArray.html#pandas.api.extensions.ExtensionArray"" title=""pandas.api.extensions.ExtensionArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">ExtensionArray</span></code></a> and
store it in a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or a column of a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>.
See <a class=""reference internal"" href=""basics.html#basics-dtypes""><span class=""std std-ref"">dtypes</span></a> for more.</p>
<p>While <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> is ndarray-like, if you need an <em>actual</em> ndarray, then use
<a class=""reference internal"" href=""../reference/api/pandas.Series.to_numpy.html#pandas.Series.to_numpy"" title=""pandas.Series.to_numpy""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.to_numpy()</span></code></a>.</p>

<p>Even if the <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> is backed by a <a class=""reference internal"" href=""../reference/api/pandas.api.extensions.ExtensionArray.html#pandas.api.extensions.ExtensionArray"" title=""pandas.api.extensions.ExtensionArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">ExtensionArray</span></code></a>,
<a class=""reference internal"" href=""../reference/api/pandas.Series.to_numpy.html#pandas.Series.to_numpy"" title=""pandas.Series.to_numpy""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.to_numpy()</span></code></a> will return a NumPy ndarray.</p>
</section>
<section id=""series-is-dict-like"">
<h3>Series is dict-like<a class=""headerlink"" href=""#series-is-dict-like"" title=""Link to this heading"">#</a></h3>
<p>A <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> is also like a fixed-size dict in that you can get and set values by index
label:</p>

<p>If a label is not contained in the index, an exception is raised:</p>

<p>Using the <a class=""reference internal"" href=""../reference/api/pandas.Series.get.html#pandas.Series.get"" title=""pandas.Series.get""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.get()</span></code></a> method, a missing label will return None or specified default:</p>

<p>These labels can also be accessed by <a class=""reference internal"" href=""indexing.html#indexing-attribute-access""><span class=""std std-ref"">attribute</span></a>.</p>
</section>
<section id=""vectorized-operations-and-label-alignment-with-series"">
<h3>Vectorized operations and label alignment with Series<a class=""headerlink"" href=""#vectorized-operations-and-label-alignment-with-series"" title=""Link to this heading"">#</a></h3>
<p>When working with raw NumPy arrays, looping through value-by-value is usually
not necessary. The same is true when working with <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> in pandas.
<a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> can also be passed into most NumPy methods expecting an ndarray.</p>

<p>A key difference between <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> and ndarray is that operations between <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>
automatically align the data based on label. Thus, you can write computations
without giving consideration to whether the <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> involved have the same
labels.</p>

<p>The result of an operation between unaligned <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> will have the <strong>union</strong> of
the indexes involved. If a label is not found in one <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or the other, the
result will be marked as missing <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>. Being able to write code without doing
any explicit data alignment grants immense freedom and flexibility in
interactive data analysis and research. The integrated data alignment features
of the pandas data structures set pandas apart from the majority of related
tools for working with labeled data.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>In general, we chose to make the default result of operations between
differently indexed objects yield the <strong>union</strong> of the indexes in order to
avoid loss of information. Having an index label, though the data is
missing, is typically important information as part of a computation. You
of course have the option of dropping labels with missing data via the
<strong>dropna</strong> function.</p>
</div>
</section>
<section id=""name-attribute"">
<h3>Name attribute<a class=""headerlink"" href=""#name-attribute"" title=""Link to this heading"">#</a></h3>
<p id=""dsintro-name-attribute""><a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> also has a <code class=""docutils literal notranslate""><span class=""pre"">name</span></code> attribute:</p>

<p>The <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> <code class=""docutils literal notranslate""><span class=""pre"">name</span></code> can be assigned automatically in many cases, in particular,
when selecting a single column from a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>, the <code class=""docutils literal notranslate""><span class=""pre"">name</span></code> will be assigned
the column label.</p>
<p>You can rename a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> with the <a class=""reference internal"" href=""../reference/api/pandas.Series.rename.html#pandas.Series.rename"" title=""pandas.Series.rename""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">pandas.Series.rename()</span></code></a> method.</p>

<p>Note that <code class=""docutils literal notranslate""><span class=""pre"">s</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">s2</span></code> refer to different objects.</p>
</section>
</section>
<section id=""dataframe"">
<span id=""basics-dataframe""></span><h2>DataFrame<a class=""headerlink"" href=""#dataframe"" title=""Link to this heading"">#</a></h2>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> is a 2-dimensional labeled data structure with columns of
potentially different types. You can think of it like a spreadsheet or SQL
table, or a dict of Series objects. It is generally the most commonly used
pandas object. Like Series, DataFrame accepts many different kinds of input:</p>
<ul class=""simple"">
<li><p>Dict of 1D ndarrays, lists, dicts, or <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a></p></li>
<li><p>2-D numpy.ndarray</p></li>
<li><p><a class=""reference external"" href=""https://numpy.org/doc/stable/user/basics.rec.html"">Structured or record</a> ndarray</p></li>
<li><p>A <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a></p></li>
<li><p>Another <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a></p></li>
</ul>
<p>Along with the data, you can optionally pass <strong>index</strong> (row labels) and
<strong>columns</strong> (column labels) arguments. If you pass an index and / or columns,
you are guaranteeing the index and / or columns of the resulting
DataFrame. Thus, a dict of Series plus a specific index will discard all data
not matching up to the passed index.</p>
<p>If axis labels are not passed, they will be constructed from the input data
based on common sense rules.</p>
<section id=""from-dict-of-series-or-dicts"">
<h3>From dict of Series or dicts<a class=""headerlink"" href=""#from-dict-of-series-or-dicts"" title=""Link to this heading"">#</a></h3>
<p>The resulting <strong>index</strong> will be the <strong>union</strong> of the indexes of the various
Series. If there are any nested dicts, these will first be converted to
Series. If no columns are passed, the columns will be the ordered list of dict
keys.</p>

<p>The row and column labels can be accessed respectively by accessing the
<strong>index</strong> and <strong>columns</strong> attributes:</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>When a particular set of columns is passed along with a dict of data, the
passed columns override the keys in the dict.</p>
</div>

</section>
<section id=""from-dict-of-ndarrays-lists"">
<h3>From dict of ndarrays / lists<a class=""headerlink"" href=""#from-dict-of-ndarrays-lists"" title=""Link to this heading"">#</a></h3>
<p>All ndarrays must share the same length. If an index is passed, it must
also be the same length as the arrays. If no index is passed, the
result will be <code class=""docutils literal notranslate""><span class=""pre"">range(n)</span></code>, where <code class=""docutils literal notranslate""><span class=""pre"">n</span></code> is the array length.</p>

</section>
<section id=""from-structured-or-record-array"">
<h3>From structured or record array<a class=""headerlink"" href=""#from-structured-or-record-array"" title=""Link to this heading"">#</a></h3>
<p>This case is handled identically to a dict of arrays.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>DataFrame is not intended to work exactly like a 2-dimensional NumPy
ndarray.</p>
</div>
</section>
<section id=""from-a-list-of-dicts"">
<span id=""basics-dataframe-from-list-of-dicts""></span><h3>From a list of dicts<a class=""headerlink"" href=""#from-a-list-of-dicts"" title=""Link to this heading"">#</a></h3>

</section>
<section id=""from-a-dict-of-tuples"">
<span id=""basics-dataframe-from-dict-of-tuples""></span><h3>From a dict of tuples<a class=""headerlink"" href=""#from-a-dict-of-tuples"" title=""Link to this heading"">#</a></h3>
<p>You can automatically create a MultiIndexed frame by passing a tuples
dictionary.</p>

</section>
<section id=""from-a-series"">
<span id=""basics-dataframe-from-series""></span><h3>From a Series<a class=""headerlink"" href=""#from-a-series"" title=""Link to this heading"">#</a></h3>
<p>The result will be a DataFrame with the same index as the input Series, and
with one column whose name is the original name of the Series (only if no other
column name provided).</p>

</section>
<section id=""from-a-list-of-namedtuples"">
<span id=""basics-dataframe-from-list-namedtuples""></span><h3>From a list of namedtuples<a class=""headerlink"" href=""#from-a-list-of-namedtuples"" title=""Link to this heading"">#</a></h3>
<p>The field names of the first <code class=""docutils literal notranslate""><span class=""pre"">namedtuple</span></code> in the list determine the columns
of the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>. The remaining namedtuples (or tuples) are simply unpacked
and their values are fed into the rows of the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>. If any of those
tuples is shorter than the first <code class=""docutils literal notranslate""><span class=""pre"">namedtuple</span></code> then the later columns in the
corresponding row are marked as missing values. If any are longer than the
first <code class=""docutils literal notranslate""><span class=""pre"">namedtuple</span></code>, a <code class=""docutils literal notranslate""><span class=""pre"">ValueError</span></code> is raised.</p>

</section>
<section id=""from-a-list-of-dataclasses"">
<span id=""basics-dataframe-from-list-dataclasses""></span><h3>From a list of dataclasses<a class=""headerlink"" href=""#from-a-list-of-dataclasses"" title=""Link to this heading"">#</a></h3>
<p>Data Classes as introduced in <a class=""reference external"" href=""https://www.python.org/dev/peps/pep-0557"">PEP557</a>,
can be passed into the DataFrame constructor.
Passing a list of dataclasses is equivalent to passing a list of dictionaries.</p>
<p>Please be aware, that all values in the list should be dataclasses, mixing
types in the list would result in a <code class=""docutils literal notranslate""><span class=""pre"">TypeError</span></code>.</p>

<p><strong>Missing data</strong></p>
<p>To construct a DataFrame with missing data, we use <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code> to
represent missing values. Alternatively, you may pass a <code class=""docutils literal notranslate""><span class=""pre"">numpy.MaskedArray</span></code>
as the data argument to the DataFrame constructor, and its masked entries will
be considered missing. See <a class=""reference internal"" href=""missing_data.html#missing-data""><span class=""std std-ref"">Missing data</span></a> for more.</p>
</section>
<section id=""alternate-constructors"">
<h3>Alternate constructors<a class=""headerlink"" href=""#alternate-constructors"" title=""Link to this heading"">#</a></h3>
<p id=""basics-dataframe-from-dict""><strong>DataFrame.from_dict</strong></p>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.from_dict.html#pandas.DataFrame.from_dict"" title=""pandas.DataFrame.from_dict""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.from_dict()</span></code></a> takes a dict of dicts or a dict of array-like sequences
and returns a DataFrame. It operates like the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> constructor except
for the <code class=""docutils literal notranslate""><span class=""pre"">orient</span></code> parameter which is <code class=""docutils literal notranslate""><span class=""pre"">'columns'</span></code> by default, but which can be
set to <code class=""docutils literal notranslate""><span class=""pre"">'index'</span></code> in order to use the dict keys as row labels.</p>

<p>If you pass <code class=""docutils literal notranslate""><span class=""pre"">orient='index'</span></code>, the keys will be the row labels. In this
case, you can also pass the desired column names:</p>

<p id=""basics-dataframe-from-records""><strong>DataFrame.from_records</strong></p>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.from_records.html#pandas.DataFrame.from_records"" title=""pandas.DataFrame.from_records""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.from_records()</span></code></a> takes a list of tuples or an ndarray with structured
dtype. It works analogously to the normal <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> constructor, except that
the resulting DataFrame index may be a specific field of the structured
dtype.</p>

</section>
<section id=""column-selection-addition-deletion"">
<span id=""basics-dataframe-sel-add-del""></span><h3>Column selection, addition, deletion<a class=""headerlink"" href=""#column-selection-addition-deletion"" title=""Link to this heading"">#</a></h3>
<p>You can treat a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> semantically like a dict of like-indexed <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>
objects. Getting, setting, and deleting columns works with the same syntax as
the analogous dict operations:</p>

<p>Columns can be deleted or popped like with a dict:</p>

<p>When inserting a scalar value, it will naturally be propagated to fill the
column:</p>

<p>When inserting a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> that does not have the same index as the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>, it
will be conformed to the DataFrame’s index:</p>

<p>You can insert raw ndarrays but their length must match the length of the
DataFrame’s index.</p>
<p>By default, columns get inserted at the end. <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.insert.html#pandas.DataFrame.insert"" title=""pandas.DataFrame.insert""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.insert()</span></code></a>
inserts at a particular location in the columns:</p>

</section>
<section id=""assigning-new-columns-in-method-chains"">
<span id=""dsintro-chained-assignment""></span><h3>Assigning new columns in method chains<a class=""headerlink"" href=""#assigning-new-columns-in-method-chains"" title=""Link to this heading"">#</a></h3>
<p>Inspired by <a class=""reference external"" href=""https://dplyr.tidyverse.org/reference/mutate.html"">dplyr’s</a>
<code class=""docutils literal notranslate""><span class=""pre"">mutate</span></code> verb, DataFrame has an <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.assign.html#pandas.DataFrame.assign"" title=""pandas.DataFrame.assign""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">assign()</span></code></a>
method that allows you to easily create new columns that are potentially
derived from existing columns.</p>

<p>In the example above, we inserted a precomputed value. We can also pass in
a function of one argument to be evaluated on the DataFrame being assigned to.</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.assign.html#pandas.DataFrame.assign"" title=""pandas.DataFrame.assign""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">assign()</span></code></a> <strong>always</strong> returns a copy of the data, leaving the original
DataFrame untouched.</p>
<p>Passing a callable, as opposed to an actual value to be inserted, is
useful when you don’t have a reference to the DataFrame at hand. This is
common when using <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.assign.html#pandas.DataFrame.assign"" title=""pandas.DataFrame.assign""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">assign()</span></code></a> in a chain of operations. For example,
we can limit the DataFrame to just those observations with a Sepal Length
greater than 5, calculate the ratio, and plot:</p>

<img alt=""../_images/basics_assign.png"" src=""../_images/basics_assign.png""/>
<p>Since a function is passed in, the function is computed on the DataFrame
being assigned to. Importantly, this is the DataFrame that’s been filtered
to those rows with sepal length greater than 5. The filtering happens first,
and then the ratio calculations. This is an example where we didn’t
have a reference to the <em>filtered</em> DataFrame available.</p>
<p>The function signature for <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.assign.html#pandas.DataFrame.assign"" title=""pandas.DataFrame.assign""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">assign()</span></code></a> is simply <code class=""docutils literal notranslate""><span class=""pre"">**kwargs</span></code>. The keys
are the column names for the new fields, and the values are either a value
to be inserted (for example, a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or NumPy array), or a function
of one argument to be called on the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>. A <em>copy</em> of the original
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> is returned, with the new values inserted.</p>
<p>The order of <code class=""docutils literal notranslate""><span class=""pre"">**kwargs</span></code> is preserved. This allows
for <em>dependent</em> assignment, where an expression later in <code class=""docutils literal notranslate""><span class=""pre"">**kwargs</span></code> can refer
to a column created earlier in the same <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.assign.html#pandas.DataFrame.assign"" title=""pandas.DataFrame.assign""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">assign()</span></code></a>.</p>

<p>In the second expression, <code class=""docutils literal notranslate""><span class=""pre"">x['C']</span></code> will refer to the newly created column,
that’s equal to <code class=""docutils literal notranslate""><span class=""pre"">dfa['A']</span> <span class=""pre"">+</span> <span class=""pre"">dfa['B']</span></code>.</p>
</section>
<section id=""indexing-selection"">
<h3>Indexing / selection<a class=""headerlink"" href=""#indexing-selection"" title=""Link to this heading"">#</a></h3>
<p>The basics of indexing are as follows:</p>

<p>Row selection, for example, returns a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> whose index is the columns of the
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>:</p>

<p>For a more exhaustive treatment of sophisticated label-based indexing and
slicing, see the <a class=""reference internal"" href=""indexing.html#indexing""><span class=""std std-ref"">section on indexing</span></a>. We will address the
fundamentals of reindexing / conforming to new sets of labels in the
<a class=""reference internal"" href=""basics.html#basics-reindexing""><span class=""std std-ref"">section on reindexing</span></a>.</p>
</section>
<section id=""data-alignment-and-arithmetic"">
<span id=""dsintro-alignment""></span><h3>Data alignment and arithmetic<a class=""headerlink"" href=""#data-alignment-and-arithmetic"" title=""Link to this heading"">#</a></h3>
<p>Data alignment between <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> objects automatically align on <strong>both the
columns and the index (row labels)</strong>. Again, the resulting object will have the
union of the column and row labels.</p>

<p>When doing an operation between <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>, the default behavior is
to align the <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> <strong>index</strong> on the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> <strong>columns</strong>, thus <a class=""reference external"" href=""https://numpy.org/doc/stable/user/basics.broadcasting.html"">broadcasting</a>
row-wise. For example:</p>

<p>For explicit control over the matching and broadcasting behavior, see the
section on <a class=""reference internal"" href=""basics.html#basics-binop""><span class=""std std-ref"">flexible binary operations</span></a>.</p>
<p>Arithmetic operations with scalars operate element-wise:</p>

<p id=""dsintro-boolean"">Boolean operators operate element-wise as well:</p>

</section>
<section id=""transposing"">
<h3>Transposing<a class=""headerlink"" href=""#transposing"" title=""Link to this heading"">#</a></h3>
<p>To transpose, access the <code class=""docutils literal notranslate""><span class=""pre"">T</span></code> attribute or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.transpose.html#pandas.DataFrame.transpose"" title=""pandas.DataFrame.transpose""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.transpose()</span></code></a>,
similar to an ndarray:</p>

</section>
<section id=""dataframe-interoperability-with-numpy-functions"">
<span id=""dsintro-numpy-interop""></span><h3>DataFrame interoperability with NumPy functions<a class=""headerlink"" href=""#dataframe-interoperability-with-numpy-functions"" title=""Link to this heading"">#</a></h3>
<p>Most NumPy functions can be called directly on <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>.</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> is not intended to be a drop-in replacement for ndarray as its
indexing semantics and data model are quite different in places from an n-dimensional
array.</p>
<p><a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> implements <code class=""docutils literal notranslate""><span class=""pre"">__array_ufunc__</span></code>, which allows it to work with NumPy’s
<a class=""reference external"" href=""https://numpy.org/doc/stable/reference/ufuncs.html"">universal functions</a>.</p>
<p>The ufunc is applied to the underlying array in a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>.</p>

<p>When multiple <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> are passed to a ufunc, they are aligned before
performing the operation.</p>
<p>Like other parts of the library, pandas will automatically align labeled inputs
as part of a ufunc with multiple inputs. For example, using <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">numpy.remainder()</span></code>
on two <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> with differently ordered labels will align before the operation.</p>

<p>As usual, the union of the two indices is taken, and non-overlapping values are filled
with missing values.</p>

<p>When a binary ufunc is applied to a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a>, the <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>
implementation takes precedence and a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> is returned.</p>

<p>NumPy ufuncs are safe to apply to <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> backed by non-ndarray arrays,
for example <a class=""reference internal"" href=""../reference/api/pandas.arrays.SparseArray.html#pandas.arrays.SparseArray"" title=""pandas.arrays.SparseArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">arrays.SparseArray</span></code></a> (see <a class=""reference internal"" href=""sparse.html#sparse-calculation""><span class=""std std-ref"">Sparse calculation</span></a>). If possible,
the ufunc is applied without converting the underlying data to an ndarray.</p>
</section>
<section id=""console-display"">
<h3>Console display<a class=""headerlink"" href=""#console-display"" title=""Link to this heading"">#</a></h3>
<p>A very large <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> will be truncated to display them in the console.
You can also get a summary using <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.info.html#pandas.DataFrame.info"" title=""pandas.DataFrame.info""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">info()</span></code></a>.
(The <strong>baseball</strong> dataset is from the <strong>plyr</strong> R package):</p>

<p>However, using <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_string.html#pandas.DataFrame.to_string"" title=""pandas.DataFrame.to_string""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.to_string()</span></code></a> will return a string representation of the
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> in tabular form, though it won’t always fit the console width:</p>

<p>Wide DataFrames will be printed across multiple rows by
default:</p>

<p>You can change how much to print on a single row by setting the <code class=""docutils literal notranslate""><span class=""pre"">display.width</span></code>
option:</p>

<p>You can adjust the max width of the individual columns by setting <code class=""docutils literal notranslate""><span class=""pre"">display.max_colwidth</span></code></p>

<p>You can also disable this feature via the <code class=""docutils literal notranslate""><span class=""pre"">expand_frame_repr</span></code> option.
This will print the table in one block.</p>
</section>
<section id=""dataframe-column-attribute-access-and-ipython-completion"">
<h3>DataFrame column attribute access and IPython completion<a class=""headerlink"" href=""#dataframe-column-attribute-access-and-ipython-completion"" title=""Link to this heading"">#</a></h3>
<p>If a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> column label is a valid Python variable name, the column can be
accessed like an attribute:</p>

<p>The columns are also connected to the <a class=""reference external"" href=""https://ipython.org"">IPython</a>
completion mechanism so they can be tab-completed:</p>

</section>
</section>
</section>
</article>","Intro to data structures # We’ll start with a quick, non-comprehensive overview of the fundamental data structures in pandas to get you started. The fundamental behavior about data types, indexing, axis labeling, and alignment apply across all of the objects. To get started, import NumPy and load pandas into your namespace: Fundamentally, data alignment is intrinsic . The link between labels and data will not be broken unless done so explicitly by you. We’ll give a brief intro to the data structures, then consider all of the broad categories of functionality and methods in separate sections. Series # Series is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index . The basic method to create a Series is to call: s = pd . Series ( data , index = index ) Here, data can be many different things: a Python dict an ndarray a scalar value (like 5) The passed index is a list of axis labels. Thus, this separates into a few cases depending on what data is : From ndarray If data is an ndarray, index must be the same length as data . If no index is passed, one will be created having values [0, ..., len(data) - 1] . Note pandas supports non-unique index values. If an operation that does not support duplicate index values is attempted, an exception will be raised at that time. From dict Series can be instantiated from dicts: If an index is passed, the values in data corresponding to the labels in the index will be pulled out. Note NaN (not a number) is the standard missing data marker used in pandas. From scalar value If data is a scalar value, an index must be provided. The value will be repeated to match the length of index . Series is ndarray-like # Series acts very similarly to a ndarray and is a valid argument to most NumPy functions. However, operations such as slicing will also slice the index. Note We will address array-based indexing like s.iloc[[4, 3, 1]] in section on indexing . Like a NumPy array, a pandas Series has a single dtype . This is often a NumPy dtype. However, pandas and 3rd-party libraries extend NumPy’s type system in a few places, in which case the dtype would be an ExtensionDtype . Some examples within pandas are Categorical data and Nullable integer data type . See dtypes for more. If you need the actual array backing a Series , use Series.array . Accessing the array can be useful when you need to do some operation without the index (to disable automatic alignment , for example). Series.array will always be an ExtensionArray . Briefly, an ExtensionArray is a thin wrapper around one or more concrete arrays like a numpy.ndarray . pandas knows how to take an ExtensionArray and store it in a Series or a column of a DataFrame . See dtypes for more. While Series is ndarray-like, if you need an actual ndarray, then use Series.to_numpy() . Even if the Series is backed by a ExtensionArray , Series.to_numpy() will return a NumPy ndarray. Series is dict-like # A Series is also like a fixed-size dict in that you can get and set values by index label: If a label is not contained in the index, an exception is raised: Using the Series.get() method, a missing label will return None or specified default: These labels can also be accessed by attribute . Vectorized operations and label alignment with Series # When working with raw NumPy arrays, looping through value-by-value is usually not necessary. The same is true when working with Series in pandas. Series can also be passed into most NumPy methods expecting an ndarray. A key difference between Series and ndarray is that operations between Series automatically align the data based on label. Thus, you can write computations without giving consideration to whether the Series involved have the same labels. The result of an operation between unaligned Series will have the union of the indexes involved. If a label is not found in one Series or the other, the result will be marked as missing NaN . Being able to write code without doing any explicit data alignment grants immense freedom and flexibility in interactive data analysis and research. The integrated data alignment features of the pandas data structures set pandas apart from the majority of related tools for working with labeled data. Note In general, we chose to make the default result of operations between differently indexed objects yield the union of the indexes in order to avoid loss of information. Having an index label, though the data is missing, is typically important information as part of a computation. You of course have the option of dropping labels with missing data via the dropna function. Name attribute # Series also has a name attribute: The Series name can be assigned automatically in many cases, in particular, when selecting a single column from a DataFrame , the name will be assigned the column label. You can rename a Series with the pandas.Series.rename() method. Note that s and s2 refer to different objects. DataFrame # DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dict of Series objects. It is generally the most commonly used pandas object. Like Series, DataFrame accepts many different kinds of input: Dict of 1D ndarrays, lists, dicts, or Series 2-D numpy.ndarray Structured or record ndarray A Series Another DataFrame Along with the data, you can optionally pass index (row labels) and columns (column labels) arguments. If you pass an index and / or columns, you are guaranteeing the index and / or columns of the resulting DataFrame. Thus, a dict of Series plus a specific index will discard all data not matching up to the passed index. If axis labels are not passed, they will be constructed from the input data based on common sense rules. From dict of Series or dicts # The resulting index will be the union of the indexes of the various Series. If there are any nested dicts, these will first be converted to Series. If no columns are passed, the columns will be the ordered list of dict keys. The row and column labels can be accessed respectively by accessing the index and columns attributes: Note When a particular set of columns is passed along with a dict of data, the passed columns override the keys in the dict. From dict of ndarrays / lists # All ndarrays must share the same length. If an index is passed, it must also be the same length as the arrays. If no index is passed, the result will be range(n) , where n is the array length. From structured or record array # This case is handled identically to a dict of arrays. Note DataFrame is not intended to work exactly like a 2-dimensional NumPy ndarray. From a list of dicts # From a dict of tuples # You can automatically create a MultiIndexed frame by passing a tuples dictionary. From a Series # The result will be a DataFrame with the same index as the input Series, and with one column whose name is the original name of the Series (only if no other column name provided). From a list of namedtuples # The field names of the first namedtuple in the list determine the columns of the DataFrame . The remaining namedtuples (or tuples) are simply unpacked and their values are fed into the rows of the DataFrame . If any of those tuples is shorter than the first namedtuple then the later columns in the corresponding row are marked as missing values. If any are longer than the first namedtuple , a ValueError is raised. From a list of dataclasses # Data Classes as introduced in PEP557 , can be passed into the DataFrame constructor. Passing a list of dataclasses is equivalent to passing a list of dictionaries. Please be aware, that all values in the list should be dataclasses, mixing types in the list would result in a TypeError . Missing data To construct a DataFrame with missing data, we use np.nan to represent missing values. Alternatively, you may pass a numpy.MaskedArray as the data argument to the DataFrame constructor, and its masked entries will be considered missing. See Missing data for more. Alternate constructors # DataFrame.from_dict DataFrame.from_dict() takes a dict of dicts or a dict of array-like sequences and returns a DataFrame. It operates like the DataFrame constructor except for the orient parameter which is 'columns' by default, but which can be set to 'index' in order to use the dict keys as row labels. If you pass orient='index' , the keys will be the row labels. In this case, you can also pass the desired column names: DataFrame.from_records DataFrame.from_records() takes a list of tuples or an ndarray with structured dtype. It works analogously to the normal DataFrame constructor, except that the resulting DataFrame index may be a specific field of the structured dtype. Column selection, addition, deletion # You can treat a DataFrame semantically like a dict of like-indexed Series objects. Getting, setting, and deleting columns works with the same syntax as the analogous dict operations: Columns can be deleted or popped like with a dict: When inserting a scalar value, it will naturally be propagated to fill the column: When inserting a Series that does not have the same index as the DataFrame , it will be conformed to the DataFrame’s index: You can insert raw ndarrays but their length must match the length of the DataFrame’s index. By default, columns get inserted at the end. DataFrame.insert() inserts at a particular location in the columns: Assigning new columns in method chains # Inspired by dplyr’s mutate verb, DataFrame has an assign() method that allows you to easily create new columns that are potentially derived from existing columns. In the example above, we inserted a precomputed value. We can also pass in a function of one argument to be evaluated on the DataFrame being assigned to. assign() always returns a copy of the data, leaving the original DataFrame untouched. Passing a callable, as opposed to an actual value to be inserted, is useful when you don’t have a reference to the DataFrame at hand. This is common when using assign() in a chain of operations. For example, we can limit the DataFrame to just those observations with a Sepal Length greater than 5, calculate the ratio, and plot: Since a function is passed in, the function is computed on the DataFrame being assigned to. Importantly, this is the DataFrame that’s been filtered to those rows with sepal length greater than 5. The filtering happens first, and then the ratio calculations. This is an example where we didn’t have a reference to the filtered DataFrame available. The function signature for assign() is simply **kwargs . The keys are the column names for the new fields, and the values are either a value to be inserted (for example, a Series or NumPy array), or a function of one argument to be called on the DataFrame . A copy of the original DataFrame is returned, with the new values inserted. The order of **kwargs is preserved. This allows for dependent assignment, where an expression later in **kwargs can refer to a column created earlier in the same assign() . In the second expression, x['C'] will refer to the newly created column, that’s equal to dfa['A'] + dfa['B'] . Indexing / selection # The basics of indexing are as follows: Row selection, for example, returns a Series whose index is the columns of the DataFrame : For a more exhaustive treatment of sophisticated label-based indexing and slicing, see the section on indexing . We will address the fundamentals of reindexing / conforming to new sets of labels in the section on reindexing . Data alignment and arithmetic # Data alignment between DataFrame objects automatically align on both the columns and the index (row labels) . Again, the resulting object will have the union of the column and row labels. When doing an operation between DataFrame and Series , the default behavior is to align the Series index on the DataFrame columns , thus broadcasting row-wise. For example: For explicit control over the matching and broadcasting behavior, see the section on flexible binary operations . Arithmetic operations with scalars operate element-wise: Boolean operators operate element-wise as well: Transposing # To transpose, access the T attribute or DataFrame.transpose() , similar to an ndarray: DataFrame interoperability with NumPy functions # Most NumPy functions can be called directly on Series and DataFrame . DataFrame is not intended to be a drop-in replacement for ndarray as its indexing semantics and data model are quite different in places from an n-dimensional array. Series implements __array_ufunc__ , which allows it to work with NumPy’s universal functions . The ufunc is applied to the underlying array in a Series . When multiple Series are passed to a ufunc, they are aligned before performing the operation. Like other parts of the library, pandas will automatically align labeled inputs as part of a ufunc with multiple inputs. For example, using numpy.remainder() on two Series with differently ordered labels will align before the operation. As usual, the union of the two indices is taken, and non-overlapping values are filled with missing values. When a binary ufunc is applied to a Series and Index , the Series implementation takes precedence and a Series is returned. NumPy ufuncs are safe to apply to Series backed by non-ndarray arrays, for example arrays.SparseArray (see Sparse calculation ). If possible, the ufunc is applied without converting the underlying data to an ndarray. Console display # A very large DataFrame will be truncated to display them in the console. You can also get a summary using info() . (The baseball dataset is from the plyr R package): However, using DataFrame.to_string() will return a string representation of the DataFrame in tabular form, though it won’t always fit the console width: Wide DataFrames will be printed across multiple rows by default: You can change how much to print on a single row by setting the display.width option: You can adjust the max width of the individual columns by setting display.max_colwidth You can also disable this feature via the expand_frame_repr option. This will print the table in one block. DataFrame column attribute access and IPython completion # If a DataFrame column label is a valid Python variable name, the column can be accessed like an attribute: The columns are also connected to the IPython completion mechanism so they can be tab-completed:"
https://pandas.pydata.org/docs/user_guide/basics.html,Essential basic functionality,"<article class=""bd-article"" role=""main"">
<section id=""essential-basic-functionality"">
<span id=""basics""></span><h1>Essential basic functionality<a class=""headerlink"" href=""#essential-basic-functionality"" title=""Link to this heading"">#</a></h1>
<p>Here we discuss a lot of the essential functionality common to the pandas data
structures. To begin, let’s create some example objects like we did in
the <a class=""reference internal"" href=""10min.html#min""><span class=""std std-ref"">10 minutes to pandas</span></a> section:</p>

<section id=""head-and-tail"">
<span id=""basics-head-tail""></span><h2>Head and tail<a class=""headerlink"" href=""#head-and-tail"" title=""Link to this heading"">#</a></h2>
<p>To view a small sample of a Series or DataFrame object, use the
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.head.html#pandas.DataFrame.head"" title=""pandas.DataFrame.head""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">head()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.tail.html#pandas.DataFrame.tail"" title=""pandas.DataFrame.tail""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">tail()</span></code></a> methods. The default number
of elements to display is five, but you may pass a custom number.</p>

</section>
<section id=""attributes-and-underlying-data"">
<span id=""basics-attrs""></span><h2>Attributes and underlying data<a class=""headerlink"" href=""#attributes-and-underlying-data"" title=""Link to this heading"">#</a></h2>
<p>pandas objects have a number of attributes enabling you to access the metadata</p>
<ul class=""simple"">
<li><p><strong>shape</strong>: gives the axis dimensions of the object, consistent with ndarray</p></li>
<li><dl class=""simple"">
<dt>Axis labels</dt><dd><ul>
<li><p><strong>Series</strong>: <em>index</em> (only axis)</p></li>
<li><p><strong>DataFrame</strong>: <em>index</em> (rows) and <em>columns</em></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>Note, <strong>these attributes can be safely assigned to</strong>!</p>

<p>pandas objects (<a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>) can be
thought of as containers for arrays, which hold the actual data and do the
actual computation. For many types, the underlying array is a
<a class=""reference external"" href=""https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray"" title=""(in NumPy v1.26)""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">numpy.ndarray</span></code></a>. However, pandas and 3rd party libraries may <em>extend</em>
NumPy’s type system to add support for custom arrays
(see <a class=""reference internal"" href=""#basics-dtypes""><span class=""std std-ref"">dtypes</span></a>).</p>
<p>To get the actual data inside a <a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>, use
the <code class=""docutils literal notranslate""><span class=""pre"">.array</span></code> property</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.Series.array.html#pandas.Series.array"" title=""pandas.Series.array""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">array</span></code></a> will always be an <a class=""reference internal"" href=""../reference/api/pandas.api.extensions.ExtensionArray.html#pandas.api.extensions.ExtensionArray"" title=""pandas.api.extensions.ExtensionArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">ExtensionArray</span></code></a>.
The exact details of what an <a class=""reference internal"" href=""../reference/api/pandas.api.extensions.ExtensionArray.html#pandas.api.extensions.ExtensionArray"" title=""pandas.api.extensions.ExtensionArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">ExtensionArray</span></code></a> is and why pandas uses them are a bit
beyond the scope of this introduction. See <a class=""reference internal"" href=""#basics-dtypes""><span class=""std std-ref"">dtypes</span></a> for more.</p>
<p>If you know you need a NumPy array, use <a class=""reference internal"" href=""../reference/api/pandas.Series.to_numpy.html#pandas.Series.to_numpy"" title=""pandas.Series.to_numpy""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">to_numpy()</span></code></a>
or <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">numpy.asarray()</span></code>.</p>

<p>When the Series or Index is backed by
an <a class=""reference internal"" href=""../reference/api/pandas.api.extensions.ExtensionArray.html#pandas.api.extensions.ExtensionArray"" title=""pandas.api.extensions.ExtensionArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">ExtensionArray</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.Series.to_numpy.html#pandas.Series.to_numpy"" title=""pandas.Series.to_numpy""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">to_numpy()</span></code></a>
may involve copying data and coercing values. See <a class=""reference internal"" href=""#basics-dtypes""><span class=""std std-ref"">dtypes</span></a> for more.</p>
<p><a class=""reference internal"" href=""../reference/api/pandas.Series.to_numpy.html#pandas.Series.to_numpy"" title=""pandas.Series.to_numpy""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">to_numpy()</span></code></a> gives some control over the <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code> of the
resulting <a class=""reference external"" href=""https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray"" title=""(in NumPy v1.26)""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">numpy.ndarray</span></code></a>. For example, consider datetimes with timezones.
NumPy doesn’t have a dtype to represent timezone-aware datetimes, so there
are two possibly useful representations:</p>
<ol class=""arabic simple"">
<li><p>An object-dtype <a class=""reference external"" href=""https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray"" title=""(in NumPy v1.26)""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">numpy.ndarray</span></code></a> with <a class=""reference internal"" href=""../reference/api/pandas.Timestamp.html#pandas.Timestamp"" title=""pandas.Timestamp""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Timestamp</span></code></a> objects, each
with the correct <code class=""docutils literal notranslate""><span class=""pre"">tz</span></code></p></li>
<li><p>A <code class=""docutils literal notranslate""><span class=""pre"">datetime64[ns]</span></code> -dtype <a class=""reference external"" href=""https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray"" title=""(in NumPy v1.26)""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">numpy.ndarray</span></code></a>, where the values have
been converted to UTC and the timezone discarded</p></li>
</ol>
<p>Timezones may be preserved with <code class=""docutils literal notranslate""><span class=""pre"">dtype=object</span></code></p>

<p>Or thrown away with <code class=""docutils literal notranslate""><span class=""pre"">dtype='datetime64[ns]'</span></code></p>

<p>Getting the “raw data” inside a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> is possibly a bit more
complex. When your <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> only has a single data type for all the
columns, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_numpy.html#pandas.DataFrame.to_numpy"" title=""pandas.DataFrame.to_numpy""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.to_numpy()</span></code></a> will return the underlying data:</p>

<p>If a DataFrame contains homogeneously-typed data, the ndarray can
actually be modified in-place, and the changes will be reflected in the data
structure. For heterogeneous data (e.g. some of the DataFrame’s columns are not
all the same dtype), this will not be the case. The values attribute itself,
unlike the axis labels, cannot be assigned to.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>When working with heterogeneous data, the dtype of the resulting ndarray
will be chosen to accommodate all of the data involved. For example, if
strings are involved, the result will be of object dtype. If there are only
floats and integers, the resulting array will be of float dtype.</p>
</div>
<p>In the past, pandas recommended <a class=""reference internal"" href=""../reference/api/pandas.Series.values.html#pandas.Series.values"" title=""pandas.Series.values""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">Series.values</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.values.html#pandas.DataFrame.values"" title=""pandas.DataFrame.values""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">DataFrame.values</span></code></a>
for extracting the data from a Series or DataFrame. You’ll still find references
to these in old code bases and online. Going forward, we recommend avoiding
<code class=""docutils literal notranslate""><span class=""pre"">.values</span></code> and using <code class=""docutils literal notranslate""><span class=""pre"">.array</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">.to_numpy()</span></code>. <code class=""docutils literal notranslate""><span class=""pre"">.values</span></code> has the following
drawbacks:</p>
<ol class=""arabic simple"">
<li><p>When your Series contains an <a class=""reference internal"" href=""../development/extending.html#extending-extension-types""><span class=""std std-ref"">extension type</span></a>, it’s
unclear whether <a class=""reference internal"" href=""../reference/api/pandas.Series.values.html#pandas.Series.values"" title=""pandas.Series.values""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">Series.values</span></code></a> returns a NumPy array or the extension array.
<a class=""reference internal"" href=""../reference/api/pandas.Series.array.html#pandas.Series.array"" title=""pandas.Series.array""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">Series.array</span></code></a> will always return an <a class=""reference internal"" href=""../reference/api/pandas.api.extensions.ExtensionArray.html#pandas.api.extensions.ExtensionArray"" title=""pandas.api.extensions.ExtensionArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">ExtensionArray</span></code></a>, and will never
copy data. <a class=""reference internal"" href=""../reference/api/pandas.Series.to_numpy.html#pandas.Series.to_numpy"" title=""pandas.Series.to_numpy""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.to_numpy()</span></code></a> will always return a NumPy array,
potentially at the cost of copying / coercing values.</p></li>
<li><p>When your DataFrame contains a mixture of data types, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.values.html#pandas.DataFrame.values"" title=""pandas.DataFrame.values""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">DataFrame.values</span></code></a> may
involve copying data and coercing values to a common dtype, a relatively expensive
operation. <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_numpy.html#pandas.DataFrame.to_numpy"" title=""pandas.DataFrame.to_numpy""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.to_numpy()</span></code></a>, being a method, makes it clearer that the
returned NumPy array may not be a view on the same data in the DataFrame.</p></li>
</ol>
</section>
<section id=""accelerated-operations"">
<span id=""basics-accelerate""></span><h2>Accelerated operations<a class=""headerlink"" href=""#accelerated-operations"" title=""Link to this heading"">#</a></h2>
<p>pandas has support for accelerating certain types of binary numerical and boolean operations using
the <code class=""docutils literal notranslate""><span class=""pre"">numexpr</span></code> library and the <code class=""docutils literal notranslate""><span class=""pre"">bottleneck</span></code> libraries.</p>
<p>These libraries are especially useful when dealing with large data sets, and provide large
speedups. <code class=""docutils literal notranslate""><span class=""pre"">numexpr</span></code> uses smart chunking, caching, and multiple cores. <code class=""docutils literal notranslate""><span class=""pre"">bottleneck</span></code> is
a set of specialized cython routines that are especially fast when dealing with arrays that have
<code class=""docutils literal notranslate""><span class=""pre"">nans</span></code>.</p>
<p>Here is a sample (using 100 column x 100,000 row <code class=""docutils literal notranslate""><span class=""pre"">DataFrames</span></code>):</p>

<p>You are highly encouraged to install both libraries. See the section
<a class=""reference internal"" href=""../getting_started/install.html#install-recommended-dependencies""><span class=""std std-ref"">Recommended Dependencies</span></a> for more installation info.</p>
<p>These are both enabled to be used by default, you can control this by setting the options:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">set_option</span><span class=""p"">(</span><span class=""s2"">""compute.use_bottleneck""</span><span class=""p"">,</span> <span class=""kc"">False</span><span class=""p"">)</span>
<span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">set_option</span><span class=""p"">(</span><span class=""s2"">""compute.use_numexpr""</span><span class=""p"">,</span> <span class=""kc"">False</span><span class=""p"">)</span>
</pre></div>
</div>
</section>
<section id=""flexible-binary-operations"">
<span id=""basics-binop""></span><h2>Flexible binary operations<a class=""headerlink"" href=""#flexible-binary-operations"" title=""Link to this heading"">#</a></h2>
<p>With binary operations between pandas data structures, there are two key points
of interest:</p>
<ul class=""simple"">
<li><p>Broadcasting behavior between higher- (e.g. DataFrame) and
lower-dimensional (e.g. Series) objects.</p></li>
<li><p>Missing data in computations.</p></li>
</ul>
<p>We will demonstrate how to manage these issues independently, though they can
be handled simultaneously.</p>
<section id=""matching-broadcasting-behavior"">
<h3>Matching / broadcasting behavior<a class=""headerlink"" href=""#matching-broadcasting-behavior"" title=""Link to this heading"">#</a></h3>
<p>DataFrame has the methods <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.add.html#pandas.DataFrame.add"" title=""pandas.DataFrame.add""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">add()</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.sub.html#pandas.DataFrame.sub"" title=""pandas.DataFrame.sub""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">sub()</span></code></a>,
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.mul.html#pandas.DataFrame.mul"" title=""pandas.DataFrame.mul""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">mul()</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.div.html#pandas.DataFrame.div"" title=""pandas.DataFrame.div""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">div()</span></code></a> and related functions
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.radd.html#pandas.DataFrame.radd"" title=""pandas.DataFrame.radd""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">radd()</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.rsub.html#pandas.DataFrame.rsub"" title=""pandas.DataFrame.rsub""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">rsub()</span></code></a>, …
for carrying out binary operations. For broadcasting behavior,
Series input is of primary interest. Using these functions, you can use to
either match on the <em>index</em> or <em>columns</em> via the <strong>axis</strong> keyword:</p>

<p>Furthermore you can align a level of a MultiIndexed DataFrame with a Series.</p>

<p>Series and Index also support the <a class=""reference external"" href=""https://docs.python.org/3/library/functions.html#divmod"" title=""(in Python v3.12)""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">divmod()</span></code></a> builtin. This function takes
the floor division and modulo operation at the same time returning a two-tuple
of the same type as the left hand side. For example:</p>

<p>We can also do elementwise <a class=""reference external"" href=""https://docs.python.org/3/library/functions.html#divmod"" title=""(in Python v3.12)""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">divmod()</span></code></a>:</p>

</section>
<section id=""missing-data-operations-with-fill-values"">
<h3>Missing data / operations with fill values<a class=""headerlink"" href=""#missing-data-operations-with-fill-values"" title=""Link to this heading"">#</a></h3>
<p>In Series and DataFrame, the arithmetic functions have the option of inputting
a <em>fill_value</em>, namely a value to substitute when at most one of the values at
a location are missing. For example, when adding two DataFrame objects, you may
wish to treat NaN as 0 unless both DataFrames are missing that value, in which
case the result will be NaN (you can later replace NaN with some other value
using <code class=""docutils literal notranslate""><span class=""pre"">fillna</span></code> if you wish).</p>

</section>
<section id=""flexible-comparisons"">
<span id=""basics-compare""></span><h3>Flexible comparisons<a class=""headerlink"" href=""#flexible-comparisons"" title=""Link to this heading"">#</a></h3>
<p>Series and DataFrame have the binary comparison methods <code class=""docutils literal notranslate""><span class=""pre"">eq</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">ne</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">lt</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">gt</span></code>,
<code class=""docutils literal notranslate""><span class=""pre"">le</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">ge</span></code> whose behavior is analogous to the binary
arithmetic operations described above:</p>

<p>These operations produce a pandas object of the same type as the left-hand-side
input that is of dtype <code class=""docutils literal notranslate""><span class=""pre"">bool</span></code>. These <code class=""docutils literal notranslate""><span class=""pre"">boolean</span></code> objects can be used in
indexing operations, see the section on <a class=""reference internal"" href=""indexing.html#indexing-boolean""><span class=""std std-ref"">Boolean indexing</span></a>.</p>
</section>
<section id=""boolean-reductions"">
<span id=""basics-reductions""></span><h3>Boolean reductions<a class=""headerlink"" href=""#boolean-reductions"" title=""Link to this heading"">#</a></h3>
<p>You can apply the reductions: <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.empty.html#pandas.DataFrame.empty"" title=""pandas.DataFrame.empty""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">empty</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.any.html#pandas.DataFrame.any"" title=""pandas.DataFrame.any""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">any()</span></code></a>,
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.all.html#pandas.DataFrame.all"" title=""pandas.DataFrame.all""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">all()</span></code></a>, and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.bool.html#pandas.DataFrame.bool"" title=""pandas.DataFrame.bool""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">bool()</span></code></a> to provide a
way to summarize a boolean result.</p>

<p>You can reduce to a final boolean value.</p>

<p>You can test if a pandas object is empty, via the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.empty.html#pandas.DataFrame.empty"" title=""pandas.DataFrame.empty""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">empty</span></code></a> property.</p>

<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Asserting the truthiness of a pandas object will raise an error, as the testing of the emptiness
or values is ambiguous.</p>


<p>See <a class=""reference internal"" href=""gotchas.html#gotchas-truth""><span class=""std std-ref"">gotchas</span></a> for a more detailed discussion.</p>
</div>
</section>
<section id=""comparing-if-objects-are-equivalent"">
<span id=""basics-equals""></span><h3>Comparing if objects are equivalent<a class=""headerlink"" href=""#comparing-if-objects-are-equivalent"" title=""Link to this heading"">#</a></h3>
<p>Often you may find that there is more than one way to compute the same
result. As a simple example, consider <code class=""docutils literal notranslate""><span class=""pre"">df</span> <span class=""pre"">+</span> <span class=""pre"">df</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">df</span> <span class=""pre"">*</span> <span class=""pre"">2</span></code>. To test
that these two computations produce the same result, given the tools
shown above, you might imagine using <code class=""docutils literal notranslate""><span class=""pre"">(df</span> <span class=""pre"">+</span> <span class=""pre"">df</span> <span class=""pre"">==</span> <span class=""pre"">df</span> <span class=""pre"">*</span> <span class=""pre"">2).all()</span></code>. But in
fact, this expression is False:</p>

<p>Notice that the boolean DataFrame <code class=""docutils literal notranslate""><span class=""pre"">df</span> <span class=""pre"">+</span> <span class=""pre"">df</span> <span class=""pre"">==</span> <span class=""pre"">df</span> <span class=""pre"">*</span> <span class=""pre"">2</span></code> contains some False values!
This is because NaNs do not compare as equals:</p>

<p>So, NDFrames (such as Series and DataFrames)
have an <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.equals.html#pandas.DataFrame.equals"" title=""pandas.DataFrame.equals""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">equals()</span></code></a> method for testing equality, with NaNs in
corresponding locations treated as equal.</p>

<p>Note that the Series or DataFrame index needs to be in the same order for
equality to be True:</p>

</section>
<section id=""comparing-array-like-objects"">
<h3>Comparing array-like objects<a class=""headerlink"" href=""#comparing-array-like-objects"" title=""Link to this heading"">#</a></h3>
<p>You can conveniently perform element-wise comparisons when comparing a pandas
data structure with a scalar value:</p>

<p>pandas also handles element-wise comparisons between different array-like
objects of the same length:</p>

<p>Trying to compare <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> objects of different lengths will
raise a ValueError:</p>

</section>
<section id=""combining-overlapping-data-sets"">
<h3>Combining overlapping data sets<a class=""headerlink"" href=""#combining-overlapping-data-sets"" title=""Link to this heading"">#</a></h3>
<p>A problem occasionally arising is the combination of two similar data sets
where values in one are preferred over the other. An example would be two data
series representing a particular economic indicator where one is considered to
be of “higher quality”. However, the lower quality series might extend further
back in history or have more complete data coverage. As such, we would like to
combine two DataFrame objects where missing values in one DataFrame are
conditionally filled with like-labeled values from the other DataFrame. The
function implementing this operation is <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.combine_first.html#pandas.DataFrame.combine_first"" title=""pandas.DataFrame.combine_first""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">combine_first()</span></code></a>,
which we illustrate:</p>

</section>
<section id=""general-dataframe-combine"">
<h3>General DataFrame combine<a class=""headerlink"" href=""#general-dataframe-combine"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.combine_first.html#pandas.DataFrame.combine_first"" title=""pandas.DataFrame.combine_first""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">combine_first()</span></code></a> method above calls the more general
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.combine.html#pandas.DataFrame.combine"" title=""pandas.DataFrame.combine""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.combine()</span></code></a>. This method takes another DataFrame
and a combiner function, aligns the input DataFrame and then passes the combiner
function pairs of Series (i.e., columns whose names are the same).</p>
<p>So, for instance, to reproduce <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.combine_first.html#pandas.DataFrame.combine_first"" title=""pandas.DataFrame.combine_first""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">combine_first()</span></code></a> as above:</p>

</section>
</section>
<section id=""descriptive-statistics"">
<span id=""basics-stats""></span><h2>Descriptive statistics<a class=""headerlink"" href=""#descriptive-statistics"" title=""Link to this heading"">#</a></h2>
<p>There exists a large number of methods for computing descriptive statistics and
other related operations on <a class=""reference internal"" href=""../reference/series.html#api-series-stats""><span class=""std std-ref"">Series</span></a>, <a class=""reference internal"" href=""../reference/frame.html#api-dataframe-stats""><span class=""std std-ref"">DataFrame</span></a>. Most of these
are aggregations (hence producing a lower-dimensional result) like
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.sum.html#pandas.DataFrame.sum"" title=""pandas.DataFrame.sum""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">sum()</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.mean.html#pandas.DataFrame.mean"" title=""pandas.DataFrame.mean""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">mean()</span></code></a>, and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.quantile.html#pandas.DataFrame.quantile"" title=""pandas.DataFrame.quantile""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">quantile()</span></code></a>,
but some of them, like <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.cumsum.html#pandas.DataFrame.cumsum"" title=""pandas.DataFrame.cumsum""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">cumsum()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.cumprod.html#pandas.DataFrame.cumprod"" title=""pandas.DataFrame.cumprod""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">cumprod()</span></code></a>,
produce an object of the same size. Generally speaking, these methods take an
<strong>axis</strong> argument, just like <em>ndarray.{sum, std, …}</em>, but the axis can be
specified by name or integer:</p>
<ul class=""simple"">
<li><p><strong>Series</strong>: no axis argument needed</p></li>
<li><p><strong>DataFrame</strong>: “index” (axis=0, default), “columns” (axis=1)</p></li>
</ul>
<p>For example:</p>

<p>All such methods have a <code class=""docutils literal notranslate""><span class=""pre"">skipna</span></code> option signaling whether to exclude missing
data (<code class=""docutils literal notranslate""><span class=""pre"">True</span></code> by default):</p>

<p>Combined with the broadcasting / arithmetic behavior, one can describe various
statistical procedures, like standardization (rendering data zero mean and
standard deviation of 1), very concisely:</p>

<p>Note that methods like <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.cumsum.html#pandas.DataFrame.cumsum"" title=""pandas.DataFrame.cumsum""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">cumsum()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.cumprod.html#pandas.DataFrame.cumprod"" title=""pandas.DataFrame.cumprod""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">cumprod()</span></code></a>
preserve the location of <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code> values. This is somewhat different from
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.expanding.html#pandas.DataFrame.expanding"" title=""pandas.DataFrame.expanding""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">expanding()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.rolling.html#pandas.DataFrame.rolling"" title=""pandas.DataFrame.rolling""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">rolling()</span></code></a> since <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code> behavior
is furthermore dictated by a <code class=""docutils literal notranslate""><span class=""pre"">min_periods</span></code> parameter.</p>

<p>Here is a quick reference summary table of common functions. Each also takes an
optional <code class=""docutils literal notranslate""><span class=""pre"">level</span></code> parameter which applies only if the object has a
<a class=""reference internal"" href=""advanced.html#advanced-hierarchical""><span class=""std std-ref"">hierarchical index</span></a>.</p>

<p>Note that by chance some NumPy methods, like <code class=""docutils literal notranslate""><span class=""pre"">mean</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">std</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">sum</span></code>,
will exclude NAs on Series input by default:</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.Series.nunique.html#pandas.Series.nunique"" title=""pandas.Series.nunique""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.nunique()</span></code></a> will return the number of unique non-NA values in a
Series:</p>

<section id=""summarizing-data-describe"">
<span id=""basics-describe""></span><h3>Summarizing data: describe<a class=""headerlink"" href=""#summarizing-data-describe"" title=""Link to this heading"">#</a></h3>
<p>There is a convenient <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.describe.html#pandas.DataFrame.describe"" title=""pandas.DataFrame.describe""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">describe()</span></code></a> function which computes a variety of summary
statistics about a Series or the columns of a DataFrame (excluding NAs of
course):</p>

<p>You can select specific percentiles to include in the output:</p>

<p>By default, the median is always included.</p>
<p>For a non-numerical Series object, <a class=""reference internal"" href=""../reference/api/pandas.Series.describe.html#pandas.Series.describe"" title=""pandas.Series.describe""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">describe()</span></code></a> will give a simple
summary of the number of unique values and most frequently occurring values:</p>

<p>Note that on a mixed-type DataFrame object, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.describe.html#pandas.DataFrame.describe"" title=""pandas.DataFrame.describe""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">describe()</span></code></a> will
restrict the summary to include only numerical columns or, if none are, only
categorical columns:</p>

<p>This behavior can be controlled by providing a list of types as <code class=""docutils literal notranslate""><span class=""pre"">include</span></code>/<code class=""docutils literal notranslate""><span class=""pre"">exclude</span></code>
arguments. The special value <code class=""docutils literal notranslate""><span class=""pre"">all</span></code> can also be used:</p>

<p>That feature relies on <a class=""reference internal"" href=""#basics-selectdtypes""><span class=""std std-ref"">select_dtypes</span></a>. Refer to
there for details about accepted inputs.</p>
</section>
<section id=""index-of-min-max-values"">
<span id=""basics-idxmin""></span><h3>Index of min/max values<a class=""headerlink"" href=""#index-of-min-max-values"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.idxmin.html#pandas.DataFrame.idxmin"" title=""pandas.DataFrame.idxmin""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">idxmin()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.idxmax.html#pandas.DataFrame.idxmax"" title=""pandas.DataFrame.idxmax""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">idxmax()</span></code></a> functions on Series
and DataFrame compute the index labels with the minimum and maximum
corresponding values:</p>

<p>When there are multiple rows (or columns) matching the minimum or maximum
value, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.idxmin.html#pandas.DataFrame.idxmin"" title=""pandas.DataFrame.idxmin""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">idxmin()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.idxmax.html#pandas.DataFrame.idxmax"" title=""pandas.DataFrame.idxmax""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">idxmax()</span></code></a> return the first
matching index:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">idxmin</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">idxmax</span></code> are called <code class=""docutils literal notranslate""><span class=""pre"">argmin</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">argmax</span></code> in NumPy.</p>
</div>
</section>
<section id=""value-counts-histogramming-mode"">
<span id=""basics-discretization""></span><h3>Value counts (histogramming) / mode<a class=""headerlink"" href=""#value-counts-histogramming-mode"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.Series.value_counts.html#pandas.Series.value_counts"" title=""pandas.Series.value_counts""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">value_counts()</span></code></a> Series method computes a histogram
of a 1D array of values. It can also be used as a function on regular arrays:</p>

<p>The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.value_counts.html#pandas.DataFrame.value_counts"" title=""pandas.DataFrame.value_counts""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">value_counts()</span></code></a> method can be used to count combinations across multiple columns.
By default all columns are used but a subset can be selected using the <code class=""docutils literal notranslate""><span class=""pre"">subset</span></code> argument.</p>

<p>Similarly, you can get the most frequently occurring value(s), i.e. the mode, of the values in a Series or DataFrame:</p>

</section>
<section id=""discretization-and-quantiling"">
<h3>Discretization and quantiling<a class=""headerlink"" href=""#discretization-and-quantiling"" title=""Link to this heading"">#</a></h3>
<p>Continuous values can be discretized using the <a class=""reference internal"" href=""../reference/api/pandas.cut.html#pandas.cut"" title=""pandas.cut""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">cut()</span></code></a> (bins based on values)
and <a class=""reference internal"" href=""../reference/api/pandas.qcut.html#pandas.qcut"" title=""pandas.qcut""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">qcut()</span></code></a> (bins based on sample quantiles) functions:</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.qcut.html#pandas.qcut"" title=""pandas.qcut""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">qcut()</span></code></a> computes sample quantiles. For example, we could slice up some
normally distributed data into equal-size quartiles like so:</p>

<p>We can also pass infinite values to define the bins:</p>

</section>
</section>
<section id=""function-application"">
<span id=""basics-apply""></span><h2>Function application<a class=""headerlink"" href=""#function-application"" title=""Link to this heading"">#</a></h2>
<p>To apply your own or another library’s functions to pandas objects,
you should be aware of the three methods below. The appropriate
method to use depends on whether your function expects to operate
on an entire <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>, row- or column-wise, or elementwise.</p>
<ol class=""arabic simple"">
<li><p><a class=""reference internal"" href=""#tablewise-function-application"">Tablewise Function Application</a>: <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.pipe.html#pandas.DataFrame.pipe"" title=""pandas.DataFrame.pipe""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">pipe()</span></code></a></p></li>
<li><p><a class=""reference internal"" href=""#row-or-column-wise-function-application"">Row or Column-wise Function Application</a>: <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply"" title=""pandas.DataFrame.apply""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">apply()</span></code></a></p></li>
<li><p><a class=""reference internal"" href=""#aggregation-api"">Aggregation API</a>: <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.agg.html#pandas.DataFrame.agg"" title=""pandas.DataFrame.agg""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">agg()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.transform.html#pandas.DataFrame.transform"" title=""pandas.DataFrame.transform""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">transform()</span></code></a></p></li>
<li><p><a class=""reference internal"" href=""#applying-elementwise-functions"">Applying Elementwise Functions</a>: <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.map.html#pandas.DataFrame.map"" title=""pandas.DataFrame.map""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">map()</span></code></a></p></li>
</ol>
<section id=""tablewise-function-application"">
<span id=""basics-pipe""></span><h3>Tablewise function application<a class=""headerlink"" href=""#tablewise-function-application"" title=""Link to this heading"">#</a></h3>
<p><code class=""docutils literal notranslate""><span class=""pre"">DataFrames</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> can be passed into functions.
However, if the function needs to be called in a chain, consider using the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.pipe.html#pandas.DataFrame.pipe"" title=""pandas.DataFrame.pipe""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">pipe()</span></code></a> method.</p>
<p>First some setup:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">extract_city_name</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">add_country_name</span></code> are functions taking and returning <code class=""docutils literal notranslate""><span class=""pre"">DataFrames</span></code>.</p>
<p>Now compare the following:</p>

<p>Is equivalent to:</p>

<p>pandas encourages the second style, which is known as method chaining.
<code class=""docutils literal notranslate""><span class=""pre"">pipe</span></code> makes it easy to use your own or another library’s functions
in method chains, alongside pandas’ methods.</p>
<p>In the example above, the functions <code class=""docutils literal notranslate""><span class=""pre"">extract_city_name</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">add_country_name</span></code> each expected a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> as the first positional argument.
What if the function you wish to apply takes its data as, say, the second argument?
In this case, provide <code class=""docutils literal notranslate""><span class=""pre"">pipe</span></code> with a tuple of <code class=""docutils literal notranslate""><span class=""pre"">(callable,</span> <span class=""pre"">data_keyword)</span></code>.
<code class=""docutils literal notranslate""><span class=""pre"">.pipe</span></code> will route the <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> to the argument specified in the tuple.</p>
<p>For example, we can fit a regression using statsmodels. Their API expects a formula first and a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> as the second argument, <code class=""docutils literal notranslate""><span class=""pre"">data</span></code>. We pass in the function, keyword pair <code class=""docutils literal notranslate""><span class=""pre"">(sm.ols,</span> <span class=""pre"">'data')</span></code> to <code class=""docutils literal notranslate""><span class=""pre"">pipe</span></code>:</p>

<p>The pipe method is inspired by unix pipes and more recently <a class=""reference external"" href=""https://github.com/tidyverse/dplyr"">dplyr</a> and <a class=""reference external"" href=""https://github.com/tidyverse/magrittr"">magrittr</a>, which
have introduced the popular <code class=""docutils literal notranslate""><span class=""pre"">(%&gt;%)</span></code> (read pipe) operator for <a class=""reference external"" href=""https://www.r-project.org"">R</a>.
The implementation of <code class=""docutils literal notranslate""><span class=""pre"">pipe</span></code> here is quite clean and feels right at home in Python.
We encourage you to view the source code of <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.pipe.html#pandas.DataFrame.pipe"" title=""pandas.DataFrame.pipe""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">pipe()</span></code></a>.</p>
</section>
<section id=""row-or-column-wise-function-application"">
<h3>Row or column-wise function application<a class=""headerlink"" href=""#row-or-column-wise-function-application"" title=""Link to this heading"">#</a></h3>
<p>Arbitrary functions can be applied along the axes of a DataFrame
using the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply"" title=""pandas.DataFrame.apply""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">apply()</span></code></a> method, which, like the descriptive
statistics methods, takes an optional <code class=""docutils literal notranslate""><span class=""pre"">axis</span></code> argument:</p>

<p>The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply"" title=""pandas.DataFrame.apply""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">apply()</span></code></a> method will also dispatch on a string method name.</p>

<p>The return type of the function passed to <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply"" title=""pandas.DataFrame.apply""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">apply()</span></code></a> affects the
type of the final output from <code class=""docutils literal notranslate""><span class=""pre"">DataFrame.apply</span></code> for the default behaviour:</p>
<ul class=""simple"">
<li><p>If the applied function returns a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>, the final output is a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>.
The columns match the index of the <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> returned by the applied function.</p></li>
<li><p>If the applied function returns any other type, the final output is a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>.</p></li>
</ul>
<p>This default behaviour can be overridden using the <code class=""docutils literal notranslate""><span class=""pre"">result_type</span></code>, which
accepts three options: <code class=""docutils literal notranslate""><span class=""pre"">reduce</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">broadcast</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">expand</span></code>.
These will determine how list-likes return values expand (or not) to a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>.</p>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply"" title=""pandas.DataFrame.apply""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">apply()</span></code></a> combined with some cleverness can be used to answer many questions
about a data set. For example, suppose we wanted to extract the date where the
maximum value for each column occurred:</p>

<p>You may also pass additional arguments and keyword arguments to the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply"" title=""pandas.DataFrame.apply""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">apply()</span></code></a>
method.</p>

<p>Another useful feature is the ability to pass Series methods to carry out some
Series operation on each column or row:</p>

<p>Finally, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply"" title=""pandas.DataFrame.apply""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">apply()</span></code></a> takes an argument <code class=""docutils literal notranslate""><span class=""pre"">raw</span></code> which is False by default, which
converts each row or column into a Series before applying the function. When
set to True, the passed function will instead receive an ndarray object, which
has positive performance implications if you do not need the indexing
functionality.</p>
</section>
<section id=""aggregation-api"">
<span id=""basics-aggregate""></span><h3>Aggregation API<a class=""headerlink"" href=""#aggregation-api"" title=""Link to this heading"">#</a></h3>
<p>The aggregation API allows one to express possibly multiple aggregation operations in a single concise way.
This API is similar across pandas objects, see <a class=""reference internal"" href=""groupby.html#groupby-aggregate""><span class=""std std-ref"">groupby API</span></a>, the
<a class=""reference internal"" href=""window.html#window-overview""><span class=""std std-ref"">window API</span></a>, and the <a class=""reference internal"" href=""timeseries.html#timeseries-aggregate""><span class=""std std-ref"">resample API</span></a>.
The entry point for aggregation is <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.aggregate.html#pandas.DataFrame.aggregate"" title=""pandas.DataFrame.aggregate""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.aggregate()</span></code></a>, or the alias
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.agg.html#pandas.DataFrame.agg"" title=""pandas.DataFrame.agg""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.agg()</span></code></a>.</p>
<p>We will use a similar starting frame from above:</p>

<p>Using a single function is equivalent to <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply"" title=""pandas.DataFrame.apply""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">apply()</span></code></a>. You can also
pass named methods as strings. These will return a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> of the aggregated
output:</p>

<p>Single aggregations on a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> this will return a scalar value:</p>

<section id=""aggregating-with-multiple-functions"">
<h4>Aggregating with multiple functions<a class=""headerlink"" href=""#aggregating-with-multiple-functions"" title=""Link to this heading"">#</a></h4>
<p>You can pass multiple aggregation arguments as a list.
The results of each of the passed functions will be a row in the resulting <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>.
These are naturally named from the aggregation function.</p>

<p>Multiple functions yield multiple rows:</p>

<p>On a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>, multiple functions return a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>, indexed by the function names:</p>

<p>Passing a <code class=""docutils literal notranslate""><span class=""pre"">lambda</span></code> function will yield a <code class=""docutils literal notranslate""><span class=""pre"">&lt;lambda&gt;</span></code> named row:</p>

<p>Passing a named function will yield that name for the row:</p>

</section>
<section id=""aggregating-with-a-dict"">
<h4>Aggregating with a dict<a class=""headerlink"" href=""#aggregating-with-a-dict"" title=""Link to this heading"">#</a></h4>
<p>Passing a dictionary of column names to a scalar or a list of scalars, to <code class=""docutils literal notranslate""><span class=""pre"">DataFrame.agg</span></code>
allows you to customize which functions are applied to which columns. Note that the results
are not in any particular order, you can use an <code class=""docutils literal notranslate""><span class=""pre"">OrderedDict</span></code> instead to guarantee ordering.</p>

<p>Passing a list-like will generate a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> output. You will get a matrix-like output
of all of the aggregators. The output will consist of all unique functions. Those that are
not noted for a particular column will be <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>:</p>

</section>
<section id=""custom-describe"">
<span id=""basics-aggregation-custom-describe""></span><h4>Custom describe<a class=""headerlink"" href=""#custom-describe"" title=""Link to this heading"">#</a></h4>
<p>With <code class=""docutils literal notranslate""><span class=""pre"">.agg()</span></code> it is possible to easily create a custom describe function, similar
to the built in <a class=""reference internal"" href=""#basics-describe""><span class=""std std-ref"">describe function</span></a>.</p>

</section>
</section>
<section id=""transform-api"">
<span id=""basics-transform""></span><h3>Transform API<a class=""headerlink"" href=""#transform-api"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.transform.html#pandas.DataFrame.transform"" title=""pandas.DataFrame.transform""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">transform()</span></code></a> method returns an object that is indexed the same (same size)
as the original. This API allows you to provide <em>multiple</em> operations at the same
time rather than one-by-one. Its API is quite similar to the <code class=""docutils literal notranslate""><span class=""pre"">.agg</span></code> API.</p>
<p>We create a frame similar to the one used in the above sections.</p>

<p>Transform the entire frame. <code class=""docutils literal notranslate""><span class=""pre"">.transform()</span></code> allows input functions as: a NumPy function, a string
function name or a user defined function.</p>

<p>Here <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.transform.html#pandas.DataFrame.transform"" title=""pandas.DataFrame.transform""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">transform()</span></code></a> received a single function; this is equivalent to a <a class=""reference external"" href=""https://numpy.org/doc/stable/reference/ufuncs.html"">ufunc</a> application.</p>

<p>Passing a single function to <code class=""docutils literal notranslate""><span class=""pre"">.transform()</span></code> with a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> will yield a single <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> in return.</p>

<section id=""transform-with-multiple-functions"">
<h4>Transform with multiple functions<a class=""headerlink"" href=""#transform-with-multiple-functions"" title=""Link to this heading"">#</a></h4>
<p>Passing multiple functions will yield a column MultiIndexed DataFrame.
The first level will be the original frame column names; the second level
will be the names of the transforming functions.</p>

<p>Passing multiple functions to a Series will yield a DataFrame. The
resulting column names will be the transforming functions.</p>

</section>
<section id=""transforming-with-a-dict"">
<h4>Transforming with a dict<a class=""headerlink"" href=""#transforming-with-a-dict"" title=""Link to this heading"">#</a></h4>
<p>Passing a dict of functions will allow selective transforming per column.</p>

<p>Passing a dict of lists will generate a MultiIndexed DataFrame with these
selective transforms.</p>

</section>
</section>
<section id=""applying-elementwise-functions"">
<span id=""basics-elementwise""></span><h3>Applying elementwise functions<a class=""headerlink"" href=""#applying-elementwise-functions"" title=""Link to this heading"">#</a></h3>
<p>Since not all functions can be vectorized (accept NumPy arrays and return
another array or value), the methods <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.map.html#pandas.DataFrame.map"" title=""pandas.DataFrame.map""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">map()</span></code></a> on DataFrame
and analogously <a class=""reference internal"" href=""../reference/api/pandas.Series.map.html#pandas.Series.map"" title=""pandas.Series.map""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">map()</span></code></a> on Series accept any Python function taking
a single value and returning a single value. For example:</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.Series.map.html#pandas.Series.map"" title=""pandas.Series.map""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.map()</span></code></a> has an additional feature; it can be used to easily
“link” or “map” values defined by a secondary series. This is closely related
to <a class=""reference internal"" href=""merging.html#merging""><span class=""std std-ref"">merging/joining functionality</span></a>:</p>

</section>
</section>
<section id=""reindexing-and-altering-labels"">
<span id=""basics-reindexing""></span><h2>Reindexing and altering labels<a class=""headerlink"" href=""#reindexing-and-altering-labels"" title=""Link to this heading"">#</a></h2>
<p><a class=""reference internal"" href=""../reference/api/pandas.Series.reindex.html#pandas.Series.reindex"" title=""pandas.Series.reindex""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">reindex()</span></code></a> is the fundamental data alignment method in pandas.
It is used to implement nearly all other features relying on label-alignment
functionality. To <em>reindex</em> means to conform the data to match a given set of
labels along a particular axis. This accomplishes several things:</p>
<ul class=""simple"">
<li><p>Reorders the existing data to match a new set of labels</p></li>
<li><p>Inserts missing value (NA) markers in label locations where no data for
that label existed</p></li>
<li><p>If specified, <strong>fill</strong> data for missing labels using logic (highly relevant
to working with time series data)</p></li>
</ul>
<p>Here is a simple example:</p>

<p>Here, the <code class=""docutils literal notranslate""><span class=""pre"">f</span></code> label was not contained in the Series and hence appears as
<code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code> in the result.</p>
<p>With a DataFrame, you can simultaneously reindex the index and columns:</p>

<p>Note that the <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> objects containing the actual axis labels can be
<strong>shared</strong> between objects. So if we have a Series and a DataFrame, the
following can be done:</p>

<p>This means that the reindexed Series’s index is the same Python object as the
DataFrame’s index.</p>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.reindex.html#pandas.DataFrame.reindex"" title=""pandas.DataFrame.reindex""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.reindex()</span></code></a> also supports an “axis-style” calling convention,
where you specify a single <code class=""docutils literal notranslate""><span class=""pre"">labels</span></code> argument and the <code class=""docutils literal notranslate""><span class=""pre"">axis</span></code> it applies to.</p>

<div class=""admonition seealso"">
<p class=""admonition-title"">See also</p>
<p><a class=""reference internal"" href=""advanced.html#advanced""><span class=""std std-ref"">MultiIndex / Advanced Indexing</span></a> is an even more concise way of
doing reindexing.</p>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>When writing performance-sensitive code, there is a good reason to spend
some time becoming a reindexing ninja: <strong>many operations are faster on
pre-aligned data</strong>. Adding two unaligned DataFrames internally triggers a
reindexing step. For exploratory analysis you will hardly notice the
difference (because <code class=""docutils literal notranslate""><span class=""pre"">reindex</span></code> has been heavily optimized), but when CPU
cycles matter sprinkling a few explicit <code class=""docutils literal notranslate""><span class=""pre"">reindex</span></code> calls here and there can
have an impact.</p>
</div>
<section id=""reindexing-to-align-with-another-object"">
<span id=""basics-reindex-like""></span><h3>Reindexing to align with another object<a class=""headerlink"" href=""#reindexing-to-align-with-another-object"" title=""Link to this heading"">#</a></h3>
<p>You may wish to take an object and reindex its axes to be labeled the same as
another object. While the syntax for this is straightforward albeit verbose, it
is a common enough operation that the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.reindex_like.html#pandas.DataFrame.reindex_like"" title=""pandas.DataFrame.reindex_like""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">reindex_like()</span></code></a> method is
available to make this simpler:</p>

</section>
<section id=""aligning-objects-with-each-other-with-align"">
<span id=""basics-align""></span><h3>Aligning objects with each other with <code class=""docutils literal notranslate""><span class=""pre"">align</span></code><a class=""headerlink"" href=""#aligning-objects-with-each-other-with-align"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.Series.align.html#pandas.Series.align"" title=""pandas.Series.align""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">align()</span></code></a> method is the fastest way to simultaneously align two objects. It
supports a <code class=""docutils literal notranslate""><span class=""pre"">join</span></code> argument (related to <a class=""reference internal"" href=""merging.html#merging""><span class=""std std-ref"">joining and merging</span></a>):</p>
<blockquote>
<div><ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">join='outer'</span></code>: take the union of the indexes (default)</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">join='left'</span></code>: use the calling object’s index</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">join='right'</span></code>: use the passed object’s index</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">join='inner'</span></code>: intersect the indexes</p></li>
</ul>
</div></blockquote>
<p>It returns a tuple with both of the reindexed Series:</p>

<p id=""basics-df-join"">For DataFrames, the join method will be applied to both the index and the
columns by default:</p>

<p>You can also pass an <code class=""docutils literal notranslate""><span class=""pre"">axis</span></code> option to only align on the specified axis:</p>

<p id=""basics-align-frame-series"">If you pass a Series to <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.align.html#pandas.DataFrame.align"" title=""pandas.DataFrame.align""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.align()</span></code></a>, you can choose to align both
objects either on the DataFrame’s index or columns using the <code class=""docutils literal notranslate""><span class=""pre"">axis</span></code> argument:</p>

</section>
<section id=""filling-while-reindexing"">
<span id=""basics-reindex-fill""></span><h3>Filling while reindexing<a class=""headerlink"" href=""#filling-while-reindexing"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.Series.reindex.html#pandas.Series.reindex"" title=""pandas.Series.reindex""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">reindex()</span></code></a> takes an optional parameter <code class=""docutils literal notranslate""><span class=""pre"">method</span></code> which is a
filling method chosen from the following table:</p>

<p>We illustrate these fill methods on a simple Series:</p>

<p>These methods require that the indexes are <strong>ordered</strong> increasing or
decreasing.</p>
<p>Note that the same result could have been achieved using
<a class=""reference internal"" href=""missing_data.html#missing-data-fillna""><span class=""std std-ref"">ffill</span></a> (except for <code class=""docutils literal notranslate""><span class=""pre"">method='nearest'</span></code>) or
<a class=""reference internal"" href=""missing_data.html#missing-data-interpolate""><span class=""std std-ref"">interpolate</span></a>:</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.Series.reindex.html#pandas.Series.reindex"" title=""pandas.Series.reindex""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">reindex()</span></code></a> will raise a ValueError if the index is not monotonically
increasing or decreasing. <a class=""reference internal"" href=""../reference/api/pandas.Series.fillna.html#pandas.Series.fillna"" title=""pandas.Series.fillna""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">fillna()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.Series.interpolate.html#pandas.Series.interpolate"" title=""pandas.Series.interpolate""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">interpolate()</span></code></a>
will not perform any checks on the order of the index.</p>
</section>
<section id=""limits-on-filling-while-reindexing"">
<span id=""basics-limits-on-reindex-fill""></span><h3>Limits on filling while reindexing<a class=""headerlink"" href=""#limits-on-filling-while-reindexing"" title=""Link to this heading"">#</a></h3>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">limit</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">tolerance</span></code> arguments provide additional control over
filling while reindexing. Limit specifies the maximum count of consecutive
matches:</p>

<p>In contrast, tolerance specifies the maximum distance between the index and
indexer values:</p>

<p>Notice that when used on a <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">TimedeltaIndex</span></code> or
<code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">tolerance</span></code> will coerced into a <code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code> if possible.
This allows you to specify tolerance with appropriate strings.</p>
</section>
<section id=""dropping-labels-from-an-axis"">
<span id=""basics-drop""></span><h3>Dropping labels from an axis<a class=""headerlink"" href=""#dropping-labels-from-an-axis"" title=""Link to this heading"">#</a></h3>
<p>A method closely related to <code class=""docutils literal notranslate""><span class=""pre"">reindex</span></code> is the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.drop.html#pandas.DataFrame.drop"" title=""pandas.DataFrame.drop""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">drop()</span></code></a> function.
It removes a set of labels from an axis:</p>

<p>Note that the following also works, but is a bit less obvious / clean:</p>

</section>
<section id=""renaming-mapping-labels"">
<span id=""basics-rename""></span><h3>Renaming / mapping labels<a class=""headerlink"" href=""#renaming-mapping-labels"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.rename.html#pandas.DataFrame.rename"" title=""pandas.DataFrame.rename""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">rename()</span></code></a> method allows you to relabel an axis based on some
mapping (a dict or Series) or an arbitrary function.</p>

<p>If you pass a function, it must return a value when called with any of the
labels (and must produce a set of unique values). A dict or
Series can also be used:</p>

<p>If the mapping doesn’t include a column/index label, it isn’t renamed. Note that
extra labels in the mapping don’t throw an error.</p>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.rename.html#pandas.DataFrame.rename"" title=""pandas.DataFrame.rename""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.rename()</span></code></a> also supports an “axis-style” calling convention, where
you specify a single <code class=""docutils literal notranslate""><span class=""pre"">mapper</span></code> and the <code class=""docutils literal notranslate""><span class=""pre"">axis</span></code> to apply that mapping to.</p>

<p>Finally, <a class=""reference internal"" href=""../reference/api/pandas.Series.rename.html#pandas.Series.rename"" title=""pandas.Series.rename""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">rename()</span></code></a> also accepts a scalar or list-like
for altering the <code class=""docutils literal notranslate""><span class=""pre"">Series.name</span></code> attribute.</p>

<p id=""basics-rename-axis"">The methods <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.rename_axis.html#pandas.DataFrame.rename_axis"" title=""pandas.DataFrame.rename_axis""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.rename_axis()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.Series.rename_axis.html#pandas.Series.rename_axis"" title=""pandas.Series.rename_axis""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.rename_axis()</span></code></a>
allow specific names of a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> to be changed (as opposed to the
labels).</p>

</section>
</section>
<section id=""iteration"">
<span id=""basics-iteration""></span><h2>Iteration<a class=""headerlink"" href=""#iteration"" title=""Link to this heading"">#</a></h2>
<p>The behavior of basic iteration over pandas objects depends on the type.
When iterating over a Series, it is regarded as array-like, and basic iteration
produces the values. DataFrames follow the dict-like convention of iterating
over the “keys” of the objects.</p>
<p>In short, basic iteration (<code class=""docutils literal notranslate""><span class=""pre"">for</span> <span class=""pre"">i</span> <span class=""pre"">in</span> <span class=""pre"">object</span></code>) produces:</p>
<ul class=""simple"">
<li><p><strong>Series</strong>: values</p></li>
<li><p><strong>DataFrame</strong>: column labels</p></li>
</ul>
<p>Thus, for example, iterating over a DataFrame gives you the column names:</p>

<p>pandas objects also have the dict-like <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.items.html#pandas.DataFrame.items"" title=""pandas.DataFrame.items""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">items()</span></code></a> method to
iterate over the (key, value) pairs.</p>
<p>To iterate over the rows of a DataFrame, you can use the following methods:</p>
<ul class=""simple"">
<li><p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.iterrows.html#pandas.DataFrame.iterrows"" title=""pandas.DataFrame.iterrows""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">iterrows()</span></code></a>: Iterate over the rows of a DataFrame as (index, Series) pairs.
This converts the rows to Series objects, which can change the dtypes and has some
performance implications.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.itertuples.html#pandas.DataFrame.itertuples"" title=""pandas.DataFrame.itertuples""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">itertuples()</span></code></a>: Iterate over the rows of a DataFrame
as namedtuples of the values. This is a lot faster than
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.iterrows.html#pandas.DataFrame.iterrows"" title=""pandas.DataFrame.iterrows""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">iterrows()</span></code></a>, and is in most cases preferable to use
to iterate over the values of a DataFrame.</p></li>
</ul>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Iterating through pandas objects is generally <strong>slow</strong>. In many cases,
iterating manually over the rows is not needed and can be avoided with
one of the following approaches:</p>
<ul class=""simple"">
<li><p>Look for a <em>vectorized</em> solution: many operations can be performed using
built-in methods or NumPy functions, (boolean) indexing, …</p></li>
<li><p>When you have a function that cannot work on the full DataFrame/Series
at once, it is better to use <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply"" title=""pandas.DataFrame.apply""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">apply()</span></code></a> instead of iterating
over the values. See the docs on <a class=""reference internal"" href=""#basics-apply""><span class=""std std-ref"">function application</span></a>.</p></li>
<li><p>If you need to do iterative manipulations on the values but performance is
important, consider writing the inner loop with cython or numba.
See the <a class=""reference internal"" href=""enhancingperf.html#enhancingperf""><span class=""std std-ref"">enhancing performance</span></a> section for some
examples of this approach.</p></li>
</ul>
</div>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>You should <strong>never modify</strong> something you are iterating over.
This is not guaranteed to work in all cases. Depending on the
data types, the iterator returns a copy and not a view, and writing
to it will have no effect!</p>
<p>For example, in the following case setting the value has no effect:</p>

</div>
<section id=""items"">
<h3>items<a class=""headerlink"" href=""#items"" title=""Link to this heading"">#</a></h3>
<p>Consistent with the dict-like interface, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.items.html#pandas.DataFrame.items"" title=""pandas.DataFrame.items""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">items()</span></code></a> iterates
through key-value pairs:</p>
<ul class=""simple"">
<li><p><strong>Series</strong>: (index, scalar value) pairs</p></li>
<li><p><strong>DataFrame</strong>: (column, Series) pairs</p></li>
</ul>
<p>For example:</p>

</section>
<section id=""iterrows"">
<span id=""basics-iterrows""></span><h3>iterrows<a class=""headerlink"" href=""#iterrows"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.iterrows.html#pandas.DataFrame.iterrows"" title=""pandas.DataFrame.iterrows""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">iterrows()</span></code></a> allows you to iterate through the rows of a
DataFrame as Series objects. It returns an iterator yielding each
index value along with a Series containing the data in each row:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Because <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.iterrows.html#pandas.DataFrame.iterrows"" title=""pandas.DataFrame.iterrows""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">iterrows()</span></code></a> returns a Series for each row,
it does <strong>not</strong> preserve dtypes across the rows (dtypes are
preserved across columns for DataFrames). For example,</p>

<p>All values in <code class=""docutils literal notranslate""><span class=""pre"">row</span></code>, returned as a Series, are now upcasted
to floats, also the original integer value in column <code class=""docutils literal notranslate""><span class=""pre"">x</span></code>:</p>

<p>To preserve dtypes while iterating over the rows, it is better
to use <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.itertuples.html#pandas.DataFrame.itertuples"" title=""pandas.DataFrame.itertuples""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">itertuples()</span></code></a> which returns namedtuples of the values
and which is generally much faster than <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.iterrows.html#pandas.DataFrame.iterrows"" title=""pandas.DataFrame.iterrows""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">iterrows()</span></code></a>.</p>
</div>
<p>For instance, a contrived way to transpose the DataFrame would be:</p>

</section>
<section id=""itertuples"">
<h3>itertuples<a class=""headerlink"" href=""#itertuples"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.itertuples.html#pandas.DataFrame.itertuples"" title=""pandas.DataFrame.itertuples""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">itertuples()</span></code></a> method will return an iterator
yielding a namedtuple for each row in the DataFrame. The first element
of the tuple will be the row’s corresponding index value, while the
remaining values are the row values.</p>
<p>For instance:</p>

<p>This method does not convert the row to a Series object; it merely
returns the values inside a namedtuple. Therefore,
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.itertuples.html#pandas.DataFrame.itertuples"" title=""pandas.DataFrame.itertuples""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">itertuples()</span></code></a> preserves the data type of the values
and is generally faster as <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.iterrows.html#pandas.DataFrame.iterrows"" title=""pandas.DataFrame.iterrows""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">iterrows()</span></code></a>.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The column names will be renamed to positional names if they are
invalid Python identifiers, repeated, or start with an underscore.
With a large number of columns (&gt;255), regular tuples are returned.</p>
</div>
</section>
</section>
<section id=""dt-accessor"">
<span id=""basics-dt-accessors""></span><h2>.dt accessor<a class=""headerlink"" href=""#dt-accessor"" title=""Link to this heading"">#</a></h2>
<p><code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> has an accessor to succinctly return datetime like properties for the
<em>values</em> of the Series, if it is a datetime/period like Series.
This will return a Series, indexed like the existing Series.</p>

<p>This enables nice expressions like this:</p>

<p>You can easily produces tz aware transformations:</p>

<p>You can also chain these types of operations:</p>

<p>You can also format datetime values as strings with <a class=""reference internal"" href=""../reference/api/pandas.Series.dt.strftime.html#pandas.Series.dt.strftime"" title=""pandas.Series.dt.strftime""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.dt.strftime()</span></code></a> which
supports the same format as the standard <a class=""reference external"" href=""https://docs.python.org/3/library/datetime.html#datetime.datetime.strftime"" title=""(in Python v3.12)""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">strftime()</span></code></a>.</p>


<p>The <code class=""docutils literal notranslate""><span class=""pre"">.dt</span></code> accessor works for period and timedelta dtypes.</p>


<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">Series.dt</span></code> will raise a <code class=""docutils literal notranslate""><span class=""pre"">TypeError</span></code> if you access with a non-datetime-like values.</p>
</div>
</section>
<section id=""vectorized-string-methods"">
<h2>Vectorized string methods<a class=""headerlink"" href=""#vectorized-string-methods"" title=""Link to this heading"">#</a></h2>
<p>Series is equipped with a set of string processing methods that make it easy to
operate on each element of the array. Perhaps most importantly, these methods
exclude missing/NA values automatically. These are accessed via the Series’s
<code class=""docutils literal notranslate""><span class=""pre"">str</span></code> attribute and generally have names matching the equivalent (scalar)
built-in string methods. For example:</p>
<blockquote>
<div>
</div></blockquote>
<p>Powerful pattern-matching methods are provided as well, but note that
pattern-matching generally uses <a class=""reference external"" href=""https://docs.python.org/3/library/re.html"">regular expressions</a> by default (and in some cases
always uses them).</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Prior to pandas 1.0, string methods were only available on <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> -dtype
<code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>. pandas 1.0 added the <a class=""reference internal"" href=""../reference/api/pandas.StringDtype.html#pandas.StringDtype"" title=""pandas.StringDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">StringDtype</span></code></a> which is dedicated
to strings. See <a class=""reference internal"" href=""text.html#text-types""><span class=""std std-ref"">Text data types</span></a> for more.</p>
</div>
<p>Please see <a class=""reference internal"" href=""text.html#text-string-methods""><span class=""std std-ref"">Vectorized String Methods</span></a> for a complete
description.</p>
</section>
<section id=""sorting"">
<span id=""basics-sorting""></span><h2>Sorting<a class=""headerlink"" href=""#sorting"" title=""Link to this heading"">#</a></h2>
<p>pandas supports three kinds of sorting: sorting by index labels,
sorting by column values, and sorting by a combination of both.</p>
<section id=""by-index"">
<span id=""basics-sort-index""></span><h3>By index<a class=""headerlink"" href=""#by-index"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.Series.sort_index.html#pandas.Series.sort_index"" title=""pandas.Series.sort_index""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.sort_index()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.sort_index.html#pandas.DataFrame.sort_index"" title=""pandas.DataFrame.sort_index""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.sort_index()</span></code></a> methods are
used to sort a pandas object by its index levels.</p>

<p id=""basics-sort-index-key"">Sorting by index also supports a <code class=""docutils literal notranslate""><span class=""pre"">key</span></code> parameter that takes a callable
function to apply to the index being sorted. For <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> objects,
the key is applied per-level to the levels specified by <code class=""docutils literal notranslate""><span class=""pre"">level</span></code>.</p>


<p>For information on key sorting by value, see <a class=""reference internal"" href=""#basics-sort-value-key""><span class=""std std-ref"">value sorting</span></a>.</p>
</section>
<section id=""by-values"">
<span id=""basics-sort-values""></span><h3>By values<a class=""headerlink"" href=""#by-values"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.Series.sort_values.html#pandas.Series.sort_values"" title=""pandas.Series.sort_values""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.sort_values()</span></code></a> method is used to sort a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> by its values. The
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.sort_values.html#pandas.DataFrame.sort_values"" title=""pandas.DataFrame.sort_values""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.sort_values()</span></code></a> method is used to sort a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> by its column or row values.
The optional <code class=""docutils literal notranslate""><span class=""pre"">by</span></code> parameter to <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.sort_values.html#pandas.DataFrame.sort_values"" title=""pandas.DataFrame.sort_values""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.sort_values()</span></code></a> may used to specify one or more columns
to use to determine the sorted order.</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">by</span></code> parameter can take a list of column names, e.g.:</p>

<p>These methods have special treatment of NA values via the <code class=""docutils literal notranslate""><span class=""pre"">na_position</span></code>
argument:</p>

<p id=""basics-sort-value-key"">Sorting also supports a <code class=""docutils literal notranslate""><span class=""pre"">key</span></code> parameter that takes a callable function
to apply to the values being sorted.</p>


<p><code class=""docutils literal notranslate""><span class=""pre"">key</span></code> will be given the <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> of values and should return a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>
or array of the same shape with the transformed values. For <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> objects,
the key is applied per column, so the key should still expect a Series and return
a Series, e.g.</p>


<p>The name or type of each column can be used to apply different functions to
different columns.</p>
</section>
<section id=""by-indexes-and-values"">
<span id=""basics-sort-indexes-and-values""></span><h3>By indexes and values<a class=""headerlink"" href=""#by-indexes-and-values"" title=""Link to this heading"">#</a></h3>
<p>Strings passed as the <code class=""docutils literal notranslate""><span class=""pre"">by</span></code> parameter to <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.sort_values.html#pandas.DataFrame.sort_values"" title=""pandas.DataFrame.sort_values""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.sort_values()</span></code></a> may
refer to either columns or index level names.</p>

<p>Sort by ‘second’ (index) and ‘A’ (column)</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>If a string matches both a column name and an index level name then a
warning is issued and the column takes precedence. This will result in an
ambiguity error in a future version.</p>
</div>
</section>
<section id=""searchsorted"">
<span id=""basics-searchsorted""></span><h3>searchsorted<a class=""headerlink"" href=""#searchsorted"" title=""Link to this heading"">#</a></h3>
<p>Series has the <a class=""reference internal"" href=""../reference/api/pandas.Series.searchsorted.html#pandas.Series.searchsorted"" title=""pandas.Series.searchsorted""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">searchsorted()</span></code></a> method, which works similarly to
<a class=""reference external"" href=""https://numpy.org/doc/stable/reference/generated/numpy.ndarray.searchsorted.html#numpy.ndarray.searchsorted"" title=""(in NumPy v1.26)""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">numpy.ndarray.searchsorted()</span></code></a>.</p>

</section>
<section id=""smallest-largest-values"">
<span id=""basics-nsorted""></span><h3>smallest / largest values<a class=""headerlink"" href=""#smallest-largest-values"" title=""Link to this heading"">#</a></h3>
<p><code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> has the <a class=""reference internal"" href=""../reference/api/pandas.Series.nsmallest.html#pandas.Series.nsmallest"" title=""pandas.Series.nsmallest""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">nsmallest()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.Series.nlargest.html#pandas.Series.nlargest"" title=""pandas.Series.nlargest""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">nlargest()</span></code></a> methods which return the
smallest or largest <span class=""math notranslate nohighlight"">\(n\)</span> values. For a large <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> this can be much
faster than sorting the entire Series and calling <code class=""docutils literal notranslate""><span class=""pre"">head(n)</span></code> on the result.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> also has the <code class=""docutils literal notranslate""><span class=""pre"">nlargest</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">nsmallest</span></code> methods.</p>

</section>
<section id=""sorting-by-a-multiindex-column"">
<span id=""basics-multiindex-sorting""></span><h3>Sorting by a MultiIndex column<a class=""headerlink"" href=""#sorting-by-a-multiindex-column"" title=""Link to this heading"">#</a></h3>
<p>You must be explicit about sorting when the column is a MultiIndex, and fully specify
all levels to <code class=""docutils literal notranslate""><span class=""pre"">by</span></code>.</p>

</section>
</section>
<section id=""copying"">
<h2>Copying<a class=""headerlink"" href=""#copying"" title=""Link to this heading"">#</a></h2>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.copy.html#pandas.DataFrame.copy"" title=""pandas.DataFrame.copy""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">copy()</span></code></a> method on pandas objects copies the underlying data (though not
the axis indexes, since they are immutable) and returns a new object. Note that
<strong>it is seldom necessary to copy objects</strong>. For example, there are only a
handful of ways to alter a DataFrame <em>in-place</em>:</p>
<ul class=""simple"">
<li><p>Inserting, deleting, or modifying a column.</p></li>
<li><p>Assigning to the <code class=""docutils literal notranslate""><span class=""pre"">index</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">columns</span></code> attributes.</p></li>
<li><p>For homogeneous data, directly modifying the values via the <code class=""docutils literal notranslate""><span class=""pre"">values</span></code>
attribute or advanced indexing.</p></li>
</ul>
<p>To be clear, no pandas method has the side effect of modifying your data;
almost every method returns a new object, leaving the original object
untouched. If the data is modified, it is because you did so explicitly.</p>
</section>
<section id=""dtypes"">
<span id=""basics-dtypes""></span><h2>dtypes<a class=""headerlink"" href=""#dtypes"" title=""Link to this heading"">#</a></h2>
<p>For the most part, pandas uses NumPy arrays and dtypes for Series or individual
columns of a DataFrame. NumPy provides support for <code class=""docutils literal notranslate""><span class=""pre"">float</span></code>,
<code class=""docutils literal notranslate""><span class=""pre"">int</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">bool</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">timedelta64[ns]</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">datetime64[ns]</span></code> (note that NumPy
does not support timezone-aware datetimes).</p>
<p>pandas and third-party libraries <em>extend</em> NumPy’s type system in a few places.
This section describes the extensions pandas has made internally.
See <a class=""reference internal"" href=""../development/extending.html#extending-extension-types""><span class=""std std-ref"">Extension types</span></a> for how to write your own extension that
works with pandas. See <a class=""reference external"" href=""https://pandas.pydata.org/community/ecosystem.html"">the ecosystem page</a> for a list of third-party
libraries that have implemented an extension.</p>
<p>The following table lists all of pandas extension types. For methods requiring <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code>
arguments, strings can be specified as indicated. See the respective
documentation sections for more on each type.</p>

<p>pandas has two ways to store strings.</p>
<ol class=""arabic simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">object</span></code> dtype, which can hold any Python object, including strings.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.StringDtype.html#pandas.StringDtype"" title=""pandas.StringDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">StringDtype</span></code></a>, which is dedicated to strings.</p></li>
</ol>
<p>Generally, we recommend using <a class=""reference internal"" href=""../reference/api/pandas.StringDtype.html#pandas.StringDtype"" title=""pandas.StringDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">StringDtype</span></code></a>. See <a class=""reference internal"" href=""text.html#text-types""><span class=""std std-ref"">Text data types</span></a> for more.</p>
<p>Finally, arbitrary objects may be stored using the <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> dtype, but should
be avoided to the extent possible (for performance and interoperability with
other libraries and methods. See <a class=""reference internal"" href=""#basics-object-conversion""><span class=""std std-ref"">object conversion</span></a>).</p>
<p>A convenient <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.dtypes.html#pandas.DataFrame.dtypes"" title=""pandas.DataFrame.dtypes""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">dtypes</span></code></a> attribute for DataFrame returns a Series
with the data type of each column.</p>

<p>On a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> object, use the <a class=""reference internal"" href=""../reference/api/pandas.Series.dtype.html#pandas.Series.dtype"" title=""pandas.Series.dtype""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">dtype</span></code></a> attribute.</p>

<p>If a pandas object contains data with multiple dtypes <em>in a single column</em>, the
dtype of the column will be chosen to accommodate all of the data types
(<code class=""docutils literal notranslate""><span class=""pre"">object</span></code> is the most general).</p>

<p>The number of columns of each type in a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> can be found by calling
<code class=""docutils literal notranslate""><span class=""pre"">DataFrame.dtypes.value_counts()</span></code>.</p>

<p>Numeric dtypes will propagate and can coexist in DataFrames.
If a dtype is passed (either directly via the <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code> keyword, a passed <code class=""docutils literal notranslate""><span class=""pre"">ndarray</span></code>,
or a passed <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>), then it will be preserved in DataFrame operations. Furthermore,
different numeric dtypes will <strong>NOT</strong> be combined. The following example will give you a taste.</p>

<section id=""defaults"">
<h3>defaults<a class=""headerlink"" href=""#defaults"" title=""Link to this heading"">#</a></h3>
<p>By default integer types are <code class=""docutils literal notranslate""><span class=""pre"">int64</span></code> and float types are <code class=""docutils literal notranslate""><span class=""pre"">float64</span></code>,
<em>regardless</em> of platform (32-bit or 64-bit).
The following will all result in <code class=""docutils literal notranslate""><span class=""pre"">int64</span></code> dtypes.</p>

<p>Note that Numpy will choose <em>platform-dependent</em> types when creating arrays.
The following <strong>WILL</strong> result in <code class=""docutils literal notranslate""><span class=""pre"">int32</span></code> on 32-bit platform.</p>

</section>
<section id=""upcasting"">
<h3>upcasting<a class=""headerlink"" href=""#upcasting"" title=""Link to this heading"">#</a></h3>
<p>Types can potentially be <em>upcasted</em> when combined with other types, meaning they are promoted
from the current type (e.g. <code class=""docutils literal notranslate""><span class=""pre"">int</span></code> to <code class=""docutils literal notranslate""><span class=""pre"">float</span></code>).</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_numpy.html#pandas.DataFrame.to_numpy"" title=""pandas.DataFrame.to_numpy""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.to_numpy()</span></code></a> will return the <em>lower-common-denominator</em> of the dtypes, meaning
the dtype that can accommodate <strong>ALL</strong> of the types in the resulting homogeneous dtyped NumPy array. This can
force some <em>upcasting</em>.</p>

</section>
<section id=""astype"">
<h3>astype<a class=""headerlink"" href=""#astype"" title=""Link to this heading"">#</a></h3>
<p id=""basics-cast"">You can use the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.astype.html#pandas.DataFrame.astype"" title=""pandas.DataFrame.astype""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">astype()</span></code></a> method to explicitly convert dtypes from one to another. These will by default return a copy,
even if the dtype was unchanged (pass <code class=""docutils literal notranslate""><span class=""pre"">copy=False</span></code> to change this behavior). In addition, they will raise an
exception if the astype operation is invalid.</p>
<p>Upcasting is always according to the <strong>NumPy</strong> rules. If two different dtypes are involved in an operation,
then the more <em>general</em> one will be used as the result of the operation.</p>

<p>Convert a subset of columns to a specified type using <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.astype.html#pandas.DataFrame.astype"" title=""pandas.DataFrame.astype""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">astype()</span></code></a>.</p>

<p>Convert certain columns to a specific dtype by passing a dict to <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.astype.html#pandas.DataFrame.astype"" title=""pandas.DataFrame.astype""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">astype()</span></code></a>.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>When trying to convert a subset of columns to a specified type using <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.astype.html#pandas.DataFrame.astype"" title=""pandas.DataFrame.astype""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">astype()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc"" title=""pandas.DataFrame.loc""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">loc()</span></code></a>, upcasting occurs.</p>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc"" title=""pandas.DataFrame.loc""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">loc()</span></code></a> tries to fit in what we are assigning to the current dtypes, while <code class=""docutils literal notranslate""><span class=""pre"">[]</span></code> will overwrite them taking the dtype from the right hand side. Therefore the following piece of code produces the unintended result.</p>

</div>
</section>
<section id=""object-conversion"">
<span id=""basics-object-conversion""></span><h3>object conversion<a class=""headerlink"" href=""#object-conversion"" title=""Link to this heading"">#</a></h3>
<p>pandas offers various functions to try to force conversion of types from the <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> dtype to other types.
In cases where the data is already of the correct type, but stored in an <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> array, the
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.infer_objects.html#pandas.DataFrame.infer_objects"" title=""pandas.DataFrame.infer_objects""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.infer_objects()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.Series.infer_objects.html#pandas.Series.infer_objects"" title=""pandas.Series.infer_objects""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.infer_objects()</span></code></a> methods can be used to soft convert
to the correct type.</p>
<blockquote>
<div>
</div></blockquote>
<p>Because the data was transposed the original inference stored all columns as object, which
<code class=""docutils literal notranslate""><span class=""pre"">infer_objects</span></code> will correct.</p>
<blockquote>
<div>
</div></blockquote>
<p>The following functions are available for one dimensional object arrays or scalars to perform
hard conversion of objects to a specified type:</p>
<ul>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.to_numeric.html#pandas.to_numeric"" title=""pandas.to_numeric""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">to_numeric()</span></code></a> (conversion to numeric dtypes)</p>

</li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.to_datetime.html#pandas.to_datetime"" title=""pandas.to_datetime""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">to_datetime()</span></code></a> (conversion to datetime objects)</p>

</li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.to_timedelta.html#pandas.to_timedelta"" title=""pandas.to_timedelta""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">to_timedelta()</span></code></a> (conversion to timedelta objects)</p>

</li>
</ul>
<p>To force a conversion, we can pass in an <code class=""docutils literal notranslate""><span class=""pre"">errors</span></code> argument, which specifies how pandas should deal with elements
that cannot be converted to desired dtype or object. By default, <code class=""docutils literal notranslate""><span class=""pre"">errors='raise'</span></code>, meaning that any errors encountered
will be raised during the conversion process. However, if <code class=""docutils literal notranslate""><span class=""pre"">errors='coerce'</span></code>, these errors will be ignored and pandas
will convert problematic elements to <code class=""docutils literal notranslate""><span class=""pre"">pd.NaT</span></code> (for datetime and timedelta) or <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code> (for numeric). This might be
useful if you are reading in data which is mostly of the desired dtype (e.g. numeric, datetime), but occasionally has
non-conforming elements intermixed that you want to represent as missing:</p>

<p>In addition to object conversion, <a class=""reference internal"" href=""../reference/api/pandas.to_numeric.html#pandas.to_numeric"" title=""pandas.to_numeric""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">to_numeric()</span></code></a> provides another argument <code class=""docutils literal notranslate""><span class=""pre"">downcast</span></code>, which gives the
option of downcasting the newly (or already) numeric data to a smaller dtype, which can conserve memory:</p>

<p>As these methods apply only to one-dimensional arrays, lists or scalars; they cannot be used directly on multi-dimensional objects such
as DataFrames. However, with <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply"" title=""pandas.DataFrame.apply""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">apply()</span></code></a>, we can “apply” the function over each column efficiently:</p>

</section>
<section id=""gotchas"">
<h3>gotchas<a class=""headerlink"" href=""#gotchas"" title=""Link to this heading"">#</a></h3>
<p>Performing selection operations on <code class=""docutils literal notranslate""><span class=""pre"">integer</span></code> type data can easily upcast the data to <code class=""docutils literal notranslate""><span class=""pre"">floating</span></code>.
The dtype of the input data will be preserved in cases where <code class=""docutils literal notranslate""><span class=""pre"">nans</span></code> are not introduced.
See also <a class=""reference internal"" href=""gotchas.html#gotchas-intna""><span class=""std std-ref"">Support for integer NA</span></a>.</p>

<p>While float dtypes are unchanged.</p>

</section>
</section>
<section id=""selecting-columns-based-on-dtype"">
<h2>Selecting columns based on <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code><a class=""headerlink"" href=""#selecting-columns-based-on-dtype"" title=""Link to this heading"">#</a></h2>
<p id=""basics-selectdtypes"">The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.select_dtypes.html#pandas.DataFrame.select_dtypes"" title=""pandas.DataFrame.select_dtypes""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">select_dtypes()</span></code></a> method implements subsetting of columns
based on their <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code>.</p>
<p>First, let’s create a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> with a slew of different
dtypes:</p>

<p>And the dtypes:</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.select_dtypes.html#pandas.DataFrame.select_dtypes"" title=""pandas.DataFrame.select_dtypes""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">select_dtypes()</span></code></a> has two parameters <code class=""docutils literal notranslate""><span class=""pre"">include</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">exclude</span></code> that allow you to
say “give me the columns <em>with</em> these dtypes” (<code class=""docutils literal notranslate""><span class=""pre"">include</span></code>) and/or “give the
columns <em>without</em> these dtypes” (<code class=""docutils literal notranslate""><span class=""pre"">exclude</span></code>).</p>
<p>For example, to select <code class=""docutils literal notranslate""><span class=""pre"">bool</span></code> columns:</p>

<p>You can also pass the name of a dtype in the <a class=""reference external"" href=""https://numpy.org/doc/stable/reference/arrays.scalars.html"">NumPy dtype hierarchy</a>:</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.select_dtypes.html#pandas.DataFrame.select_dtypes"" title=""pandas.DataFrame.select_dtypes""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">select_dtypes()</span></code></a> also works with generic dtypes as well.</p>
<p>For example, to select all numeric and boolean columns while excluding unsigned
integers:</p>

<p>To select string columns you must use the <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> dtype:</p>

<p>To see all the child dtypes of a generic <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code> like <code class=""docutils literal notranslate""><span class=""pre"">numpy.number</span></code> you
can define a function that returns a tree of child dtypes:</p>

<p>All NumPy dtypes are subclasses of <code class=""docutils literal notranslate""><span class=""pre"">numpy.generic</span></code>:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>pandas also defines the types <code class=""docutils literal notranslate""><span class=""pre"">category</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">datetime64[ns,</span> <span class=""pre"">tz]</span></code>, which are not integrated into the normal
NumPy hierarchy and won’t show up with the above function.</p>
</div>
</section>
</section>
</article>","Essential basic functionality # Here we discuss a lot of the essential functionality common to the pandas data structures. To begin, let’s create some example objects like we did in the 10 minutes to pandas section: Head and tail # To view a small sample of a Series or DataFrame object, use the head() and tail() methods. The default number of elements to display is five, but you may pass a custom number. Attributes and underlying data # pandas objects have a number of attributes enabling you to access the metadata shape : gives the axis dimensions of the object, consistent with ndarray Axis labels Series : index (only axis) DataFrame : index (rows) and columns Note, these attributes can be safely assigned to ! pandas objects ( Index , Series , DataFrame ) can be thought of as containers for arrays, which hold the actual data and do the actual computation. For many types, the underlying array is a numpy.ndarray . However, pandas and 3rd party libraries may extend NumPy’s type system to add support for custom arrays (see dtypes ). To get the actual data inside a Index or Series , use the .array property array will always be an ExtensionArray . The exact details of what an ExtensionArray is and why pandas uses them are a bit beyond the scope of this introduction. See dtypes for more. If you know you need a NumPy array, use to_numpy() or numpy.asarray() . When the Series or Index is backed by an ExtensionArray , to_numpy() may involve copying data and coercing values. See dtypes for more. to_numpy() gives some control over the dtype of the resulting numpy.ndarray . For example, consider datetimes with timezones. NumPy doesn’t have a dtype to represent timezone-aware datetimes, so there are two possibly useful representations: An object-dtype numpy.ndarray with Timestamp objects, each with the correct tz A datetime64[ns] -dtype numpy.ndarray , where the values have been converted to UTC and the timezone discarded Timezones may be preserved with dtype=object Or thrown away with dtype='datetime64[ns]' Getting the “raw data” inside a DataFrame is possibly a bit more complex. When your DataFrame only has a single data type for all the columns, DataFrame.to_numpy() will return the underlying data: If a DataFrame contains homogeneously-typed data, the ndarray can actually be modified in-place, and the changes will be reflected in the data structure. For heterogeneous data (e.g. some of the DataFrame’s columns are not all the same dtype), this will not be the case. The values attribute itself, unlike the axis labels, cannot be assigned to. Note When working with heterogeneous data, the dtype of the resulting ndarray will be chosen to accommodate all of the data involved. For example, if strings are involved, the result will be of object dtype. If there are only floats and integers, the resulting array will be of float dtype. In the past, pandas recommended Series.values or DataFrame.values for extracting the data from a Series or DataFrame. You’ll still find references to these in old code bases and online. Going forward, we recommend avoiding .values and using .array or .to_numpy() . .values has the following drawbacks: When your Series contains an extension type , it’s unclear whether Series.values returns a NumPy array or the extension array. Series.array will always return an ExtensionArray , and will never copy data. Series.to_numpy() will always return a NumPy array, potentially at the cost of copying / coercing values. When your DataFrame contains a mixture of data types, DataFrame.values may involve copying data and coercing values to a common dtype, a relatively expensive operation. DataFrame.to_numpy() , being a method, makes it clearer that the returned NumPy array may not be a view on the same data in the DataFrame. Accelerated operations # pandas has support for accelerating certain types of binary numerical and boolean operations using the numexpr library and the bottleneck libraries. These libraries are especially useful when dealing with large data sets, and provide large speedups. numexpr uses smart chunking, caching, and multiple cores. bottleneck is a set of specialized cython routines that are especially fast when dealing with arrays that have nans . Here is a sample (using 100 column x 100,000 row DataFrames ): You are highly encouraged to install both libraries. See the section Recommended Dependencies for more installation info. These are both enabled to be used by default, you can control this by setting the options: pd . set_option ( ""compute.use_bottleneck"" , False ) pd . set_option ( ""compute.use_numexpr"" , False ) Flexible binary operations # With binary operations between pandas data structures, there are two key points of interest: Broadcasting behavior between higher- (e.g. DataFrame) and lower-dimensional (e.g. Series) objects. Missing data in computations. We will demonstrate how to manage these issues independently, though they can be handled simultaneously. Matching / broadcasting behavior # DataFrame has the methods add() , sub() , mul() , div() and related functions radd() , rsub() , … for carrying out binary operations. For broadcasting behavior, Series input is of primary interest. Using these functions, you can use to either match on the index or columns via the axis keyword: Furthermore you can align a level of a MultiIndexed DataFrame with a Series. Series and Index also support the divmod() builtin. This function takes the floor division and modulo operation at the same time returning a two-tuple of the same type as the left hand side. For example: We can also do elementwise divmod() : Missing data / operations with fill values # In Series and DataFrame, the arithmetic functions have the option of inputting a fill_value , namely a value to substitute when at most one of the values at a location are missing. For example, when adding two DataFrame objects, you may wish to treat NaN as 0 unless both DataFrames are missing that value, in which case the result will be NaN (you can later replace NaN with some other value using fillna if you wish). Flexible comparisons # Series and DataFrame have the binary comparison methods eq , ne , lt , gt , le , and ge whose behavior is analogous to the binary arithmetic operations described above: These operations produce a pandas object of the same type as the left-hand-side input that is of dtype bool . These boolean objects can be used in indexing operations, see the section on Boolean indexing . Boolean reductions # You can apply the reductions: empty , any() , all() , and bool() to provide a way to summarize a boolean result. You can reduce to a final boolean value. You can test if a pandas object is empty, via the empty property. Warning Asserting the truthiness of a pandas object will raise an error, as the testing of the emptiness or values is ambiguous. See gotchas for a more detailed discussion. Comparing if objects are equivalent # Often you may find that there is more than one way to compute the same result. As a simple example, consider df + df and df * 2 . To test that these two computations produce the same result, given the tools shown above, you might imagine using (df + df == df * 2).all() . But in fact, this expression is False: Notice that the boolean DataFrame df + df == df * 2 contains some False values! This is because NaNs do not compare as equals: So, NDFrames (such as Series and DataFrames) have an equals() method for testing equality, with NaNs in corresponding locations treated as equal. Note that the Series or DataFrame index needs to be in the same order for equality to be True: Comparing array-like objects # You can conveniently perform element-wise comparisons when comparing a pandas data structure with a scalar value: pandas also handles element-wise comparisons between different array-like objects of the same length: Trying to compare Index or Series objects of different lengths will raise a ValueError: Combining overlapping data sets # A problem occasionally arising is the combination of two similar data sets where values in one are preferred over the other. An example would be two data series representing a particular economic indicator where one is considered to be of “higher quality”. However, the lower quality series might extend further back in history or have more complete data coverage. As such, we would like to combine two DataFrame objects where missing values in one DataFrame are conditionally filled with like-labeled values from the other DataFrame. The function implementing this operation is combine_first() , which we illustrate: General DataFrame combine # The combine_first() method above calls the more general DataFrame.combine() . This method takes another DataFrame and a combiner function, aligns the input DataFrame and then passes the combiner function pairs of Series (i.e., columns whose names are the same). So, for instance, to reproduce combine_first() as above: Descriptive statistics # There exists a large number of methods for computing descriptive statistics and other related operations on Series , DataFrame . Most of these are aggregations (hence producing a lower-dimensional result) like sum() , mean() , and quantile() , but some of them, like cumsum() and cumprod() , produce an object of the same size. Generally speaking, these methods take an axis argument, just like ndarray.{sum, std, …} , but the axis can be specified by name or integer: Series : no axis argument needed DataFrame : “index” (axis=0, default), “columns” (axis=1) For example: All such methods have a skipna option signaling whether to exclude missing data ( True by default): Combined with the broadcasting / arithmetic behavior, one can describe various statistical procedures, like standardization (rendering data zero mean and standard deviation of 1), very concisely: Note that methods like cumsum() and cumprod() preserve the location of NaN values. This is somewhat different from expanding() and rolling() since NaN behavior is furthermore dictated by a min_periods parameter. Here is a quick reference summary table of common functions. Each also takes an optional level parameter which applies only if the object has a hierarchical index . Note that by chance some NumPy methods, like mean , std , and sum , will exclude NAs on Series input by default: Series.nunique() will return the number of unique non-NA values in a Series: Summarizing data: describe # There is a convenient describe() function which computes a variety of summary statistics about a Series or the columns of a DataFrame (excluding NAs of course): You can select specific percentiles to include in the output: By default, the median is always included. For a non-numerical Series object, describe() will give a simple summary of the number of unique values and most frequently occurring values: Note that on a mixed-type DataFrame object, describe() will restrict the summary to include only numerical columns or, if none are, only categorical columns: This behavior can be controlled by providing a list of types as include / exclude arguments. The special value all can also be used: That feature relies on select_dtypes . Refer to there for details about accepted inputs. Index of min/max values # The idxmin() and idxmax() functions on Series and DataFrame compute the index labels with the minimum and maximum corresponding values: When there are multiple rows (or columns) matching the minimum or maximum value, idxmin() and idxmax() return the first matching index: Note idxmin and idxmax are called argmin and argmax in NumPy. Value counts (histogramming) / mode # The value_counts() Series method computes a histogram of a 1D array of values. It can also be used as a function on regular arrays: The value_counts() method can be used to count combinations across multiple columns. By default all columns are used but a subset can be selected using the subset argument. Similarly, you can get the most frequently occurring value(s), i.e. the mode, of the values in a Series or DataFrame: Discretization and quantiling # Continuous values can be discretized using the cut() (bins based on values) and qcut() (bins based on sample quantiles) functions: qcut() computes sample quantiles. For example, we could slice up some normally distributed data into equal-size quartiles like so: We can also pass infinite values to define the bins: Function application # To apply your own or another library’s functions to pandas objects, you should be aware of the three methods below. The appropriate method to use depends on whether your function expects to operate on an entire DataFrame or Series , row- or column-wise, or elementwise. Tablewise Function Application : pipe() Row or Column-wise Function Application : apply() Aggregation API : agg() and transform() Applying Elementwise Functions : map() Tablewise function application # DataFrames and Series can be passed into functions. However, if the function needs to be called in a chain, consider using the pipe() method. First some setup: extract_city_name and add_country_name are functions taking and returning DataFrames . Now compare the following: Is equivalent to: pandas encourages the second style, which is known as method chaining. pipe makes it easy to use your own or another library’s functions in method chains, alongside pandas’ methods. In the example above, the functions extract_city_name and add_country_name each expected a DataFrame as the first positional argument. What if the function you wish to apply takes its data as, say, the second argument? In this case, provide pipe with a tuple of (callable, data_keyword) . .pipe will route the DataFrame to the argument specified in the tuple. For example, we can fit a regression using statsmodels. Their API expects a formula first and a DataFrame as the second argument, data . We pass in the function, keyword pair (sm.ols, 'data') to pipe : The pipe method is inspired by unix pipes and more recently dplyr and magrittr , which have introduced the popular (%>%) (read pipe) operator for R . The implementation of pipe here is quite clean and feels right at home in Python. We encourage you to view the source code of pipe() . Row or column-wise function application # Arbitrary functions can be applied along the axes of a DataFrame using the apply() method, which, like the descriptive statistics methods, takes an optional axis argument: The apply() method will also dispatch on a string method name. The return type of the function passed to apply() affects the type of the final output from DataFrame.apply for the default behaviour: If the applied function returns a Series , the final output is a DataFrame . The columns match the index of the Series returned by the applied function. If the applied function returns any other type, the final output is a Series . This default behaviour can be overridden using the result_type , which accepts three options: reduce , broadcast , and expand . These will determine how list-likes return values expand (or not) to a DataFrame . apply() combined with some cleverness can be used to answer many questions about a data set. For example, suppose we wanted to extract the date where the maximum value for each column occurred: You may also pass additional arguments and keyword arguments to the apply() method. Another useful feature is the ability to pass Series methods to carry out some Series operation on each column or row: Finally, apply() takes an argument raw which is False by default, which converts each row or column into a Series before applying the function. When set to True, the passed function will instead receive an ndarray object, which has positive performance implications if you do not need the indexing functionality. Aggregation API # The aggregation API allows one to express possibly multiple aggregation operations in a single concise way. This API is similar across pandas objects, see groupby API , the window API , and the resample API . The entry point for aggregation is DataFrame.aggregate() , or the alias DataFrame.agg() . We will use a similar starting frame from above: Using a single function is equivalent to apply() . You can also pass named methods as strings. These will return a Series of the aggregated output: Single aggregations on a Series this will return a scalar value: Aggregating with multiple functions # You can pass multiple aggregation arguments as a list. The results of each of the passed functions will be a row in the resulting DataFrame . These are naturally named from the aggregation function. Multiple functions yield multiple rows: On a Series , multiple functions return a Series , indexed by the function names: Passing a lambda function will yield a <lambda> named row: Passing a named function will yield that name for the row: Aggregating with a dict # Passing a dictionary of column names to a scalar or a list of scalars, to DataFrame.agg allows you to customize which functions are applied to which columns. Note that the results are not in any particular order, you can use an OrderedDict instead to guarantee ordering. Passing a list-like will generate a DataFrame output. You will get a matrix-like output of all of the aggregators. The output will consist of all unique functions. Those that are not noted for a particular column will be NaN : Custom describe # With .agg() it is possible to easily create a custom describe function, similar to the built in describe function . Transform API # The transform() method returns an object that is indexed the same (same size) as the original. This API allows you to provide multiple operations at the same time rather than one-by-one. Its API is quite similar to the .agg API. We create a frame similar to the one used in the above sections. Transform the entire frame. .transform() allows input functions as: a NumPy function, a string function name or a user defined function. Here transform() received a single function; this is equivalent to a ufunc application. Passing a single function to .transform() with a Series will yield a single Series in return. Transform with multiple functions # Passing multiple functions will yield a column MultiIndexed DataFrame. The first level will be the original frame column names; the second level will be the names of the transforming functions. Passing multiple functions to a Series will yield a DataFrame. The resulting column names will be the transforming functions. Transforming with a dict # Passing a dict of functions will allow selective transforming per column. Passing a dict of lists will generate a MultiIndexed DataFrame with these selective transforms. Applying elementwise functions # Since not all functions can be vectorized (accept NumPy arrays and return another array or value), the methods map() on DataFrame and analogously map() on Series accept any Python function taking a single value and returning a single value. For example: Series.map() has an additional feature; it can be used to easily “link” or “map” values defined by a secondary series. This is closely related to merging/joining functionality : Reindexing and altering labels # reindex() is the fundamental data alignment method in pandas. It is used to implement nearly all other features relying on label-alignment functionality. To reindex means to conform the data to match a given set of labels along a particular axis. This accomplishes several things: Reorders the existing data to match a new set of labels Inserts missing value (NA) markers in label locations where no data for that label existed If specified, fill data for missing labels using logic (highly relevant to working with time series data) Here is a simple example: Here, the f label was not contained in the Series and hence appears as NaN in the result. With a DataFrame, you can simultaneously reindex the index and columns: Note that the Index objects containing the actual axis labels can be shared between objects. So if we have a Series and a DataFrame, the following can be done: This means that the reindexed Series’s index is the same Python object as the DataFrame’s index. DataFrame.reindex() also supports an “axis-style” calling convention, where you specify a single labels argument and the axis it applies to. See also MultiIndex / Advanced Indexing is an even more concise way of doing reindexing. Note When writing performance-sensitive code, there is a good reason to spend some time becoming a reindexing ninja: many operations are faster on pre-aligned data . Adding two unaligned DataFrames internally triggers a reindexing step. For exploratory analysis you will hardly notice the difference (because reindex has been heavily optimized), but when CPU cycles matter sprinkling a few explicit reindex calls here and there can have an impact. Reindexing to align with another object # You may wish to take an object and reindex its axes to be labeled the same as another object. While the syntax for this is straightforward albeit verbose, it is a common enough operation that the reindex_like() method is available to make this simpler: Aligning objects with each other with align # The align() method is the fastest way to simultaneously align two objects. It supports a join argument (related to joining and merging ): join='outer' : take the union of the indexes (default) join='left' : use the calling object’s index join='right' : use the passed object’s index join='inner' : intersect the indexes It returns a tuple with both of the reindexed Series: For DataFrames, the join method will be applied to both the index and the columns by default: You can also pass an axis option to only align on the specified axis: If you pass a Series to DataFrame.align() , you can choose to align both objects either on the DataFrame’s index or columns using the axis argument: Filling while reindexing # reindex() takes an optional parameter method which is a filling method chosen from the following table: We illustrate these fill methods on a simple Series: These methods require that the indexes are ordered increasing or decreasing. Note that the same result could have been achieved using ffill (except for method='nearest' ) or interpolate : reindex() will raise a ValueError if the index is not monotonically increasing or decreasing. fillna() and interpolate() will not perform any checks on the order of the index. Limits on filling while reindexing # The limit and tolerance arguments provide additional control over filling while reindexing. Limit specifies the maximum count of consecutive matches: In contrast, tolerance specifies the maximum distance between the index and indexer values: Notice that when used on a DatetimeIndex , TimedeltaIndex or PeriodIndex , tolerance will coerced into a Timedelta if possible. This allows you to specify tolerance with appropriate strings. Dropping labels from an axis # A method closely related to reindex is the drop() function. It removes a set of labels from an axis: Note that the following also works, but is a bit less obvious / clean: Renaming / mapping labels # The rename() method allows you to relabel an axis based on some mapping (a dict or Series) or an arbitrary function. If you pass a function, it must return a value when called with any of the labels (and must produce a set of unique values). A dict or Series can also be used: If the mapping doesn’t include a column/index label, it isn’t renamed. Note that extra labels in the mapping don’t throw an error. DataFrame.rename() also supports an “axis-style” calling convention, where you specify a single mapper and the axis to apply that mapping to. Finally, rename() also accepts a scalar or list-like for altering the Series.name attribute. The methods DataFrame.rename_axis() and Series.rename_axis() allow specific names of a MultiIndex to be changed (as opposed to the labels). Iteration # The behavior of basic iteration over pandas objects depends on the type. When iterating over a Series, it is regarded as array-like, and basic iteration produces the values. DataFrames follow the dict-like convention of iterating over the “keys” of the objects. In short, basic iteration ( for i in object ) produces: Series : values DataFrame : column labels Thus, for example, iterating over a DataFrame gives you the column names: pandas objects also have the dict-like items() method to iterate over the (key, value) pairs. To iterate over the rows of a DataFrame, you can use the following methods: iterrows() : Iterate over the rows of a DataFrame as (index, Series) pairs. This converts the rows to Series objects, which can change the dtypes and has some performance implications. itertuples() : Iterate over the rows of a DataFrame as namedtuples of the values. This is a lot faster than iterrows() , and is in most cases preferable to use to iterate over the values of a DataFrame. Warning Iterating through pandas objects is generally slow . In many cases, iterating manually over the rows is not needed and can be avoided with one of the following approaches: Look for a vectorized solution: many operations can be performed using built-in methods or NumPy functions, (boolean) indexing, … When you have a function that cannot work on the full DataFrame/Series at once, it is better to use apply() instead of iterating over the values. See the docs on function application . If you need to do iterative manipulations on the values but performance is important, consider writing the inner loop with cython or numba. See the enhancing performance section for some examples of this approach. Warning You should never modify something you are iterating over. This is not guaranteed to work in all cases. Depending on the data types, the iterator returns a copy and not a view, and writing to it will have no effect! For example, in the following case setting the value has no effect: items # Consistent with the dict-like interface, items() iterates through key-value pairs: Series : (index, scalar value) pairs DataFrame : (column, Series) pairs For example: iterrows # iterrows() allows you to iterate through the rows of a DataFrame as Series objects. It returns an iterator yielding each index value along with a Series containing the data in each row: Note Because iterrows() returns a Series for each row, it does not preserve dtypes across the rows (dtypes are preserved across columns for DataFrames). For example, All values in row , returned as a Series, are now upcasted to floats, also the original integer value in column x : To preserve dtypes while iterating over the rows, it is better to use itertuples() which returns namedtuples of the values and which is generally much faster than iterrows() . For instance, a contrived way to transpose the DataFrame would be: itertuples # The itertuples() method will return an iterator yielding a namedtuple for each row in the DataFrame. The first element of the tuple will be the row’s corresponding index value, while the remaining values are the row values. For instance: This method does not convert the row to a Series object; it merely returns the values inside a namedtuple. Therefore, itertuples() preserves the data type of the values and is generally faster as iterrows() . Note The column names will be renamed to positional names if they are invalid Python identifiers, repeated, or start with an underscore. With a large number of columns (>255), regular tuples are returned. .dt accessor # Series has an accessor to succinctly return datetime like properties for the values of the Series, if it is a datetime/period like Series. This will return a Series, indexed like the existing Series. This enables nice expressions like this: You can easily produces tz aware transformations: You can also chain these types of operations: You can also format datetime values as strings with Series.dt.strftime() which supports the same format as the standard strftime() . The .dt accessor works for period and timedelta dtypes. Note Series.dt will raise a TypeError if you access with a non-datetime-like values. Vectorized string methods # Series is equipped with a set of string processing methods that make it easy to operate on each element of the array. Perhaps most importantly, these methods exclude missing/NA values automatically. These are accessed via the Series’s str attribute and generally have names matching the equivalent (scalar) built-in string methods. For example: Powerful pattern-matching methods are provided as well, but note that pattern-matching generally uses regular expressions by default (and in some cases always uses them). Note Prior to pandas 1.0, string methods were only available on object -dtype Series . pandas 1.0 added the StringDtype which is dedicated to strings. See Text data types for more. Please see Vectorized String Methods for a complete description. Sorting # pandas supports three kinds of sorting: sorting by index labels, sorting by column values, and sorting by a combination of both. By index # The Series.sort_index() and DataFrame.sort_index() methods are used to sort a pandas object by its index levels. Sorting by index also supports a key parameter that takes a callable function to apply to the index being sorted. For MultiIndex objects, the key is applied per-level to the levels specified by level . For information on key sorting by value, see value sorting . By values # The Series.sort_values() method is used to sort a Series by its values. The DataFrame.sort_values() method is used to sort a DataFrame by its column or row values. The optional by parameter to DataFrame.sort_values() may used to specify one or more columns to use to determine the sorted order. The by parameter can take a list of column names, e.g.: These methods have special treatment of NA values via the na_position argument: Sorting also supports a key parameter that takes a callable function to apply to the values being sorted. key will be given the Series of values and should return a Series or array of the same shape with the transformed values. For DataFrame objects, the key is applied per column, so the key should still expect a Series and return a Series, e.g. The name or type of each column can be used to apply different functions to different columns. By indexes and values # Strings passed as the by parameter to DataFrame.sort_values() may refer to either columns or index level names. Sort by ‘second’ (index) and ‘A’ (column) Note If a string matches both a column name and an index level name then a warning is issued and the column takes precedence. This will result in an ambiguity error in a future version. searchsorted # Series has the searchsorted() method, which works similarly to numpy.ndarray.searchsorted() . smallest / largest values # Series has the nsmallest() and nlargest() methods which return the smallest or largest \(n\) values. For a large Series this can be much faster than sorting the entire Series and calling head(n) on the result. DataFrame also has the nlargest and nsmallest methods. Sorting by a MultiIndex column # You must be explicit about sorting when the column is a MultiIndex, and fully specify all levels to by . Copying # The copy() method on pandas objects copies the underlying data (though not the axis indexes, since they are immutable) and returns a new object. Note that it is seldom necessary to copy objects . For example, there are only a handful of ways to alter a DataFrame in-place : Inserting, deleting, or modifying a column. Assigning to the index or columns attributes. For homogeneous data, directly modifying the values via the values attribute or advanced indexing. To be clear, no pandas method has the side effect of modifying your data; almost every method returns a new object, leaving the original object untouched. If the data is modified, it is because you did so explicitly. dtypes # For the most part, pandas uses NumPy arrays and dtypes for Series or individual columns of a DataFrame. NumPy provides support for float , int , bool , timedelta64[ns] and datetime64[ns] (note that NumPy does not support timezone-aware datetimes). pandas and third-party libraries extend NumPy’s type system in a few places. This section describes the extensions pandas has made internally. See Extension types for how to write your own extension that works with pandas. See the ecosystem page for a list of third-party libraries that have implemented an extension. The following table lists all of pandas extension types. For methods requiring dtype arguments, strings can be specified as indicated. See the respective documentation sections for more on each type. pandas has two ways to store strings. object dtype, which can hold any Python object, including strings. StringDtype , which is dedicated to strings. Generally, we recommend using StringDtype . See Text data types for more. Finally, arbitrary objects may be stored using the object dtype, but should be avoided to the extent possible (for performance and interoperability with other libraries and methods. See object conversion ). A convenient dtypes attribute for DataFrame returns a Series with the data type of each column. On a Series object, use the dtype attribute. If a pandas object contains data with multiple dtypes in a single column , the dtype of the column will be chosen to accommodate all of the data types ( object is the most general). The number of columns of each type in a DataFrame can be found by calling DataFrame.dtypes.value_counts() . Numeric dtypes will propagate and can coexist in DataFrames. If a dtype is passed (either directly via the dtype keyword, a passed ndarray , or a passed Series ), then it will be preserved in DataFrame operations. Furthermore, different numeric dtypes will NOT be combined. The following example will give you a taste. defaults # By default integer types are int64 and float types are float64 , regardless of platform (32-bit or 64-bit). The following will all result in int64 dtypes. Note that Numpy will choose platform-dependent types when creating arrays. The following WILL result in int32 on 32-bit platform. upcasting # Types can potentially be upcasted when combined with other types, meaning they are promoted from the current type (e.g. int to float ). DataFrame.to_numpy() will return the lower-common-denominator of the dtypes, meaning the dtype that can accommodate ALL of the types in the resulting homogeneous dtyped NumPy array. This can force some upcasting . astype # You can use the astype() method to explicitly convert dtypes from one to another. These will by default return a copy, even if the dtype was unchanged (pass copy=False to change this behavior). In addition, they will raise an exception if the astype operation is invalid. Upcasting is always according to the NumPy rules. If two different dtypes are involved in an operation, then the more general one will be used as the result of the operation. Convert a subset of columns to a specified type using astype() . Convert certain columns to a specific dtype by passing a dict to astype() . Note When trying to convert a subset of columns to a specified type using astype() and loc() , upcasting occurs. loc() tries to fit in what we are assigning to the current dtypes, while [] will overwrite them taking the dtype from the right hand side. Therefore the following piece of code produces the unintended result. object conversion # pandas offers various functions to try to force conversion of types from the object dtype to other types. In cases where the data is already of the correct type, but stored in an object array, the DataFrame.infer_objects() and Series.infer_objects() methods can be used to soft convert to the correct type. Because the data was transposed the original inference stored all columns as object, which infer_objects will correct. The following functions are available for one dimensional object arrays or scalars to perform hard conversion of objects to a specified type: to_numeric() (conversion to numeric dtypes) to_datetime() (conversion to datetime objects) to_timedelta() (conversion to timedelta objects) To force a conversion, we can pass in an errors argument, which specifies how pandas should deal with elements that cannot be converted to desired dtype or object. By default, errors='raise' , meaning that any errors encountered will be raised during the conversion process. However, if errors='coerce' , these errors will be ignored and pandas will convert problematic elements to pd.NaT (for datetime and timedelta) or np.nan (for numeric). This might be useful if you are reading in data which is mostly of the desired dtype (e.g. numeric, datetime), but occasionally has non-conforming elements intermixed that you want to represent as missing: In addition to object conversion, to_numeric() provides another argument downcast , which gives the option of downcasting the newly (or already) numeric data to a smaller dtype, which can conserve memory: As these methods apply only to one-dimensional arrays, lists or scalars; they cannot be used directly on multi-dimensional objects such as DataFrames. However, with apply() , we can “apply” the function over each column efficiently: gotchas # Performing selection operations on integer type data can easily upcast the data to floating . The dtype of the input data will be preserved in cases where nans are not introduced. See also Support for integer NA . While float dtypes are unchanged. Selecting columns based on dtype # The select_dtypes() method implements subsetting of columns based on their dtype . First, let’s create a DataFrame with a slew of different dtypes: And the dtypes: select_dtypes() has two parameters include and exclude that allow you to say “give me the columns with these dtypes” ( include ) and/or “give the columns without these dtypes” ( exclude ). For example, to select bool columns: You can also pass the name of a dtype in the NumPy dtype hierarchy : select_dtypes() also works with generic dtypes as well. For example, to select all numeric and boolean columns while excluding unsigned integers: To select string columns you must use the object dtype: To see all the child dtypes of a generic dtype like numpy.number you can define a function that returns a tree of child dtypes: All NumPy dtypes are subclasses of numpy.generic : Note pandas also defines the types category , and datetime64[ns, tz] , which are not integrated into the normal NumPy hierarchy and won’t show up with the above function."
https://pandas.pydata.org/docs/user_guide/io.html,"IO tools (text, CSV, HDF5, …)","<article class=""bd-article"" role=""main"">
<section id=""io-tools-text-csv-hdf5"">
<span id=""io""></span><h1>IO tools (text, CSV, HDF5, …)<a class=""headerlink"" href=""#io-tools-text-csv-hdf5"" title=""Link to this heading"">#</a></h1>
<p>The pandas I/O API is a set of top level <code class=""docutils literal notranslate""><span class=""pre"">reader</span></code> functions accessed like
<a class=""reference internal"" href=""../reference/api/pandas.read_csv.html#pandas.read_csv"" title=""pandas.read_csv""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.read_csv()</span></code></a> that generally return a pandas object. The corresponding
<code class=""docutils literal notranslate""><span class=""pre"">writer</span></code> functions are object methods that are accessed like
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_csv.html#pandas.DataFrame.to_csv"" title=""pandas.DataFrame.to_csv""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.to_csv()</span></code></a>. Below is a table containing available <code class=""docutils literal notranslate""><span class=""pre"">readers</span></code> and
<code class=""docutils literal notranslate""><span class=""pre"">writers</span></code>.</p>

<p><a class=""reference internal"" href=""#io-perf""><span class=""std std-ref"">Here</span></a> is an informal performance comparison for some of these IO methods.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>For examples that use the <code class=""docutils literal notranslate""><span class=""pre"">StringIO</span></code> class, make sure you import it
with <code class=""docutils literal notranslate""><span class=""pre"">from</span> <span class=""pre"">io</span> <span class=""pre"">import</span> <span class=""pre"">StringIO</span></code> for Python 3.</p>
</div>
<section id=""csv-text-files"">
<span id=""io-read-csv-table""></span><h2>CSV &amp; text files<a class=""headerlink"" href=""#csv-text-files"" title=""Link to this heading"">#</a></h2>
<p>The workhorse function for reading text files (a.k.a. flat files) is
<a class=""reference internal"" href=""../reference/api/pandas.read_csv.html#pandas.read_csv"" title=""pandas.read_csv""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_csv()</span></code></a>. See the <a class=""reference internal"" href=""cookbook.html#cookbook-csv""><span class=""std std-ref"">cookbook</span></a> for some advanced strategies.</p>
<section id=""parsing-options"">
<h3>Parsing options<a class=""headerlink"" href=""#parsing-options"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.read_csv.html#pandas.read_csv"" title=""pandas.read_csv""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_csv()</span></code></a> accepts the following common arguments:</p>
<section id=""basic"">
<h4>Basic<a class=""headerlink"" href=""#basic"" title=""Link to this heading"">#</a></h4>
<dl>
<dt>filepath_or_buffer<span class=""classifier"">various</span></dt><dd><p>Either a path to a file (a <a class=""reference external"" href=""https://docs.python.org/3/library/stdtypes.html#str"" title=""(in Python v3.12)""><code class=""docutils literal notranslate""><span class=""pre"">str</span></code></a>, <a class=""reference external"" href=""https://docs.python.org/3/library/pathlib.html#pathlib.Path"" title=""(in Python v3.12)""><code class=""docutils literal notranslate""><span class=""pre"">pathlib.Path</span></code></a>,
or <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">py:py._path.local.LocalPath</span></code>), URL (including http, ftp, and S3
locations), or any object with a <code class=""docutils literal notranslate""><span class=""pre"">read()</span></code> method (such as an open file or
<a class=""reference external"" href=""https://docs.python.org/3/library/io.html#io.StringIO"" title=""(in Python v3.12)""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">StringIO</span></code></a>).</p>
</dd>
<dt>sep<span class=""classifier"">str, defaults to <code class=""docutils literal notranslate""><span class=""pre"">','</span></code> for <a class=""reference internal"" href=""../reference/api/pandas.read_csv.html#pandas.read_csv"" title=""pandas.read_csv""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_csv()</span></code></a>, <code class=""docutils literal notranslate""><span class=""pre"">\t</span></code> for <a class=""reference internal"" href=""../reference/api/pandas.read_table.html#pandas.read_table"" title=""pandas.read_table""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_table()</span></code></a></span></dt><dd><p>Delimiter to use. If sep is <code class=""docutils literal notranslate""><span class=""pre"">None</span></code>, the C engine cannot automatically detect
the separator, but the Python parsing engine can, meaning the latter will be
used and automatically detect the separator by Python’s builtin sniffer tool,
<a class=""reference external"" href=""https://docs.python.org/3/library/csv.html#csv.Sniffer"" title=""(in Python v3.12)""><code class=""docutils literal notranslate""><span class=""pre"">csv.Sniffer</span></code></a>. In addition, separators longer than 1 character and
different from <code class=""docutils literal notranslate""><span class=""pre"">'\s+'</span></code> will be interpreted as regular expressions and
will also force the use of the Python parsing engine. Note that regex
delimiters are prone to ignoring quoted data. Regex example: <code class=""docutils literal notranslate""><span class=""pre"">'\\r\\t'</span></code>.</p>
</dd>
<dt>delimiter<span class=""classifier"">str, default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>Alternative argument name for sep.</p>
</dd>
<dt>delim_whitespace<span class=""classifier"">boolean, default False</span></dt><dd><p>Specifies whether or not whitespace (e.g. <code class=""docutils literal notranslate""><span class=""pre"">'</span> <span class=""pre"">'</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">'\t'</span></code>)
will be used as the delimiter. Equivalent to setting <code class=""docutils literal notranslate""><span class=""pre"">sep='\s+'</span></code>.
If this option is set to <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>, nothing should be passed in for the
<code class=""docutils literal notranslate""><span class=""pre"">delimiter</span></code> parameter.</p>
</dd>
</dl>
</section>
<section id=""column-and-index-locations-and-names"">
<h4>Column and index locations and names<a class=""headerlink"" href=""#column-and-index-locations-and-names"" title=""Link to this heading"">#</a></h4>
<dl>
<dt>header<span class=""classifier"">int or list of ints, default <code class=""docutils literal notranslate""><span class=""pre"">'infer'</span></code></span></dt><dd><p>Row number(s) to use as the column names, and the start of the
data. Default behavior is to infer the column names: if no names are
passed the behavior is identical to <code class=""docutils literal notranslate""><span class=""pre"">header=0</span></code> and column names
are inferred from the first line of the file, if column names are
passed explicitly then the behavior is identical to
<code class=""docutils literal notranslate""><span class=""pre"">header=None</span></code>. Explicitly pass <code class=""docutils literal notranslate""><span class=""pre"">header=0</span></code> to be able to replace
existing names.</p>
<p>The header can be a list of ints that specify row locations
for a MultiIndex on the columns e.g. <code class=""docutils literal notranslate""><span class=""pre"">[0,1,3]</span></code>. Intervening rows
that are not specified will be skipped (e.g. 2 in this example is
skipped). Note that this parameter ignores commented lines and empty
lines if <code class=""docutils literal notranslate""><span class=""pre"">skip_blank_lines=True</span></code>, so header=0 denotes the first
line of data rather than the first line of the file.</p>
</dd>
<dt>names<span class=""classifier"">array-like, default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>List of column names to use. If file contains no header row, then you should
explicitly pass <code class=""docutils literal notranslate""><span class=""pre"">header=None</span></code>. Duplicates in this list are not allowed.</p>
</dd>
<dt>index_col<span class=""classifier"">int, str, sequence of int / str, or False, optional, default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>Column(s) to use as the row labels of the <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>, either given as
string name or column index. If a sequence of int / str is given, a
MultiIndex is used.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">index_col=False</span></code> can be used to force pandas to <em>not</em> use the first
column as the index, e.g. when you have a malformed file with delimiters at
the end of each line.</p>
</div>
<p>The default value of <code class=""docutils literal notranslate""><span class=""pre"">None</span></code> instructs pandas to guess. If the number of
fields in the column header row is equal to the number of fields in the body
of the data file, then a default index is used. If it is larger, then
the first columns are used as index so that the remaining number of fields in
the body are equal to the number of fields in the header.</p>
<p>The first row after the header is used to determine the number of columns,
which will go into the index. If the subsequent rows contain less columns
than the first row, they are filled with <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>.</p>
<p>This can be avoided through <code class=""docutils literal notranslate""><span class=""pre"">usecols</span></code>. This ensures that the columns are
taken as is and the trailing data are ignored.</p>
</dd>
<dt>usecols<span class=""classifier"">list-like or callable, default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>Return a subset of the columns. If list-like, all elements must either
be positional (i.e. integer indices into the document columns) or strings
that correspond to column names provided either by the user in <code class=""docutils literal notranslate""><span class=""pre"">names</span></code> or
inferred from the document header row(s). If <code class=""docutils literal notranslate""><span class=""pre"">names</span></code> are given, the document
header row(s) are not taken into account. For example, a valid list-like
<code class=""docutils literal notranslate""><span class=""pre"">usecols</span></code> parameter would be <code class=""docutils literal notranslate""><span class=""pre"">[0,</span> <span class=""pre"">1,</span> <span class=""pre"">2]</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">['foo',</span> <span class=""pre"">'bar',</span> <span class=""pre"">'baz']</span></code>.</p>
<p>Element order is ignored, so <code class=""docutils literal notranslate""><span class=""pre"">usecols=[0,</span> <span class=""pre"">1]</span></code> is the same as <code class=""docutils literal notranslate""><span class=""pre"">[1,</span> <span class=""pre"">0]</span></code>. To
instantiate a DataFrame from <code class=""docutils literal notranslate""><span class=""pre"">data</span></code> with element order preserved use
<code class=""docutils literal notranslate""><span class=""pre"">pd.read_csv(data,</span> <span class=""pre"">usecols=['foo',</span> <span class=""pre"">'bar'])[['foo',</span> <span class=""pre"">'bar']]</span></code> for columns
in <code class=""docutils literal notranslate""><span class=""pre"">['foo',</span> <span class=""pre"">'bar']</span></code> order or
<code class=""docutils literal notranslate""><span class=""pre"">pd.read_csv(data,</span> <span class=""pre"">usecols=['foo',</span> <span class=""pre"">'bar'])[['bar',</span> <span class=""pre"">'foo']]</span></code> for
<code class=""docutils literal notranslate""><span class=""pre"">['bar',</span> <span class=""pre"">'foo']</span></code> order.</p>
<p>If callable, the callable function will be evaluated against the column names,
returning names where the callable function evaluates to True:</p>

<p>Using this parameter results in much faster parsing time and lower memory usage
when using the c engine. The Python engine loads the data first before deciding
which columns to drop.</p>
</dd>
</dl>
</section>
<section id=""general-parsing-configuration"">
<h4>General parsing configuration<a class=""headerlink"" href=""#general-parsing-configuration"" title=""Link to this heading"">#</a></h4>
<dl>
<dt>dtype<span class=""classifier"">Type name or dict of column -&gt; type, default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>Data type for data or columns. E.g. <code class=""docutils literal notranslate""><span class=""pre"">{'a':</span> <span class=""pre"">np.float64,</span> <span class=""pre"">'b':</span> <span class=""pre"">np.int32,</span> <span class=""pre"">'c':</span> <span class=""pre"">'Int64'}</span></code>
Use <code class=""docutils literal notranslate""><span class=""pre"">str</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> together with suitable <code class=""docutils literal notranslate""><span class=""pre"">na_values</span></code> settings to preserve
and not interpret dtype. If converters are specified, they will be applied INSTEAD
of dtype conversion.</p>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.5.0: </span>Support for defaultdict was added. Specify a defaultdict as input where
the default determines the dtype of the columns which are not explicitly
listed.</p>
</div>
</dd>
<dt>dtype_backend<span class=""classifier"">{“numpy_nullable”, “pyarrow”}, defaults to NumPy backed DataFrames</span></dt><dd><p>Which dtype_backend to use, e.g. whether a DataFrame should have NumPy
arrays, nullable dtypes are used for all dtypes that have a nullable
implementation when “numpy_nullable” is set, pyarrow is used for all
dtypes if “pyarrow” is set.</p>
<p>The dtype_backends are still experimential.</p>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 2.0.</span></p>
</div>
</dd>
<dt>engine<span class=""classifier"">{<code class=""docutils literal notranslate""><span class=""pre"">'c'</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">'python'</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">'pyarrow'</span></code>}</span></dt><dd><p>Parser engine to use. The C and pyarrow engines are faster, while the python engine
is currently more feature-complete. Multithreading is currently only supported by
the pyarrow engine.</p>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.4.0: </span>The “pyarrow” engine was added as an <em>experimental</em> engine, and some features
are unsupported, or may not work correctly, with this engine.</p>
</div>
</dd>
<dt>converters<span class=""classifier"">dict, default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>Dict of functions for converting values in certain columns. Keys can either be
integers or column labels.</p>
</dd>
<dt>true_values<span class=""classifier"">list, default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>Values to consider as <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>.</p>
</dd>
<dt>false_values<span class=""classifier"">list, default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>Values to consider as <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>.</p>
</dd>
<dt>skipinitialspace<span class=""classifier"">boolean, default <code class=""docutils literal notranslate""><span class=""pre"">False</span></code></span></dt><dd><p>Skip spaces after delimiter.</p>
</dd>
<dt>skiprows<span class=""classifier"">list-like or integer, default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>Line numbers to skip (0-indexed) or number of lines to skip (int) at the start
of the file.</p>
<p>If callable, the callable function will be evaluated against the row
indices, returning True if the row should be skipped and False otherwise:</p>

</dd>
<dt>skipfooter<span class=""classifier"">int, default <code class=""docutils literal notranslate""><span class=""pre"">0</span></code></span></dt><dd><p>Number of lines at bottom of file to skip (unsupported with engine=’c’).</p>
</dd>
<dt>nrows<span class=""classifier"">int, default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>Number of rows of file to read. Useful for reading pieces of large files.</p>
</dd>
<dt>low_memory<span class=""classifier"">boolean, default <code class=""docutils literal notranslate""><span class=""pre"">True</span></code></span></dt><dd><p>Internally process the file in chunks, resulting in lower memory use
while parsing, but possibly mixed type inference. To ensure no mixed
types either set <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>, or specify the type with the <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code> parameter.
Note that the entire file is read into a single <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> regardless,
use the <code class=""docutils literal notranslate""><span class=""pre"">chunksize</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">iterator</span></code> parameter to return the data in chunks.
(Only valid with C parser)</p>
</dd>
<dt>memory_map<span class=""classifier"">boolean, default False</span></dt><dd><p>If a filepath is provided for <code class=""docutils literal notranslate""><span class=""pre"">filepath_or_buffer</span></code>, map the file object
directly onto memory and access the data directly from there. Using this
option can improve performance because there is no longer any I/O overhead.</p>
</dd>
</dl>
</section>
<section id=""na-and-missing-data-handling"">
<h4>NA and missing data handling<a class=""headerlink"" href=""#na-and-missing-data-handling"" title=""Link to this heading"">#</a></h4>
<dl>
<dt>na_values<span class=""classifier"">scalar, str, list-like, or dict, default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>Additional strings to recognize as NA/NaN. If dict passed, specific per-column
NA values. See <a class=""reference internal"" href=""#io-navaluesconst""><span class=""std std-ref"">na values const</span></a> below
for a list of the values interpreted as NaN by default.</p>
</dd>
<dt>keep_default_na<span class=""classifier"">boolean, default <code class=""docutils literal notranslate""><span class=""pre"">True</span></code></span></dt><dd><p>Whether or not to include the default NaN values when parsing the data.
Depending on whether <code class=""docutils literal notranslate""><span class=""pre"">na_values</span></code> is passed in, the behavior is as follows:</p>
<ul class=""simple"">
<li><p>If <code class=""docutils literal notranslate""><span class=""pre"">keep_default_na</span></code> is <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">na_values</span></code> are specified, <code class=""docutils literal notranslate""><span class=""pre"">na_values</span></code>
is appended to the default NaN values used for parsing.</p></li>
<li><p>If <code class=""docutils literal notranslate""><span class=""pre"">keep_default_na</span></code> is <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">na_values</span></code> are not specified, only
the default NaN values are used for parsing.</p></li>
<li><p>If <code class=""docutils literal notranslate""><span class=""pre"">keep_default_na</span></code> is <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">na_values</span></code> are specified, only
the NaN values specified <code class=""docutils literal notranslate""><span class=""pre"">na_values</span></code> are used for parsing.</p></li>
<li><p>If <code class=""docutils literal notranslate""><span class=""pre"">keep_default_na</span></code> is <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">na_values</span></code> are not specified, no
strings will be parsed as NaN.</p></li>
</ul>
<p>Note that if <code class=""docutils literal notranslate""><span class=""pre"">na_filter</span></code> is passed in as <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>, the <code class=""docutils literal notranslate""><span class=""pre"">keep_default_na</span></code> and
<code class=""docutils literal notranslate""><span class=""pre"">na_values</span></code> parameters will be ignored.</p>
</dd>
<dt>na_filter<span class=""classifier"">boolean, default <code class=""docutils literal notranslate""><span class=""pre"">True</span></code></span></dt><dd><p>Detect missing value markers (empty strings and the value of na_values). In
data without any NAs, passing <code class=""docutils literal notranslate""><span class=""pre"">na_filter=False</span></code> can improve the performance
of reading a large file.</p>
</dd>
<dt>verbose<span class=""classifier"">boolean, default <code class=""docutils literal notranslate""><span class=""pre"">False</span></code></span></dt><dd><p>Indicate number of NA values placed in non-numeric columns.</p>
</dd>
<dt>skip_blank_lines<span class=""classifier"">boolean, default <code class=""docutils literal notranslate""><span class=""pre"">True</span></code></span></dt><dd><p>If <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>, skip over blank lines rather than interpreting as NaN values.</p>
</dd>
</dl>
</section>
<section id=""datetime-handling"">
<span id=""io-read-csv-table-datetime""></span><h4>Datetime handling<a class=""headerlink"" href=""#datetime-handling"" title=""Link to this heading"">#</a></h4>
<dl>
<dt>parse_dates<span class=""classifier"">boolean or list of ints or names or list of lists or dict, default <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>.</span></dt><dd><ul class=""simple"">
<li><p>If <code class=""docutils literal notranslate""><span class=""pre"">True</span></code> -&gt; try parsing the index.</p></li>
<li><p>If <code class=""docutils literal notranslate""><span class=""pre"">[1,</span> <span class=""pre"">2,</span> <span class=""pre"">3]</span></code> -&gt; try parsing columns 1, 2, 3 each as a separate date
column.</p></li>
<li><p>If <code class=""docutils literal notranslate""><span class=""pre"">[[1,</span> <span class=""pre"">3]]</span></code> -&gt; combine columns 1 and 3 and parse as a single date
column.</p></li>
<li><p>If <code class=""docutils literal notranslate""><span class=""pre"">{'foo':</span> <span class=""pre"">[1,</span> <span class=""pre"">3]}</span></code> -&gt; parse columns 1, 3 as date and call result ‘foo’.</p></li>
</ul>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>A fast-path exists for iso8601-formatted dates.</p>
</div>
</dd>
<dt>infer_datetime_format<span class=""classifier"">boolean, default <code class=""docutils literal notranslate""><span class=""pre"">False</span></code></span></dt><dd><p>If <code class=""docutils literal notranslate""><span class=""pre"">True</span></code> and parse_dates is enabled for a column, attempt to infer the
datetime format to speed up the processing.</p>
<div class=""deprecated"">
<p><span class=""versionmodified deprecated"">Deprecated since version 2.0.0: </span>A strict version of this argument is now the default, passing it has no effect.</p>
</div>
</dd>
<dt>keep_date_col<span class=""classifier"">boolean, default <code class=""docutils literal notranslate""><span class=""pre"">False</span></code></span></dt><dd><p>If <code class=""docutils literal notranslate""><span class=""pre"">True</span></code> and parse_dates specifies combining multiple columns then keep the
original columns.</p>
</dd>
<dt>date_parser<span class=""classifier"">function, default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>Function to use for converting a sequence of string columns to an array of
datetime instances. The default uses <code class=""docutils literal notranslate""><span class=""pre"">dateutil.parser.parser</span></code> to do the
conversion. pandas will try to call date_parser in three different ways,
advancing to the next if an exception occurs: 1) Pass one or more arrays (as
defined by parse_dates) as arguments; 2) concatenate (row-wise) the string
values from the columns defined by parse_dates into a single array and pass
that; and 3) call date_parser once for each row using one or more strings
(corresponding to the columns defined by parse_dates) as arguments.</p>
<div class=""deprecated"">
<p><span class=""versionmodified deprecated"">Deprecated since version 2.0.0: </span>Use <code class=""docutils literal notranslate""><span class=""pre"">date_format</span></code> instead, or read in as <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> and then apply
<a class=""reference internal"" href=""../reference/api/pandas.to_datetime.html#pandas.to_datetime"" title=""pandas.to_datetime""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">to_datetime()</span></code></a> as-needed.</p>
</div>
</dd>
<dt>date_format<span class=""classifier"">str or dict of column -&gt; format, default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>If used in conjunction with <code class=""docutils literal notranslate""><span class=""pre"">parse_dates</span></code>, will parse dates according to this
format. For anything more complex,
please read in as <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> and then apply <a class=""reference internal"" href=""../reference/api/pandas.to_datetime.html#pandas.to_datetime"" title=""pandas.to_datetime""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">to_datetime()</span></code></a> as-needed.</p>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 2.0.0.</span></p>
</div>
</dd>
<dt>dayfirst<span class=""classifier"">boolean, default <code class=""docutils literal notranslate""><span class=""pre"">False</span></code></span></dt><dd><p>DD/MM format dates, international and European format.</p>
</dd>
<dt>cache_dates<span class=""classifier"">boolean, default True</span></dt><dd><p>If True, use a cache of unique, converted dates to apply the datetime
conversion. May produce significant speed-up when parsing duplicate
date strings, especially ones with timezone offsets.</p>
</dd>
</dl>
</section>
<section id=""iteration"">
<h4>Iteration<a class=""headerlink"" href=""#iteration"" title=""Link to this heading"">#</a></h4>
<dl>
<dt>iterator<span class=""classifier"">boolean, default <code class=""docutils literal notranslate""><span class=""pre"">False</span></code></span></dt><dd><p>Return <code class=""docutils literal notranslate""><span class=""pre"">TextFileReader</span></code> object for iteration or getting chunks with
<code class=""docutils literal notranslate""><span class=""pre"">get_chunk()</span></code>.</p>
</dd>
<dt>chunksize<span class=""classifier"">int, default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>Return <code class=""docutils literal notranslate""><span class=""pre"">TextFileReader</span></code> object for iteration. See <a class=""reference internal"" href=""#io-chunking""><span class=""std std-ref"">iterating and chunking</span></a> below.</p>
</dd>
</dl>
</section>
<section id=""quoting-compression-and-file-format"">
<h4>Quoting, compression, and file format<a class=""headerlink"" href=""#quoting-compression-and-file-format"" title=""Link to this heading"">#</a></h4>
<dl>
<dt>compression<span class=""classifier"">{<code class=""docutils literal notranslate""><span class=""pre"">'infer'</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">'gzip'</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">'bz2'</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">'zip'</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">'xz'</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">'zstd'</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">None</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">dict</span></code>}, default <code class=""docutils literal notranslate""><span class=""pre"">'infer'</span></code></span></dt><dd><p>For on-the-fly decompression of on-disk data. If ‘infer’, then use gzip,
bz2, zip, xz, or zstandard if <code class=""docutils literal notranslate""><span class=""pre"">filepath_or_buffer</span></code> is path-like ending in ‘.gz’, ‘.bz2’,
‘.zip’, ‘.xz’, ‘.zst’, respectively, and no decompression otherwise. If using ‘zip’,
the ZIP file must contain only one data file to be read in.
Set to <code class=""docutils literal notranslate""><span class=""pre"">None</span></code> for no decompression. Can also be a dict with key <code class=""docutils literal notranslate""><span class=""pre"">'method'</span></code>
set to one of {<code class=""docutils literal notranslate""><span class=""pre"">'zip'</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">'gzip'</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">'bz2'</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">'zstd'</span></code>} and other key-value pairs are
forwarded to <code class=""docutils literal notranslate""><span class=""pre"">zipfile.ZipFile</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">gzip.GzipFile</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">bz2.BZ2File</span></code>, or <code class=""docutils literal notranslate""><span class=""pre"">zstandard.ZstdDecompressor</span></code>.
As an example, the following could be passed for faster compression and to
create a reproducible gzip archive:
<code class=""docutils literal notranslate""><span class=""pre"">compression={'method':</span> <span class=""pre"">'gzip',</span> <span class=""pre"">'compresslevel':</span> <span class=""pre"">1,</span> <span class=""pre"">'mtime':</span> <span class=""pre"">1}</span></code>.</p>
<div class=""versionchanged"">
<p><span class=""versionmodified changed"">Changed in version 1.2.0: </span>Previous versions forwarded dict entries for ‘gzip’ to <code class=""docutils literal notranslate""><span class=""pre"">gzip.open</span></code>.</p>
</div>
</dd>
<dt>thousands<span class=""classifier"">str, default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>Thousands separator.</p>
</dd>
<dt>decimal<span class=""classifier"">str, default <code class=""docutils literal notranslate""><span class=""pre"">'.'</span></code></span></dt><dd><p>Character to recognize as decimal point. E.g. use <code class=""docutils literal notranslate""><span class=""pre"">','</span></code> for European data.</p>
</dd>
<dt>float_precision<span class=""classifier"">string, default None</span></dt><dd><p>Specifies which converter the C engine should use for floating-point values.
The options are <code class=""docutils literal notranslate""><span class=""pre"">None</span></code> for the ordinary converter, <code class=""docutils literal notranslate""><span class=""pre"">high</span></code> for the
high-precision converter, and <code class=""docutils literal notranslate""><span class=""pre"">round_trip</span></code> for the round-trip converter.</p>
</dd>
<dt>lineterminator<span class=""classifier"">str (length 1), default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>Character to break file into lines. Only valid with C parser.</p>
</dd>
<dt>quotechar<span class=""classifier"">str (length 1)</span></dt><dd><p>The character used to denote the start and end of a quoted item. Quoted items
can include the delimiter and it will be ignored.</p>
</dd>
<dt>quoting<span class=""classifier"">int or <code class=""docutils literal notranslate""><span class=""pre"">csv.QUOTE_*</span></code> instance, default <code class=""docutils literal notranslate""><span class=""pre"">0</span></code></span></dt><dd><p>Control field quoting behavior per <code class=""docutils literal notranslate""><span class=""pre"">csv.QUOTE_*</span></code> constants. Use one of
<code class=""docutils literal notranslate""><span class=""pre"">QUOTE_MINIMAL</span></code> (0), <code class=""docutils literal notranslate""><span class=""pre"">QUOTE_ALL</span></code> (1), <code class=""docutils literal notranslate""><span class=""pre"">QUOTE_NONNUMERIC</span></code> (2) or
<code class=""docutils literal notranslate""><span class=""pre"">QUOTE_NONE</span></code> (3).</p>
</dd>
<dt>doublequote<span class=""classifier"">boolean, default <code class=""docutils literal notranslate""><span class=""pre"">True</span></code></span></dt><dd><p>When <code class=""docutils literal notranslate""><span class=""pre"">quotechar</span></code> is specified and <code class=""docutils literal notranslate""><span class=""pre"">quoting</span></code> is not <code class=""docutils literal notranslate""><span class=""pre"">QUOTE_NONE</span></code>,
indicate whether or not to interpret two consecutive <code class=""docutils literal notranslate""><span class=""pre"">quotechar</span></code> elements
<strong>inside</strong> a field as a single <code class=""docutils literal notranslate""><span class=""pre"">quotechar</span></code> element.</p>
</dd>
<dt>escapechar<span class=""classifier"">str (length 1), default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>One-character string used to escape delimiter when quoting is <code class=""docutils literal notranslate""><span class=""pre"">QUOTE_NONE</span></code>.</p>
</dd>
<dt>comment<span class=""classifier"">str, default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>Indicates remainder of line should not be parsed. If found at the beginning of
a line, the line will be ignored altogether. This parameter must be a single
character. Like empty lines (as long as <code class=""docutils literal notranslate""><span class=""pre"">skip_blank_lines=True</span></code>), fully
commented lines are ignored by the parameter <code class=""docutils literal notranslate""><span class=""pre"">header</span></code> but not by <code class=""docutils literal notranslate""><span class=""pre"">skiprows</span></code>.
For example, if <code class=""docutils literal notranslate""><span class=""pre"">comment='#'</span></code>, parsing ‘#empty\na,b,c\n1,2,3’ with
<code class=""docutils literal notranslate""><span class=""pre"">header=0</span></code> will result in ‘a,b,c’ being treated as the header.</p>
</dd>
<dt>encoding<span class=""classifier"">str, default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>Encoding to use for UTF when reading/writing (e.g. <code class=""docutils literal notranslate""><span class=""pre"">'utf-8'</span></code>). <a class=""reference external"" href=""https://docs.python.org/3/library/codecs.html#standard-encodings"">List of
Python standard encodings</a>.</p>
</dd>
<dt>dialect<span class=""classifier"">str or <a class=""reference external"" href=""https://docs.python.org/3/library/csv.html#csv.Dialect"" title=""(in Python v3.12)""><code class=""docutils literal notranslate""><span class=""pre"">csv.Dialect</span></code></a> instance, default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></span></dt><dd><p>If provided, this parameter will override values (default or not) for the
following parameters: <code class=""docutils literal notranslate""><span class=""pre"">delimiter</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">doublequote</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">escapechar</span></code>,
<code class=""docutils literal notranslate""><span class=""pre"">skipinitialspace</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">quotechar</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">quoting</span></code>. If it is necessary to
override values, a ParserWarning will be issued. See <a class=""reference external"" href=""https://docs.python.org/3/library/csv.html#csv.Dialect"" title=""(in Python v3.12)""><code class=""docutils literal notranslate""><span class=""pre"">csv.Dialect</span></code></a>
documentation for more details.</p>
</dd>
</dl>
</section>
<section id=""error-handling"">
<h4>Error handling<a class=""headerlink"" href=""#error-handling"" title=""Link to this heading"">#</a></h4>
<dl>
<dt>on_bad_lines<span class=""classifier"">(‘error’, ‘warn’, ‘skip’), default ‘error’</span></dt><dd><p>Specifies what to do upon encountering a bad line (a line with too many fields).
Allowed values are :</p>
<ul class=""simple"">
<li><p>‘error’, raise an ParserError when a bad line is encountered.</p></li>
<li><p>‘warn’, print a warning when a bad line is encountered and skip that line.</p></li>
<li><p>‘skip’, skip bad lines without raising or warning when they are encountered.</p></li>
</ul>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.3.0.</span></p>
</div>
</dd>
</dl>
</section>
</section>
<section id=""specifying-column-data-types"">
<span id=""io-dtypes""></span><h3>Specifying column data types<a class=""headerlink"" href=""#specifying-column-data-types"" title=""Link to this heading"">#</a></h3>
<p>You can indicate the data type for the whole <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> or individual
columns:</p>

<p>Fortunately, pandas offers more than one way to ensure that your column(s)
contain only one <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code>. If you’re unfamiliar with these concepts, you can
see <a class=""reference internal"" href=""basics.html#basics-dtypes""><span class=""std std-ref"">here</span></a> to learn more about dtypes, and
<a class=""reference internal"" href=""basics.html#basics-object-conversion""><span class=""std std-ref"">here</span></a> to learn more about <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> conversion in
pandas.</p>
<p>For instance, you can use the <code class=""docutils literal notranslate""><span class=""pre"">converters</span></code> argument
of <a class=""reference internal"" href=""../reference/api/pandas.read_csv.html#pandas.read_csv"" title=""pandas.read_csv""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_csv()</span></code></a>:</p>

<p>Or you can use the <a class=""reference internal"" href=""../reference/api/pandas.to_numeric.html#pandas.to_numeric"" title=""pandas.to_numeric""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">to_numeric()</span></code></a> function to coerce the
dtypes after reading in the data,</p>

<p>which will convert all valid parsing to floats, leaving the invalid parsing
as <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>.</p>
<p>Ultimately, how you deal with reading in columns containing mixed dtypes
depends on your specific needs. In the case above, if you wanted to <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code> out
the data anomalies, then <a class=""reference internal"" href=""../reference/api/pandas.to_numeric.html#pandas.to_numeric"" title=""pandas.to_numeric""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">to_numeric()</span></code></a> is probably your best option.
However, if you wanted for all the data to be coerced, no matter the type, then
using the <code class=""docutils literal notranslate""><span class=""pre"">converters</span></code> argument of <a class=""reference internal"" href=""../reference/api/pandas.read_csv.html#pandas.read_csv"" title=""pandas.read_csv""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_csv()</span></code></a> would certainly be
worth trying.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>In some cases, reading in abnormal data with columns containing mixed dtypes
will result in an inconsistent dataset. If you rely on pandas to infer the
dtypes of your columns, the parsing engine will go and infer the dtypes for
different chunks of the data, rather than the whole dataset at once. Consequently,
you can end up with column(s) with mixed dtypes. For example,</p>

<p>will result with <code class=""docutils literal notranslate""><span class=""pre"">mixed_df</span></code> containing an <code class=""docutils literal notranslate""><span class=""pre"">int</span></code> dtype for certain chunks
of the column, and <code class=""docutils literal notranslate""><span class=""pre"">str</span></code> for others due to the mixed dtypes from the
data that was read in. It is important to note that the overall column will be
marked with a <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code> of <code class=""docutils literal notranslate""><span class=""pre"">object</span></code>, which is used for columns with mixed dtypes.</p>
</div>
<p>Setting <code class=""docutils literal notranslate""><span class=""pre"">dtype_backend=""numpy_nullable""</span></code> will result in nullable dtypes for every column.</p>

</section>
<section id=""specifying-categorical-dtype"">
<span id=""io-categorical""></span><h3>Specifying categorical dtype<a class=""headerlink"" href=""#specifying-categorical-dtype"" title=""Link to this heading"">#</a></h3>
<p><code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> columns can be parsed directly by specifying <code class=""docutils literal notranslate""><span class=""pre"">dtype='category'</span></code> or
<code class=""docutils literal notranslate""><span class=""pre"">dtype=CategoricalDtype(categories,</span> <span class=""pre"">ordered)</span></code>.</p>

<p>Individual columns can be parsed as a <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> using a dict
specification:</p>

<p>Specifying <code class=""docutils literal notranslate""><span class=""pre"">dtype='category'</span></code> will result in an unordered <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code>
whose <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code> are the unique values observed in the data. For more
control on the categories and order, create a
<code class=""xref py py-class docutils literal notranslate""><span class=""pre"">CategoricalDtype</span></code> ahead of time, and pass that for
that column’s <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code>.</p>

<p>When using <code class=""docutils literal notranslate""><span class=""pre"">dtype=CategoricalDtype</span></code>, “unexpected” values outside of
<code class=""docutils literal notranslate""><span class=""pre"">dtype.categories</span></code> are treated as missing values.</p>

<p>This matches the behavior of <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Categorical.set_categories()</span></code>.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>With <code class=""docutils literal notranslate""><span class=""pre"">dtype='category'</span></code>, the resulting categories will always be parsed
as strings (object dtype). If the categories are numeric they can be
converted using the <a class=""reference internal"" href=""../reference/api/pandas.to_numeric.html#pandas.to_numeric"" title=""pandas.to_numeric""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">to_numeric()</span></code></a> function, or as appropriate, another
converter such as <a class=""reference internal"" href=""../reference/api/pandas.to_datetime.html#pandas.to_datetime"" title=""pandas.to_datetime""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">to_datetime()</span></code></a>.</p>
<p>When <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code> is a <code class=""docutils literal notranslate""><span class=""pre"">CategoricalDtype</span></code> with homogeneous <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code> (
all numeric, all datetimes, etc.), the conversion is done automatically.</p>

</div>
</section>
<section id=""naming-and-using-columns"">
<h3>Naming and using columns<a class=""headerlink"" href=""#naming-and-using-columns"" title=""Link to this heading"">#</a></h3>
<section id=""handling-column-names"">
<span id=""io-headers""></span><h4>Handling column names<a class=""headerlink"" href=""#handling-column-names"" title=""Link to this heading"">#</a></h4>
<p>A file may or may not have a header row. pandas assumes the first row should be
used as the column names:</p>

<p>By specifying the <code class=""docutils literal notranslate""><span class=""pre"">names</span></code> argument in conjunction with <code class=""docutils literal notranslate""><span class=""pre"">header</span></code> you can
indicate other names to use and whether or not to throw away the header row (if
any):</p>

<p>If the header is in a row other than the first, pass the row number to
<code class=""docutils literal notranslate""><span class=""pre"">header</span></code>. This will skip the preceding rows:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Default behavior is to infer the column names: if no names are
passed the behavior is identical to <code class=""docutils literal notranslate""><span class=""pre"">header=0</span></code> and column names
are inferred from the first non-blank line of the file, if column
names are passed explicitly then the behavior is identical to
<code class=""docutils literal notranslate""><span class=""pre"">header=None</span></code>.</p>
</div>
</section>
</section>
<section id=""duplicate-names-parsing"">
<span id=""io-dupe-names""></span><h3>Duplicate names parsing<a class=""headerlink"" href=""#duplicate-names-parsing"" title=""Link to this heading"">#</a></h3>
<p>If the file or header contains duplicate names, pandas will by default
distinguish between them so as to prevent overwriting data:</p>

<p>There is no more duplicate data because duplicate columns ‘X’, …, ‘X’ become
‘X’, ‘X.1’, …, ‘X.N’.</p>
<section id=""filtering-columns-usecols"">
<span id=""io-usecols""></span><h4>Filtering columns (<code class=""docutils literal notranslate""><span class=""pre"">usecols</span></code>)<a class=""headerlink"" href=""#filtering-columns-usecols"" title=""Link to this heading"">#</a></h4>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">usecols</span></code> argument allows you to select any subset of the columns in a
file, either using the column names, position numbers or a callable:</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">usecols</span></code> argument can also be used to specify which columns not to
use in the final result:</p>

<p>In this case, the callable is specifying that we exclude the “a” and “c”
columns from the output.</p>
</section>
</section>
<section id=""comments-and-empty-lines"">
<h3>Comments and empty lines<a class=""headerlink"" href=""#comments-and-empty-lines"" title=""Link to this heading"">#</a></h3>
<section id=""ignoring-line-comments-and-empty-lines"">
<span id=""io-skiplines""></span><h4>Ignoring line comments and empty lines<a class=""headerlink"" href=""#ignoring-line-comments-and-empty-lines"" title=""Link to this heading"">#</a></h4>
<p>If the <code class=""docutils literal notranslate""><span class=""pre"">comment</span></code> parameter is specified, then completely commented lines will
be ignored. By default, completely blank lines will be ignored as well.</p>

<p>If <code class=""docutils literal notranslate""><span class=""pre"">skip_blank_lines=False</span></code>, then <code class=""docutils literal notranslate""><span class=""pre"">read_csv</span></code> will not ignore blank lines:</p>

<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>The presence of ignored lines might create ambiguities involving line numbers;
the parameter <code class=""docutils literal notranslate""><span class=""pre"">header</span></code> uses row numbers (ignoring commented/empty
lines), while <code class=""docutils literal notranslate""><span class=""pre"">skiprows</span></code> uses line numbers (including commented/empty lines):</p>

<p>If both <code class=""docutils literal notranslate""><span class=""pre"">header</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">skiprows</span></code> are specified, <code class=""docutils literal notranslate""><span class=""pre"">header</span></code> will be
relative to the end of <code class=""docutils literal notranslate""><span class=""pre"">skiprows</span></code>. For example:</p>
</div>

</section>
<section id=""comments"">
<span id=""io-comments""></span><h4>Comments<a class=""headerlink"" href=""#comments"" title=""Link to this heading"">#</a></h4>
<p>Sometimes comments or meta data may be included in a file:</p>

<p>By default, the parser includes the comments in the output:</p>

<p>We can suppress the comments using the <code class=""docutils literal notranslate""><span class=""pre"">comment</span></code> keyword:</p>

</section>
</section>
<section id=""dealing-with-unicode-data"">
<span id=""io-unicode""></span><h3>Dealing with Unicode data<a class=""headerlink"" href=""#dealing-with-unicode-data"" title=""Link to this heading"">#</a></h3>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">encoding</span></code> argument should be used for encoded unicode data, which will
result in byte strings being decoded to unicode in the result:</p>

<p>Some formats which encode all characters as multiple bytes, like UTF-16, won’t
parse correctly at all without specifying the encoding. <a class=""reference external"" href=""https://docs.python.org/3/library/codecs.html#standard-encodings"">Full list of Python
standard encodings</a>.</p>
</section>
<section id=""index-columns-and-trailing-delimiters"">
<span id=""io-index-col""></span><h3>Index columns and trailing delimiters<a class=""headerlink"" href=""#index-columns-and-trailing-delimiters"" title=""Link to this heading"">#</a></h3>
<p>If a file has one more column of data than the number of column names, the
first column will be used as the <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>’s row names:</p>


<p>Ordinarily, you can achieve this behavior using the <code class=""docutils literal notranslate""><span class=""pre"">index_col</span></code> option.</p>
<p>There are some exception cases when a file has been prepared with delimiters at
the end of each data line, confusing the parser. To explicitly disable the
index column inference and discard the last column, pass <code class=""docutils literal notranslate""><span class=""pre"">index_col=False</span></code>:</p>

<p>If a subset of data is being parsed using the <code class=""docutils literal notranslate""><span class=""pre"">usecols</span></code> option, the
<code class=""docutils literal notranslate""><span class=""pre"">index_col</span></code> specification is based on that subset, not the original data.</p>

</section>
<section id=""date-handling"">
<span id=""io-parse-dates""></span><h3>Date Handling<a class=""headerlink"" href=""#date-handling"" title=""Link to this heading"">#</a></h3>
<section id=""specifying-date-columns"">
<h4>Specifying date columns<a class=""headerlink"" href=""#specifying-date-columns"" title=""Link to this heading"">#</a></h4>
<p>To better facilitate working with datetime data, <a class=""reference internal"" href=""../reference/api/pandas.read_csv.html#pandas.read_csv"" title=""pandas.read_csv""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_csv()</span></code></a>
uses the keyword arguments <code class=""docutils literal notranslate""><span class=""pre"">parse_dates</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">date_format</span></code>
to allow users to specify a variety of columns and date/time formats to turn the
input text data into <code class=""docutils literal notranslate""><span class=""pre"">datetime</span></code> objects.</p>
<p>The simplest case is to just pass in <code class=""docutils literal notranslate""><span class=""pre"">parse_dates=True</span></code>:</p>

<p>It is often the case that we may want to store date and time data separately,
or store various date fields separately. the <code class=""docutils literal notranslate""><span class=""pre"">parse_dates</span></code> keyword can be
used to specify a combination of columns to parse the dates and/or times from.</p>
<p>You can specify a list of column lists to <code class=""docutils literal notranslate""><span class=""pre"">parse_dates</span></code>, the resulting date
columns will be prepended to the output (so as to not affect the existing column
order) and the new column names will be the concatenation of the component
column names:</p>

<p>By default the parser removes the component date columns, but you can choose
to retain them via the <code class=""docutils literal notranslate""><span class=""pre"">keep_date_col</span></code> keyword:</p>

<p>Note that if you wish to combine multiple columns into a single date column, a
nested list must be used. In other words, <code class=""docutils literal notranslate""><span class=""pre"">parse_dates=[1,</span> <span class=""pre"">2]</span></code> indicates that
the second and third columns should each be parsed as separate date columns
while <code class=""docutils literal notranslate""><span class=""pre"">parse_dates=[[1,</span> <span class=""pre"">2]]</span></code> means the two columns should be parsed into a
single column.</p>
<p>You can also use a dict to specify custom name columns:</p>

<p>It is important to remember that if multiple text columns are to be parsed into
a single date column, then a new column is prepended to the data. The <code class=""docutils literal notranslate""><span class=""pre"">index_col</span></code>
specification is based off of this new set of columns rather than the original
data columns:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>If a column or index contains an unparsable date, the entire column or
index will be returned unaltered as an object data type. For non-standard
datetime parsing, use <a class=""reference internal"" href=""../reference/api/pandas.to_datetime.html#pandas.to_datetime"" title=""pandas.to_datetime""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">to_datetime()</span></code></a> after <code class=""docutils literal notranslate""><span class=""pre"">pd.read_csv</span></code>.</p>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>read_csv has a fast_path for parsing datetime strings in iso8601 format,
e.g “2000-01-01T00:01:02+00:00” and similar variations. If you can arrange
for your data to store datetimes in this format, load times will be
significantly faster, ~20x has been observed.</p>
</div>
<div class=""deprecated"">
<p><span class=""versionmodified deprecated"">Deprecated since version 2.2.0: </span>Combining date columns inside read_csv is deprecated. Use <code class=""docutils literal notranslate""><span class=""pre"">pd.to_datetime</span></code>
on the relevant result columns instead.</p>
</div>
</section>
<section id=""date-parsing-functions"">
<h4>Date parsing functions<a class=""headerlink"" href=""#date-parsing-functions"" title=""Link to this heading"">#</a></h4>
<p>Finally, the parser allows you to specify a custom <code class=""docutils literal notranslate""><span class=""pre"">date_format</span></code>.
Performance-wise, you should try these methods of parsing dates in order:</p>
<ol class=""arabic simple"">
<li><p>If you know the format, use <code class=""docutils literal notranslate""><span class=""pre"">date_format</span></code>, e.g.:
<code class=""docutils literal notranslate""><span class=""pre"">date_format=""%d/%m/%Y""</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">date_format={column_name:</span> <span class=""pre"">""%d/%m/%Y""}</span></code>.</p></li>
<li><p>If you different formats for different columns, or want to pass any extra options (such
as <code class=""docutils literal notranslate""><span class=""pre"">utc</span></code>) to <code class=""docutils literal notranslate""><span class=""pre"">to_datetime</span></code>, then you should read in your data as <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> dtype, and
then use <code class=""docutils literal notranslate""><span class=""pre"">to_datetime</span></code>.</p></li>
</ol>
</section>
<section id=""parsing-a-csv-with-mixed-timezones"">
<span id=""io-csv-mixed-timezones""></span><h4>Parsing a CSV with mixed timezones<a class=""headerlink"" href=""#parsing-a-csv-with-mixed-timezones"" title=""Link to this heading"">#</a></h4>
<p>pandas cannot natively represent a column or index with mixed timezones. If your CSV
file contains columns with a mixture of timezones, the default result will be
an object-dtype column with strings, even with <code class=""docutils literal notranslate""><span class=""pre"">parse_dates</span></code>.
To parse the mixed-timezone values as a datetime column, read in as <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> dtype and
then call <a class=""reference internal"" href=""../reference/api/pandas.to_datetime.html#pandas.to_datetime"" title=""pandas.to_datetime""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">to_datetime()</span></code></a> with <code class=""docutils literal notranslate""><span class=""pre"">utc=True</span></code>.</p>

</section>
<section id=""inferring-datetime-format"">
<span id=""io-dayfirst""></span><h4>Inferring datetime format<a class=""headerlink"" href=""#inferring-datetime-format"" title=""Link to this heading"">#</a></h4>
<p>Here are some examples of datetime strings that can be guessed (all
representing December 30th, 2011 at 00:00:00):</p>
<ul class=""simple"">
<li><p>“20111230”</p></li>
<li><p>“2011/12/30”</p></li>
<li><p>“20111230 00:00:00”</p></li>
<li><p>“12/30/2011 00:00:00”</p></li>
<li><p>“30/Dec/2011 00:00:00”</p></li>
<li><p>“30/December/2011 00:00:00”</p></li>
</ul>
<p>Note that format inference is sensitive to <code class=""docutils literal notranslate""><span class=""pre"">dayfirst</span></code>. With
<code class=""docutils literal notranslate""><span class=""pre"">dayfirst=True</span></code>, it will guess “01/12/2011” to be December 1st. With
<code class=""docutils literal notranslate""><span class=""pre"">dayfirst=False</span></code> (default) it will guess “01/12/2011” to be January 12th.</p>
<p>If you try to parse a column of date strings, pandas will attempt to guess the format
from the first non-NaN element, and will then parse the rest of the column with that
format. If pandas fails to guess the format (for example if your first string is
<code class=""docutils literal notranslate""><span class=""pre"">'01</span> <span class=""pre"">December</span> <span class=""pre"">US/Pacific</span> <span class=""pre"">2000'</span></code>), then a warning will be raised and each
row will be parsed individually by <code class=""docutils literal notranslate""><span class=""pre"">dateutil.parser.parse</span></code>. The safest
way to parse dates is to explicitly set <code class=""docutils literal notranslate""><span class=""pre"">format=</span></code>.</p>

<p>In the case that you have mixed datetime formats within the same column, you can
pass <code class=""docutils literal notranslate""><span class=""pre"">format='mixed'</span></code></p>

<p>or, if your datetime formats are all ISO8601 (possibly not identically-formatted):</p>

</section>
<section id=""international-date-formats"">
<h4>International date formats<a class=""headerlink"" href=""#international-date-formats"" title=""Link to this heading"">#</a></h4>
<p>While US date formats tend to be MM/DD/YYYY, many international formats use
DD/MM/YYYY instead. For convenience, a <code class=""docutils literal notranslate""><span class=""pre"">dayfirst</span></code> keyword is provided:</p>

</section>
<section id=""writing-csvs-to-binary-file-objects"">
<h4>Writing CSVs to binary file objects<a class=""headerlink"" href=""#writing-csvs-to-binary-file-objects"" title=""Link to this heading"">#</a></h4>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.2.0.</span></p>
</div>
<p><code class=""docutils literal notranslate""><span class=""pre"">df.to_csv(...,</span> <span class=""pre"">mode=""wb"")</span></code> allows writing a CSV to a file object
opened binary mode. In most cases, it is not necessary to specify
<code class=""docutils literal notranslate""><span class=""pre"">mode</span></code> as Pandas will auto-detect whether the file object is
opened in text or binary mode.</p>

</section>
</section>
<section id=""specifying-method-for-floating-point-conversion"">
<span id=""io-float-precision""></span><h3>Specifying method for floating-point conversion<a class=""headerlink"" href=""#specifying-method-for-floating-point-conversion"" title=""Link to this heading"">#</a></h3>
<p>The parameter <code class=""docutils literal notranslate""><span class=""pre"">float_precision</span></code> can be specified in order to use
a specific floating-point converter during parsing with the C engine.
The options are the ordinary converter, the high-precision converter, and
the round-trip converter (which is guaranteed to round-trip values after
writing to a file). For example:</p>

</section>
<section id=""thousand-separators"">
<span id=""io-thousands""></span><h3>Thousand separators<a class=""headerlink"" href=""#thousand-separators"" title=""Link to this heading"">#</a></h3>
<p>For large numbers that have been written with a thousands separator, you can
set the <code class=""docutils literal notranslate""><span class=""pre"">thousands</span></code> keyword to a string of length 1 so that integers will be parsed
correctly:</p>
<p>By default, numbers with a thousands separator will be parsed as strings:</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">thousands</span></code> keyword allows integers to be parsed correctly:</p>

</section>
<section id=""na-values"">
<span id=""io-na-values""></span><h3>NA values<a class=""headerlink"" href=""#na-values"" title=""Link to this heading"">#</a></h3>
<p>To control which values are parsed as missing values (which are signified by
<code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>), specify a string in <code class=""docutils literal notranslate""><span class=""pre"">na_values</span></code>. If you specify a list of strings,
then all values in it are considered to be missing values. If you specify a
number (a <code class=""docutils literal notranslate""><span class=""pre"">float</span></code>, like <code class=""docutils literal notranslate""><span class=""pre"">5.0</span></code> or an <code class=""docutils literal notranslate""><span class=""pre"">integer</span></code> like <code class=""docutils literal notranslate""><span class=""pre"">5</span></code>), the
corresponding equivalent values will also imply a missing value (in this case
effectively <code class=""docutils literal notranslate""><span class=""pre"">[5.0,</span> <span class=""pre"">5]</span></code> are recognized as <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>).</p>
<p>To completely override the default values that are recognized as missing, specify <code class=""docutils literal notranslate""><span class=""pre"">keep_default_na=False</span></code>.</p>
<p id=""io-navaluesconst"">The default <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code> recognized values are <code class=""docutils literal notranslate""><span class=""pre"">['-1.#IND',</span> <span class=""pre"">'1.#QNAN',</span> <span class=""pre"">'1.#IND',</span> <span class=""pre"">'-1.#QNAN',</span> <span class=""pre"">'#N/A</span> <span class=""pre"">N/A',</span> <span class=""pre"">'#N/A',</span> <span class=""pre"">'N/A',</span>
<span class=""pre"">'n/a',</span> <span class=""pre"">'NA',</span> <span class=""pre"">'&lt;NA&gt;',</span> <span class=""pre"">'#NA',</span> <span class=""pre"">'NULL',</span> <span class=""pre"">'null',</span> <span class=""pre"">'NaN',</span> <span class=""pre"">'-NaN',</span> <span class=""pre"">'nan',</span> <span class=""pre"">'-nan',</span> <span class=""pre"">'None',</span> <span class=""pre"">'']</span></code>.</p>
<p>Let us consider some examples:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_csv</span><span class=""p"">(</span><span class=""s2"">""path_to_file.csv""</span><span class=""p"">,</span> <span class=""n"">na_values</span><span class=""o"">=</span><span class=""p"">[</span><span class=""mi"">5</span><span class=""p"">])</span>
</pre></div>
</div>
<p>In the example above <code class=""docutils literal notranslate""><span class=""pre"">5</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">5.0</span></code> will be recognized as <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>, in
addition to the defaults. A string will first be interpreted as a numerical
<code class=""docutils literal notranslate""><span class=""pre"">5</span></code>, then as a <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_csv</span><span class=""p"">(</span><span class=""s2"">""path_to_file.csv""</span><span class=""p"">,</span> <span class=""n"">keep_default_na</span><span class=""o"">=</span><span class=""kc"">False</span><span class=""p"">,</span> <span class=""n"">na_values</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""""</span><span class=""p"">])</span>
</pre></div>
</div>
<p>Above, only an empty field will be recognized as <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_csv</span><span class=""p"">(</span><span class=""s2"">""path_to_file.csv""</span><span class=""p"">,</span> <span class=""n"">keep_default_na</span><span class=""o"">=</span><span class=""kc"">False</span><span class=""p"">,</span> <span class=""n"">na_values</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""NA""</span><span class=""p"">,</span> <span class=""s2"">""0""</span><span class=""p"">])</span>
</pre></div>
</div>
<p>Above, both <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">0</span></code> as strings are <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_csv</span><span class=""p"">(</span><span class=""s2"">""path_to_file.csv""</span><span class=""p"">,</span> <span class=""n"">na_values</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""Nope""</span><span class=""p"">])</span>
</pre></div>
</div>
<p>The default values, in addition to the string <code class=""docutils literal notranslate""><span class=""pre"">""Nope""</span></code> are recognized as
<code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>.</p>
</section>
<section id=""infinity"">
<span id=""io-infinity""></span><h3>Infinity<a class=""headerlink"" href=""#infinity"" title=""Link to this heading"">#</a></h3>
<p><code class=""docutils literal notranslate""><span class=""pre"">inf</span></code> like values will be parsed as <code class=""docutils literal notranslate""><span class=""pre"">np.inf</span></code> (positive infinity), and <code class=""docutils literal notranslate""><span class=""pre"">-inf</span></code> as <code class=""docutils literal notranslate""><span class=""pre"">-np.inf</span></code> (negative infinity).
These will ignore the case of the value, meaning <code class=""docutils literal notranslate""><span class=""pre"">Inf</span></code>, will also be parsed as <code class=""docutils literal notranslate""><span class=""pre"">np.inf</span></code>.</p>
</section>
<section id=""boolean-values"">
<span id=""io-boolean""></span><h3>Boolean values<a class=""headerlink"" href=""#boolean-values"" title=""Link to this heading"">#</a></h3>
<p>The common values <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">TRUE</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">FALSE</span></code> are all
recognized as boolean. Occasionally you might want to recognize other values
as being boolean. To do this, use the <code class=""docutils literal notranslate""><span class=""pre"">true_values</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">false_values</span></code>
options as follows:</p>

</section>
<section id=""handling-bad-lines"">
<span id=""io-bad-lines""></span><h3>Handling “bad” lines<a class=""headerlink"" href=""#handling-bad-lines"" title=""Link to this heading"">#</a></h3>
<p>Some files may have malformed lines with too few fields or too many. Lines with
too few fields will have NA values filled in the trailing fields. Lines with
too many fields will raise an error by default:</p>

<p>You can elect to skip bad lines:</p>

<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.4.0.</span></p>
</div>
<p>Or pass a callable function to handle the bad line if <code class=""docutils literal notranslate""><span class=""pre"">engine=""python""</span></code>.
The bad line will be a list of strings that was split by the <code class=""docutils literal notranslate""><span class=""pre"">sep</span></code>:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The callable function will handle only a line with too many fields.
Bad lines caused by other errors will be silently skipped.</p>

<p>The line was not processed in this case, as a “bad line” here is caused by an escape character.</p>
</div>
<p>You can also use the <code class=""docutils literal notranslate""><span class=""pre"">usecols</span></code> parameter to eliminate extraneous column
data that appear in some lines but not others:</p>

<p>In case you want to keep all data including the lines with too many fields, you can
specify a sufficient number of <code class=""docutils literal notranslate""><span class=""pre"">names</span></code>. This ensures that lines with not enough
fields are filled with <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>.</p>

</section>
<section id=""dialect"">
<span id=""io-dialect""></span><h3>Dialect<a class=""headerlink"" href=""#dialect"" title=""Link to this heading"">#</a></h3>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">dialect</span></code> keyword gives greater flexibility in specifying the file format.
By default it uses the Excel dialect but you can specify either the dialect name
or a <a class=""reference external"" href=""https://docs.python.org/3/library/csv.html#csv.Dialect"" title=""(in Python v3.12)""><code class=""docutils literal notranslate""><span class=""pre"">csv.Dialect</span></code></a> instance.</p>
<p>Suppose you had data with unenclosed quotes:</p>

<p>By default, <code class=""docutils literal notranslate""><span class=""pre"">read_csv</span></code> uses the Excel dialect and treats the double quote as
the quote character, which causes it to fail when it finds a newline before it
finds the closing double quote.</p>
<p>We can get around this using <code class=""docutils literal notranslate""><span class=""pre"">dialect</span></code>:</p>

<p>All of the dialect options can be specified separately by keyword arguments:</p>

<p>Another common dialect option is <code class=""docutils literal notranslate""><span class=""pre"">skipinitialspace</span></code>, to skip any whitespace
after a delimiter:</p>

<p>The parsers make every attempt to “do the right thing” and not be fragile. Type
inference is a pretty big deal. If a column can be coerced to integer dtype
without altering the contents, the parser will do so. Any non-numeric
columns will come through as object dtype as with the rest of pandas objects.</p>
</section>
<section id=""quoting-and-escape-characters"">
<span id=""io-quoting""></span><h3>Quoting and Escape Characters<a class=""headerlink"" href=""#quoting-and-escape-characters"" title=""Link to this heading"">#</a></h3>
<p>Quotes (and other escape characters) in embedded fields can be handled in any
number of ways. One way is to use backslashes; to properly parse this data, you
should pass the <code class=""docutils literal notranslate""><span class=""pre"">escapechar</span></code> option:</p>

</section>
<section id=""files-with-fixed-width-columns"">
<span id=""io-fwf""></span><span id=""io-fwf-reader""></span><h3>Files with fixed width columns<a class=""headerlink"" href=""#files-with-fixed-width-columns"" title=""Link to this heading"">#</a></h3>
<p>While <a class=""reference internal"" href=""../reference/api/pandas.read_csv.html#pandas.read_csv"" title=""pandas.read_csv""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_csv()</span></code></a> reads delimited data, the <a class=""reference internal"" href=""../reference/api/pandas.read_fwf.html#pandas.read_fwf"" title=""pandas.read_fwf""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_fwf()</span></code></a> function works
with data files that have known and fixed column widths. The function parameters
to <code class=""docutils literal notranslate""><span class=""pre"">read_fwf</span></code> are largely the same as <code class=""docutils literal notranslate""><span class=""pre"">read_csv</span></code> with two extra parameters, and
a different usage of the <code class=""docutils literal notranslate""><span class=""pre"">delimiter</span></code> parameter:</p>
<ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">colspecs</span></code>: A list of pairs (tuples) giving the extents of the
fixed-width fields of each line as half-open intervals (i.e., [from, to[ ).
String value ‘infer’ can be used to instruct the parser to try detecting
the column specifications from the first 100 rows of the data. Default
behavior, if not specified, is to infer.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">widths</span></code>: A list of field widths which can be used instead of ‘colspecs’
if the intervals are contiguous.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">delimiter</span></code>: Characters to consider as filler characters in the fixed-width file.
Can be used to specify the filler character of the fields
if it is not spaces (e.g., ‘~’).</p></li>
</ul>
<p>Consider a typical fixed-width data file:</p>

<p>In order to parse this file into a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>, we simply need to supply the
column specifications to the <code class=""docutils literal notranslate""><span class=""pre"">read_fwf</span></code> function along with the file name:</p>

<p>Note how the parser automatically picks column names X.&lt;column number&gt; when
<code class=""docutils literal notranslate""><span class=""pre"">header=None</span></code> argument is specified. Alternatively, you can supply just the
column widths for contiguous columns:</p>

<p>The parser will take care of extra white spaces around the columns
so it’s ok to have extra separation between the columns in the file.</p>
<p>By default, <code class=""docutils literal notranslate""><span class=""pre"">read_fwf</span></code> will try to infer the file’s <code class=""docutils literal notranslate""><span class=""pre"">colspecs</span></code> by using the
first 100 rows of the file. It can do it only in cases when the columns are
aligned and correctly separated by the provided <code class=""docutils literal notranslate""><span class=""pre"">delimiter</span></code> (default delimiter
is whitespace).</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">read_fwf</span></code> supports the <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code> parameter for specifying the types of
parsed columns to be different from the inferred type.</p>

</section>
<section id=""indexes"">
<h3>Indexes<a class=""headerlink"" href=""#indexes"" title=""Link to this heading"">#</a></h3>
<section id=""files-with-an-implicit-index-column"">
<h4>Files with an “implicit” index column<a class=""headerlink"" href=""#files-with-an-implicit-index-column"" title=""Link to this heading"">#</a></h4>
<p>Consider a file with one less entry in the header than the number of data
column:</p>

<p>In this special case, <code class=""docutils literal notranslate""><span class=""pre"">read_csv</span></code> assumes that the first column is to be used
as the index of the <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>:</p>

<p>Note that the dates weren’t automatically parsed. In that case you would need
to do as before:</p>

</section>
<section id=""reading-an-index-with-a-multiindex"">
<h4>Reading an index with a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code><a class=""headerlink"" href=""#reading-an-index-with-a-multiindex"" title=""Link to this heading"">#</a></h4>
<p id=""io-csv-multiindex"">Suppose you have data indexed by two columns:</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">index_col</span></code> argument to <code class=""docutils literal notranslate""><span class=""pre"">read_csv</span></code> can take a list of
column numbers to turn multiple columns into a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> for the index of the
returned object:</p>

</section>
<section id=""reading-columns-with-a-multiindex"">
<span id=""io-multi-index-columns""></span><h4>Reading columns with a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code><a class=""headerlink"" href=""#reading-columns-with-a-multiindex"" title=""Link to this heading"">#</a></h4>
<p>By specifying list of row locations for the <code class=""docutils literal notranslate""><span class=""pre"">header</span></code> argument, you
can read in a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> for the columns. Specifying non-consecutive
rows will skip the intervening rows.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">read_csv</span></code> is also able to interpret a more common format
of multi-columns indices.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>If an <code class=""docutils literal notranslate""><span class=""pre"">index_col</span></code> is not specified (e.g. you don’t have an index, or wrote it
with <code class=""docutils literal notranslate""><span class=""pre"">df.to_csv(...,</span> <span class=""pre"">index=False)</span></code>, then any <code class=""docutils literal notranslate""><span class=""pre"">names</span></code> on the columns index will
be <em>lost</em>.</p>
</div>
</section>
</section>
<section id=""automatically-sniffing-the-delimiter"">
<span id=""io-sniff""></span><h3>Automatically “sniffing” the delimiter<a class=""headerlink"" href=""#automatically-sniffing-the-delimiter"" title=""Link to this heading"">#</a></h3>
<p><code class=""docutils literal notranslate""><span class=""pre"">read_csv</span></code> is capable of inferring delimited (not necessarily
comma-separated) files, as pandas uses the <a class=""reference external"" href=""https://docs.python.org/3/library/csv.html#csv.Sniffer"" title=""(in Python v3.12)""><code class=""docutils literal notranslate""><span class=""pre"">csv.Sniffer</span></code></a>
class of the csv module. For this, you have to specify <code class=""docutils literal notranslate""><span class=""pre"">sep=None</span></code>.</p>

</section>
<section id=""reading-multiple-files-to-create-a-single-dataframe"">
<span id=""io-multiple-files""></span><h3>Reading multiple files to create a single DataFrame<a class=""headerlink"" href=""#reading-multiple-files-to-create-a-single-dataframe"" title=""Link to this heading"">#</a></h3>
<p>It’s best to use <a class=""reference internal"" href=""../reference/api/pandas.concat.html#pandas.concat"" title=""pandas.concat""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">concat()</span></code></a> to combine multiple files.
See the <a class=""reference internal"" href=""cookbook.html#cookbook-csv-multiple-files""><span class=""std std-ref"">cookbook</span></a> for an example.</p>
</section>
<section id=""iterating-through-files-chunk-by-chunk"">
<span id=""io-chunking""></span><h3>Iterating through files chunk by chunk<a class=""headerlink"" href=""#iterating-through-files-chunk-by-chunk"" title=""Link to this heading"">#</a></h3>
<p>Suppose you wish to iterate through a (potentially very large) file lazily
rather than reading the entire file into memory, such as the following:</p>

<p>By specifying a <code class=""docutils literal notranslate""><span class=""pre"">chunksize</span></code> to <code class=""docutils literal notranslate""><span class=""pre"">read_csv</span></code>, the return
value will be an iterable object of type <code class=""docutils literal notranslate""><span class=""pre"">TextFileReader</span></code>:</p>

<div class=""versionchanged"">
<p><span class=""versionmodified changed"">Changed in version 1.2: </span><code class=""docutils literal notranslate""><span class=""pre"">read_csv/json/sas</span></code> return a context-manager when iterating through a file.</p>
</div>
<p>Specifying <code class=""docutils literal notranslate""><span class=""pre"">iterator=True</span></code> will also return the <code class=""docutils literal notranslate""><span class=""pre"">TextFileReader</span></code> object:</p>

</section>
<section id=""specifying-the-parser-engine"">
<h3>Specifying the parser engine<a class=""headerlink"" href=""#specifying-the-parser-engine"" title=""Link to this heading"">#</a></h3>
<p>Pandas currently supports three engines, the C engine, the python engine, and an experimental
pyarrow engine (requires the <code class=""docutils literal notranslate""><span class=""pre"">pyarrow</span></code> package). In general, the pyarrow engine is fastest
on larger workloads and is equivalent in speed to the C engine on most other workloads.
The python engine tends to be slower than the pyarrow and C engines on most workloads. However,
the pyarrow engine is much less robust than the C engine, which lacks a few features compared to the
Python engine.</p>
<p>Where possible, pandas uses the C parser (specified as <code class=""docutils literal notranslate""><span class=""pre"">engine='c'</span></code>), but it may fall
back to Python if C-unsupported options are specified.</p>
<p>Currently, options unsupported by the C and pyarrow engines include:</p>
<ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">sep</span></code> other than a single character (e.g. regex separators)</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">skipfooter</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">sep=None</span></code> with <code class=""docutils literal notranslate""><span class=""pre"">delim_whitespace=False</span></code></p></li>
</ul>
<p>Specifying any of the above options will produce a <code class=""docutils literal notranslate""><span class=""pre"">ParserWarning</span></code> unless the
python engine is selected explicitly using <code class=""docutils literal notranslate""><span class=""pre"">engine='python'</span></code>.</p>
<p>Options that are unsupported by the pyarrow engine which are not covered by the list above include:</p>
<ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">float_precision</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">chunksize</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">comment</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">nrows</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">thousands</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">memory_map</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">dialect</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">on_bad_lines</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">delim_whitespace</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">quoting</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">lineterminator</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">converters</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">decimal</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">iterator</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">dayfirst</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">infer_datetime_format</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">verbose</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">skipinitialspace</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">low_memory</span></code></p></li>
</ul>
<p>Specifying these options with <code class=""docutils literal notranslate""><span class=""pre"">engine='pyarrow'</span></code> will raise a <code class=""docutils literal notranslate""><span class=""pre"">ValueError</span></code>.</p>
</section>
<section id=""reading-writing-remote-files"">
<span id=""io-remote""></span><h3>Reading/writing remote files<a class=""headerlink"" href=""#reading-writing-remote-files"" title=""Link to this heading"">#</a></h3>
<p>You can pass in a URL to read or write remote files to many of pandas’ IO
functions - the following example shows reading a CSV file:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_csv</span><span class=""p"">(</span><span class=""s2"">""https://download.bls.gov/pub/time.series/cu/cu.item""</span><span class=""p"">,</span> <span class=""n"">sep</span><span class=""o"">=</span><span class=""s2"">""</span><span class=""se"">\t</span><span class=""s2"">""</span><span class=""p"">)</span>
</pre></div>
</div>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.3.0.</span></p>
</div>
<p>A custom header can be sent alongside HTTP(s) requests by passing a dictionary
of header key value mappings to the <code class=""docutils literal notranslate""><span class=""pre"">storage_options</span></code> keyword argument as shown below:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">headers</span> <span class=""o"">=</span> <span class=""p"">{</span><span class=""s2"">""User-Agent""</span><span class=""p"">:</span> <span class=""s2"">""pandas""</span><span class=""p"">}</span>
<span class=""n"">df</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_csv</span><span class=""p"">(</span>
    <span class=""s2"">""https://download.bls.gov/pub/time.series/cu/cu.item""</span><span class=""p"">,</span>
    <span class=""n"">sep</span><span class=""o"">=</span><span class=""s2"">""</span><span class=""se"">\t</span><span class=""s2"">""</span><span class=""p"">,</span>
    <span class=""n"">storage_options</span><span class=""o"">=</span><span class=""n"">headers</span>
<span class=""p"">)</span>
</pre></div>
</div>
<p>All URLs which are not local files or HTTP(s) are handled by
<a class=""reference external"" href=""https://filesystem-spec.readthedocs.io/en/latest/"">fsspec</a>, if installed, and its various filesystem implementations
(including Amazon S3, Google Cloud, SSH, FTP, webHDFS…).
Some of these implementations will require additional packages to be
installed, for example
S3 URLs require the <a class=""reference external"" href=""https://pypi.org/project/s3fs/"">s3fs</a> library:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_json</span><span class=""p"">(</span><span class=""s2"">""s3://pandas-test/adatafile.json""</span><span class=""p"">)</span>
</pre></div>
</div>
<p>When dealing with remote storage systems, you might need
extra configuration with environment variables or config files in
special locations. For example, to access data in your S3 bucket,
you will need to define credentials in one of the several ways listed in
the <a class=""reference external"" href=""https://s3fs.readthedocs.io/en/latest/#credentials"">S3Fs documentation</a>. The same is true
for several of the storage backends, and you should follow the links
at <a class=""reference external"" href=""https://filesystem-spec.readthedocs.io/en/latest/api.html#built-in-implementations"">fsimpl1</a> for implementations built into <code class=""docutils literal notranslate""><span class=""pre"">fsspec</span></code> and <a class=""reference external"" href=""https://filesystem-spec.readthedocs.io/en/latest/api.html#other-known-implementations"">fsimpl2</a>
for those not included in the main <code class=""docutils literal notranslate""><span class=""pre"">fsspec</span></code>
distribution.</p>
<p>You can also pass parameters directly to the backend driver. Since <code class=""docutils literal notranslate""><span class=""pre"">fsspec</span></code> does not
utilize the <code class=""docutils literal notranslate""><span class=""pre"">AWS_S3_HOST</span></code> environment variable, we can directly define a
dictionary containing the endpoint_url and pass the object into the storage
option parameter:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">storage_options</span> <span class=""o"">=</span> <span class=""p"">{</span><span class=""s2"">""client_kwargs""</span><span class=""p"">:</span> <span class=""p"">{</span><span class=""s2"">""endpoint_url""</span><span class=""p"">:</span> <span class=""s2"">""http://127.0.0.1:5555""</span><span class=""p"">}}}</span>
<span class=""n"">df</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_json</span><span class=""p"">(</span><span class=""s2"">""s3://pandas-test/test-1""</span><span class=""p"">,</span> <span class=""n"">storage_options</span><span class=""o"">=</span><span class=""n"">storage_options</span><span class=""p"">)</span>
</pre></div>
</div>
<p>More sample configurations and documentation can be found at <a class=""reference external"" href=""https://s3fs.readthedocs.io/en/latest/index.html?highlight=host#s3-compatible-storage"">S3Fs documentation</a>.</p>
<p>If you do <em>not</em> have S3 credentials, you can still access public
data by specifying an anonymous connection, such as</p>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.2.0.</span></p>
</div>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_csv</span><span class=""p"">(</span>
    <span class=""s2"">""s3://ncei-wcsd-archive/data/processed/SH1305/18kHz/SaKe2013""</span>
    <span class=""s2"">""-D20130523-T080854_to_SaKe2013-D20130523-T085643.csv""</span><span class=""p"">,</span>
    <span class=""n"">storage_options</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s2"">""anon""</span><span class=""p"">:</span> <span class=""kc"">True</span><span class=""p"">},</span>
<span class=""p"">)</span>
</pre></div>
</div>
<p><code class=""docutils literal notranslate""><span class=""pre"">fsspec</span></code> also allows complex URLs, for accessing data in compressed
archives, local caching of files, and more. To locally cache the above
example, you would modify the call to</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_csv</span><span class=""p"">(</span>
    <span class=""s2"">""simplecache::s3://ncei-wcsd-archive/data/processed/SH1305/18kHz/""</span>
    <span class=""s2"">""SaKe2013-D20130523-T080854_to_SaKe2013-D20130523-T085643.csv""</span><span class=""p"">,</span>
    <span class=""n"">storage_options</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s2"">""s3""</span><span class=""p"">:</span> <span class=""p"">{</span><span class=""s2"">""anon""</span><span class=""p"">:</span> <span class=""kc"">True</span><span class=""p"">}},</span>
<span class=""p"">)</span>
</pre></div>
</div>
<p>where we specify that the “anon” parameter is meant for the “s3” part of
the implementation, not to the caching implementation. Note that this caches to a temporary
directory for the duration of the session only, but you can also specify
a permanent store.</p>
</section>
<section id=""writing-out-data"">
<h3>Writing out data<a class=""headerlink"" href=""#writing-out-data"" title=""Link to this heading"">#</a></h3>
<section id=""writing-to-csv-format"">
<span id=""io-store-in-csv""></span><h4>Writing to CSV format<a class=""headerlink"" href=""#writing-to-csv-format"" title=""Link to this heading"">#</a></h4>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> objects have an instance method <code class=""docutils literal notranslate""><span class=""pre"">to_csv</span></code> which
allows storing the contents of the object as a comma-separated-values file. The
function takes a number of arguments. Only the first is required.</p>
<ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">path_or_buf</span></code>: A string path to the file to write or a file object. If a file object it must be opened with <code class=""docutils literal notranslate""><span class=""pre"">newline=''</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">sep</span></code> : Field delimiter for the output file (default “,”)</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">na_rep</span></code>: A string representation of a missing value (default ‘’)</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">float_format</span></code>: Format string for floating point numbers</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">columns</span></code>: Columns to write (default None)</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">header</span></code>: Whether to write out the column names (default True)</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">index</span></code>: whether to write row (index) names (default True)</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">index_label</span></code>: Column label(s) for index column(s) if desired. If None
(default), and <code class=""docutils literal notranslate""><span class=""pre"">header</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">index</span></code> are True, then the index names are
used. (A sequence should be given if the <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> uses MultiIndex).</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">mode</span></code> : Python write mode, default ‘w’</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">encoding</span></code>: a string representing the encoding to use if the contents are
non-ASCII, for Python versions prior to 3</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">lineterminator</span></code>: Character sequence denoting line end (default <code class=""docutils literal notranslate""><span class=""pre"">os.linesep</span></code>)</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">quoting</span></code>: Set quoting rules as in csv module (default csv.QUOTE_MINIMAL). Note that if you have set a <code class=""docutils literal notranslate""><span class=""pre"">float_format</span></code> then floats are converted to strings and csv.QUOTE_NONNUMERIC will treat them as non-numeric</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">quotechar</span></code>: Character used to quote fields (default ‘”’)</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">doublequote</span></code>: Control quoting of <code class=""docutils literal notranslate""><span class=""pre"">quotechar</span></code> in fields (default True)</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">escapechar</span></code>: Character used to escape <code class=""docutils literal notranslate""><span class=""pre"">sep</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">quotechar</span></code> when
appropriate (default None)</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">chunksize</span></code>: Number of rows to write at a time</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">date_format</span></code>: Format string for datetime objects</p></li>
</ul>
</section>
<section id=""writing-a-formatted-string"">
<h4>Writing a formatted string<a class=""headerlink"" href=""#writing-a-formatted-string"" title=""Link to this heading"">#</a></h4>
<p id=""io-formatting"">The <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> object has an instance method <code class=""docutils literal notranslate""><span class=""pre"">to_string</span></code> which allows control
over the string representation of the object. All arguments are optional:</p>
<ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">buf</span></code> default None, for example a StringIO object</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">columns</span></code> default None, which columns to write</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">col_space</span></code> default None, minimum width of each column.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">na_rep</span></code> default <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>, representation of NA value</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">formatters</span></code> default None, a dictionary (by column) of functions each of
which takes a single argument and returns a formatted string</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">float_format</span></code> default None, a function which takes a single (float)
argument and returns a formatted string; to be applied to floats in the
<code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">sparsify</span></code> default True, set to False for a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> with a hierarchical
index to print every MultiIndex key at each row.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">index_names</span></code> default True, will print the names of the indices</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">index</span></code> default True, will print the index (ie, row labels)</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">header</span></code> default True, will print the column labels</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">justify</span></code> default <code class=""docutils literal notranslate""><span class=""pre"">left</span></code>, will print column headers left- or
right-justified</p></li>
</ul>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> object also has a <code class=""docutils literal notranslate""><span class=""pre"">to_string</span></code> method, but with only the <code class=""docutils literal notranslate""><span class=""pre"">buf</span></code>,
<code class=""docutils literal notranslate""><span class=""pre"">na_rep</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">float_format</span></code> arguments. There is also a <code class=""docutils literal notranslate""><span class=""pre"">length</span></code> argument
which, if set to <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>, will additionally output the length of the Series.</p>
</section>
</section>
</section>
<section id=""json"">
<span id=""io-json""></span><h2>JSON<a class=""headerlink"" href=""#json"" title=""Link to this heading"">#</a></h2>
<p>Read and write <code class=""docutils literal notranslate""><span class=""pre"">JSON</span></code> format files and strings.</p>
<section id=""writing-json"">
<span id=""io-json-writer""></span><h3>Writing JSON<a class=""headerlink"" href=""#writing-json"" title=""Link to this heading"">#</a></h3>
<p>A <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> can be converted to a valid JSON string. Use <code class=""docutils literal notranslate""><span class=""pre"">to_json</span></code>
with optional parameters:</p>
<ul>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">path_or_buf</span></code> : the pathname or buffer to write the output.
This can be <code class=""docutils literal notranslate""><span class=""pre"">None</span></code> in which case a JSON string is returned.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">orient</span></code> :</p>
<dl class=""simple"">
<dt><code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>:</dt><dd><ul class=""simple"">
<li><p>default is <code class=""docutils literal notranslate""><span class=""pre"">index</span></code></p></li>
<li><p>allowed values are {<code class=""docutils literal notranslate""><span class=""pre"">split</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">records</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">index</span></code>}</p></li>
</ul>
</dd>
<dt><code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>:</dt><dd><ul class=""simple"">
<li><p>default is <code class=""docutils literal notranslate""><span class=""pre"">columns</span></code></p></li>
<li><p>allowed values are {<code class=""docutils literal notranslate""><span class=""pre"">split</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">records</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">index</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">columns</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">values</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">table</span></code>}</p></li>
</ul>
</dd>
</dl>
<p>The format of the JSON string</p>

</li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">date_format</span></code> : string, type of date conversion, ‘epoch’ for timestamp, ‘iso’ for ISO8601.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">double_precision</span></code> : The number of decimal places to use when encoding floating point values, default 10.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">force_ascii</span></code> : force encoded string to be ASCII, default True.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">date_unit</span></code> : The time unit to encode to, governs timestamp and ISO8601 precision. One of ‘s’, ‘ms’, ‘us’ or ‘ns’ for seconds, milliseconds, microseconds and nanoseconds respectively. Default ‘ms’.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">default_handler</span></code> : The handler to call if an object cannot otherwise be converted to a suitable format for JSON. Takes a single argument, which is the object to convert, and returns a serializable object.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">lines</span></code> : If <code class=""docutils literal notranslate""><span class=""pre"">records</span></code> orient, then will write each record per line as json.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">mode</span></code> : string, writer mode when writing to path. ‘w’ for write, ‘a’ for append. Default ‘w’</p></li>
</ul>
<p>Note <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>’s, <code class=""docutils literal notranslate""><span class=""pre"">NaT</span></code>’s and <code class=""docutils literal notranslate""><span class=""pre"">None</span></code> will be converted to <code class=""docutils literal notranslate""><span class=""pre"">null</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">datetime</span></code> objects will be converted based on the <code class=""docutils literal notranslate""><span class=""pre"">date_format</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">date_unit</span></code> parameters.</p>

<section id=""orient-options"">
<h4>Orient options<a class=""headerlink"" href=""#orient-options"" title=""Link to this heading"">#</a></h4>
<p>There are a number of different options for the format of the resulting JSON
file / string. Consider the following <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>:</p>

<p><strong>Column oriented</strong> (the default for <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>) serializes the data as
nested JSON objects with column labels acting as the primary index:</p>

<p><strong>Index oriented</strong> (the default for <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>) similar to column oriented
but the index labels are now primary:</p>

<p><strong>Record oriented</strong> serializes the data to a JSON array of column -&gt; value records,
index labels are not included. This is useful for passing <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> data to plotting
libraries, for example the JavaScript library <code class=""docutils literal notranslate""><span class=""pre"">d3.js</span></code>:</p>

<p><strong>Value oriented</strong> is a bare-bones option which serializes to nested JSON arrays of
values only, column and index labels are not included:</p>

<p><strong>Split oriented</strong> serializes to a JSON object containing separate entries for
values, index and columns. Name is also included for <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>:</p>

<p><strong>Table oriented</strong> serializes to the JSON <a class=""reference external"" href=""https://specs.frictionlessdata.io/table-schema/"">Table Schema</a>, allowing for the
preservation of metadata including but not limited to dtypes and index names.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Any orient option that encodes to a JSON object will not preserve the ordering of
index and column labels during round-trip serialization. If you wish to preserve
label ordering use the <code class=""docutils literal notranslate""><span class=""pre"">split</span></code> option as it uses ordered containers.</p>
</div>
</section>
<section id=""id1"">
<h4>Date handling<a class=""headerlink"" href=""#id1"" title=""Link to this heading"">#</a></h4>
<p>Writing in ISO date format:</p>

<p>Writing in ISO date format, with microseconds:</p>

<p>Epoch timestamps, in seconds:</p>

<p>Writing to a file, with a date index and a date column:</p>

</section>
<section id=""fallback-behavior"">
<h4>Fallback behavior<a class=""headerlink"" href=""#fallback-behavior"" title=""Link to this heading"">#</a></h4>
<p>If the JSON serializer cannot handle the container contents directly it will
fall back in the following manner:</p>
<ul>
<li><p>if the dtype is unsupported (e.g. <code class=""docutils literal notranslate""><span class=""pre"">np.complex_</span></code>) then the <code class=""docutils literal notranslate""><span class=""pre"">default_handler</span></code>, if provided, will be called
for each value, otherwise an exception is raised.</p></li>
<li><p>if an object is unsupported it will attempt the following:</p>
<blockquote>
<div><ul class=""simple"">
<li><p>check if the object has defined a <code class=""docutils literal notranslate""><span class=""pre"">toDict</span></code> method and call it.
A <code class=""docutils literal notranslate""><span class=""pre"">toDict</span></code> method should return a <code class=""docutils literal notranslate""><span class=""pre"">dict</span></code> which will then be JSON serialized.</p></li>
<li><p>invoke the <code class=""docutils literal notranslate""><span class=""pre"">default_handler</span></code> if one was provided.</p></li>
<li><p>convert the object to a <code class=""docutils literal notranslate""><span class=""pre"">dict</span></code> by traversing its contents. However this will often fail
with an <code class=""docutils literal notranslate""><span class=""pre"">OverflowError</span></code> or give unexpected results.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<p>In general the best approach for unsupported objects or dtypes is to provide a <code class=""docutils literal notranslate""><span class=""pre"">default_handler</span></code>.
For example:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">DataFrame</span><span class=""p"">([</span><span class=""mf"">1.0</span><span class=""p"">,</span> <span class=""mf"">2.0</span><span class=""p"">,</span> <span class=""nb"">complex</span><span class=""p"">(</span><span class=""mf"">1.0</span><span class=""p"">,</span> <span class=""mf"">2.0</span><span class=""p"">)])</span><span class=""o"">.</span><span class=""n"">to_json</span><span class=""p"">()</span>  <span class=""c1""># raises</span>
<span class=""go"">RuntimeError: Unhandled numpy dtype 15</span>
</pre></div>
</div>
<p>can be dealt with by specifying a simple <code class=""docutils literal notranslate""><span class=""pre"">default_handler</span></code>:</p>

</section>
</section>
<section id=""reading-json"">
<span id=""io-json-reader""></span><h3>Reading JSON<a class=""headerlink"" href=""#reading-json"" title=""Link to this heading"">#</a></h3>
<p>Reading a JSON string to pandas object can take a number of parameters.
The parser will try to parse a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> if <code class=""docutils literal notranslate""><span class=""pre"">typ</span></code> is not supplied or
is <code class=""docutils literal notranslate""><span class=""pre"">None</span></code>. To explicitly force <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> parsing, pass <code class=""docutils literal notranslate""><span class=""pre"">typ=series</span></code></p>
<ul>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">filepath_or_buffer</span></code> : a <strong>VALID</strong> JSON string or file handle / StringIO. The string could be
a URL. Valid URL schemes include http, ftp, S3, and file. For file URLs, a host
is expected. For instance, a local file could be
file ://localhost/path/to/table.json</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">typ</span></code> : type of object to recover (series or frame), default ‘frame’</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">orient</span></code> :</p>
<dl class=""simple"">
<dt>Series :</dt><dd><ul class=""simple"">
<li><p>default is <code class=""docutils literal notranslate""><span class=""pre"">index</span></code></p></li>
<li><p>allowed values are {<code class=""docutils literal notranslate""><span class=""pre"">split</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">records</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">index</span></code>}</p></li>
</ul>
</dd>
<dt>DataFrame</dt><dd><ul class=""simple"">
<li><p>default is <code class=""docutils literal notranslate""><span class=""pre"">columns</span></code></p></li>
<li><p>allowed values are {<code class=""docutils literal notranslate""><span class=""pre"">split</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">records</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">index</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">columns</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">values</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">table</span></code>}</p></li>
</ul>
</dd>
</dl>
<p>The format of the JSON string</p>

</li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code> : if True, infer dtypes, if a dict of column to dtype, then use those, if <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>, then don’t infer dtypes at all, default is True, apply only to the data.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">convert_axes</span></code> : boolean, try to convert the axes to the proper dtypes, default is <code class=""docutils literal notranslate""><span class=""pre"">True</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">convert_dates</span></code> : a list of columns to parse for dates; If <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>, then try to parse date-like columns, default is <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">keep_default_dates</span></code> : boolean, default <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>. If parsing dates, then parse the default date-like columns.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">precise_float</span></code> : boolean, default <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>. Set to enable usage of higher precision (strtod) function when decoding string to double values. Default (<code class=""docutils literal notranslate""><span class=""pre"">False</span></code>) is to use fast but less precise builtin functionality.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">date_unit</span></code> : string, the timestamp unit to detect if converting dates. Default
None. By default the timestamp precision will be detected, if this is not desired
then pass one of ‘s’, ‘ms’, ‘us’ or ‘ns’ to force timestamp precision to
seconds, milliseconds, microseconds or nanoseconds respectively.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">lines</span></code> : reads file as one json object per line.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">encoding</span></code> : The encoding to use to decode py3 bytes.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">chunksize</span></code> : when used in combination with <code class=""docutils literal notranslate""><span class=""pre"">lines=True</span></code>, return a <code class=""docutils literal notranslate""><span class=""pre"">pandas.api.typing.JsonReader</span></code> which reads in <code class=""docutils literal notranslate""><span class=""pre"">chunksize</span></code> lines per iteration.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">engine</span></code>: Either <code class=""docutils literal notranslate""><span class=""pre"">""ujson""</span></code>, the built-in JSON parser, or <code class=""docutils literal notranslate""><span class=""pre"">""pyarrow""</span></code> which dispatches to pyarrow’s <code class=""docutils literal notranslate""><span class=""pre"">pyarrow.json.read_json</span></code>.
The <code class=""docutils literal notranslate""><span class=""pre"">""pyarrow""</span></code> is only available when <code class=""docutils literal notranslate""><span class=""pre"">lines=True</span></code></p></li>
</ul>
<p>The parser will raise one of <code class=""docutils literal notranslate""><span class=""pre"">ValueError/TypeError/AssertionError</span></code> if the JSON is not parseable.</p>
<p>If a non-default <code class=""docutils literal notranslate""><span class=""pre"">orient</span></code> was used when encoding to JSON be sure to pass the same
option here so that decoding produces sensible results, see <a class=""reference internal"" href=""#orient-options"">Orient Options</a> for an
overview.</p>
<section id=""data-conversion"">
<h4>Data conversion<a class=""headerlink"" href=""#data-conversion"" title=""Link to this heading"">#</a></h4>
<p>The default of <code class=""docutils literal notranslate""><span class=""pre"">convert_axes=True</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">dtype=True</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">convert_dates=True</span></code>
will try to parse the axes, and all of the data into appropriate types,
including dates. If you need to override specific dtypes, pass a dict to
<code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code>. <code class=""docutils literal notranslate""><span class=""pre"">convert_axes</span></code> should only be set to <code class=""docutils literal notranslate""><span class=""pre"">False</span></code> if you need to
preserve string-like numbers (e.g. ‘1’, ‘2’) in an axes.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Large integer values may be converted to dates if <code class=""docutils literal notranslate""><span class=""pre"">convert_dates=True</span></code> and the data and / or column labels appear ‘date-like’. The exact threshold depends on the <code class=""docutils literal notranslate""><span class=""pre"">date_unit</span></code> specified. ‘date-like’ means that the column label meets one of the following criteria:</p>
<ul class=""simple"">
<li><p>it ends with <code class=""docutils literal notranslate""><span class=""pre"">'_at'</span></code></p></li>
<li><p>it ends with <code class=""docutils literal notranslate""><span class=""pre"">'_time'</span></code></p></li>
<li><p>it begins with <code class=""docutils literal notranslate""><span class=""pre"">'timestamp'</span></code></p></li>
<li><p>it is <code class=""docutils literal notranslate""><span class=""pre"">'modified'</span></code></p></li>
<li><p>it is <code class=""docutils literal notranslate""><span class=""pre"">'date'</span></code></p></li>
</ul>
</div>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>When reading JSON data, automatic coercing into dtypes has some quirks:</p>
<ul class=""simple"">
<li><p>an index can be reconstructed in a different order from serialization, that is, the returned order is not guaranteed to be the same as before serialization</p></li>
<li><p>a column that was <code class=""docutils literal notranslate""><span class=""pre"">float</span></code> data will be converted to <code class=""docutils literal notranslate""><span class=""pre"">integer</span></code> if it can be done safely, e.g. a column of <code class=""docutils literal notranslate""><span class=""pre"">1.</span></code></p></li>
<li><p>bool columns will be converted to <code class=""docutils literal notranslate""><span class=""pre"">integer</span></code> on reconstruction</p></li>
</ul>
<p>Thus there are times where you may want to specify specific dtypes via the <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code> keyword argument.</p>
</div>
<p>Reading from a JSON string:</p>

<p>Reading from a file:</p>

<p>Don’t convert any data (but still convert axes and dates):</p>

<p>Specify dtypes for conversion:</p>

<p>Preserve string indices:</p>

<p>Dates written in nanoseconds need to be read back in nanoseconds:</p>

<p>By setting the <code class=""docutils literal notranslate""><span class=""pre"">dtype_backend</span></code> argument you can control the default dtypes used for the resulting DataFrame.</p>

</section>
</section>
<section id=""normalization"">
<span id=""io-json-normalize""></span><h3>Normalization<a class=""headerlink"" href=""#normalization"" title=""Link to this heading"">#</a></h3>
<p>pandas provides a utility function to take a dict or list of dicts and <em>normalize</em> this semi-structured data
into a flat table.</p>


<p>The max_level parameter provides more control over which level to end normalization.
With max_level=1 the following snippet normalizes until 1st nesting level of the provided dict.</p>

</section>
<section id=""line-delimited-json"">
<span id=""io-jsonl""></span><h3>Line delimited json<a class=""headerlink"" href=""#line-delimited-json"" title=""Link to this heading"">#</a></h3>
<p>pandas is able to read and write line-delimited json files that are common in data processing pipelines
using Hadoop or Spark.</p>
<p>For line-delimited json files, pandas can also return an iterator which reads in <code class=""docutils literal notranslate""><span class=""pre"">chunksize</span></code> lines at a time. This can be useful for large files or to read from a stream.</p>

<p>Line-limited json can also be read using the pyarrow reader by specifying <code class=""docutils literal notranslate""><span class=""pre"">engine=""pyarrow""</span></code>.</p>

<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 2.0.0.</span></p>
</div>
</section>
<section id=""table-schema"">
<span id=""io-table-schema""></span><h3>Table schema<a class=""headerlink"" href=""#table-schema"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference external"" href=""https://specs.frictionlessdata.io/table-schema/"">Table Schema</a> is a spec for describing tabular datasets as a JSON
object. The JSON includes information on the field names, types, and
other attributes. You can use the orient <code class=""docutils literal notranslate""><span class=""pre"">table</span></code> to build
a JSON string with two fields, <code class=""docutils literal notranslate""><span class=""pre"">schema</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">data</span></code>.</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">schema</span></code> field contains the <code class=""docutils literal notranslate""><span class=""pre"">fields</span></code> key, which itself contains
a list of column name to type pairs, including the <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code>
(see below for a list of types).
The <code class=""docutils literal notranslate""><span class=""pre"">schema</span></code> field also contains a <code class=""docutils literal notranslate""><span class=""pre"">primaryKey</span></code> field if the (Multi)index
is unique.</p>
<p>The second field, <code class=""docutils literal notranslate""><span class=""pre"">data</span></code>, contains the serialized data with the <code class=""docutils literal notranslate""><span class=""pre"">records</span></code>
orient.
The index is included, and any datetimes are ISO 8601 formatted, as required
by the Table Schema spec.</p>
<p>The full list of types supported are described in the Table Schema
spec. This table shows the mapping from pandas types:</p>

<p>A few notes on the generated table schema:</p>
<ul>
<li><p>The <code class=""docutils literal notranslate""><span class=""pre"">schema</span></code> object contains a <code class=""docutils literal notranslate""><span class=""pre"">pandas_version</span></code> field. This contains
the version of pandas’ dialect of the schema, and will be incremented
with each revision.</p></li>
<li><p>All dates are converted to UTC when serializing. Even timezone naive values,
which are treated as UTC with an offset of 0.</p>

</li>
<li><p>datetimes with a timezone (before serializing), include an additional field
<code class=""docutils literal notranslate""><span class=""pre"">tz</span></code> with the time zone name (e.g. <code class=""docutils literal notranslate""><span class=""pre"">'US/Central'</span></code>).</p>

</li>
<li><p>Periods are converted to timestamps before serialization, and so have the
same behavior of being converted to UTC. In addition, periods will contain
and additional field <code class=""docutils literal notranslate""><span class=""pre"">freq</span></code> with the period’s frequency, e.g. <code class=""docutils literal notranslate""><span class=""pre"">'A-DEC'</span></code>.</p>

</li>
<li><p>Categoricals use the <code class=""docutils literal notranslate""><span class=""pre"">any</span></code> type and an <code class=""docutils literal notranslate""><span class=""pre"">enum</span></code> constraint listing
the set of possible values. Additionally, an <code class=""docutils literal notranslate""><span class=""pre"">ordered</span></code> field is included:</p>

</li>
<li><p>A <code class=""docutils literal notranslate""><span class=""pre"">primaryKey</span></code> field, containing an array of labels, is included
<em>if the index is unique</em>:</p>

</li>
<li><p>The <code class=""docutils literal notranslate""><span class=""pre"">primaryKey</span></code> behavior is the same with MultiIndexes, but in this
case the <code class=""docutils literal notranslate""><span class=""pre"">primaryKey</span></code> is an array:</p>

</li>
<li><p>The default naming roughly follows these rules:</p>
<blockquote>
<div><ul class=""simple"">
<li><p>For series, the <code class=""docutils literal notranslate""><span class=""pre"">object.name</span></code> is used. If that’s none, then the
name is <code class=""docutils literal notranslate""><span class=""pre"">values</span></code></p></li>
<li><p>For <code class=""docutils literal notranslate""><span class=""pre"">DataFrames</span></code>, the stringified version of the column name is used</p></li>
<li><p>For <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> (not <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code>), <code class=""docutils literal notranslate""><span class=""pre"">index.name</span></code> is used, with a
fallback to <code class=""docutils literal notranslate""><span class=""pre"">index</span></code> if that is None.</p></li>
<li><p>For <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">mi.names</span></code> is used. If any level has no name,
then <code class=""docutils literal notranslate""><span class=""pre"">level_&lt;i&gt;</span></code> is used.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<p><code class=""docutils literal notranslate""><span class=""pre"">read_json</span></code> also accepts <code class=""docutils literal notranslate""><span class=""pre"">orient='table'</span></code> as an argument. This allows for
the preservation of metadata such as dtypes and index names in a
round-trippable manner.</p>

<p>Please note that the literal string ‘index’ as the name of an <a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a>
is not round-trippable, nor are any names beginning with <code class=""docutils literal notranslate""><span class=""pre"">'level_'</span></code> within a
<a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a>. These are used by default in <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_json.html#pandas.DataFrame.to_json"" title=""pandas.DataFrame.to_json""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">DataFrame.to_json()</span></code></a> to
indicate missing values and the subsequent read cannot distinguish the intent.</p>

<p>When using <code class=""docutils literal notranslate""><span class=""pre"">orient='table'</span></code> along with user-defined <code class=""docutils literal notranslate""><span class=""pre"">ExtensionArray</span></code>,
the generated schema will contain an additional <code class=""docutils literal notranslate""><span class=""pre"">extDtype</span></code> key in the respective
<code class=""docutils literal notranslate""><span class=""pre"">fields</span></code> element. This extra key is not standard but does enable JSON roundtrips
for extension types (e.g. <code class=""docutils literal notranslate""><span class=""pre"">read_json(df.to_json(orient=""table""),</span> <span class=""pre"">orient=""table"")</span></code>).</p>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">extDtype</span></code> key carries the name of the extension, if you have properly registered
the <code class=""docutils literal notranslate""><span class=""pre"">ExtensionDtype</span></code>, pandas will use said name to perform a lookup into the registry
and re-convert the serialized data into your custom dtype.</p>
</section>
</section>
<section id=""html"">
<h2>HTML<a class=""headerlink"" href=""#html"" title=""Link to this heading"">#</a></h2>
<section id=""reading-html-content"">
<span id=""io-read-html""></span><h3>Reading HTML content<a class=""headerlink"" href=""#reading-html-content"" title=""Link to this heading"">#</a></h3>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>We <strong>highly encourage</strong> you to read the <a class=""reference internal"" href=""#io-html-gotchas""><span class=""std std-ref"">HTML Table Parsing gotchas</span></a>
below regarding the issues surrounding the BeautifulSoup4/html5lib/lxml parsers.</p>
</div>
<p>The top-level <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_html()</span></code> function can accept an HTML
string/file/URL and will parse HTML tables into list of pandas <code class=""docutils literal notranslate""><span class=""pre"">DataFrames</span></code>.
Let’s look at a few examples.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">read_html</span></code> returns a <code class=""docutils literal notranslate""><span class=""pre"">list</span></code> of <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> objects, even if there is
only a single table contained in the HTML content.</p>
</div>
<p>Read a URL with no options:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The data from the above URL changes every Monday so the resulting data above may be slightly different.</p>
</div>
<p>Read a URL while passing headers alongside the HTTP request:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>We see above that the headers we passed are reflected in the HTTP request.</p>
</div>
<p>Read in the content of the file from the above URL and pass it to <code class=""docutils literal notranslate""><span class=""pre"">read_html</span></code>
as a string:</p>

<p>You can even pass in an instance of <code class=""docutils literal notranslate""><span class=""pre"">StringIO</span></code> if you so desire:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The following examples are not run by the IPython evaluator due to the fact
that having so many network-accessing functions slows down the documentation
build. If you spot an error or an example that doesn’t run, please do not
hesitate to report it over on <a class=""reference external"" href=""https://github.com/pandas-dev/pandas/issues"">pandas GitHub issues page</a>.</p>
</div>
<p>Read a URL and match a table that contains specific text:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">match</span> <span class=""o"">=</span> <span class=""s2"">""Metcalf Bank""</span>
<span class=""n"">df_list</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_html</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">match</span><span class=""o"">=</span><span class=""n"">match</span><span class=""p"">)</span>
</pre></div>
</div>
<p>Specify a header row (by default <code class=""docutils literal notranslate""><span class=""pre"">&lt;th&gt;</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">&lt;td&gt;</span></code> elements located within a
<code class=""docutils literal notranslate""><span class=""pre"">&lt;thead&gt;</span></code> are used to form the column index, if multiple rows are contained within
<code class=""docutils literal notranslate""><span class=""pre"">&lt;thead&gt;</span></code> then a MultiIndex is created); if specified, the header row is taken
from the data minus the parsed header elements (<code class=""docutils literal notranslate""><span class=""pre"">&lt;th&gt;</span></code> elements).</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">dfs</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_html</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">header</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">)</span>
</pre></div>
</div>
<p>Specify an index column:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">dfs</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_html</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">index_col</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">)</span>
</pre></div>
</div>
<p>Specify a number of rows to skip:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">dfs</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_html</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">skiprows</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">)</span>
</pre></div>
</div>
<p>Specify a number of rows to skip using a list (<code class=""docutils literal notranslate""><span class=""pre"">range</span></code> works
as well):</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">dfs</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_html</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">skiprows</span><span class=""o"">=</span><span class=""nb"">range</span><span class=""p"">(</span><span class=""mi"">2</span><span class=""p"">))</span>
</pre></div>
</div>
<p>Specify an HTML attribute:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">dfs1</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_html</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">attrs</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s2"">""id""</span><span class=""p"">:</span> <span class=""s2"">""table""</span><span class=""p"">})</span>
<span class=""n"">dfs2</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_html</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">attrs</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s2"">""class""</span><span class=""p"">:</span> <span class=""s2"">""sortable""</span><span class=""p"">})</span>
<span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">np</span><span class=""o"">.</span><span class=""n"">array_equal</span><span class=""p"">(</span><span class=""n"">dfs1</span><span class=""p"">[</span><span class=""mi"">0</span><span class=""p"">],</span> <span class=""n"">dfs2</span><span class=""p"">[</span><span class=""mi"">0</span><span class=""p"">]))</span>  <span class=""c1""># Should be True</span>
</pre></div>
</div>
<p>Specify values that should be converted to NaN:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">dfs</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_html</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">na_values</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""No Acquirer""</span><span class=""p"">])</span>
</pre></div>
</div>
<p>Specify whether to keep the default set of NaN values:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">dfs</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_html</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">keep_default_na</span><span class=""o"">=</span><span class=""kc"">False</span><span class=""p"">)</span>
</pre></div>
</div>
<p>Specify converters for columns. This is useful for numerical text data that has
leading zeros. By default columns that are numerical are cast to numeric
types and the leading zeros are lost. To avoid this, we can convert these
columns to strings.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">url_mcc</span> <span class=""o"">=</span> <span class=""s2"">""https://en.wikipedia.org/wiki/Mobile_country_code?oldid=899173761""</span>
<span class=""n"">dfs</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_html</span><span class=""p"">(</span>
    <span class=""n"">url_mcc</span><span class=""p"">,</span>
    <span class=""n"">match</span><span class=""o"">=</span><span class=""s2"">""Telekom Albania""</span><span class=""p"">,</span>
    <span class=""n"">header</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">,</span>
    <span class=""n"">converters</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s2"">""MNC""</span><span class=""p"">:</span> <span class=""nb"">str</span><span class=""p"">},</span>
<span class=""p"">)</span>
</pre></div>
</div>
<p>Use some combination of the above:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">dfs</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_html</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""n"">match</span><span class=""o"">=</span><span class=""s2"">""Metcalf Bank""</span><span class=""p"">,</span> <span class=""n"">index_col</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">)</span>
</pre></div>
</div>
<p>Read in pandas <code class=""docutils literal notranslate""><span class=""pre"">to_html</span></code> output (with some loss of floating point precision):</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">(</span><span class=""n"">np</span><span class=""o"">.</span><span class=""n"">random</span><span class=""o"">.</span><span class=""n"">randn</span><span class=""p"">(</span><span class=""mi"">2</span><span class=""p"">,</span> <span class=""mi"">2</span><span class=""p"">))</span>
<span class=""n"">s</span> <span class=""o"">=</span> <span class=""n"">df</span><span class=""o"">.</span><span class=""n"">to_html</span><span class=""p"">(</span><span class=""n"">float_format</span><span class=""o"">=</span><span class=""s2"">""</span><span class=""si"">{0:.40g}</span><span class=""s2"">""</span><span class=""o"">.</span><span class=""n"">format</span><span class=""p"">)</span>
<span class=""n"">dfin</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_html</span><span class=""p"">(</span><span class=""n"">s</span><span class=""p"">,</span> <span class=""n"">index_col</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">)</span>
</pre></div>
</div>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">lxml</span></code> backend will raise an error on a failed parse if that is the only
parser you provide. If you only have a single parser you can provide just a
string, but it is considered good practice to pass a list with one string if,
for example, the function expects a sequence of strings. You may use:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">dfs</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_html</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""s2"">""Metcalf Bank""</span><span class=""p"">,</span> <span class=""n"">index_col</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">,</span> <span class=""n"">flavor</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""lxml""</span><span class=""p"">])</span>
</pre></div>
</div>
<p>Or you could pass <code class=""docutils literal notranslate""><span class=""pre"">flavor='lxml'</span></code> without a list:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">dfs</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_html</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""s2"">""Metcalf Bank""</span><span class=""p"">,</span> <span class=""n"">index_col</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">,</span> <span class=""n"">flavor</span><span class=""o"">=</span><span class=""s2"">""lxml""</span><span class=""p"">)</span>
</pre></div>
</div>
<p>However, if you have bs4 and html5lib installed and pass <code class=""docutils literal notranslate""><span class=""pre"">None</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">['lxml',</span>
<span class=""pre"">'bs4']</span></code> then the parse will most likely succeed. Note that <em>as soon as a parse
succeeds, the function will return</em>.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">dfs</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_html</span><span class=""p"">(</span><span class=""n"">url</span><span class=""p"">,</span> <span class=""s2"">""Metcalf Bank""</span><span class=""p"">,</span> <span class=""n"">index_col</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">,</span> <span class=""n"">flavor</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""lxml""</span><span class=""p"">,</span> <span class=""s2"">""bs4""</span><span class=""p"">])</span>
</pre></div>
</div>
<p>Links can be extracted from cells along with the text using <code class=""docutils literal notranslate""><span class=""pre"">extract_links=""all""</span></code>.</p>

<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.5.0.</span></p>
</div>
</section>
<section id=""writing-to-html-files"">
<span id=""io-html""></span><h3>Writing to HTML files<a class=""headerlink"" href=""#writing-to-html-files"" title=""Link to this heading"">#</a></h3>
<p><code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> objects have an instance method <code class=""docutils literal notranslate""><span class=""pre"">to_html</span></code> which renders the
contents of the <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> as an HTML table. The function arguments are as
in the method <code class=""docutils literal notranslate""><span class=""pre"">to_string</span></code> described above.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Not all of the possible options for <code class=""docutils literal notranslate""><span class=""pre"">DataFrame.to_html</span></code> are shown here for
brevity’s sake. See <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">DataFrame.to_html()</span></code> for the
full set of options.</p>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>In an HTML-rendering supported environment like a Jupyter Notebook, <code class=""docutils literal notranslate""><span class=""pre"">display(HTML(...))`</span></code>
will render the raw HTML into the environment.</p>
</div>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">columns</span></code> argument will limit the columns shown:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">float_format</span></code> takes a Python callable to control the precision of floating
point values:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">bold_rows</span></code> will make the row labels bold by default, but you can turn that
off:</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">classes</span></code> argument provides the ability to give the resulting HTML
table CSS classes. Note that these classes are <em>appended</em> to the existing
<code class=""docutils literal notranslate""><span class=""pre"">'dataframe'</span></code> class.</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">render_links</span></code> argument provides the ability to add hyperlinks to cells
that contain URLs.</p>

<p>Finally, the <code class=""docutils literal notranslate""><span class=""pre"">escape</span></code> argument allows you to control whether the
“&lt;”, “&gt;” and “&amp;” characters escaped in the resulting HTML (by default it is
<code class=""docutils literal notranslate""><span class=""pre"">True</span></code>). So to get the HTML without escaped characters pass <code class=""docutils literal notranslate""><span class=""pre"">escape=False</span></code></p>

<p>Escaped:</p>

<p>Not escaped:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Some browsers may not show a difference in the rendering of the previous two
HTML tables.</p>
</div>
</section>
<section id=""html-table-parsing-gotchas"">
<span id=""io-html-gotchas""></span><h3>HTML Table Parsing Gotchas<a class=""headerlink"" href=""#html-table-parsing-gotchas"" title=""Link to this heading"">#</a></h3>
<p>There are some versioning issues surrounding the libraries that are used to
parse HTML tables in the top-level pandas io function <code class=""docutils literal notranslate""><span class=""pre"">read_html</span></code>.</p>
<p><strong>Issues with</strong> <a class=""reference external"" href=""https://lxml.de""><strong>lxml</strong></a></p>
<ul>
<li><p>Benefits</p>
<blockquote>
<div><ul class=""simple"">
<li><p><a class=""reference external"" href=""https://lxml.de""><strong>lxml</strong></a> is very fast.</p></li>
<li><p><a class=""reference external"" href=""https://lxml.de""><strong>lxml</strong></a> requires Cython to install correctly.</p></li>
</ul>
</div></blockquote>
</li>
<li><p>Drawbacks</p>
<blockquote>
<div><ul class=""simple"">
<li><p><a class=""reference external"" href=""https://lxml.de""><strong>lxml</strong></a> does <em>not</em> make any guarantees about the results of its parse
<em>unless</em> it is given <a class=""reference external"" href=""https://validator.w3.org/docs/help.html#validation_basics""><strong>strictly valid markup</strong></a>.</p></li>
<li><p>In light of the above, we have chosen to allow you, the user, to use the
<a class=""reference external"" href=""https://lxml.de""><strong>lxml</strong></a> backend, but <strong>this backend will use</strong> <a class=""reference external"" href=""https://github.com/html5lib/html5lib-python""><strong>html5lib</strong></a> if <a class=""reference external"" href=""https://lxml.de""><strong>lxml</strong></a>
fails to parse</p></li>
<li><p>It is therefore <em>highly recommended</em> that you install both
<a class=""reference external"" href=""https://www.crummy.com/software/BeautifulSoup""><strong>BeautifulSoup4</strong></a> and <a class=""reference external"" href=""https://github.com/html5lib/html5lib-python""><strong>html5lib</strong></a>, so that you will still get a valid
result (provided everything else is valid) even if <a class=""reference external"" href=""https://lxml.de""><strong>lxml</strong></a> fails.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<p><strong>Issues with</strong> <a class=""reference external"" href=""https://www.crummy.com/software/BeautifulSoup""><strong>BeautifulSoup4</strong></a> <strong>using</strong> <a class=""reference external"" href=""https://lxml.de""><strong>lxml</strong></a> <strong>as a backend</strong></p>
<ul class=""simple"">
<li><p>The above issues hold here as well since <a class=""reference external"" href=""https://www.crummy.com/software/BeautifulSoup""><strong>BeautifulSoup4</strong></a> is essentially
just a wrapper around a parser backend.</p></li>
</ul>
<p><strong>Issues with</strong> <a class=""reference external"" href=""https://www.crummy.com/software/BeautifulSoup""><strong>BeautifulSoup4</strong></a> <strong>using</strong> <a class=""reference external"" href=""https://github.com/html5lib/html5lib-python""><strong>html5lib</strong></a> <strong>as a backend</strong></p>
<ul>
<li><p>Benefits</p>
<blockquote>
<div><ul class=""simple"">
<li><p><a class=""reference external"" href=""https://github.com/html5lib/html5lib-python""><strong>html5lib</strong></a> is far more lenient than <a class=""reference external"" href=""https://lxml.de""><strong>lxml</strong></a> and consequently deals
with <em>real-life markup</em> in a much saner way rather than just, e.g.,
dropping an element without notifying you.</p></li>
<li><p><a class=""reference external"" href=""https://github.com/html5lib/html5lib-python""><strong>html5lib</strong></a> <em>generates valid HTML5 markup from invalid markup
automatically</em>. This is extremely important for parsing HTML tables,
since it guarantees a valid document. However, that does NOT mean that
it is “correct”, since the process of fixing markup does not have a
single definition.</p></li>
<li><p><a class=""reference external"" href=""https://github.com/html5lib/html5lib-python""><strong>html5lib</strong></a> is pure Python and requires no additional build steps beyond
its own installation.</p></li>
</ul>
</div></blockquote>
</li>
<li><p>Drawbacks</p>
<blockquote>
<div><ul class=""simple"">
<li><p>The biggest drawback to using <a class=""reference external"" href=""https://github.com/html5lib/html5lib-python""><strong>html5lib</strong></a> is that it is slow as
molasses. However consider the fact that many tables on the web are not
big enough for the parsing algorithm runtime to matter. It is more
likely that the bottleneck will be in the process of reading the raw
text from the URL over the web, i.e., IO (input-output). For very large
tables, this might not be true.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</section>
</section>
<section id=""latex"">
<span id=""io-latex""></span><h2>LaTeX<a class=""headerlink"" href=""#latex"" title=""Link to this heading"">#</a></h2>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.3.0.</span></p>
</div>
<p>Currently there are no methods to read from LaTeX, only output methods.</p>
<section id=""writing-to-latex-files"">
<h3>Writing to LaTeX files<a class=""headerlink"" href=""#writing-to-latex-files"" title=""Link to this heading"">#</a></h3>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>DataFrame <em>and</em> Styler objects currently have a <code class=""docutils literal notranslate""><span class=""pre"">to_latex</span></code> method. We recommend
using the <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.to_latex.html""><span class=""doc"">Styler.to_latex()</span></a> method
over <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_latex.html""><span class=""doc"">DataFrame.to_latex()</span></a> due to the former’s greater flexibility with
conditional styling, and the latter’s possible future deprecation.</p>
</div>
<p>Review the documentation for <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.to_latex.html""><span class=""doc"">Styler.to_latex</span></a>,
which gives examples of conditional styling and explains the operation of its keyword
arguments.</p>
<p>For simple application the following pattern is sufficient.</p>

<p>To format values before output, chain the <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.format.html""><span class=""doc"">Styler.format</span></a>
method.</p>

</section>
</section>
<section id=""xml"">
<h2>XML<a class=""headerlink"" href=""#xml"" title=""Link to this heading"">#</a></h2>
<section id=""reading-xml"">
<span id=""io-read-xml""></span><h3>Reading XML<a class=""headerlink"" href=""#reading-xml"" title=""Link to this heading"">#</a></h3>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.3.0.</span></p>
</div>
<p>The top-level <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_xml()</span></code> function can accept an XML
string/file/URL and will parse nodes and attributes into a pandas <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Since there is no standard XML structure where design types can vary in
many ways, <code class=""docutils literal notranslate""><span class=""pre"">read_xml</span></code> works best with flatter, shallow versions. If
an XML document is deeply nested, use the <code class=""docutils literal notranslate""><span class=""pre"">stylesheet</span></code> feature to
transform XML into a flatter version.</p>
</div>
<p>Let’s look at a few examples.</p>
<p>Read an XML string:</p>

<p>Read a URL with no options:</p>

<p>Read in the content of the “books.xml” file and pass it to <code class=""docutils literal notranslate""><span class=""pre"">read_xml</span></code>
as a string:</p>

<p>Read in the content of the “books.xml” as instance of <code class=""docutils literal notranslate""><span class=""pre"">StringIO</span></code> or
<code class=""docutils literal notranslate""><span class=""pre"">BytesIO</span></code> and pass it to <code class=""docutils literal notranslate""><span class=""pre"">read_xml</span></code>:</p>


<p>Even read XML from AWS S3 buckets such as NIH NCBI PMC Article Datasets providing
Biomedical and Life Science Jorurnals:</p>

<p>With <a class=""reference external"" href=""https://lxml.de"">lxml</a> as default <code class=""docutils literal notranslate""><span class=""pre"">parser</span></code>, you access the full-featured XML library
that extends Python’s ElementTree API. One powerful tool is ability to query
nodes selectively or conditionally with more expressive XPath:</p>

<p>Specify only elements or only attributes to parse:</p>


<p>XML documents can have namespaces with prefixes and default namespaces without
prefixes both of which are denoted with a special attribute <code class=""docutils literal notranslate""><span class=""pre"">xmlns</span></code>. In order
to parse by node under a namespace context, <code class=""docutils literal notranslate""><span class=""pre"">xpath</span></code> must reference a prefix.</p>
<p>For example, below XML contains a namespace with prefix, <code class=""docutils literal notranslate""><span class=""pre"">doc</span></code>, and URI at
<code class=""docutils literal notranslate""><span class=""pre"">https://example.com</span></code>. In order to parse <code class=""docutils literal notranslate""><span class=""pre"">doc:row</span></code> nodes,
<code class=""docutils literal notranslate""><span class=""pre"">namespaces</span></code> must be used.</p>

<p>Similarly, an XML document can have a default namespace without prefix. Failing
to assign a temporary prefix will return no nodes and raise a <code class=""docutils literal notranslate""><span class=""pre"">ValueError</span></code>.
But assigning <em>any</em> temporary name to correct URI allows parsing by nodes.</p>

<p>However, if XPath does not reference node names such as default, <code class=""docutils literal notranslate""><span class=""pre"">/*</span></code>, then
<code class=""docutils literal notranslate""><span class=""pre"">namespaces</span></code> is not required.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Since <code class=""docutils literal notranslate""><span class=""pre"">xpath</span></code> identifies the parent of content to be parsed, only immediate
desendants which include child nodes or current attributes are parsed.
Therefore, <code class=""docutils literal notranslate""><span class=""pre"">read_xml</span></code> will not parse the text of grandchildren or other
descendants and will not parse attributes of any descendant. To retrieve
lower level content, adjust xpath to lower level. For example,</p>

<p>shows the attribute <code class=""docutils literal notranslate""><span class=""pre"">sides</span></code> on <code class=""docutils literal notranslate""><span class=""pre"">shape</span></code> element was not parsed as
expected since this attribute resides on the child of <code class=""docutils literal notranslate""><span class=""pre"">row</span></code> element
and not <code class=""docutils literal notranslate""><span class=""pre"">row</span></code> element itself. In other words, <code class=""docutils literal notranslate""><span class=""pre"">sides</span></code> attribute is a
grandchild level descendant of <code class=""docutils literal notranslate""><span class=""pre"">row</span></code> element. However, the <code class=""docutils literal notranslate""><span class=""pre"">xpath</span></code>
targets <code class=""docutils literal notranslate""><span class=""pre"">row</span></code> element which covers only its children and attributes.</p>
</div>
<p>With <a class=""reference external"" href=""https://lxml.de"">lxml</a> as parser, you can flatten nested XML documents with an XSLT
script which also can be string/file/URL types. As background, <a class=""reference external"" href=""https://www.w3.org/TR/xslt/"">XSLT</a> is
a special-purpose language written in a special XML file that can transform
original XML documents into other XML, HTML, even text (CSV, JSON, etc.)
using an XSLT processor.</p>
<p>For example, consider this somewhat nested structure of Chicago “L” Rides
where station and rides elements encapsulate data in their own sections.
With below XSLT, <code class=""docutils literal notranslate""><span class=""pre"">lxml</span></code> can transform original nested document into a flatter
output (as shown below for demonstration) for easier parse into <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>:</p>

<p>For very large XML files that can range in hundreds of megabytes to gigabytes, <a class=""reference internal"" href=""../reference/api/pandas.read_xml.html#pandas.read_xml"" title=""pandas.read_xml""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.read_xml()</span></code></a>
supports parsing such sizeable files using <a class=""reference external"" href=""https://lxml.de/3.2/parsing.html#iterparse-and-iterwalk"">lxml’s iterparse</a> and <a class=""reference external"" href=""https://docs.python.org/3/library/xml.etree.elementtree.html#xml.etree.ElementTree.iterparse"">etree’s iterparse</a>
which are memory-efficient methods to iterate through an XML tree and extract specific elements and attributes.
without holding entire tree in memory.</p>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.5.0.</span></p>
</div>
<p>To use this feature, you must pass a physical XML file path into <code class=""docutils literal notranslate""><span class=""pre"">read_xml</span></code> and use the <code class=""docutils literal notranslate""><span class=""pre"">iterparse</span></code> argument.
Files should not be compressed or point to online sources but stored on local disk. Also, <code class=""docutils literal notranslate""><span class=""pre"">iterparse</span></code> should be
a dictionary where the key is the repeating nodes in document (which become the rows) and the value is a list of
any element or attribute that is a descendant (i.e., child, grandchild) of repeating node. Since XPath is not
used in this method, descendants do not need to share same relationship with one another. Below shows example
of reading in Wikipedia’s very large (12 GB+) latest article data dump.</p>

</section>
<section id=""writing-xml"">
<span id=""io-xml""></span><h3>Writing XML<a class=""headerlink"" href=""#writing-xml"" title=""Link to this heading"">#</a></h3>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.3.0.</span></p>
</div>
<p><code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> objects have an instance method <code class=""docutils literal notranslate""><span class=""pre"">to_xml</span></code> which renders the
contents of the <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> as an XML document.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>This method does not support special properties of XML including DTD,
CData, XSD schemas, processing instructions, comments, and others.
Only namespaces at the root level is supported. However, <code class=""docutils literal notranslate""><span class=""pre"">stylesheet</span></code>
allows design changes after initial output.</p>
</div>
<p>Let’s look at a few examples.</p>
<p>Write an XML without options:</p>

<p>Write an XML with new root and row name:</p>

<p>Write an attribute-centric XML:</p>

<p>Write a mix of elements and attributes:</p>

<p>Any <code class=""docutils literal notranslate""><span class=""pre"">DataFrames</span></code> with hierarchical columns will be flattened for XML element names
with levels delimited by underscores:</p>

<p>Write an XML with default namespace:</p>

<p>Write an XML with namespace prefix:</p>

<p>Write an XML without declaration or pretty print:</p>

<p>Write an XML and transform with stylesheet:</p>

</section>
<section id=""xml-final-notes"">
<h3>XML Final Notes<a class=""headerlink"" href=""#xml-final-notes"" title=""Link to this heading"">#</a></h3>
<ul class=""simple"">
<li><p>All XML documents adhere to <a class=""reference external"" href=""https://www.w3.org/TR/xml/"">W3C specifications</a>. Both <code class=""docutils literal notranslate""><span class=""pre"">etree</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">lxml</span></code>
parsers will fail to parse any markup document that is not well-formed or
follows XML syntax rules. Do be aware HTML is not an XML document unless it
follows XHTML specs. However, other popular markup types including KML, XAML,
RSS, MusicML, MathML are compliant <a class=""reference external"" href=""https://en.wikipedia.org/wiki/List_of_types_of_XML_schemas"">XML schemas</a>.</p></li>
<li><p>For above reason, if your application builds XML prior to pandas operations,
use appropriate DOM libraries like <code class=""docutils literal notranslate""><span class=""pre"">etree</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">lxml</span></code> to build the necessary
document and not by string concatenation or regex adjustments. Always remember
XML is a <em>special</em> text file with markup rules.</p></li>
<li><p>With very large XML files (several hundred MBs to GBs), XPath and XSLT
can become memory-intensive operations. Be sure to have enough available
RAM for reading and writing to large XML files (roughly about 5 times the
size of text).</p></li>
<li><p>Because XSLT is a programming language, use it with caution since such scripts
can pose a security risk in your environment and can run large or infinite
recursive operations. Always test scripts on small fragments before full run.</p></li>
<li><p>The <a class=""reference external"" href=""https://docs.python.org/3/library/xml.etree.elementtree.html"">etree</a> parser supports all functionality of both <code class=""docutils literal notranslate""><span class=""pre"">read_xml</span></code> and
<code class=""docutils literal notranslate""><span class=""pre"">to_xml</span></code> except for complex XPath and any XSLT. Though limited in features,
<code class=""docutils literal notranslate""><span class=""pre"">etree</span></code> is still a reliable and capable parser and tree builder. Its
performance may trail <code class=""docutils literal notranslate""><span class=""pre"">lxml</span></code> to a certain degree for larger files but
relatively unnoticeable on small to medium size files.</p></li>
</ul>
</section>
</section>
<section id=""excel-files"">
<span id=""io-excel""></span><h2>Excel files<a class=""headerlink"" href=""#excel-files"" title=""Link to this heading"">#</a></h2>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.read_excel.html#pandas.read_excel"" title=""pandas.read_excel""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_excel()</span></code></a> method can read Excel 2007+ (<code class=""docutils literal notranslate""><span class=""pre"">.xlsx</span></code>) files
using the <code class=""docutils literal notranslate""><span class=""pre"">openpyxl</span></code> Python module. Excel 2003 (<code class=""docutils literal notranslate""><span class=""pre"">.xls</span></code>) files
can be read using <code class=""docutils literal notranslate""><span class=""pre"">xlrd</span></code>. Binary Excel (<code class=""docutils literal notranslate""><span class=""pre"">.xlsb</span></code>)
files can be read using <code class=""docutils literal notranslate""><span class=""pre"">pyxlsb</span></code>. All formats can be read
using <a class=""reference internal"" href=""#io-calamine""><span class=""std std-ref"">calamine</span></a> engine.
The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_excel.html#pandas.DataFrame.to_excel"" title=""pandas.DataFrame.to_excel""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">to_excel()</span></code></a> instance method is used for
saving a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> to Excel. Generally the semantics are
similar to working with <a class=""reference internal"" href=""#io-read-csv-table""><span class=""std std-ref"">csv</span></a> data.
See the <a class=""reference internal"" href=""cookbook.html#cookbook-excel""><span class=""std std-ref"">cookbook</span></a> for some advanced strategies.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>When <code class=""docutils literal notranslate""><span class=""pre"">engine=None</span></code>, the following logic will be used to determine the engine:</p>
<ul class=""simple"">
<li><p>If <code class=""docutils literal notranslate""><span class=""pre"">path_or_buffer</span></code> is an OpenDocument format (.odf, .ods, .odt),
then <a class=""reference external"" href=""https://pypi.org/project/odfpy/"">odf</a> will be used.</p></li>
<li><p>Otherwise if <code class=""docutils literal notranslate""><span class=""pre"">path_or_buffer</span></code> is an xls format, <code class=""docutils literal notranslate""><span class=""pre"">xlrd</span></code> will be used.</p></li>
<li><p>Otherwise if <code class=""docutils literal notranslate""><span class=""pre"">path_or_buffer</span></code> is in xlsb format, <code class=""docutils literal notranslate""><span class=""pre"">pyxlsb</span></code> will be used.</p></li>
<li><p>Otherwise <code class=""docutils literal notranslate""><span class=""pre"">openpyxl</span></code> will be used.</p></li>
</ul>
</div>
<section id=""reading-excel-files"">
<span id=""io-excel-reader""></span><h3>Reading Excel files<a class=""headerlink"" href=""#reading-excel-files"" title=""Link to this heading"">#</a></h3>
<p>In the most basic use-case, <code class=""docutils literal notranslate""><span class=""pre"">read_excel</span></code> takes a path to an Excel
file, and the <code class=""docutils literal notranslate""><span class=""pre"">sheet_name</span></code> indicating which sheet to parse.</p>
<p>When using the <code class=""docutils literal notranslate""><span class=""pre"">engine_kwargs</span></code> parameter, pandas will pass these arguments to the
engine. For this, it is important to know which function pandas is
using internally.</p>
<ul class=""simple"">
<li><p>For the engine openpyxl, pandas is using <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">openpyxl.load_workbook()</span></code> to read in (<code class=""docutils literal notranslate""><span class=""pre"">.xlsx</span></code>) and (<code class=""docutils literal notranslate""><span class=""pre"">.xlsm</span></code>) files.</p></li>
<li><p>For the engine xlrd, pandas is using <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">xlrd.open_workbook()</span></code> to read in (<code class=""docutils literal notranslate""><span class=""pre"">.xls</span></code>) files.</p></li>
<li><p>For the engine pyxlsb, pandas is using <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pyxlsb.open_workbook()</span></code> to read in (<code class=""docutils literal notranslate""><span class=""pre"">.xlsb</span></code>) files.</p></li>
<li><p>For the engine odf, pandas is using <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">odf.opendocument.load()</span></code> to read in (<code class=""docutils literal notranslate""><span class=""pre"">.ods</span></code>) files.</p></li>
<li><p>For the engine calamine, pandas is using <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">python_calamine.load_workbook()</span></code>
to read in (<code class=""docutils literal notranslate""><span class=""pre"">.xlsx</span></code>), (<code class=""docutils literal notranslate""><span class=""pre"">.xlsm</span></code>), (<code class=""docutils literal notranslate""><span class=""pre"">.xls</span></code>), (<code class=""docutils literal notranslate""><span class=""pre"">.xlsb</span></code>), (<code class=""docutils literal notranslate""><span class=""pre"">.ods</span></code>) files.</p></li>
</ul>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""c1""># Returns a DataFrame</span>
<span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xls""</span><span class=""p"">,</span> <span class=""n"">sheet_name</span><span class=""o"">=</span><span class=""s2"">""Sheet1""</span><span class=""p"">)</span>
</pre></div>
</div>
<section id=""excelfile-class"">
<span id=""io-excel-excelfile-class""></span><h4><code class=""docutils literal notranslate""><span class=""pre"">ExcelFile</span></code> class<a class=""headerlink"" href=""#excelfile-class"" title=""Link to this heading"">#</a></h4>
<p>To facilitate working with multiple sheets from the same file, the <code class=""docutils literal notranslate""><span class=""pre"">ExcelFile</span></code>
class can be used to wrap the file and can be passed into <code class=""docutils literal notranslate""><span class=""pre"">read_excel</span></code>
There will be a performance benefit for reading multiple sheets as the file is
read into memory only once.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">xlsx</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">ExcelFile</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xls""</span><span class=""p"">)</span>
<span class=""n"">df</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""n"">xlsx</span><span class=""p"">,</span> <span class=""s2"">""Sheet1""</span><span class=""p"">)</span>
</pre></div>
</div>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">ExcelFile</span></code> class can also be used as a context manager.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""k"">with</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">ExcelFile</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xls""</span><span class=""p"">)</span> <span class=""k"">as</span> <span class=""n"">xls</span><span class=""p"">:</span>
    <span class=""n"">df1</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""n"">xls</span><span class=""p"">,</span> <span class=""s2"">""Sheet1""</span><span class=""p"">)</span>
    <span class=""n"">df2</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""n"">xls</span><span class=""p"">,</span> <span class=""s2"">""Sheet2""</span><span class=""p"">)</span>
</pre></div>
</div>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">sheet_names</span></code> property will generate
a list of the sheet names in the file.</p>
<p>The primary use-case for an <code class=""docutils literal notranslate""><span class=""pre"">ExcelFile</span></code> is parsing multiple sheets with
different parameters:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">data</span> <span class=""o"">=</span> <span class=""p"">{}</span>
<span class=""c1""># For when Sheet1's format differs from Sheet2</span>
<span class=""k"">with</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">ExcelFile</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xls""</span><span class=""p"">)</span> <span class=""k"">as</span> <span class=""n"">xls</span><span class=""p"">:</span>
    <span class=""n"">data</span><span class=""p"">[</span><span class=""s2"">""Sheet1""</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""n"">xls</span><span class=""p"">,</span> <span class=""s2"">""Sheet1""</span><span class=""p"">,</span> <span class=""n"">index_col</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""n"">na_values</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""NA""</span><span class=""p"">])</span>
    <span class=""n"">data</span><span class=""p"">[</span><span class=""s2"">""Sheet2""</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""n"">xls</span><span class=""p"">,</span> <span class=""s2"">""Sheet2""</span><span class=""p"">,</span> <span class=""n"">index_col</span><span class=""o"">=</span><span class=""mi"">1</span><span class=""p"">)</span>
</pre></div>
</div>
<p>Note that if the same parsing parameters are used for all sheets, a list
of sheet names can simply be passed to <code class=""docutils literal notranslate""><span class=""pre"">read_excel</span></code> with no loss in performance.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""c1""># using the ExcelFile class</span>
<span class=""n"">data</span> <span class=""o"">=</span> <span class=""p"">{}</span>
<span class=""k"">with</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">ExcelFile</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xls""</span><span class=""p"">)</span> <span class=""k"">as</span> <span class=""n"">xls</span><span class=""p"">:</span>
    <span class=""n"">data</span><span class=""p"">[</span><span class=""s2"">""Sheet1""</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""n"">xls</span><span class=""p"">,</span> <span class=""s2"">""Sheet1""</span><span class=""p"">,</span> <span class=""n"">index_col</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""n"">na_values</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""NA""</span><span class=""p"">])</span>
    <span class=""n"">data</span><span class=""p"">[</span><span class=""s2"">""Sheet2""</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""n"">xls</span><span class=""p"">,</span> <span class=""s2"">""Sheet2""</span><span class=""p"">,</span> <span class=""n"">index_col</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""n"">na_values</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""NA""</span><span class=""p"">])</span>

<span class=""c1""># equivalent using the read_excel function</span>
<span class=""n"">data</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span>
    <span class=""s2"">""path_to_file.xls""</span><span class=""p"">,</span> <span class=""p"">[</span><span class=""s2"">""Sheet1""</span><span class=""p"">,</span> <span class=""s2"">""Sheet2""</span><span class=""p"">],</span> <span class=""n"">index_col</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""n"">na_values</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""NA""</span><span class=""p"">]</span>
<span class=""p"">)</span>
</pre></div>
</div>
<p><code class=""docutils literal notranslate""><span class=""pre"">ExcelFile</span></code> can also be called with a <code class=""docutils literal notranslate""><span class=""pre"">xlrd.book.Book</span></code> object
as a parameter. This allows the user to control how the excel file is read.
For example, sheets can be loaded on demand by calling <code class=""docutils literal notranslate""><span class=""pre"">xlrd.open_workbook()</span></code>
with <code class=""docutils literal notranslate""><span class=""pre"">on_demand=True</span></code>.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">xlrd</span>

<span class=""n"">xlrd_book</span> <span class=""o"">=</span> <span class=""n"">xlrd</span><span class=""o"">.</span><span class=""n"">open_workbook</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xls""</span><span class=""p"">,</span> <span class=""n"">on_demand</span><span class=""o"">=</span><span class=""kc"">True</span><span class=""p"">)</span>
<span class=""k"">with</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">ExcelFile</span><span class=""p"">(</span><span class=""n"">xlrd_book</span><span class=""p"">)</span> <span class=""k"">as</span> <span class=""n"">xls</span><span class=""p"">:</span>
    <span class=""n"">df1</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""n"">xls</span><span class=""p"">,</span> <span class=""s2"">""Sheet1""</span><span class=""p"">)</span>
    <span class=""n"">df2</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""n"">xls</span><span class=""p"">,</span> <span class=""s2"">""Sheet2""</span><span class=""p"">)</span>
</pre></div>
</div>
</section>
<section id=""specifying-sheets"">
<span id=""io-excel-specifying-sheets""></span><h4>Specifying sheets<a class=""headerlink"" href=""#specifying-sheets"" title=""Link to this heading"">#</a></h4>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The second argument is <code class=""docutils literal notranslate""><span class=""pre"">sheet_name</span></code>, not to be confused with <code class=""docutils literal notranslate""><span class=""pre"">ExcelFile.sheet_names</span></code>.</p>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>An ExcelFile’s attribute <code class=""docutils literal notranslate""><span class=""pre"">sheet_names</span></code> provides access to a list of sheets.</p>
</div>
<ul class=""simple"">
<li><p>The arguments <code class=""docutils literal notranslate""><span class=""pre"">sheet_name</span></code> allows specifying the sheet or sheets to read.</p></li>
<li><p>The default value for <code class=""docutils literal notranslate""><span class=""pre"">sheet_name</span></code> is 0, indicating to read the first sheet</p></li>
<li><p>Pass a string to refer to the name of a particular sheet in the workbook.</p></li>
<li><p>Pass an integer to refer to the index of a sheet. Indices follow Python
convention, beginning at 0.</p></li>
<li><p>Pass a list of either strings or integers, to return a dictionary of specified sheets.</p></li>
<li><p>Pass a <code class=""docutils literal notranslate""><span class=""pre"">None</span></code> to return a dictionary of all available sheets.</p></li>
</ul>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""c1""># Returns a DataFrame</span>
<span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xls""</span><span class=""p"">,</span> <span class=""s2"">""Sheet1""</span><span class=""p"">,</span> <span class=""n"">index_col</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""n"">na_values</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""NA""</span><span class=""p"">])</span>
</pre></div>
</div>
<p>Using the sheet index:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""c1""># Returns a DataFrame</span>
<span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xls""</span><span class=""p"">,</span> <span class=""mi"">0</span><span class=""p"">,</span> <span class=""n"">index_col</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""n"">na_values</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""NA""</span><span class=""p"">])</span>
</pre></div>
</div>
<p>Using all default values:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""c1""># Returns a DataFrame</span>
<span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xls""</span><span class=""p"">)</span>
</pre></div>
</div>
<p>Using None to get all sheets:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""c1""># Returns a dictionary of DataFrames</span>
<span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xls""</span><span class=""p"">,</span> <span class=""n"">sheet_name</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">)</span>
</pre></div>
</div>
<p>Using a list to get multiple sheets:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""c1""># Returns the 1st and 4th sheet, as a dictionary of DataFrames.</span>
<span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xls""</span><span class=""p"">,</span> <span class=""n"">sheet_name</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""Sheet1""</span><span class=""p"">,</span> <span class=""mi"">3</span><span class=""p"">])</span>
</pre></div>
</div>
<p><code class=""docutils literal notranslate""><span class=""pre"">read_excel</span></code> can read more than one sheet, by setting <code class=""docutils literal notranslate""><span class=""pre"">sheet_name</span></code> to either
a list of sheet names, a list of sheet positions, or <code class=""docutils literal notranslate""><span class=""pre"">None</span></code> to read all sheets.
Sheets can be specified by sheet index or sheet name, using an integer or string,
respectively.</p>
</section>
<section id=""reading-a-multiindex"">
<span id=""io-excel-reading-multiindex""></span><h4>Reading a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code><a class=""headerlink"" href=""#reading-a-multiindex"" title=""Link to this heading"">#</a></h4>
<p><code class=""docutils literal notranslate""><span class=""pre"">read_excel</span></code> can read a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> index, by passing a list of columns to <code class=""docutils literal notranslate""><span class=""pre"">index_col</span></code>
and a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> column by passing a list of rows to <code class=""docutils literal notranslate""><span class=""pre"">header</span></code>. If either the <code class=""docutils literal notranslate""><span class=""pre"">index</span></code>
or <code class=""docutils literal notranslate""><span class=""pre"">columns</span></code> have serialized level names those will be read in as well by specifying
the rows/columns that make up the levels.</p>
<p>For example, to read in a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> index without names:</p>

<p>If the index has level names, they will parsed as well, using the same
parameters.</p>

<p>If the source file has both <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> index and columns, lists specifying each
should be passed to <code class=""docutils literal notranslate""><span class=""pre"">index_col</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">header</span></code>:</p>

<p>Missing values in columns specified in <code class=""docutils literal notranslate""><span class=""pre"">index_col</span></code> will be forward filled to
allow roundtripping with <code class=""docutils literal notranslate""><span class=""pre"">to_excel</span></code> for <code class=""docutils literal notranslate""><span class=""pre"">merged_cells=True</span></code>. To avoid forward
filling the missing values use <code class=""docutils literal notranslate""><span class=""pre"">set_index</span></code> after reading the data instead of
<code class=""docutils literal notranslate""><span class=""pre"">index_col</span></code>.</p>
</section>
<section id=""parsing-specific-columns"">
<h4>Parsing specific columns<a class=""headerlink"" href=""#parsing-specific-columns"" title=""Link to this heading"">#</a></h4>
<p>It is often the case that users will insert columns to do temporary computations
in Excel and you may not want to read in those columns. <code class=""docutils literal notranslate""><span class=""pre"">read_excel</span></code> takes
a <code class=""docutils literal notranslate""><span class=""pre"">usecols</span></code> keyword to allow you to specify a subset of columns to parse.</p>
<p>You can specify a comma-delimited set of Excel columns and ranges as a string:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xls""</span><span class=""p"">,</span> <span class=""s2"">""Sheet1""</span><span class=""p"">,</span> <span class=""n"">usecols</span><span class=""o"">=</span><span class=""s2"">""A,C:E""</span><span class=""p"">)</span>
</pre></div>
</div>
<p>If <code class=""docutils literal notranslate""><span class=""pre"">usecols</span></code> is a list of integers, then it is assumed to be the file column
indices to be parsed.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xls""</span><span class=""p"">,</span> <span class=""s2"">""Sheet1""</span><span class=""p"">,</span> <span class=""n"">usecols</span><span class=""o"">=</span><span class=""p"">[</span><span class=""mi"">0</span><span class=""p"">,</span> <span class=""mi"">2</span><span class=""p"">,</span> <span class=""mi"">3</span><span class=""p"">])</span>
</pre></div>
</div>
<p>Element order is ignored, so <code class=""docutils literal notranslate""><span class=""pre"">usecols=[0,</span> <span class=""pre"">1]</span></code> is the same as <code class=""docutils literal notranslate""><span class=""pre"">[1,</span> <span class=""pre"">0]</span></code>.</p>
<p>If <code class=""docutils literal notranslate""><span class=""pre"">usecols</span></code> is a list of strings, it is assumed that each string corresponds
to a column name provided either by the user in <code class=""docutils literal notranslate""><span class=""pre"">names</span></code> or inferred from the
document header row(s). Those strings define which columns will be parsed:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xls""</span><span class=""p"">,</span> <span class=""s2"">""Sheet1""</span><span class=""p"">,</span> <span class=""n"">usecols</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""foo""</span><span class=""p"">,</span> <span class=""s2"">""bar""</span><span class=""p"">])</span>
</pre></div>
</div>
<p>Element order is ignored, so <code class=""docutils literal notranslate""><span class=""pre"">usecols=['baz',</span> <span class=""pre"">'joe']</span></code> is the same as <code class=""docutils literal notranslate""><span class=""pre"">['joe',</span> <span class=""pre"">'baz']</span></code>.</p>
<p>If <code class=""docutils literal notranslate""><span class=""pre"">usecols</span></code> is callable, the callable function will be evaluated against
the column names, returning names where the callable function evaluates to <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xls""</span><span class=""p"">,</span> <span class=""s2"">""Sheet1""</span><span class=""p"">,</span> <span class=""n"">usecols</span><span class=""o"">=</span><span class=""k"">lambda</span> <span class=""n"">x</span><span class=""p"">:</span> <span class=""n"">x</span><span class=""o"">.</span><span class=""n"">isalpha</span><span class=""p"">())</span>
</pre></div>
</div>
</section>
<section id=""parsing-dates"">
<h4>Parsing dates<a class=""headerlink"" href=""#parsing-dates"" title=""Link to this heading"">#</a></h4>
<p>Datetime-like values are normally automatically converted to the appropriate
dtype when reading the excel file. But if you have a column of strings that
<em>look</em> like dates (but are not actually formatted as dates in excel), you can
use the <code class=""docutils literal notranslate""><span class=""pre"">parse_dates</span></code> keyword to parse those strings to datetimes:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xls""</span><span class=""p"">,</span> <span class=""s2"">""Sheet1""</span><span class=""p"">,</span> <span class=""n"">parse_dates</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""date_strings""</span><span class=""p"">])</span>
</pre></div>
</div>
</section>
<section id=""cell-converters"">
<h4>Cell converters<a class=""headerlink"" href=""#cell-converters"" title=""Link to this heading"">#</a></h4>
<p>It is possible to transform the contents of Excel cells via the <code class=""docutils literal notranslate""><span class=""pre"">converters</span></code>
option. For instance, to convert a column to boolean:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xls""</span><span class=""p"">,</span> <span class=""s2"">""Sheet1""</span><span class=""p"">,</span> <span class=""n"">converters</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s2"">""MyBools""</span><span class=""p"">:</span> <span class=""nb"">bool</span><span class=""p"">})</span>
</pre></div>
</div>
<p>This options handles missing values and treats exceptions in the converters
as missing data. Transformations are applied cell by cell rather than to the
column as a whole, so the array dtype is not guaranteed. For instance, a
column of integers with missing values cannot be transformed to an array
with integer dtype, because NaN is strictly a float. You can manually mask
missing data to recover integer dtype:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">cfun</span><span class=""p"">(</span><span class=""n"">x</span><span class=""p"">):</span>
    <span class=""k"">return</span> <span class=""nb"">int</span><span class=""p"">(</span><span class=""n"">x</span><span class=""p"">)</span> <span class=""k"">if</span> <span class=""n"">x</span> <span class=""k"">else</span> <span class=""o"">-</span><span class=""mi"">1</span>


<span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xls""</span><span class=""p"">,</span> <span class=""s2"">""Sheet1""</span><span class=""p"">,</span> <span class=""n"">converters</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s2"">""MyInts""</span><span class=""p"">:</span> <span class=""n"">cfun</span><span class=""p"">})</span>
</pre></div>
</div>
</section>
<section id=""dtype-specifications"">
<h4>Dtype specifications<a class=""headerlink"" href=""#dtype-specifications"" title=""Link to this heading"">#</a></h4>
<p>As an alternative to converters, the type for an entire column can
be specified using the <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code> keyword, which takes a dictionary
mapping column names to types. To interpret data with
no type inference, use the type <code class=""docutils literal notranslate""><span class=""pre"">str</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">object</span></code>.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xls""</span><span class=""p"">,</span> <span class=""n"">dtype</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s2"">""MyInts""</span><span class=""p"">:</span> <span class=""s2"">""int64""</span><span class=""p"">,</span> <span class=""s2"">""MyText""</span><span class=""p"">:</span> <span class=""nb"">str</span><span class=""p"">})</span>
</pre></div>
</div>
</section>
</section>
<section id=""writing-excel-files"">
<span id=""io-excel-writer""></span><h3>Writing Excel files<a class=""headerlink"" href=""#writing-excel-files"" title=""Link to this heading"">#</a></h3>
<section id=""writing-excel-files-to-disk"">
<h4>Writing Excel files to disk<a class=""headerlink"" href=""#writing-excel-files-to-disk"" title=""Link to this heading"">#</a></h4>
<p>To write a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> object to a sheet of an Excel file, you can use the
<code class=""docutils literal notranslate""><span class=""pre"">to_excel</span></code> instance method. The arguments are largely the same as <code class=""docutils literal notranslate""><span class=""pre"">to_csv</span></code>
described above, the first argument being the name of the excel file, and the
optional second argument the name of the sheet to which the <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> should be
written. For example:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df</span><span class=""o"">.</span><span class=""n"">to_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xlsx""</span><span class=""p"">,</span> <span class=""n"">sheet_name</span><span class=""o"">=</span><span class=""s2"">""Sheet1""</span><span class=""p"">)</span>
</pre></div>
</div>
<p>Files with a
<code class=""docutils literal notranslate""><span class=""pre"">.xlsx</span></code> extension will be written using <code class=""docutils literal notranslate""><span class=""pre"">xlsxwriter</span></code> (if available) or
<code class=""docutils literal notranslate""><span class=""pre"">openpyxl</span></code>.</p>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> will be written in a way that tries to mimic the REPL output.
The <code class=""docutils literal notranslate""><span class=""pre"">index_label</span></code> will be placed in the second
row instead of the first. You can place it in the first row by setting the
<code class=""docutils literal notranslate""><span class=""pre"">merge_cells</span></code> option in <code class=""docutils literal notranslate""><span class=""pre"">to_excel()</span></code> to <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df</span><span class=""o"">.</span><span class=""n"">to_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xlsx""</span><span class=""p"">,</span> <span class=""n"">index_label</span><span class=""o"">=</span><span class=""s2"">""label""</span><span class=""p"">,</span> <span class=""n"">merge_cells</span><span class=""o"">=</span><span class=""kc"">False</span><span class=""p"">)</span>
</pre></div>
</div>
<p>In order to write separate <code class=""docutils literal notranslate""><span class=""pre"">DataFrames</span></code> to separate sheets in a single Excel file,
one can pass an <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">ExcelWriter</span></code>.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""k"">with</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">ExcelWriter</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xlsx""</span><span class=""p"">)</span> <span class=""k"">as</span> <span class=""n"">writer</span><span class=""p"">:</span>
    <span class=""n"">df1</span><span class=""o"">.</span><span class=""n"">to_excel</span><span class=""p"">(</span><span class=""n"">writer</span><span class=""p"">,</span> <span class=""n"">sheet_name</span><span class=""o"">=</span><span class=""s2"">""Sheet1""</span><span class=""p"">)</span>
    <span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">to_excel</span><span class=""p"">(</span><span class=""n"">writer</span><span class=""p"">,</span> <span class=""n"">sheet_name</span><span class=""o"">=</span><span class=""s2"">""Sheet2""</span><span class=""p"">)</span>
</pre></div>
</div>
<p id=""io-excel-writing-buffer"">When using the <code class=""docutils literal notranslate""><span class=""pre"">engine_kwargs</span></code> parameter, pandas will pass these arguments to the
engine. For this, it is important to know which function pandas is using internally.</p>
<ul class=""simple"">
<li><p>For the engine openpyxl, pandas is using <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">openpyxl.Workbook()</span></code> to create a new sheet and <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">openpyxl.load_workbook()</span></code> to append data to an existing sheet. The openpyxl engine writes to (<code class=""docutils literal notranslate""><span class=""pre"">.xlsx</span></code>) and (<code class=""docutils literal notranslate""><span class=""pre"">.xlsm</span></code>) files.</p></li>
<li><p>For the engine xlsxwriter, pandas is using <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">xlsxwriter.Workbook()</span></code> to write to (<code class=""docutils literal notranslate""><span class=""pre"">.xlsx</span></code>) files.</p></li>
<li><p>For the engine odf, pandas is using <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">odf.opendocument.OpenDocumentSpreadsheet()</span></code> to write to (<code class=""docutils literal notranslate""><span class=""pre"">.ods</span></code>) files.</p></li>
</ul>
</section>
<section id=""writing-excel-files-to-memory"">
<h4>Writing Excel files to memory<a class=""headerlink"" href=""#writing-excel-files-to-memory"" title=""Link to this heading"">#</a></h4>
<p>pandas supports writing Excel files to buffer-like objects such as <code class=""docutils literal notranslate""><span class=""pre"">StringIO</span></code> or
<code class=""docutils literal notranslate""><span class=""pre"">BytesIO</span></code> using <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">ExcelWriter</span></code>.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">io</span> <span class=""kn"">import</span> <span class=""n"">BytesIO</span>

<span class=""n"">bio</span> <span class=""o"">=</span> <span class=""n"">BytesIO</span><span class=""p"">()</span>

<span class=""c1""># By setting the 'engine' in the ExcelWriter constructor.</span>
<span class=""n"">writer</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">ExcelWriter</span><span class=""p"">(</span><span class=""n"">bio</span><span class=""p"">,</span> <span class=""n"">engine</span><span class=""o"">=</span><span class=""s2"">""xlsxwriter""</span><span class=""p"">)</span>
<span class=""n"">df</span><span class=""o"">.</span><span class=""n"">to_excel</span><span class=""p"">(</span><span class=""n"">writer</span><span class=""p"">,</span> <span class=""n"">sheet_name</span><span class=""o"">=</span><span class=""s2"">""Sheet1""</span><span class=""p"">)</span>

<span class=""c1""># Save the workbook</span>
<span class=""n"">writer</span><span class=""o"">.</span><span class=""n"">save</span><span class=""p"">()</span>

<span class=""c1""># Seek to the beginning and read to copy the workbook to a variable in memory</span>
<span class=""n"">bio</span><span class=""o"">.</span><span class=""n"">seek</span><span class=""p"">(</span><span class=""mi"">0</span><span class=""p"">)</span>
<span class=""n"">workbook</span> <span class=""o"">=</span> <span class=""n"">bio</span><span class=""o"">.</span><span class=""n"">read</span><span class=""p"">()</span>
</pre></div>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">engine</span></code> is optional but recommended. Setting the engine determines
the version of workbook produced. Setting <code class=""docutils literal notranslate""><span class=""pre"">engine='xlrd'</span></code> will produce an
Excel 2003-format workbook (xls). Using either <code class=""docutils literal notranslate""><span class=""pre"">'openpyxl'</span></code> or
<code class=""docutils literal notranslate""><span class=""pre"">'xlsxwriter'</span></code> will produce an Excel 2007-format workbook (xlsx). If
omitted, an Excel 2007-formatted workbook is produced.</p>
</div>
</section>
</section>
<section id=""excel-writer-engines"">
<span id=""io-excel-writers""></span><h3>Excel writer engines<a class=""headerlink"" href=""#excel-writer-engines"" title=""Link to this heading"">#</a></h3>
<p>pandas chooses an Excel writer via two methods:</p>
<ol class=""arabic simple"">
<li><p>the <code class=""docutils literal notranslate""><span class=""pre"">engine</span></code> keyword argument</p></li>
<li><p>the filename extension (via the default specified in config options)</p></li>
</ol>
<p>By default, pandas uses the <a class=""reference external"" href=""https://xlsxwriter.readthedocs.io"">XlsxWriter</a> for <code class=""docutils literal notranslate""><span class=""pre"">.xlsx</span></code>, <a class=""reference external"" href=""https://openpyxl.readthedocs.io/"">openpyxl</a>
for <code class=""docutils literal notranslate""><span class=""pre"">.xlsm</span></code>. If you have multiple
engines installed, you can set the default engine through <a class=""reference internal"" href=""options.html#options""><span class=""std std-ref"">setting the
config options</span></a> <code class=""docutils literal notranslate""><span class=""pre"">io.excel.xlsx.writer</span></code> and
<code class=""docutils literal notranslate""><span class=""pre"">io.excel.xls.writer</span></code>. pandas will fall back on <a class=""reference external"" href=""https://openpyxl.readthedocs.io/"">openpyxl</a> for <code class=""docutils literal notranslate""><span class=""pre"">.xlsx</span></code>
files if <a class=""reference external"" href=""https://xlsxwriter.readthedocs.io"">Xlsxwriter</a> is not available.</p>
<p>To specify which writer you want to use, you can pass an engine keyword
argument to <code class=""docutils literal notranslate""><span class=""pre"">to_excel</span></code> and to <code class=""docutils literal notranslate""><span class=""pre"">ExcelWriter</span></code>. The built-in engines are:</p>
<ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">openpyxl</span></code>: version 2.4 or higher is required</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">xlsxwriter</span></code></p></li>
</ul>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""c1""># By setting the 'engine' in the DataFrame 'to_excel()' methods.</span>
<span class=""n"">df</span><span class=""o"">.</span><span class=""n"">to_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xlsx""</span><span class=""p"">,</span> <span class=""n"">sheet_name</span><span class=""o"">=</span><span class=""s2"">""Sheet1""</span><span class=""p"">,</span> <span class=""n"">engine</span><span class=""o"">=</span><span class=""s2"">""xlsxwriter""</span><span class=""p"">)</span>

<span class=""c1""># By setting the 'engine' in the ExcelWriter constructor.</span>
<span class=""n"">writer</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">ExcelWriter</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xlsx""</span><span class=""p"">,</span> <span class=""n"">engine</span><span class=""o"">=</span><span class=""s2"">""xlsxwriter""</span><span class=""p"">)</span>

<span class=""c1""># Or via pandas configuration.</span>
<span class=""kn"">from</span> <span class=""nn"">pandas</span> <span class=""kn"">import</span> <span class=""n"">options</span>  <span class=""c1""># noqa: E402</span>

<span class=""n"">options</span><span class=""o"">.</span><span class=""n"">io</span><span class=""o"">.</span><span class=""n"">excel</span><span class=""o"">.</span><span class=""n"">xlsx</span><span class=""o"">.</span><span class=""n"">writer</span> <span class=""o"">=</span> <span class=""s2"">""xlsxwriter""</span>

<span class=""n"">df</span><span class=""o"">.</span><span class=""n"">to_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xlsx""</span><span class=""p"">,</span> <span class=""n"">sheet_name</span><span class=""o"">=</span><span class=""s2"">""Sheet1""</span><span class=""p"">)</span>
</pre></div>
</div>
</section>
<section id=""style-and-formatting"">
<span id=""io-excel-style""></span><h3>Style and formatting<a class=""headerlink"" href=""#style-and-formatting"" title=""Link to this heading"">#</a></h3>
<p>The look and feel of Excel worksheets created from pandas can be modified using the following parameters on the <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>’s <code class=""docutils literal notranslate""><span class=""pre"">to_excel</span></code> method.</p>
<ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">float_format</span></code> : Format string for floating point numbers (default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code>).</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">freeze_panes</span></code> : A tuple of two integers representing the bottommost row and rightmost column to freeze. Each of these parameters is one-based, so (1, 1) will freeze the first row and first column (default <code class=""docutils literal notranslate""><span class=""pre"">None</span></code>).</p></li>
</ul>
<p>Using the <a class=""reference external"" href=""https://xlsxwriter.readthedocs.io"">Xlsxwriter</a> engine provides many options for controlling the
format of an Excel worksheet created with the <code class=""docutils literal notranslate""><span class=""pre"">to_excel</span></code> method. Excellent examples can be found in the
<a class=""reference external"" href=""https://xlsxwriter.readthedocs.io"">Xlsxwriter</a> documentation here: <a class=""reference external"" href=""https://xlsxwriter.readthedocs.io/working_with_pandas.html"">https://xlsxwriter.readthedocs.io/working_with_pandas.html</a></p>
</section>
</section>
<section id=""opendocument-spreadsheets"">
<span id=""io-ods""></span><h2>OpenDocument Spreadsheets<a class=""headerlink"" href=""#opendocument-spreadsheets"" title=""Link to this heading"">#</a></h2>
<p>The io methods for <a class=""reference internal"" href=""#excel-files"">Excel files</a> also support reading and writing OpenDocument spreadsheets
using the <a class=""reference external"" href=""https://pypi.org/project/odfpy/"">odfpy</a> module. The semantics and features for reading and writing
OpenDocument spreadsheets match what can be done for <a class=""reference internal"" href=""#excel-files"">Excel files</a> using
<code class=""docutils literal notranslate""><span class=""pre"">engine='odf'</span></code>. The optional dependency ‘odfpy’ needs to be installed.</p>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.read_excel.html#pandas.read_excel"" title=""pandas.read_excel""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_excel()</span></code></a> method can read OpenDocument spreadsheets</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""c1""># Returns a DataFrame</span>
<span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.ods""</span><span class=""p"">,</span> <span class=""n"">engine</span><span class=""o"">=</span><span class=""s2"">""odf""</span><span class=""p"">)</span>
</pre></div>
</div>
<p>Similarly, the <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">to_excel()</span></code> method can write OpenDocument spreadsheets</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""c1""># Writes DataFrame to a .ods file</span>
<span class=""n"">df</span><span class=""o"">.</span><span class=""n"">to_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.ods""</span><span class=""p"">,</span> <span class=""n"">engine</span><span class=""o"">=</span><span class=""s2"">""odf""</span><span class=""p"">)</span>
</pre></div>
</div>
</section>
<section id=""binary-excel-xlsb-files"">
<span id=""io-xlsb""></span><h2>Binary Excel (.xlsb) files<a class=""headerlink"" href=""#binary-excel-xlsb-files"" title=""Link to this heading"">#</a></h2>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.read_excel.html#pandas.read_excel"" title=""pandas.read_excel""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_excel()</span></code></a> method can also read binary Excel files
using the <code class=""docutils literal notranslate""><span class=""pre"">pyxlsb</span></code> module. The semantics and features for reading
binary Excel files mostly match what can be done for <a class=""reference internal"" href=""#excel-files"">Excel files</a> using
<code class=""docutils literal notranslate""><span class=""pre"">engine='pyxlsb'</span></code>. <code class=""docutils literal notranslate""><span class=""pre"">pyxlsb</span></code> does not recognize datetime types
in files and will return floats instead (you can use <a class=""reference internal"" href=""#io-calamine""><span class=""std std-ref"">calamine</span></a>
if you need recognize datetime types).</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""c1""># Returns a DataFrame</span>
<span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xlsb""</span><span class=""p"">,</span> <span class=""n"">engine</span><span class=""o"">=</span><span class=""s2"">""pyxlsb""</span><span class=""p"">)</span>
</pre></div>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Currently pandas only supports <em>reading</em> binary Excel files. Writing
is not implemented.</p>
</div>
</section>
<section id=""calamine-excel-and-ods-files"">
<span id=""io-calamine""></span><h2>Calamine (Excel and ODS files)<a class=""headerlink"" href=""#calamine-excel-and-ods-files"" title=""Link to this heading"">#</a></h2>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.read_excel.html#pandas.read_excel"" title=""pandas.read_excel""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_excel()</span></code></a> method can read Excel file (<code class=""docutils literal notranslate""><span class=""pre"">.xlsx</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">.xlsm</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">.xls</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">.xlsb</span></code>)
and OpenDocument spreadsheets (<code class=""docutils literal notranslate""><span class=""pre"">.ods</span></code>) using the <code class=""docutils literal notranslate""><span class=""pre"">python-calamine</span></code> module.
This module is a binding for Rust library <a class=""reference external"" href=""https://crates.io/crates/calamine"">calamine</a>
and is faster than other engines in most cases. The optional dependency ‘python-calamine’ needs to be installed.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""c1""># Returns a DataFrame</span>
<span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_excel</span><span class=""p"">(</span><span class=""s2"">""path_to_file.xlsb""</span><span class=""p"">,</span> <span class=""n"">engine</span><span class=""o"">=</span><span class=""s2"">""calamine""</span><span class=""p"">)</span>
</pre></div>
</div>
</section>
<section id=""clipboard"">
<span id=""io-clipboard""></span><h2>Clipboard<a class=""headerlink"" href=""#clipboard"" title=""Link to this heading"">#</a></h2>
<p>A handy way to grab data is to use the <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">read_clipboard()</span></code> method,
which takes the contents of the clipboard buffer and passes them to the
<code class=""docutils literal notranslate""><span class=""pre"">read_csv</span></code> method. For instance, you can copy the following text to the
clipboard (CTRL-C on many operating systems):</p>
<div class=""highlight-console notranslate""><div class=""highlight""><pre><span></span><span class=""go"">  A B C</span>
<span class=""go"">x 1 4 p</span>
<span class=""go"">y 2 5 q</span>
<span class=""go"">z 3 6 r</span>
</pre></div>
</div>
<p>And then import the data directly to a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> by calling:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">clipdf</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_clipboard</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">clipdf</span>
<span class=""go"">  A B C</span>
<span class=""go"">x 1 4 p</span>
<span class=""go"">y 2 5 q</span>
<span class=""go"">z 3 6 r</span>
</pre></div>
</div>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">to_clipboard</span></code> method can be used to write the contents of a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> to
the clipboard. Following which you can paste the clipboard contents into other
applications (CTRL-V on many operating systems). Here we illustrate writing a
<code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> into clipboard and reading it back.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">df</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">(</span>
<span class=""gp"">... </span>    <span class=""p"">{</span><span class=""s2"">""A""</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""mi"">1</span><span class=""p"">,</span> <span class=""mi"">2</span><span class=""p"">,</span> <span class=""mi"">3</span><span class=""p"">],</span> <span class=""s2"">""B""</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""mi"">4</span><span class=""p"">,</span> <span class=""mi"">5</span><span class=""p"">,</span> <span class=""mi"">6</span><span class=""p"">],</span> <span class=""s2"">""C""</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""s2"">""p""</span><span class=""p"">,</span> <span class=""s2"">""q""</span><span class=""p"">,</span> <span class=""s2"">""r""</span><span class=""p"">]},</span> <span class=""n"">index</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""x""</span><span class=""p"">,</span> <span class=""s2"">""y""</span><span class=""p"">,</span> <span class=""s2"">""z""</span><span class=""p"">]</span>
<span class=""gp"">... </span><span class=""p"">)</span>

<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">df</span>
<span class=""go"">  A B C</span>
<span class=""go"">x 1 4 p</span>
<span class=""go"">y 2 5 q</span>
<span class=""go"">z 3 6 r</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">df</span><span class=""o"">.</span><span class=""n"">to_clipboard</span><span class=""p"">()</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_clipboard</span><span class=""p"">()</span>
<span class=""go"">  A B C</span>
<span class=""go"">x 1 4 p</span>
<span class=""go"">y 2 5 q</span>
<span class=""go"">z 3 6 r</span>
</pre></div>
</div>
<p>We can see that we got the same content back, which we had earlier written to the clipboard.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>You may need to install xclip or xsel (with PyQt5, PyQt4 or qtpy) on Linux to use these methods.</p>
</div>
</section>
<section id=""pickling"">
<span id=""io-pickle""></span><h2>Pickling<a class=""headerlink"" href=""#pickling"" title=""Link to this heading"">#</a></h2>
<p>All pandas objects are equipped with <code class=""docutils literal notranslate""><span class=""pre"">to_pickle</span></code> methods which use Python’s
<code class=""docutils literal notranslate""><span class=""pre"">cPickle</span></code> module to save data structures to disk using the pickle format.</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">read_pickle</span></code> function in the <code class=""docutils literal notranslate""><span class=""pre"">pandas</span></code> namespace can be used to load
any pickled pandas object (or any other pickled object) from file:</p>

<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Loading pickled data received from untrusted sources can be unsafe.</p>
<p>See: <a class=""reference external"" href=""https://docs.python.org/3/library/pickle.html"">https://docs.python.org/3/library/pickle.html</a></p>
</div>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p><a class=""reference internal"" href=""../reference/api/pandas.read_pickle.html#pandas.read_pickle"" title=""pandas.read_pickle""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_pickle()</span></code></a> is only guaranteed backwards compatible back to a few minor release.</p>
</div>
<section id=""compressed-pickle-files"">
<span id=""io-pickle-compression""></span><h3>Compressed pickle files<a class=""headerlink"" href=""#compressed-pickle-files"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.read_pickle.html#pandas.read_pickle"" title=""pandas.read_pickle""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_pickle()</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_pickle.html#pandas.DataFrame.to_pickle"" title=""pandas.DataFrame.to_pickle""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.to_pickle()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.Series.to_pickle.html#pandas.Series.to_pickle"" title=""pandas.Series.to_pickle""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.to_pickle()</span></code></a> can read
and write compressed pickle files. The compression types of <code class=""docutils literal notranslate""><span class=""pre"">gzip</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">bz2</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">xz</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">zstd</span></code> are supported for reading and writing.
The <code class=""docutils literal notranslate""><span class=""pre"">zip</span></code> file format only supports reading and must contain only one data file
to be read.</p>
<p>The compression type can be an explicit parameter or be inferred from the file extension.
If ‘infer’, then use <code class=""docutils literal notranslate""><span class=""pre"">gzip</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">bz2</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">zip</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">xz</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">zstd</span></code> if filename ends in <code class=""docutils literal notranslate""><span class=""pre"">'.gz'</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">'.bz2'</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">'.zip'</span></code>,
<code class=""docutils literal notranslate""><span class=""pre"">'.xz'</span></code>, or <code class=""docutils literal notranslate""><span class=""pre"">'.zst'</span></code>, respectively.</p>
<p>The compression parameter can also be a <code class=""docutils literal notranslate""><span class=""pre"">dict</span></code> in order to pass options to the
compression protocol. It must have a <code class=""docutils literal notranslate""><span class=""pre"">'method'</span></code> key set to the name
of the compression protocol, which must be one of
{<code class=""docutils literal notranslate""><span class=""pre"">'zip'</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">'gzip'</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">'bz2'</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">'xz'</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">'zstd'</span></code>}. All other key-value pairs are passed to
the underlying compression library.</p>

<p>Using an explicit compression type:</p>

<p>Inferring compression type from the extension:</p>

<p>The default is to ‘infer’:</p>

<p>Passing options to the compression protocol in order to speed up compression:</p>

</section>
</section>
<section id=""msgpack"">
<span id=""io-msgpack""></span><h2>msgpack<a class=""headerlink"" href=""#msgpack"" title=""Link to this heading"">#</a></h2>
<p>pandas support for <code class=""docutils literal notranslate""><span class=""pre"">msgpack</span></code> has been removed in version 1.0.0. It is
recommended to use <a class=""reference internal"" href=""#io-pickle""><span class=""std std-ref"">pickle</span></a> instead.</p>
<p>Alternatively, you can also the Arrow IPC serialization format for on-the-wire
transmission of pandas objects. For documentation on pyarrow, see
<a class=""reference external"" href=""https://arrow.apache.org/docs/python/ipc.html"">here</a>.</p>
</section>
<section id=""hdf5-pytables"">
<span id=""io-hdf5""></span><h2>HDF5 (PyTables)<a class=""headerlink"" href=""#hdf5-pytables"" title=""Link to this heading"">#</a></h2>
<p><code class=""docutils literal notranslate""><span class=""pre"">HDFStore</span></code> is a dict-like object which reads and writes pandas using
the high performance HDF5 format using the excellent <a class=""reference external"" href=""https://www.pytables.org/"">PyTables</a> library. See the <a class=""reference internal"" href=""cookbook.html#cookbook-hdf""><span class=""std std-ref"">cookbook</span></a>
for some advanced strategies</p>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>pandas uses PyTables for reading and writing HDF5 files, which allows
serializing object-dtype data with pickle. Loading pickled data received from
untrusted sources can be unsafe.</p>
<p>See: <a class=""reference external"" href=""https://docs.python.org/3/library/pickle.html"">https://docs.python.org/3/library/pickle.html</a> for more.</p>
</div>

<p>Objects can be written to the file just like adding key-value pairs to a
dict:</p>

<p>In a current or later Python session, you can retrieve stored objects:</p>

<p>Deletion of the object specified by the key:</p>

<p>Closing a Store and using a context manager:</p>

<section id=""read-write-api"">
<h3>Read/write API<a class=""headerlink"" href=""#read-write-api"" title=""Link to this heading"">#</a></h3>
<p><code class=""docutils literal notranslate""><span class=""pre"">HDFStore</span></code> supports a top-level API using <code class=""docutils literal notranslate""><span class=""pre"">read_hdf</span></code> for reading and <code class=""docutils literal notranslate""><span class=""pre"">to_hdf</span></code> for writing,
similar to how <code class=""docutils literal notranslate""><span class=""pre"">read_csv</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">to_csv</span></code> work.</p>

<p>HDFStore will by default not drop rows that are all missing. This behavior can be changed by setting <code class=""docutils literal notranslate""><span class=""pre"">dropna=True</span></code>.</p>

</section>
<section id=""fixed-format"">
<span id=""io-hdf5-fixed""></span><h3>Fixed format<a class=""headerlink"" href=""#fixed-format"" title=""Link to this heading"">#</a></h3>
<p>The examples above show storing using <code class=""docutils literal notranslate""><span class=""pre"">put</span></code>, which write the HDF5 to <code class=""docutils literal notranslate""><span class=""pre"">PyTables</span></code> in a fixed array format, called
the <code class=""docutils literal notranslate""><span class=""pre"">fixed</span></code> format. These types of stores are <strong>not</strong> appendable once written (though you can simply
remove them and rewrite). Nor are they <strong>queryable</strong>; they must be
retrieved in their entirety. They also do not support dataframes with non-unique column names.
The <code class=""docutils literal notranslate""><span class=""pre"">fixed</span></code> format stores offer very fast writing and slightly faster reading than <code class=""docutils literal notranslate""><span class=""pre"">table</span></code> stores.
This format is specified by default when using <code class=""docutils literal notranslate""><span class=""pre"">put</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">to_hdf</span></code> or by <code class=""docutils literal notranslate""><span class=""pre"">format='fixed'</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">format='f'</span></code>.</p>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>A <code class=""docutils literal notranslate""><span class=""pre"">fixed</span></code> format will raise a <code class=""docutils literal notranslate""><span class=""pre"">TypeError</span></code> if you try to retrieve using a <code class=""docutils literal notranslate""><span class=""pre"">where</span></code>:</p>

</div>
</section>
<section id=""table-format"">
<span id=""io-hdf5-table""></span><h3>Table format<a class=""headerlink"" href=""#table-format"" title=""Link to this heading"">#</a></h3>
<p><code class=""docutils literal notranslate""><span class=""pre"">HDFStore</span></code> supports another <code class=""docutils literal notranslate""><span class=""pre"">PyTables</span></code> format on disk, the <code class=""docutils literal notranslate""><span class=""pre"">table</span></code>
format. Conceptually a <code class=""docutils literal notranslate""><span class=""pre"">table</span></code> is shaped very much like a DataFrame,
with rows and columns. A <code class=""docutils literal notranslate""><span class=""pre"">table</span></code> may be appended to in the same or
other sessions. In addition, delete and query type operations are
supported. This format is specified by <code class=""docutils literal notranslate""><span class=""pre"">format='table'</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">format='t'</span></code>
to <code class=""docutils literal notranslate""><span class=""pre"">append</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">put</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">to_hdf</span></code>.</p>
<p>This format can be set as an option as well <code class=""docutils literal notranslate""><span class=""pre"">pd.set_option('io.hdf.default_format','table')</span></code> to
enable <code class=""docutils literal notranslate""><span class=""pre"">put/append/to_hdf</span></code> to by default store in the <code class=""docutils literal notranslate""><span class=""pre"">table</span></code> format.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>You can also create a <code class=""docutils literal notranslate""><span class=""pre"">table</span></code> by passing <code class=""docutils literal notranslate""><span class=""pre"">format='table'</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">format='t'</span></code> to a <code class=""docutils literal notranslate""><span class=""pre"">put</span></code> operation.</p>
</div>
</section>
<section id=""hierarchical-keys"">
<span id=""io-hdf5-keys""></span><h3>Hierarchical keys<a class=""headerlink"" href=""#hierarchical-keys"" title=""Link to this heading"">#</a></h3>
<p>Keys to a store can be specified as a string. These can be in a
hierarchical path-name like format (e.g. <code class=""docutils literal notranslate""><span class=""pre"">foo/bar/bah</span></code>), which will
generate a hierarchy of sub-stores (or <code class=""docutils literal notranslate""><span class=""pre"">Groups</span></code> in PyTables
parlance). Keys can be specified without the leading ‘/’ and are <strong>always</strong>
absolute (e.g. ‘foo’ refers to ‘/foo’). Removal operations can remove
everything in the sub-store and <strong>below</strong>, so be <em>careful</em>.</p>

<p>You can walk through the group hierarchy using the <code class=""docutils literal notranslate""><span class=""pre"">walk</span></code> method which
will yield a tuple for each group key along with the relative keys of its contents.</p>

<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Hierarchical keys cannot be retrieved as dotted (attribute) access as described above for items stored under the root node.</p>


<p>Instead, use explicit string based keys:</p>

</div>
</section>
<section id=""storing-types"">
<span id=""io-hdf5-types""></span><h3>Storing types<a class=""headerlink"" href=""#storing-types"" title=""Link to this heading"">#</a></h3>
<section id=""storing-mixed-types-in-a-table"">
<h4>Storing mixed types in a table<a class=""headerlink"" href=""#storing-mixed-types-in-a-table"" title=""Link to this heading"">#</a></h4>
<p>Storing mixed-dtype data is supported. Strings are stored as a
fixed-width using the maximum size of the appended column. Subsequent attempts
at appending longer strings will raise a <code class=""docutils literal notranslate""><span class=""pre"">ValueError</span></code>.</p>
<p>Passing <code class=""docutils literal notranslate""><span class=""pre"">min_itemsize={`values`:</span> <span class=""pre"">size}</span></code> as a parameter to append
will set a larger minimum for the string columns. Storing <code class=""docutils literal notranslate""><span class=""pre"">floats,</span>
<span class=""pre"">strings,</span> <span class=""pre"">ints,</span> <span class=""pre"">bools,</span> <span class=""pre"">datetime64</span></code> are currently supported. For string
columns, passing <code class=""docutils literal notranslate""><span class=""pre"">nan_rep</span> <span class=""pre"">=</span> <span class=""pre"">'nan'</span></code> to append will change the default
nan representation on disk (which converts to/from <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code>), this
defaults to <code class=""docutils literal notranslate""><span class=""pre"">nan</span></code>.</p>

</section>
<section id=""storing-multiindex-dataframes"">
<h4>Storing MultiIndex DataFrames<a class=""headerlink"" href=""#storing-multiindex-dataframes"" title=""Link to this heading"">#</a></h4>
<p>Storing MultiIndex <code class=""docutils literal notranslate""><span class=""pre"">DataFrames</span></code> as tables is very similar to
storing/selecting from homogeneous index <code class=""docutils literal notranslate""><span class=""pre"">DataFrames</span></code>.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">index</span></code> keyword is reserved and cannot be use as a level name.</p>
</div>
</section>
</section>
<section id=""querying"">
<span id=""io-hdf5-query""></span><h3>Querying<a class=""headerlink"" href=""#querying"" title=""Link to this heading"">#</a></h3>
<section id=""querying-a-table"">
<h4>Querying a table<a class=""headerlink"" href=""#querying-a-table"" title=""Link to this heading"">#</a></h4>
<p><code class=""docutils literal notranslate""><span class=""pre"">select</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">delete</span></code> operations have an optional criterion that can
be specified to select/delete only a subset of the data. This allows one
to have a very large on-disk table and retrieve only a portion of the
data.</p>
<p>A query is specified using the <code class=""docutils literal notranslate""><span class=""pre"">Term</span></code> class under the hood, as a boolean expression.</p>
<ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">index</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">columns</span></code> are supported indexers of <code class=""docutils literal notranslate""><span class=""pre"">DataFrames</span></code>.</p></li>
<li><p>if <code class=""docutils literal notranslate""><span class=""pre"">data_columns</span></code> are specified, these can be used as additional indexers.</p></li>
<li><p>level name in a MultiIndex, with default name <code class=""docutils literal notranslate""><span class=""pre"">level_0</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">level_1</span></code>, … if not provided.</p></li>
</ul>
<p>Valid comparison operators are:</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">=,</span> <span class=""pre"">==,</span> <span class=""pre"">!=,</span> <span class=""pre"">&gt;,</span> <span class=""pre"">&gt;=,</span> <span class=""pre"">&lt;,</span> <span class=""pre"">&lt;=</span></code></p>
<p>Valid boolean expressions are combined with:</p>
<ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">|</span></code> : or</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">&amp;</span></code> : and</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">(</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">)</span></code> : for grouping</p></li>
</ul>
<p>These rules are similar to how boolean expressions are used in pandas for indexing.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">=</span></code> will be automatically expanded to the comparison operator <code class=""docutils literal notranslate""><span class=""pre"">==</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">~</span></code> is the not operator, but can only be used in very limited
circumstances</p></li>
<li><p>If a list/tuple of expressions is passed they will be combined via <code class=""docutils literal notranslate""><span class=""pre"">&amp;</span></code></p></li>
</ul>
</div>
<p>The following are valid expressions:</p>
<ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">'index</span> <span class=""pre"">&gt;=</span> <span class=""pre"">date'</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">""columns</span> <span class=""pre"">=</span> <span class=""pre"">['A',</span> <span class=""pre"">'D']""</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">""columns</span> <span class=""pre"">in</span> <span class=""pre"">['A',</span> <span class=""pre"">'D']""</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">'columns</span> <span class=""pre"">=</span> <span class=""pre"">A'</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">'columns</span> <span class=""pre"">==</span> <span class=""pre"">A'</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">""~(columns</span> <span class=""pre"">=</span> <span class=""pre"">['A',</span> <span class=""pre"">'B'])""</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">'index</span> <span class=""pre"">&gt;</span> <span class=""pre"">df.index[3]</span> <span class=""pre"">&amp;</span> <span class=""pre"">string</span> <span class=""pre"">=</span> <span class=""pre"">""bar""'</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">'(index</span> <span class=""pre"">&gt;</span> <span class=""pre"">df.index[3]</span> <span class=""pre"">&amp;</span> <span class=""pre"">index</span> <span class=""pre"">&lt;=</span> <span class=""pre"">df.index[6])</span> <span class=""pre"">|</span> <span class=""pre"">string</span> <span class=""pre"">=</span> <span class=""pre"">""bar""'</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">""ts</span> <span class=""pre"">&gt;=</span> <span class=""pre"">Timestamp('2012-02-01')""</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">""major_axis&gt;=20130101""</span></code></p></li>
</ul>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">indexers</span></code> are on the left-hand side of the sub-expression:</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">columns</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">major_axis</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">ts</span></code></p>
<p>The right-hand side of the sub-expression (after a comparison operator) can be:</p>
<ul class=""simple"">
<li><p>functions that will be evaluated, e.g. <code class=""docutils literal notranslate""><span class=""pre"">Timestamp('2012-02-01')</span></code></p></li>
<li><p>strings, e.g. <code class=""docutils literal notranslate""><span class=""pre"">""bar""</span></code></p></li>
<li><p>date-like, e.g. <code class=""docutils literal notranslate""><span class=""pre"">20130101</span></code>, or <code class=""docutils literal notranslate""><span class=""pre"">""20130101""</span></code></p></li>
<li><p>lists, e.g. <code class=""docutils literal notranslate""><span class=""pre"">""['A',</span> <span class=""pre"">'B']""</span></code></p></li>
<li><p>variables that are defined in the local names space, e.g. <code class=""docutils literal notranslate""><span class=""pre"">date</span></code></p></li>
</ul>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Passing a string to a query by interpolating it into the query
expression is not recommended. Simply assign the string of interest to a
variable and use that variable in an expression. For example, do this</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">string</span> <span class=""o"">=</span> <span class=""s2"">""HolyMoly'""</span>
<span class=""n"">store</span><span class=""o"">.</span><span class=""n"">select</span><span class=""p"">(</span><span class=""s2"">""df""</span><span class=""p"">,</span> <span class=""s2"">""index == string""</span><span class=""p"">)</span>
</pre></div>
</div>
<p>instead of this</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">string</span> <span class=""o"">=</span> <span class=""s2"">""HolyMoly'""</span>
<span class=""n"">store</span><span class=""o"">.</span><span class=""n"">select</span><span class=""p"">(</span><span class=""s1"">'df'</span><span class=""p"">,</span> <span class=""sa"">f</span><span class=""s1"">'index == </span><span class=""si"">{</span><span class=""n"">string</span><span class=""si"">}</span><span class=""s1"">'</span><span class=""p"">)</span>
</pre></div>
</div>
<p>The latter will <strong>not</strong> work and will raise a <code class=""docutils literal notranslate""><span class=""pre"">SyntaxError</span></code>.Note that
there’s a single quote followed by a double quote in the <code class=""docutils literal notranslate""><span class=""pre"">string</span></code>
variable.</p>
<p>If you <em>must</em> interpolate, use the <code class=""docutils literal notranslate""><span class=""pre"">'%r'</span></code> format specifier</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">store</span><span class=""o"">.</span><span class=""n"">select</span><span class=""p"">(</span><span class=""s2"">""df""</span><span class=""p"">,</span> <span class=""s2"">""index == </span><span class=""si"">%r</span><span class=""s2"">""</span> <span class=""o"">%</span> <span class=""n"">string</span><span class=""p"">)</span>
</pre></div>
</div>
<p>which will quote <code class=""docutils literal notranslate""><span class=""pre"">string</span></code>.</p>
</div>
<p>Here are some examples:</p>

<p>Use boolean expressions, with in-line function evaluation.</p>

<p>Use inline column reference.</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">columns</span></code> keyword can be supplied to select a list of columns to be
returned, this is equivalent to passing a
<code class=""docutils literal notranslate""><span class=""pre"">'columns=list_of_columns_to_filter'</span></code>:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">start</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">stop</span></code> parameters can be specified to limit the total search
space. These are in terms of the total number of rows in a table.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">select</span></code> will raise a <code class=""docutils literal notranslate""><span class=""pre"">ValueError</span></code> if the query expression has an unknown
variable reference. Usually this means that you are trying to select on a column
that is <strong>not</strong> a data_column.</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">select</span></code> will raise a <code class=""docutils literal notranslate""><span class=""pre"">SyntaxError</span></code> if the query expression is not valid.</p>
</div>
</section>
<section id=""query-timedelta64-ns"">
<span id=""io-hdf5-timedelta""></span><h4>Query timedelta64[ns]<a class=""headerlink"" href=""#query-timedelta64-ns"" title=""Link to this heading"">#</a></h4>
<p>You can store and query using the <code class=""docutils literal notranslate""><span class=""pre"">timedelta64[ns]</span></code> type. Terms can be
specified in the format: <code class=""docutils literal notranslate""><span class=""pre"">&lt;float&gt;(&lt;unit&gt;)</span></code>, where float may be signed (and fractional), and unit can be
<code class=""docutils literal notranslate""><span class=""pre"">D,s,ms,us,ns</span></code> for the timedelta. Here’s an example:</p>

</section>
<section id=""query-multiindex"">
<span id=""io-query-multi""></span><h4>Query MultiIndex<a class=""headerlink"" href=""#query-multiindex"" title=""Link to this heading"">#</a></h4>
<p>Selecting from a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> can be achieved by using the name of the level.</p>

<p>If the <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> levels names are <code class=""docutils literal notranslate""><span class=""pre"">None</span></code>, the levels are automatically made available via
the <code class=""docutils literal notranslate""><span class=""pre"">level_n</span></code> keyword with <code class=""docutils literal notranslate""><span class=""pre"">n</span></code> the level of the <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> you want to select from.</p>

</section>
<section id=""indexing"">
<h4>Indexing<a class=""headerlink"" href=""#indexing"" title=""Link to this heading"">#</a></h4>
<p>You can create/modify an index for a table with <code class=""docutils literal notranslate""><span class=""pre"">create_table_index</span></code>
after data is already in the table (after and <code class=""docutils literal notranslate""><span class=""pre"">append/put</span></code>
operation). Creating a table index is <strong>highly</strong> encouraged. This will
speed your queries a great deal when you use a <code class=""docutils literal notranslate""><span class=""pre"">select</span></code> with the
indexed dimension as the <code class=""docutils literal notranslate""><span class=""pre"">where</span></code>.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Indexes are automagically created on the indexables
and any data columns you specify. This behavior can be turned off by passing
<code class=""docutils literal notranslate""><span class=""pre"">index=False</span></code> to <code class=""docutils literal notranslate""><span class=""pre"">append</span></code>.</p>
</div>

<p>Oftentimes when appending large amounts of data to a store, it is useful to turn off index creation for each append, then recreate at the end.</p>

<p>Then create the index when finished appending.</p>

<p>See <a class=""reference external"" href=""https://stackoverflow.com/questions/17893370/ptrepack-sortby-needs-full-index"">here</a> for how to create a completely-sorted-index (CSI) on an existing store.</p>
</section>
<section id=""query-via-data-columns"">
<span id=""io-hdf5-query-data-columns""></span><h4>Query via data columns<a class=""headerlink"" href=""#query-via-data-columns"" title=""Link to this heading"">#</a></h4>
<p>You can designate (and index) certain columns that you want to be able
to perform queries (other than the <code class=""docutils literal notranslate""><span class=""pre"">indexable</span></code> columns, which you can
always query). For instance say you want to perform this common
operation, on-disk, and return just the frame that matches this
query. You can specify <code class=""docutils literal notranslate""><span class=""pre"">data_columns</span> <span class=""pre"">=</span> <span class=""pre"">True</span></code> to force all columns to
be <code class=""docutils literal notranslate""><span class=""pre"">data_columns</span></code>.</p>

<p>There is some performance degradation by making lots of columns into
<code class=""docutils literal notranslate""><span class=""pre"">data</span> <span class=""pre"">columns</span></code>, so it is up to the user to designate these. In addition,
you cannot change data columns (nor indexables) after the first
append/put operation (Of course you can simply read in the data and
create a new table!).</p>
</section>
<section id=""iterator"">
<h4>Iterator<a class=""headerlink"" href=""#iterator"" title=""Link to this heading"">#</a></h4>
<p>You can pass <code class=""docutils literal notranslate""><span class=""pre"">iterator=True</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">chunksize=number_in_a_chunk</span></code>
to <code class=""docutils literal notranslate""><span class=""pre"">select</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">select_as_multiple</span></code> to return an iterator on the results.
The default is 50,000 rows returned in a chunk.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>You can also use the iterator with <code class=""docutils literal notranslate""><span class=""pre"">read_hdf</span></code> which will open, then
automatically close the store when finished iterating.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""k"">for</span> <span class=""n"">df</span> <span class=""ow"">in</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_hdf</span><span class=""p"">(</span><span class=""s2"">""store.h5""</span><span class=""p"">,</span> <span class=""s2"">""df""</span><span class=""p"">,</span> <span class=""n"">chunksize</span><span class=""o"">=</span><span class=""mi"">3</span><span class=""p"">):</span>
    <span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">df</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<p>Note, that the chunksize keyword applies to the <strong>source</strong> rows. So if you
are doing a query, then the chunksize will subdivide the total rows in the table
and the query applied, returning an iterator on potentially unequal sized chunks.</p>
<p>Here is a recipe for generating a query and using it to create equal sized return
chunks.</p>

</section>
<section id=""advanced-queries"">
<h4>Advanced queries<a class=""headerlink"" href=""#advanced-queries"" title=""Link to this heading"">#</a></h4>
<section id=""select-a-single-column"">
<h5>Select a single column<a class=""headerlink"" href=""#select-a-single-column"" title=""Link to this heading"">#</a></h5>
<p>To retrieve a single indexable or data column, use the
method <code class=""docutils literal notranslate""><span class=""pre"">select_column</span></code>. This will, for example, enable you to get the index
very quickly. These return a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> of the result, indexed by the row number.
These do not currently accept the <code class=""docutils literal notranslate""><span class=""pre"">where</span></code> selector.</p>

</section>
<section id=""selecting-coordinates"">
<span id=""io-hdf5-selecting-coordinates""></span><h5>Selecting coordinates<a class=""headerlink"" href=""#selecting-coordinates"" title=""Link to this heading"">#</a></h5>
<p>Sometimes you want to get the coordinates (a.k.a the index locations) of your query. This returns an
<code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> of the resulting locations. These coordinates can also be passed to subsequent
<code class=""docutils literal notranslate""><span class=""pre"">where</span></code> operations.</p>

</section>
<section id=""selecting-using-a-where-mask"">
<span id=""io-hdf5-where-mask""></span><h5>Selecting using a where mask<a class=""headerlink"" href=""#selecting-using-a-where-mask"" title=""Link to this heading"">#</a></h5>
<p>Sometime your query can involve creating a list of rows to select. Usually this <code class=""docutils literal notranslate""><span class=""pre"">mask</span></code> would
be a resulting <code class=""docutils literal notranslate""><span class=""pre"">index</span></code> from an indexing operation. This example selects the months of
a datetimeindex which are 5.</p>

</section>
<section id=""storer-object"">
<h5>Storer object<a class=""headerlink"" href=""#storer-object"" title=""Link to this heading"">#</a></h5>
<p>If you want to inspect the stored object, retrieve via
<code class=""docutils literal notranslate""><span class=""pre"">get_storer</span></code>. You could use this programmatically to say get the number
of rows in an object.</p>

</section>
</section>
<section id=""multiple-table-queries"">
<h4>Multiple table queries<a class=""headerlink"" href=""#multiple-table-queries"" title=""Link to this heading"">#</a></h4>
<p>The methods <code class=""docutils literal notranslate""><span class=""pre"">append_to_multiple</span></code> and
<code class=""docutils literal notranslate""><span class=""pre"">select_as_multiple</span></code> can perform appending/selecting from
multiple tables at once. The idea is to have one table (call it the
selector table) that you index most/all of the columns, and perform your
queries. The other table(s) are data tables with an index matching the
selector table’s index. You can then perform a very fast query
on the selector table, yet get lots of data back. This method is similar to
having a very wide table, but enables more efficient queries.</p>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">append_to_multiple</span></code> method splits a given single DataFrame
into multiple tables according to <code class=""docutils literal notranslate""><span class=""pre"">d</span></code>, a dictionary that maps the
table names to a list of ‘columns’ you want in that table. If <code class=""docutils literal notranslate""><span class=""pre"">None</span></code>
is used in place of a list, that table will have the remaining
unspecified columns of the given DataFrame. The argument <code class=""docutils literal notranslate""><span class=""pre"">selector</span></code>
defines which table is the selector table (which you can make queries from).
The argument <code class=""docutils literal notranslate""><span class=""pre"">dropna</span></code> will drop rows from the input <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> to ensure
tables are synchronized. This means that if a row for one of the tables
being written to is entirely <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code>, that row will be dropped from all tables.</p>
<p>If <code class=""docutils literal notranslate""><span class=""pre"">dropna</span></code> is False, <strong>THE USER IS RESPONSIBLE FOR SYNCHRONIZING THE TABLES</strong>.
Remember that entirely <code class=""docutils literal notranslate""><span class=""pre"">np.Nan</span></code> rows are not written to the HDFStore, so if
you choose to call <code class=""docutils literal notranslate""><span class=""pre"">dropna=False</span></code>, some tables may have more rows than others,
and therefore <code class=""docutils literal notranslate""><span class=""pre"">select_as_multiple</span></code> may not work or it may return unexpected
results.</p>

</section>
</section>
<section id=""delete-from-a-table"">
<h3>Delete from a table<a class=""headerlink"" href=""#delete-from-a-table"" title=""Link to this heading"">#</a></h3>
<p>You can delete from a table selectively by specifying a <code class=""docutils literal notranslate""><span class=""pre"">where</span></code>. In
deleting rows, it is important to understand the <code class=""docutils literal notranslate""><span class=""pre"">PyTables</span></code> deletes
rows by erasing the rows, then <strong>moving</strong> the following data. Thus
deleting can potentially be a very expensive operation depending on the
orientation of your data. To get optimal performance, it’s
worthwhile to have the dimension you are deleting be the first of the
<code class=""docutils literal notranslate""><span class=""pre"">indexables</span></code>.</p>
<p>Data is ordered (on the disk) in terms of the <code class=""docutils literal notranslate""><span class=""pre"">indexables</span></code>. Here’s a
simple use case. You store panel-type data, with dates in the
<code class=""docutils literal notranslate""><span class=""pre"">major_axis</span></code> and ids in the <code class=""docutils literal notranslate""><span class=""pre"">minor_axis</span></code>. The data is then
interleaved like this:</p>
<ul class=""simple"">
<li><dl class=""simple"">
<dt>date_1</dt><dd><ul>
<li><p>id_1</p></li>
<li><p>id_2</p></li>
<li><p>.</p></li>
<li><p>id_n</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class=""simple"">
<dt>date_2</dt><dd><ul>
<li><p>id_1</p></li>
<li><p>.</p></li>
<li><p>id_n</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>It should be clear that a delete operation on the <code class=""docutils literal notranslate""><span class=""pre"">major_axis</span></code> will be
fairly quick, as one chunk is removed, then the following data moved. On
the other hand a delete operation on the <code class=""docutils literal notranslate""><span class=""pre"">minor_axis</span></code> will be very
expensive. In this case it would almost certainly be faster to rewrite
the table using a <code class=""docutils literal notranslate""><span class=""pre"">where</span></code> that selects all but the missing data.</p>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Please note that HDF5 <strong>DOES NOT RECLAIM SPACE</strong> in the h5 files
automatically. Thus, repeatedly deleting (or removing nodes) and adding
again, <strong>WILL TEND TO INCREASE THE FILE SIZE</strong>.</p>
<p>To <em>repack and clean</em> the file, use <a class=""reference internal"" href=""#io-hdf5-ptrepack""><span class=""std std-ref"">ptrepack</span></a>.</p>
</div>
</section>
<section id=""notes-caveats"">
<span id=""io-hdf5-notes""></span><h3>Notes &amp; caveats<a class=""headerlink"" href=""#notes-caveats"" title=""Link to this heading"">#</a></h3>
<section id=""compression"">
<h4>Compression<a class=""headerlink"" href=""#compression"" title=""Link to this heading"">#</a></h4>
<p><code class=""docutils literal notranslate""><span class=""pre"">PyTables</span></code> allows the stored data to be compressed. This applies to
all kinds of stores, not just tables. Two parameters are used to
control compression: <code class=""docutils literal notranslate""><span class=""pre"">complevel</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">complib</span></code>.</p>
<ul>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">complevel</span></code> specifies if and how hard data is to be compressed.
<code class=""docutils literal notranslate""><span class=""pre"">complevel=0</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">complevel=None</span></code> disables compression and
<code class=""docutils literal notranslate""><span class=""pre"">0&lt;complevel&lt;10</span></code> enables compression.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">complib</span></code> specifies which compression library to use.
If nothing is specified the default library <code class=""docutils literal notranslate""><span class=""pre"">zlib</span></code> is used. A
compression library usually optimizes for either good compression rates
or speed and the results will depend on the type of data. Which type of
compression to choose depends on your specific needs and data. The list
of supported compression libraries:</p>
<ul>
<li><p><a class=""reference external"" href=""https://zlib.net/"">zlib</a>: The default compression library.
A classic in terms of compression, achieves good compression
rates but is somewhat slow.</p></li>
<li><p><a class=""reference external"" href=""https://www.oberhumer.com/opensource/lzo/"">lzo</a>: Fast
compression and decompression.</p></li>
<li><p><a class=""reference external"" href=""https://sourceware.org/bzip2/"">bzip2</a>: Good compression rates.</p></li>
<li><p><a class=""reference external"" href=""https://www.blosc.org/"">blosc</a>: Fast compression and
decompression.</p>
<p>Support for alternative blosc compressors:</p>
<ul class=""simple"">
<li><p><a class=""reference external"" href=""https://www.blosc.org/"">blosc:blosclz</a> This is the
default compressor for <code class=""docutils literal notranslate""><span class=""pre"">blosc</span></code></p></li>
<li><p><a class=""reference external"" href=""https://fastcompression.blogspot.com/p/lz4.html"">blosc:lz4</a>:
A compact, very popular and fast compressor.</p></li>
<li><p><a class=""reference external"" href=""https://fastcompression.blogspot.com/p/lz4.html"">blosc:lz4hc</a>:
A tweaked version of LZ4, produces better
compression ratios at the expense of speed.</p></li>
<li><p><a class=""reference external"" href=""https://google.github.io/snappy/"">blosc:snappy</a>:
A popular compressor used in many places.</p></li>
<li><p><a class=""reference external"" href=""https://zlib.net/"">blosc:zlib</a>: A classic;
somewhat slower than the previous ones, but
achieving better compression ratios.</p></li>
<li><p><a class=""reference external"" href=""https://facebook.github.io/zstd/"">blosc:zstd</a>: An
extremely well balanced codec; it provides the best
compression ratios among the others above, and at
reasonably fast speed.</p></li>
</ul>
</li>
</ul>
<p>If <code class=""docutils literal notranslate""><span class=""pre"">complib</span></code> is defined as something other than the listed libraries a
<code class=""docutils literal notranslate""><span class=""pre"">ValueError</span></code> exception is issued.</p>
</li>
</ul>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>If the library specified with the <code class=""docutils literal notranslate""><span class=""pre"">complib</span></code> option is missing on your platform,
compression defaults to <code class=""docutils literal notranslate""><span class=""pre"">zlib</span></code> without further ado.</p>
</div>
<p>Enable compression for all objects within the file:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">store_compressed</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">HDFStore</span><span class=""p"">(</span>
    <span class=""s2"">""store_compressed.h5""</span><span class=""p"">,</span> <span class=""n"">complevel</span><span class=""o"">=</span><span class=""mi"">9</span><span class=""p"">,</span> <span class=""n"">complib</span><span class=""o"">=</span><span class=""s2"">""blosc:blosclz""</span>
<span class=""p"">)</span>
</pre></div>
</div>
<p>Or on-the-fly compression (this only applies to tables) in stores where compression is not enabled:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">store</span><span class=""o"">.</span><span class=""n"">append</span><span class=""p"">(</span><span class=""s2"">""df""</span><span class=""p"">,</span> <span class=""n"">df</span><span class=""p"">,</span> <span class=""n"">complib</span><span class=""o"">=</span><span class=""s2"">""zlib""</span><span class=""p"">,</span> <span class=""n"">complevel</span><span class=""o"">=</span><span class=""mi"">5</span><span class=""p"">)</span>
</pre></div>
</div>
</section>
<section id=""ptrepack"">
<span id=""io-hdf5-ptrepack""></span><h4>ptrepack<a class=""headerlink"" href=""#ptrepack"" title=""Link to this heading"">#</a></h4>
<p><code class=""docutils literal notranslate""><span class=""pre"">PyTables</span></code> offers better write performance when tables are compressed after
they are written, as opposed to turning on compression at the very
beginning. You can use the supplied <code class=""docutils literal notranslate""><span class=""pre"">PyTables</span></code> utility
<code class=""docutils literal notranslate""><span class=""pre"">ptrepack</span></code>. In addition, <code class=""docutils literal notranslate""><span class=""pre"">ptrepack</span></code> can change compression levels
after the fact.</p>
<div class=""highlight-console notranslate""><div class=""highlight""><pre><span></span><span class=""go"">ptrepack --chunkshape=auto --propindexes --complevel=9 --complib=blosc in.h5 out.h5</span>
</pre></div>
</div>
<p>Furthermore <code class=""docutils literal notranslate""><span class=""pre"">ptrepack</span> <span class=""pre"">in.h5</span> <span class=""pre"">out.h5</span></code> will <em>repack</em> the file to allow
you to reuse previously deleted space. Alternatively, one can simply
remove the file and write again, or use the <code class=""docutils literal notranslate""><span class=""pre"">copy</span></code> method.</p>
</section>
<section id=""caveats"">
<span id=""io-hdf5-caveats""></span><h4>Caveats<a class=""headerlink"" href=""#caveats"" title=""Link to this heading"">#</a></h4>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">HDFStore</span></code> is <strong>not-threadsafe for writing</strong>. The underlying
<code class=""docutils literal notranslate""><span class=""pre"">PyTables</span></code> only supports concurrent reads (via threading or
processes). If you need reading and writing <em>at the same time</em>, you
need to serialize these operations in a single thread in a single
process. You will corrupt your data otherwise. See the (<a class=""reference external"" href=""https://github.com/pandas-dev/pandas/issues/2397"">GH 2397</a>) for more information.</p>
</div>
<ul class=""simple"">
<li><p>If you use locks to manage write access between multiple processes, you
may want to use <a class=""reference external"" href=""https://docs.python.org/3/library/os.html#os.fsync"" title=""(in Python v3.12)""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">fsync()</span></code></a> before releasing write locks. For
convenience you can use <code class=""docutils literal notranslate""><span class=""pre"">store.flush(fsync=True)</span></code> to do this for you.</p></li>
<li><p>Once a <code class=""docutils literal notranslate""><span class=""pre"">table</span></code> is created columns (DataFrame)
are fixed; only exactly the same columns can be appended</p></li>
<li><p>Be aware that timezones (e.g., <code class=""docutils literal notranslate""><span class=""pre"">pytz.timezone('US/Eastern')</span></code>)
are not necessarily equal across timezone versions. So if data is
localized to a specific timezone in the HDFStore using one version
of a timezone library and that data is updated with another version, the data
will be converted to UTC since these timezones are not considered
equal. Either use the same version of timezone library or use <code class=""docutils literal notranslate""><span class=""pre"">tz_convert</span></code> with
the updated timezone definition.</p></li>
</ul>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">PyTables</span></code> will show a <code class=""docutils literal notranslate""><span class=""pre"">NaturalNameWarning</span></code> if a column name
cannot be used as an attribute selector.
<em>Natural</em> identifiers contain only letters, numbers, and underscores,
and may not begin with a number.
Other identifiers cannot be used in a <code class=""docutils literal notranslate""><span class=""pre"">where</span></code> clause
and are generally a bad idea.</p>
</div>
</section>
</section>
<section id=""datatypes"">
<span id=""io-hdf5-data-types""></span><h3>DataTypes<a class=""headerlink"" href=""#datatypes"" title=""Link to this heading"">#</a></h3>
<p><code class=""docutils literal notranslate""><span class=""pre"">HDFStore</span></code> will map an object dtype to the <code class=""docutils literal notranslate""><span class=""pre"">PyTables</span></code> underlying
dtype. This means the following types are known to work:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">unicode</span></code> columns are not supported, and <strong>WILL FAIL</strong>.</p>
<section id=""categorical-data"">
<span id=""io-hdf5-categorical""></span><h4>Categorical data<a class=""headerlink"" href=""#categorical-data"" title=""Link to this heading"">#</a></h4>
<p>You can write data that contains <code class=""docutils literal notranslate""><span class=""pre"">category</span></code> dtypes to a <code class=""docutils literal notranslate""><span class=""pre"">HDFStore</span></code>.
Queries work the same as if it was an object array. However, the <code class=""docutils literal notranslate""><span class=""pre"">category</span></code> dtyped data is
stored in a more efficient manner.</p>

</section>
<section id=""string-columns"">
<h4>String columns<a class=""headerlink"" href=""#string-columns"" title=""Link to this heading"">#</a></h4>
<p><strong>min_itemsize</strong></p>
<p>The underlying implementation of <code class=""docutils literal notranslate""><span class=""pre"">HDFStore</span></code> uses a fixed column width (itemsize) for string columns.
A string column itemsize is calculated as the maximum of the
length of data (for that column) that is passed to the <code class=""docutils literal notranslate""><span class=""pre"">HDFStore</span></code>, <strong>in the first append</strong>. Subsequent appends,
may introduce a string for a column <strong>larger</strong> than the column can hold, an Exception will be raised (otherwise you
could have a silent truncation of these columns, leading to loss of information). In the future we may relax this and
allow a user-specified truncation to occur.</p>
<p>Pass <code class=""docutils literal notranslate""><span class=""pre"">min_itemsize</span></code> on the first table creation to a-priori specify the minimum length of a particular string column.
<code class=""docutils literal notranslate""><span class=""pre"">min_itemsize</span></code> can be an integer, or a dict mapping a column name to an integer. You can pass <code class=""docutils literal notranslate""><span class=""pre"">values</span></code> as a key to
allow all <em>indexables</em> or <em>data_columns</em> to have this min_itemsize.</p>
<p>Passing a <code class=""docutils literal notranslate""><span class=""pre"">min_itemsize</span></code> dict will cause all passed columns to be created as <em>data_columns</em> automatically.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>If you are not passing any <code class=""docutils literal notranslate""><span class=""pre"">data_columns</span></code>, then the <code class=""docutils literal notranslate""><span class=""pre"">min_itemsize</span></code> will be the maximum of the length of any string passed</p>
</div>

<p><strong>nan_rep</strong></p>
<p>String columns will serialize a <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code> (a missing value) with the <code class=""docutils literal notranslate""><span class=""pre"">nan_rep</span></code> string representation. This defaults to the string value <code class=""docutils literal notranslate""><span class=""pre"">nan</span></code>.
You could inadvertently turn an actual <code class=""docutils literal notranslate""><span class=""pre"">nan</span></code> value into a missing value.</p>

</section>
</section>
<section id=""performance"">
<h3>Performance<a class=""headerlink"" href=""#performance"" title=""Link to this heading"">#</a></h3>
<ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">tables</span></code> format come with a writing performance penalty as compared to
<code class=""docutils literal notranslate""><span class=""pre"">fixed</span></code> stores. The benefit is the ability to append/delete and
query (potentially very large amounts of data). Write times are
generally longer as compared with regular stores. Query times can
be quite fast, especially on an indexed axis.</p></li>
<li><p>You can pass <code class=""docutils literal notranslate""><span class=""pre"">chunksize=&lt;int&gt;</span></code> to <code class=""docutils literal notranslate""><span class=""pre"">append</span></code>, specifying the
write chunksize (default is 50000). This will significantly lower
your memory usage on writing.</p></li>
<li><p>You can pass <code class=""docutils literal notranslate""><span class=""pre"">expectedrows=&lt;int&gt;</span></code> to the first <code class=""docutils literal notranslate""><span class=""pre"">append</span></code>,
to set the TOTAL number of rows that <code class=""docutils literal notranslate""><span class=""pre"">PyTables</span></code> will expect.
This will optimize read/write performance.</p></li>
<li><p>Duplicate rows can be written to tables, but are filtered out in
selection (with the last items being selected; thus a table is
unique on major, minor pairs)</p></li>
<li><p>A <code class=""docutils literal notranslate""><span class=""pre"">PerformanceWarning</span></code> will be raised if you are attempting to
store types that will be pickled by PyTables (rather than stored as
endemic types). See
<a class=""reference external"" href=""https://stackoverflow.com/questions/14355151/how-to-make-pandas-hdfstore-put-operation-faster/14370190#14370190"">Here</a>
for more information and some solutions.</p></li>
</ul>
</section>
</section>
<section id=""feather"">
<span id=""io-feather""></span><h2>Feather<a class=""headerlink"" href=""#feather"" title=""Link to this heading"">#</a></h2>
<p>Feather provides binary columnar serialization for data frames. It is designed to make reading and writing data
frames efficient, and to make sharing data across data analysis languages easy.</p>
<p>Feather is designed to faithfully serialize and de-serialize DataFrames, supporting all of the pandas
dtypes, including extension dtypes such as categorical and datetime with tz.</p>
<p>Several caveats:</p>
<ul class=""simple"">
<li><p>The format will NOT write an <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code>, or <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> for the
<code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> and will raise an error if a non-default one is provided. You
can <code class=""docutils literal notranslate""><span class=""pre"">.reset_index()</span></code> to store the index or <code class=""docutils literal notranslate""><span class=""pre"">.reset_index(drop=True)</span></code> to
ignore it.</p></li>
<li><p>Duplicate column names and non-string columns names are not supported</p></li>
<li><p>Actual Python objects in object dtype columns are not supported. These will
raise a helpful error message on an attempt at serialization.</p></li>
</ul>
<p>See the <a class=""reference external"" href=""https://github.com/wesm/feather"">Full Documentation</a>.</p>

<p>Write to a feather file.</p>

<p>Read from a feather file.</p>

</section>
<section id=""parquet"">
<span id=""io-parquet""></span><h2>Parquet<a class=""headerlink"" href=""#parquet"" title=""Link to this heading"">#</a></h2>
<p><a class=""reference external"" href=""https://parquet.apache.org/"">Apache Parquet</a> provides a partitioned binary columnar serialization for data frames. It is designed to
make reading and writing data frames efficient, and to make sharing data across data analysis
languages easy. Parquet can use a variety of compression techniques to shrink the file size as much as possible
while still maintaining good read performance.</p>
<p>Parquet is designed to faithfully serialize and de-serialize <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> s, supporting all of the pandas
dtypes, including extension dtypes such as datetime with tz.</p>
<p>Several caveats.</p>
<ul class=""simple"">
<li><p>Duplicate column names and non-string columns names are not supported.</p></li>
<li><p>The <code class=""docutils literal notranslate""><span class=""pre"">pyarrow</span></code> engine always writes the index to the output, but <code class=""docutils literal notranslate""><span class=""pre"">fastparquet</span></code> only writes non-default
indexes. This extra column can cause problems for non-pandas consumers that are not expecting it. You can
force including or omitting indexes with the <code class=""docutils literal notranslate""><span class=""pre"">index</span></code> argument, regardless of the underlying engine.</p></li>
<li><p>Index level names, if specified, must be strings.</p></li>
<li><p>In the <code class=""docutils literal notranslate""><span class=""pre"">pyarrow</span></code> engine, categorical dtypes for non-string types can be serialized to parquet, but will de-serialize as their primitive dtype.</p></li>
<li><p>The <code class=""docutils literal notranslate""><span class=""pre"">pyarrow</span></code> engine preserves the <code class=""docutils literal notranslate""><span class=""pre"">ordered</span></code> flag of categorical dtypes with string types. <code class=""docutils literal notranslate""><span class=""pre"">fastparquet</span></code> does not preserve the <code class=""docutils literal notranslate""><span class=""pre"">ordered</span></code> flag.</p></li>
<li><p>Non supported types include <code class=""docutils literal notranslate""><span class=""pre"">Interval</span></code> and actual Python object types. These will raise a helpful error message
on an attempt at serialization. <code class=""docutils literal notranslate""><span class=""pre"">Period</span></code> type is supported with pyarrow &gt;= 0.16.0.</p></li>
<li><p>The <code class=""docutils literal notranslate""><span class=""pre"">pyarrow</span></code> engine preserves extension data types such as the nullable integer and string data
type (requiring pyarrow &gt;= 0.16.0, and requiring the extension type to implement the needed protocols,
see the <a class=""reference internal"" href=""../development/extending.html#extending-extension-arrow""><span class=""std std-ref"">extension types documentation</span></a>).</p></li>
</ul>
<p>You can specify an <code class=""docutils literal notranslate""><span class=""pre"">engine</span></code> to direct the serialization. This can be one of <code class=""docutils literal notranslate""><span class=""pre"">pyarrow</span></code>, or <code class=""docutils literal notranslate""><span class=""pre"">fastparquet</span></code>, or <code class=""docutils literal notranslate""><span class=""pre"">auto</span></code>.
If the engine is NOT specified, then the <code class=""docutils literal notranslate""><span class=""pre"">pd.options.io.parquet.engine</span></code> option is checked; if this is also <code class=""docutils literal notranslate""><span class=""pre"">auto</span></code>,
then <code class=""docutils literal notranslate""><span class=""pre"">pyarrow</span></code> is tried, and falling back to <code class=""docutils literal notranslate""><span class=""pre"">fastparquet</span></code>.</p>
<p>See the documentation for <a class=""reference external"" href=""https://arrow.apache.org/docs/python/"">pyarrow</a> and <a class=""reference external"" href=""https://fastparquet.readthedocs.io/en/latest/"">fastparquet</a>.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>These engines are very similar and should read/write nearly identical parquet format files.
<code class=""docutils literal notranslate""><span class=""pre"">pyarrow&gt;=8.0.0</span></code> supports timedelta data, <code class=""docutils literal notranslate""><span class=""pre"">fastparquet&gt;=0.1.4</span></code> supports timezone aware datetimes.
These libraries differ by having different underlying dependencies (<code class=""docutils literal notranslate""><span class=""pre"">fastparquet</span></code> by using <code class=""docutils literal notranslate""><span class=""pre"">numba</span></code>, while <code class=""docutils literal notranslate""><span class=""pre"">pyarrow</span></code> uses a c-library).</p>
</div>

<p>Write to a parquet file.</p>

<p>Read from a parquet file.</p>

<p>By setting the <code class=""docutils literal notranslate""><span class=""pre"">dtype_backend</span></code> argument you can control the default dtypes used for the resulting DataFrame.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Note that this is not supported for <code class=""docutils literal notranslate""><span class=""pre"">fastparquet</span></code>.</p>
</div>
<p>Read only certain columns of a parquet file.</p>

<section id=""handling-indexes"">
<h3>Handling indexes<a class=""headerlink"" href=""#handling-indexes"" title=""Link to this heading"">#</a></h3>
<p>Serializing a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> to parquet may include the implicit index as one or
more columns in the output file. Thus, this code:</p>

<p>creates a parquet file with <em>three</em> columns if you use <code class=""docutils literal notranslate""><span class=""pre"">pyarrow</span></code> for serialization:
<code class=""docutils literal notranslate""><span class=""pre"">a</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">b</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">__index_level_0__</span></code>. If you’re using <code class=""docutils literal notranslate""><span class=""pre"">fastparquet</span></code>, the
index <a class=""reference external"" href=""https://fastparquet.readthedocs.io/en/latest/api.html#fastparquet.write"">may or may not</a>
be written to the file.</p>
<p>This unexpected extra column causes some databases like Amazon Redshift to reject
the file, because that column doesn’t exist in the target table.</p>
<p>If you want to omit a dataframe’s indexes when writing, pass <code class=""docutils literal notranslate""><span class=""pre"">index=False</span></code> to
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_parquet.html#pandas.DataFrame.to_parquet"" title=""pandas.DataFrame.to_parquet""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">to_parquet()</span></code></a>:</p>

<p>This creates a parquet file with just the two expected columns, <code class=""docutils literal notranslate""><span class=""pre"">a</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">b</span></code>.
If your <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> has a custom index, you won’t get it back when you load
this file into a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>.</p>
<p>Passing <code class=""docutils literal notranslate""><span class=""pre"">index=True</span></code> will <em>always</em> write the index, even if that’s not the
underlying engine’s default behavior.</p>
</section>
<section id=""partitioning-parquet-files"">
<h3>Partitioning Parquet files<a class=""headerlink"" href=""#partitioning-parquet-files"" title=""Link to this heading"">#</a></h3>
<p>Parquet supports partitioning of data based on the values of one or more columns.</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">path</span></code> specifies the parent directory to which data will be saved.
The <code class=""docutils literal notranslate""><span class=""pre"">partition_cols</span></code> are the column names by which the dataset will be partitioned.
Columns are partitioned in the order they are given. The partition splits are
determined by the unique values in the partition columns.
The above example creates a partitioned dataset that may look like:</p>
<div class=""highlight-text notranslate""><div class=""highlight""><pre><span></span>test
├── a=0
│   ├── 0bac803e32dc42ae83fddfd029cbdebc.parquet
│   └──  ...
└── a=1
    ├── e6ab24a4f45147b49b54a662f0c412a3.parquet
    └── ...
</pre></div>
</div>
</section>
</section>
<section id=""orc"">
<span id=""io-orc""></span><h2>ORC<a class=""headerlink"" href=""#orc"" title=""Link to this heading"">#</a></h2>
<p>Similar to the <a class=""reference internal"" href=""#io-parquet""><span class=""std std-ref"">parquet</span></a> format, the <a class=""reference external"" href=""https://orc.apache.org/"">ORC Format</a> is a binary columnar serialization
for data frames. It is designed to make reading data frames efficient. pandas provides both the reader and the writer for the
ORC format, <a class=""reference internal"" href=""../reference/api/pandas.read_orc.html#pandas.read_orc"" title=""pandas.read_orc""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_orc()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_orc.html#pandas.DataFrame.to_orc"" title=""pandas.DataFrame.to_orc""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">to_orc()</span></code></a>. This requires the <a class=""reference external"" href=""https://arrow.apache.org/docs/python/"">pyarrow</a> library.</p>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<ul class=""simple"">
<li><p>It is <em>highly recommended</em> to install pyarrow using conda due to some issues occurred by pyarrow.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_orc.html#pandas.DataFrame.to_orc"" title=""pandas.DataFrame.to_orc""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">to_orc()</span></code></a> requires pyarrow&gt;=7.0.0.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.read_orc.html#pandas.read_orc"" title=""pandas.read_orc""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_orc()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_orc.html#pandas.DataFrame.to_orc"" title=""pandas.DataFrame.to_orc""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">to_orc()</span></code></a> are not supported on Windows yet, you can find valid environments on <a class=""reference internal"" href=""../getting_started/install.html#install-warn-orc""><span class=""std std-ref"">install optional dependencies</span></a>.</p></li>
<li><p>For supported dtypes please refer to <a class=""reference external"" href=""https://arrow.apache.org/docs/cpp/orc.html#data-types"">supported ORC features in Arrow</a>.</p></li>
<li><p>Currently timezones in datetime columns are not preserved when a dataframe is converted into ORC files.</p></li>
</ul>
</div>

<p>Write to an orc file.</p>

<p>Read from an orc file.</p>

<p>Read only certain columns of an orc file.</p>

</section>
<section id=""sql-queries"">
<span id=""io-sql""></span><h2>SQL queries<a class=""headerlink"" href=""#sql-queries"" title=""Link to this heading"">#</a></h2>
<p>The <code class=""xref py py-mod docutils literal notranslate""><span class=""pre"">pandas.io.sql</span></code> module provides a collection of query wrappers to both
facilitate data retrieval and to reduce dependency on DB-specific API.</p>
<p>Where available, users may first want to opt for <a class=""reference external"" href=""https://arrow.apache.org/adbc/current/index.html"">Apache Arrow ADBC</a> drivers. These drivers
should provide the best performance, null handling, and type detection.</p>
<blockquote>
<div><div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 2.2.0: </span>Added native support for ADBC drivers</p>
</div>
</div></blockquote>
<p>For a full list of ADBC drivers and their development status, see the <a class=""reference external"" href=""https://arrow.apache.org/adbc/current/driver/status.html"">ADBC Driver
Implementation Status</a>
documentation.</p>
<p>Where an ADBC driver is not available or may be missing functionality,
users should opt for installing SQLAlchemy alongside their database driver library.
Examples of such drivers are <a class=""reference external"" href=""https://www.psycopg.org/"">psycopg2</a>
for PostgreSQL or <a class=""reference external"" href=""https://github.com/PyMySQL/PyMySQL"">pymysql</a> for MySQL.
For <a class=""reference external"" href=""https://docs.python.org/3/library/sqlite3.html"">SQLite</a> this is
included in Python’s standard library by default.
You can find an overview of supported drivers for each SQL dialect in the
<a class=""reference external"" href=""https://docs.sqlalchemy.org/en/latest/dialects/index.html"">SQLAlchemy docs</a>.</p>
<p>If SQLAlchemy is not installed, you can use a <a class=""reference external"" href=""https://docs.python.org/3/library/sqlite3.html#sqlite3.Connection"" title=""(in Python v3.12)""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">sqlite3.Connection</span></code></a> in place of
a SQLAlchemy engine, connection, or URI string.</p>
<p>See also some <a class=""reference internal"" href=""cookbook.html#cookbook-sql""><span class=""std std-ref"">cookbook examples</span></a> for some advanced strategies.</p>
<p>The key functions are:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The function <a class=""reference internal"" href=""../reference/api/pandas.read_sql.html#pandas.read_sql"" title=""pandas.read_sql""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_sql()</span></code></a> is a convenience wrapper around
<a class=""reference internal"" href=""../reference/api/pandas.read_sql_table.html#pandas.read_sql_table"" title=""pandas.read_sql_table""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_sql_table()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.read_sql_query.html#pandas.read_sql_query"" title=""pandas.read_sql_query""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_sql_query()</span></code></a> (and for
backward compatibility) and will delegate to specific function depending on
the provided input (database table name or sql query).
Table names do not need to be quoted if they have special characters.</p>
</div>
<p>In the following example, we use the <a class=""reference external"" href=""https://www.sqlite.org/index.html"">SQlite</a> SQL database
engine. You can use a temporary SQLite database where data are stored in
“memory”.</p>
<p>To connect using an ADBC driver you will want to install the <code class=""docutils literal notranslate""><span class=""pre"">adbc_driver_sqlite</span></code> using your
package manager. Once installed, you can use the DBAPI interface provided by the ADBC driver
to connect to your database.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">adbc_driver_sqlite.dbapi</span> <span class=""k"">as</span> <span class=""nn"">sqlite_dbapi</span>

<span class=""c1""># Create the connection</span>
<span class=""k"">with</span> <span class=""n"">sqlite_dbapi</span><span class=""o"">.</span><span class=""n"">connect</span><span class=""p"">(</span><span class=""s2"">""sqlite:///:memory:""</span><span class=""p"">)</span> <span class=""k"">as</span> <span class=""n"">conn</span><span class=""p"">:</span>
     <span class=""n"">df</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_sql_table</span><span class=""p"">(</span><span class=""s2"">""data""</span><span class=""p"">,</span> <span class=""n"">conn</span><span class=""p"">)</span>
</pre></div>
</div>
<p>To connect with SQLAlchemy you use the <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">create_engine()</span></code> function to create an engine
object from database URI. You only need to create the engine once per database you are
connecting to.
For more information on <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">create_engine()</span></code> and the URI formatting, see the examples
below and the SQLAlchemy <a class=""reference external"" href=""https://docs.sqlalchemy.org/en/latest/core/engines.html"">documentation</a></p>

<p>If you want to manage your own connections you can pass one of those instead. The example below opens a
connection to the database using a Python context manager that automatically closes the connection after
the block has completed.
See the <a class=""reference external"" href=""https://docs.sqlalchemy.org/en/latest/core/connections.html#basic-usage"">SQLAlchemy docs</a>
for an explanation of how the database connection is handled.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""k"">with</span> <span class=""n"">engine</span><span class=""o"">.</span><span class=""n"">connect</span><span class=""p"">()</span> <span class=""k"">as</span> <span class=""n"">conn</span><span class=""p"">,</span> <span class=""n"">conn</span><span class=""o"">.</span><span class=""n"">begin</span><span class=""p"">():</span>
    <span class=""n"">data</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_sql_table</span><span class=""p"">(</span><span class=""s2"">""data""</span><span class=""p"">,</span> <span class=""n"">conn</span><span class=""p"">)</span>
</pre></div>
</div>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>When you open a connection to a database you are also responsible for closing it.
Side effects of leaving a connection open may include locking the database or
other breaking behaviour.</p>
</div>
<section id=""writing-dataframes"">
<h3>Writing DataFrames<a class=""headerlink"" href=""#writing-dataframes"" title=""Link to this heading"">#</a></h3>
<p>Assuming the following data is in a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> <code class=""docutils literal notranslate""><span class=""pre"">data</span></code>, we can insert it into
the database using <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_sql.html#pandas.DataFrame.to_sql"" title=""pandas.DataFrame.to_sql""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">to_sql()</span></code></a>.</p>


<p>With some databases, writing large DataFrames can result in errors due to
packet size limitations being exceeded. This can be avoided by setting the
<code class=""docutils literal notranslate""><span class=""pre"">chunksize</span></code> parameter when calling <code class=""docutils literal notranslate""><span class=""pre"">to_sql</span></code>. For example, the following
writes <code class=""docutils literal notranslate""><span class=""pre"">data</span></code> to the database in batches of 1000 rows at a time:</p>

<section id=""sql-data-types"">
<h4>SQL data types<a class=""headerlink"" href=""#sql-data-types"" title=""Link to this heading"">#</a></h4>
<p>Ensuring consistent data type management across SQL databases is challenging.
Not every SQL database offers the same types, and even when they do the implementation
of a given type can vary in ways that have subtle effects on how types can be
preserved.</p>
<p>For the best odds at preserving database types users are advised to use
ADBC drivers when available. The Arrow type system offers a wider array of
types that more closely match database types than the historical pandas/NumPy
type system. To illustrate, note this (non-exhaustive) listing of types
available in different databases and pandas backends:</p>

<p class=""rubric"">Footnotes</p>
<aside class=""footnote-list brackets"">
<aside class=""footnote brackets"" id=""f1"" role=""doc-footnote"">
<span class=""label""><span class=""fn-bracket"">[</span>1<span class=""fn-bracket"">]</span></span>
<span class=""backrefs"">(<a href=""#id5"" role=""doc-backlink"">1</a>,<a href=""#id6"" role=""doc-backlink"">2</a>,<a href=""#id7"" role=""doc-backlink"">3</a>)</span>
<p>Not implemented as of writing, but theoretically possible</p>
</aside>
</aside>
<p>If you are interested in preserving database types as best as possible
throughout the lifecycle of your DataFrame, users are encouraged to
leverage the <code class=""docutils literal notranslate""><span class=""pre"">dtype_backend=""pyarrow""</span></code> argument of <a class=""reference internal"" href=""../reference/api/pandas.read_sql.html#pandas.read_sql"" title=""pandas.read_sql""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_sql()</span></code></a></p>

<p>This will prevent your data from being converted to the traditional pandas/NumPy
type system, which often converts SQL types in ways that make them impossible to
round-trip.</p>
<p>In case an ADBC driver is not available, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_sql.html#pandas.DataFrame.to_sql"" title=""pandas.DataFrame.to_sql""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">to_sql()</span></code></a>
will try to map your data to an appropriate SQL data type based on the dtype of
the data. When you have columns of dtype <code class=""docutils literal notranslate""><span class=""pre"">object</span></code>, pandas will try to infer
the data type.</p>
<p>You can always override the default type by specifying the desired SQL type of
any of the columns by using the <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code> argument. This argument needs a
dictionary mapping column names to SQLAlchemy types (or strings for the sqlite3
fallback mode).
For example, specifying to use the sqlalchemy <code class=""docutils literal notranslate""><span class=""pre"">String</span></code> type instead of the
default <code class=""docutils literal notranslate""><span class=""pre"">Text</span></code> type for string columns:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Due to the limited support for timedelta’s in the different database
flavors, columns with type <code class=""docutils literal notranslate""><span class=""pre"">timedelta64</span></code> will be written as integer
values as nanoseconds to the database and a warning will be raised. The only
exception to this is when using the ADBC PostgreSQL driver in which case a
timedelta will be written to the database as an <code class=""docutils literal notranslate""><span class=""pre"">INTERVAL</span></code></p>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Columns of <code class=""docutils literal notranslate""><span class=""pre"">category</span></code> dtype will be converted to the dense representation
as you would get with <code class=""docutils literal notranslate""><span class=""pre"">np.asarray(categorical)</span></code> (e.g. for string categories
this gives an array of strings).
Because of this, reading the database table back in does <strong>not</strong> generate
a categorical.</p>
</div>
</section>
</section>
<section id=""datetime-data-types"">
<span id=""io-sql-datetime-data""></span><h3>Datetime data types<a class=""headerlink"" href=""#datetime-data-types"" title=""Link to this heading"">#</a></h3>
<p>Using ADBC or SQLAlchemy, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_sql.html#pandas.DataFrame.to_sql"" title=""pandas.DataFrame.to_sql""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">to_sql()</span></code></a> is capable of writing
datetime data that is timezone naive or timezone aware. However, the resulting
data stored in the database ultimately depends on the supported data type
for datetime data of the database system being used.</p>
<p>The following table lists supported data types for datetime data for some
common databases. Other database dialects may have different data types for
datetime data.</p>

<p>When writing timezone aware data to databases that do not support timezones,
the data will be written as timezone naive timestamps that are in local time
with respect to the timezone.</p>
<p><a class=""reference internal"" href=""../reference/api/pandas.read_sql_table.html#pandas.read_sql_table"" title=""pandas.read_sql_table""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_sql_table()</span></code></a> is also capable of reading datetime data that is
timezone aware or naive. When reading <code class=""docutils literal notranslate""><span class=""pre"">TIMESTAMP</span> <span class=""pre"">WITH</span> <span class=""pre"">TIME</span> <span class=""pre"">ZONE</span></code> types, pandas
will convert the data to UTC.</p>
<section id=""insertion-method"">
<span id=""io-sql-method""></span><h4>Insertion method<a class=""headerlink"" href=""#insertion-method"" title=""Link to this heading"">#</a></h4>
<p>The parameter <code class=""docutils literal notranslate""><span class=""pre"">method</span></code> controls the SQL insertion clause used.
Possible values are:</p>
<ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">None</span></code>: Uses standard SQL <code class=""docutils literal notranslate""><span class=""pre"">INSERT</span></code> clause (one per row).</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">'multi'</span></code>: Pass multiple values in a single <code class=""docutils literal notranslate""><span class=""pre"">INSERT</span></code> clause.
It uses a <em>special</em> SQL syntax not supported by all backends.
This usually provides better performance for analytic databases
like <em>Presto</em> and <em>Redshift</em>, but has worse performance for
traditional SQL backend if the table contains many columns.
For more information check the SQLAlchemy <a class=""reference external"" href=""https://docs.sqlalchemy.org/en/latest/core/dml.html#sqlalchemy.sql.expression.Insert.values.params.*args"">documentation</a>.</p></li>
<li><p>callable with signature <code class=""docutils literal notranslate""><span class=""pre"">(pd_table,</span> <span class=""pre"">conn,</span> <span class=""pre"">keys,</span> <span class=""pre"">data_iter)</span></code>:
This can be used to implement a more performant insertion method based on
specific backend dialect features.</p></li>
</ul>
<p>Example of a callable using PostgreSQL <a class=""reference external"" href=""https://www.postgresql.org/docs/current/sql-copy.html"">COPY clause</a>:</p>
<div class=""highlight-default notranslate""><div class=""highlight""><pre><span></span><span class=""c1""># Alternative to_sql() *method* for DBs that support COPY FROM</span>
<span class=""kn"">import</span> <span class=""nn"">csv</span>
<span class=""kn"">from</span> <span class=""nn"">io</span> <span class=""kn"">import</span> <span class=""n"">StringIO</span>

<span class=""k"">def</span> <span class=""nf"">psql_insert_copy</span><span class=""p"">(</span><span class=""n"">table</span><span class=""p"">,</span> <span class=""n"">conn</span><span class=""p"">,</span> <span class=""n"">keys</span><span class=""p"">,</span> <span class=""n"">data_iter</span><span class=""p"">):</span>
<span class=""w"">    </span><span class=""sd"">""""""</span>
<span class=""sd"">    Execute SQL statement inserting data</span>

<span class=""sd"">    Parameters</span>
<span class=""sd"">    ----------</span>
<span class=""sd"">    table : pandas.io.sql.SQLTable</span>
<span class=""sd"">    conn : sqlalchemy.engine.Engine or sqlalchemy.engine.Connection</span>
<span class=""sd"">    keys : list of str</span>
<span class=""sd"">        Column names</span>
<span class=""sd"">    data_iter : Iterable that iterates the values to be inserted</span>
<span class=""sd"">    """"""</span>
    <span class=""c1""># gets a DBAPI connection that can provide a cursor</span>
    <span class=""n"">dbapi_conn</span> <span class=""o"">=</span> <span class=""n"">conn</span><span class=""o"">.</span><span class=""n"">connection</span>
    <span class=""k"">with</span> <span class=""n"">dbapi_conn</span><span class=""o"">.</span><span class=""n"">cursor</span><span class=""p"">()</span> <span class=""k"">as</span> <span class=""n"">cur</span><span class=""p"">:</span>
        <span class=""n"">s_buf</span> <span class=""o"">=</span> <span class=""n"">StringIO</span><span class=""p"">()</span>
        <span class=""n"">writer</span> <span class=""o"">=</span> <span class=""n"">csv</span><span class=""o"">.</span><span class=""n"">writer</span><span class=""p"">(</span><span class=""n"">s_buf</span><span class=""p"">)</span>
        <span class=""n"">writer</span><span class=""o"">.</span><span class=""n"">writerows</span><span class=""p"">(</span><span class=""n"">data_iter</span><span class=""p"">)</span>
        <span class=""n"">s_buf</span><span class=""o"">.</span><span class=""n"">seek</span><span class=""p"">(</span><span class=""mi"">0</span><span class=""p"">)</span>

        <span class=""n"">columns</span> <span class=""o"">=</span> <span class=""s1"">', '</span><span class=""o"">.</span><span class=""n"">join</span><span class=""p"">([</span><span class=""s1"">'""</span><span class=""si"">{}</span><span class=""s1"">""'</span><span class=""o"">.</span><span class=""n"">format</span><span class=""p"">(</span><span class=""n"">k</span><span class=""p"">)</span> <span class=""k"">for</span> <span class=""n"">k</span> <span class=""ow"">in</span> <span class=""n"">keys</span><span class=""p"">])</span>
        <span class=""k"">if</span> <span class=""n"">table</span><span class=""o"">.</span><span class=""n"">schema</span><span class=""p"">:</span>
            <span class=""n"">table_name</span> <span class=""o"">=</span> <span class=""s1"">'</span><span class=""si"">{}</span><span class=""s1"">.</span><span class=""si"">{}</span><span class=""s1"">'</span><span class=""o"">.</span><span class=""n"">format</span><span class=""p"">(</span><span class=""n"">table</span><span class=""o"">.</span><span class=""n"">schema</span><span class=""p"">,</span> <span class=""n"">table</span><span class=""o"">.</span><span class=""n"">name</span><span class=""p"">)</span>
        <span class=""k"">else</span><span class=""p"">:</span>
            <span class=""n"">table_name</span> <span class=""o"">=</span> <span class=""n"">table</span><span class=""o"">.</span><span class=""n"">name</span>

        <span class=""n"">sql</span> <span class=""o"">=</span> <span class=""s1"">'COPY </span><span class=""si"">{}</span><span class=""s1""> (</span><span class=""si"">{}</span><span class=""s1"">) FROM STDIN WITH CSV'</span><span class=""o"">.</span><span class=""n"">format</span><span class=""p"">(</span>
            <span class=""n"">table_name</span><span class=""p"">,</span> <span class=""n"">columns</span><span class=""p"">)</span>
        <span class=""n"">cur</span><span class=""o"">.</span><span class=""n"">copy_expert</span><span class=""p"">(</span><span class=""n"">sql</span><span class=""o"">=</span><span class=""n"">sql</span><span class=""p"">,</span> <span class=""n"">file</span><span class=""o"">=</span><span class=""n"">s_buf</span><span class=""p"">)</span>
</pre></div>
</div>
</section>
</section>
<section id=""reading-tables"">
<h3>Reading tables<a class=""headerlink"" href=""#reading-tables"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.read_sql_table.html#pandas.read_sql_table"" title=""pandas.read_sql_table""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_sql_table()</span></code></a> will read a database table given the
table name and optionally a subset of columns to read.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>In order to use <a class=""reference internal"" href=""../reference/api/pandas.read_sql_table.html#pandas.read_sql_table"" title=""pandas.read_sql_table""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_sql_table()</span></code></a>, you <strong>must</strong> have the
ADBC driver or SQLAlchemy optional dependency installed.</p>
</div>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>ADBC drivers will map database types directly back to arrow types. For other drivers
note that pandas infers column dtypes from query outputs, and not by looking
up data types in the physical database schema. For example, assume <code class=""docutils literal notranslate""><span class=""pre"">userid</span></code>
is an integer column in a table. Then, intuitively, <code class=""docutils literal notranslate""><span class=""pre"">select</span> <span class=""pre"">userid</span> <span class=""pre"">...</span></code> will
return integer-valued series, while <code class=""docutils literal notranslate""><span class=""pre"">select</span> <span class=""pre"">cast(userid</span> <span class=""pre"">as</span> <span class=""pre"">text)</span> <span class=""pre"">...</span></code> will
return object-valued (str) series. Accordingly, if the query output is empty,
then all resulting columns will be returned as object-valued (since they are
most general). If you foresee that your query will sometimes generate an empty
result, you may want to explicitly typecast afterwards to ensure dtype
integrity.</p>
</div>
<p>You can also specify the name of the column as the <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> index,
and specify a subset of columns to be read.</p>

<p>And you can explicitly force columns to be parsed as dates:</p>

<p>If needed you can explicitly specify a format string, or a dict of arguments
to pass to <a class=""reference internal"" href=""../reference/api/pandas.to_datetime.html#pandas.to_datetime"" title=""pandas.to_datetime""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.to_datetime()</span></code></a>:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_sql_table</span><span class=""p"">(</span><span class=""s2"">""data""</span><span class=""p"">,</span> <span class=""n"">engine</span><span class=""p"">,</span> <span class=""n"">parse_dates</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s2"">""Date""</span><span class=""p"">:</span> <span class=""s2"">""%Y-%m-</span><span class=""si"">%d</span><span class=""s2"">""</span><span class=""p"">})</span>
<span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_sql_table</span><span class=""p"">(</span>
    <span class=""s2"">""data""</span><span class=""p"">,</span>
    <span class=""n"">engine</span><span class=""p"">,</span>
    <span class=""n"">parse_dates</span><span class=""o"">=</span><span class=""p"">{</span><span class=""s2"">""Date""</span><span class=""p"">:</span> <span class=""p"">{</span><span class=""s2"">""format""</span><span class=""p"">:</span> <span class=""s2"">""%Y-%m-</span><span class=""si"">%d</span><span class=""s2""> %H:%M:%S""</span><span class=""p"">}},</span>
<span class=""p"">)</span>
</pre></div>
</div>
<p>You can check if a table exists using <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">has_table()</span></code></p>
</section>
<section id=""schema-support"">
<h3>Schema support<a class=""headerlink"" href=""#schema-support"" title=""Link to this heading"">#</a></h3>
<p>Reading from and writing to different schema’s is supported through the <code class=""docutils literal notranslate""><span class=""pre"">schema</span></code>
keyword in the <a class=""reference internal"" href=""../reference/api/pandas.read_sql_table.html#pandas.read_sql_table"" title=""pandas.read_sql_table""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_sql_table()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.to_sql.html#pandas.DataFrame.to_sql"" title=""pandas.DataFrame.to_sql""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">to_sql()</span></code></a>
functions. Note however that this depends on the database flavor (sqlite does not
have schema’s). For example:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df</span><span class=""o"">.</span><span class=""n"">to_sql</span><span class=""p"">(</span><span class=""n"">name</span><span class=""o"">=</span><span class=""s2"">""table""</span><span class=""p"">,</span> <span class=""n"">con</span><span class=""o"">=</span><span class=""n"">engine</span><span class=""p"">,</span> <span class=""n"">schema</span><span class=""o"">=</span><span class=""s2"">""other_schema""</span><span class=""p"">)</span>
<span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_sql_table</span><span class=""p"">(</span><span class=""s2"">""table""</span><span class=""p"">,</span> <span class=""n"">engine</span><span class=""p"">,</span> <span class=""n"">schema</span><span class=""o"">=</span><span class=""s2"">""other_schema""</span><span class=""p"">)</span>
</pre></div>
</div>
</section>
<section id=""id8"">
<h3>Querying<a class=""headerlink"" href=""#id8"" title=""Link to this heading"">#</a></h3>
<p>You can query using raw SQL in the <a class=""reference internal"" href=""../reference/api/pandas.read_sql_query.html#pandas.read_sql_query"" title=""pandas.read_sql_query""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_sql_query()</span></code></a> function.
In this case you must use the SQL variant appropriate for your database.
When using SQLAlchemy, you can also pass SQLAlchemy Expression language constructs,
which are database-agnostic.</p>

<p>Of course, you can specify a more “complex” query.</p>

<p>The <a class=""reference internal"" href=""../reference/api/pandas.read_sql_query.html#pandas.read_sql_query"" title=""pandas.read_sql_query""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_sql_query()</span></code></a> function supports a <code class=""docutils literal notranslate""><span class=""pre"">chunksize</span></code> argument.
Specifying this will return an iterator through chunks of the query result:</p>


</section>
<section id=""engine-connection-examples"">
<h3>Engine connection examples<a class=""headerlink"" href=""#engine-connection-examples"" title=""Link to this heading"">#</a></h3>
<p>To connect with SQLAlchemy you use the <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">create_engine()</span></code> function to create an engine
object from database URI. You only need to create the engine once per database you are
connecting to.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">sqlalchemy</span> <span class=""kn"">import</span> <span class=""n"">create_engine</span>

<span class=""n"">engine</span> <span class=""o"">=</span> <span class=""n"">create_engine</span><span class=""p"">(</span><span class=""s2"">""postgresql://scott:tiger@localhost:5432/mydatabase""</span><span class=""p"">)</span>

<span class=""n"">engine</span> <span class=""o"">=</span> <span class=""n"">create_engine</span><span class=""p"">(</span><span class=""s2"">""mysql+mysqldb://scott:tiger@localhost/foo""</span><span class=""p"">)</span>

<span class=""n"">engine</span> <span class=""o"">=</span> <span class=""n"">create_engine</span><span class=""p"">(</span><span class=""s2"">""oracle://scott:<a class=""__cf_email__"" data-cfemail=""c6b2afa1a3b486f7f4f1e8f6e8f6e8f7"" href=""/cdn-cgi/l/email-protection"">[email protected]</a>:1521/sidname""</span><span class=""p"">)</span>

<span class=""n"">engine</span> <span class=""o"">=</span> <span class=""n"">create_engine</span><span class=""p"">(</span><span class=""s2"">""mssql+pyodbc://mydsn""</span><span class=""p"">)</span>

<span class=""c1""># sqlite://&lt;nohostname&gt;/&lt;path&gt;</span>
<span class=""c1""># where &lt;path&gt; is relative:</span>
<span class=""n"">engine</span> <span class=""o"">=</span> <span class=""n"">create_engine</span><span class=""p"">(</span><span class=""s2"">""sqlite:///foo.db""</span><span class=""p"">)</span>

<span class=""c1""># or absolute, starting with a slash:</span>
<span class=""n"">engine</span> <span class=""o"">=</span> <span class=""n"">create_engine</span><span class=""p"">(</span><span class=""s2"">""sqlite:////absolute/path/to/foo.db""</span><span class=""p"">)</span>
</pre></div>
</div>
<p>For more information see the examples the SQLAlchemy <a class=""reference external"" href=""https://docs.sqlalchemy.org/en/latest/core/engines.html"">documentation</a></p>
</section>
<section id=""advanced-sqlalchemy-queries"">
<h3>Advanced SQLAlchemy queries<a class=""headerlink"" href=""#advanced-sqlalchemy-queries"" title=""Link to this heading"">#</a></h3>
<p>You can use SQLAlchemy constructs to describe your query.</p>
<p>Use <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">sqlalchemy.text()</span></code> to specify query parameters in a backend-neutral way</p>

<p>If you have an SQLAlchemy description of your database you can express where conditions using SQLAlchemy expressions</p>

<p>You can combine SQLAlchemy expressions with parameters passed to <a class=""reference internal"" href=""../reference/api/pandas.read_sql.html#pandas.read_sql"" title=""pandas.read_sql""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_sql()</span></code></a> using <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">sqlalchemy.bindparam()</span></code></p>

</section>
<section id=""sqlite-fallback"">
<h3>Sqlite fallback<a class=""headerlink"" href=""#sqlite-fallback"" title=""Link to this heading"">#</a></h3>
<p>The use of sqlite is supported without using SQLAlchemy.
This mode requires a Python database adapter which respect the <a class=""reference external"" href=""https://www.python.org/dev/peps/pep-0249/"">Python
DB-API</a>.</p>
<p>You can create connections like so:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">sqlite3</span>

<span class=""n"">con</span> <span class=""o"">=</span> <span class=""n"">sqlite3</span><span class=""o"">.</span><span class=""n"">connect</span><span class=""p"">(</span><span class=""s2"">"":memory:""</span><span class=""p"">)</span>
</pre></div>
</div>
<p>And then issue the following queries:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">data</span><span class=""o"">.</span><span class=""n"">to_sql</span><span class=""p"">(</span><span class=""s2"">""data""</span><span class=""p"">,</span> <span class=""n"">con</span><span class=""p"">)</span>
<span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_sql_query</span><span class=""p"">(</span><span class=""s2"">""SELECT * FROM data""</span><span class=""p"">,</span> <span class=""n"">con</span><span class=""p"">)</span>
</pre></div>
</div>
</section>
</section>
<section id=""google-bigquery"">
<span id=""io-bigquery""></span><h2>Google BigQuery<a class=""headerlink"" href=""#google-bigquery"" title=""Link to this heading"">#</a></h2>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">pandas-gbq</span></code> package provides functionality to read/write from Google BigQuery.</p>
<p>pandas integrates with this external package. if <code class=""docutils literal notranslate""><span class=""pre"">pandas-gbq</span></code> is installed, you can
use the pandas methods <code class=""docutils literal notranslate""><span class=""pre"">pd.read_gbq</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">DataFrame.to_gbq</span></code>, which will call the
respective functions from <code class=""docutils literal notranslate""><span class=""pre"">pandas-gbq</span></code>.</p>
<p>Full documentation can be found <a class=""reference external"" href=""https://pandas-gbq.readthedocs.io/en/latest/"">here</a>.</p>
</section>
<section id=""stata-format"">
<span id=""io-stata""></span><h2>Stata format<a class=""headerlink"" href=""#stata-format"" title=""Link to this heading"">#</a></h2>
<section id=""writing-to-stata-format"">
<span id=""io-stata-writer""></span><h3>Writing to stata format<a class=""headerlink"" href=""#writing-to-stata-format"" title=""Link to this heading"">#</a></h3>
<p>The method <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">DataFrame.to_stata()</span></code> will write a DataFrame
into a .dta file. The format version of this file is always 115 (Stata 12).</p>

<p><em>Stata</em> data files have limited data type support; only strings with
244 or fewer characters, <code class=""docutils literal notranslate""><span class=""pre"">int8</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">int16</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">int32</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">float32</span></code>
and <code class=""docutils literal notranslate""><span class=""pre"">float64</span></code> can be stored in <code class=""docutils literal notranslate""><span class=""pre"">.dta</span></code> files. Additionally,
<em>Stata</em> reserves certain values to represent missing data. Exporting a
non-missing value that is outside of the permitted range in Stata for
a particular data type will retype the variable to the next larger
size. For example, <code class=""docutils literal notranslate""><span class=""pre"">int8</span></code> values are restricted to lie between -127
and 100 in Stata, and so variables with values above 100 will trigger
a conversion to <code class=""docutils literal notranslate""><span class=""pre"">int16</span></code>. <code class=""docutils literal notranslate""><span class=""pre"">nan</span></code> values in floating points data
types are stored as the basic missing data type (<code class=""docutils literal notranslate""><span class=""pre"">.</span></code> in <em>Stata</em>).</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>It is not possible to export missing data values for integer data types.</p>
</div>
<p>The <em>Stata</em> writer gracefully handles other data types including <code class=""docutils literal notranslate""><span class=""pre"">int64</span></code>,
<code class=""docutils literal notranslate""><span class=""pre"">bool</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">uint8</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">uint16</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">uint32</span></code> by casting to
the smallest supported type that can represent the data. For example, data
with a type of <code class=""docutils literal notranslate""><span class=""pre"">uint8</span></code> will be cast to <code class=""docutils literal notranslate""><span class=""pre"">int8</span></code> if all values are less than
100 (the upper bound for non-missing <code class=""docutils literal notranslate""><span class=""pre"">int8</span></code> data in <em>Stata</em>), or, if values are
outside of this range, the variable is cast to <code class=""docutils literal notranslate""><span class=""pre"">int16</span></code>.</p>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Conversion from <code class=""docutils literal notranslate""><span class=""pre"">int64</span></code> to <code class=""docutils literal notranslate""><span class=""pre"">float64</span></code> may result in a loss of precision
if <code class=""docutils literal notranslate""><span class=""pre"">int64</span></code> values are larger than 2**53.</p>
</div>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">StataWriter</span></code> and
<code class=""xref py py-func docutils literal notranslate""><span class=""pre"">DataFrame.to_stata()</span></code> only support fixed width
strings containing up to 244 characters, a limitation imposed by the version
115 dta file format. Attempting to write <em>Stata</em> dta files with strings
longer than 244 characters raises a <code class=""docutils literal notranslate""><span class=""pre"">ValueError</span></code>.</p>
</div>
</section>
<section id=""reading-from-stata-format"">
<span id=""io-stata-reader""></span><h3>Reading from Stata format<a class=""headerlink"" href=""#reading-from-stata-format"" title=""Link to this heading"">#</a></h3>
<p>The top-level function <code class=""docutils literal notranslate""><span class=""pre"">read_stata</span></code> will read a dta file and return
either a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> or a <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">pandas.api.typing.StataReader</span></code> that can
be used to read the file incrementally.</p>

<p>Specifying a <code class=""docutils literal notranslate""><span class=""pre"">chunksize</span></code> yields a
<code class=""xref py py-class docutils literal notranslate""><span class=""pre"">pandas.api.typing.StataReader</span></code> instance that can be used to
read <code class=""docutils literal notranslate""><span class=""pre"">chunksize</span></code> lines from the file at a time. The <code class=""docutils literal notranslate""><span class=""pre"">StataReader</span></code>
object can be used as an iterator.</p>

<p>For more fine-grained control, use <code class=""docutils literal notranslate""><span class=""pre"">iterator=True</span></code> and specify
<code class=""docutils literal notranslate""><span class=""pre"">chunksize</span></code> with each call to
<code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read()</span></code>.</p>

<p>Currently the <code class=""docutils literal notranslate""><span class=""pre"">index</span></code> is retrieved as a column.</p>
<p>The parameter <code class=""docutils literal notranslate""><span class=""pre"">convert_categoricals</span></code> indicates whether value labels should be
read and used to create a <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> variable from them. Value labels can
also be retrieved by the function <code class=""docutils literal notranslate""><span class=""pre"">value_labels</span></code>, which requires <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read()</span></code>
to be called before use.</p>
<p>The parameter <code class=""docutils literal notranslate""><span class=""pre"">convert_missing</span></code> indicates whether missing value
representations in Stata should be preserved. If <code class=""docutils literal notranslate""><span class=""pre"">False</span></code> (the default),
missing values are represented as <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code>. If <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>, missing values are
represented using <code class=""docutils literal notranslate""><span class=""pre"">StataMissingValue</span></code> objects, and columns containing missing
values will have <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> data type.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p><a class=""reference internal"" href=""../reference/api/pandas.read_stata.html#pandas.read_stata"" title=""pandas.read_stata""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_stata()</span></code></a> and
<code class=""xref py py-class docutils literal notranslate""><span class=""pre"">StataReader</span></code> support .dta formats 113-115
(Stata 10-12), 117 (Stata 13), and 118 (Stata 14).</p>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Setting <code class=""docutils literal notranslate""><span class=""pre"">preserve_dtypes=False</span></code> will upcast to the standard pandas data types:
<code class=""docutils literal notranslate""><span class=""pre"">int64</span></code> for all integer types and <code class=""docutils literal notranslate""><span class=""pre"">float64</span></code> for floating point data. By default,
the Stata data types are preserved when importing.</p>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>All <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">StataReader</span></code> objects, whether created by <a class=""reference internal"" href=""../reference/api/pandas.read_stata.html#pandas.read_stata"" title=""pandas.read_stata""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_stata()</span></code></a>
(when using <code class=""docutils literal notranslate""><span class=""pre"">iterator=True</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">chunksize</span></code>) or instantiated by hand, must be used as context
managers (e.g. the <code class=""docutils literal notranslate""><span class=""pre"">with</span></code> statement).
While the <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">close()</span></code> method is available, its use is unsupported.
It is not part of the public API and will be removed in with future without warning.</p>
</div>
<section id=""io-stata-categorical"">
<span id=""id9""></span><h4>Categorical data<a class=""headerlink"" href=""#io-stata-categorical"" title=""Link to this heading"">#</a></h4>
<p><code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> data can be exported to <em>Stata</em> data files as value labeled data.
The exported data consists of the underlying category codes as integer data values
and the categories as value labels. <em>Stata</em> does not have an explicit equivalent
to a <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> and information about <em>whether</em> the variable is ordered
is lost when exporting.</p>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p><em>Stata</em> only supports string value labels, and so <code class=""docutils literal notranslate""><span class=""pre"">str</span></code> is called on the
categories when exporting data. Exporting <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> variables with
non-string categories produces a warning, and can result a loss of
information if the <code class=""docutils literal notranslate""><span class=""pre"">str</span></code> representations of the categories are not unique.</p>
</div>
<p>Labeled data can similarly be imported from <em>Stata</em> data files as <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code>
variables using the keyword argument <code class=""docutils literal notranslate""><span class=""pre"">convert_categoricals</span></code> (<code class=""docutils literal notranslate""><span class=""pre"">True</span></code> by default).
The keyword argument <code class=""docutils literal notranslate""><span class=""pre"">order_categoricals</span></code> (<code class=""docutils literal notranslate""><span class=""pre"">True</span></code> by default) determines
whether imported <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> variables are ordered.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>When importing categorical data, the values of the variables in the <em>Stata</em>
data file are not preserved since <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> variables always
use integer data types between <code class=""docutils literal notranslate""><span class=""pre"">-1</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">n-1</span></code> where <code class=""docutils literal notranslate""><span class=""pre"">n</span></code> is the number
of categories. If the original values in the <em>Stata</em> data file are required,
these can be imported by setting <code class=""docutils literal notranslate""><span class=""pre"">convert_categoricals=False</span></code>, which will
import original data (but not the variable labels). The original values can
be matched to the imported categorical data since there is a simple mapping
between the original <em>Stata</em> data values and the category codes of imported
Categorical variables: missing values are assigned code <code class=""docutils literal notranslate""><span class=""pre"">-1</span></code>, and the
smallest original value is assigned <code class=""docutils literal notranslate""><span class=""pre"">0</span></code>, the second smallest is assigned
<code class=""docutils literal notranslate""><span class=""pre"">1</span></code> and so on until the largest original value is assigned the code <code class=""docutils literal notranslate""><span class=""pre"">n-1</span></code>.</p>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p><em>Stata</em> supports partially labeled series. These series have value labels for
some but not all data values. Importing a partially labeled series will produce
a <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> with string categories for the values that are labeled and
numeric categories for values with no label.</p>
</div>
</section>
</section>
</section>
<section id=""sas-formats"">
<span id=""io-sas-reader""></span><span id=""io-sas""></span><h2>SAS formats<a class=""headerlink"" href=""#sas-formats"" title=""Link to this heading"">#</a></h2>
<p>The top-level function <a class=""reference internal"" href=""../reference/api/pandas.read_sas.html#pandas.read_sas"" title=""pandas.read_sas""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_sas()</span></code></a> can read (but not write) SAS
XPORT (.xpt) and SAS7BDAT (.sas7bdat) format files.</p>
<p>SAS files only contain two value types: ASCII text and floating point
values (usually 8 bytes but sometimes truncated). For xport files,
there is no automatic type conversion to integers, dates, or
categoricals. For SAS7BDAT files, the format codes may allow date
variables to be automatically converted to dates. By default the
whole file is read and returned as a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>.</p>
<p>Specify a <code class=""docutils literal notranslate""><span class=""pre"">chunksize</span></code> or use <code class=""docutils literal notranslate""><span class=""pre"">iterator=True</span></code> to obtain reader
objects (<code class=""docutils literal notranslate""><span class=""pre"">XportReader</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">SAS7BDATReader</span></code>) for incrementally
reading the file. The reader objects also have attributes that
contain additional information about the file and its variables.</p>
<p>Read a SAS7BDAT file:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_sas</span><span class=""p"">(</span><span class=""s2"">""sas_data.sas7bdat""</span><span class=""p"">)</span>
</pre></div>
</div>
<p>Obtain an iterator and read an XPORT file 100,000 lines at a time:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">do_something</span><span class=""p"">(</span><span class=""n"">chunk</span><span class=""p"">):</span>
    <span class=""k"">pass</span>


<span class=""k"">with</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_sas</span><span class=""p"">(</span><span class=""s2"">""sas_xport.xpt""</span><span class=""p"">,</span> <span class=""n"">chunk</span><span class=""o"">=</span><span class=""mi"">100000</span><span class=""p"">)</span> <span class=""k"">as</span> <span class=""n"">rdr</span><span class=""p"">:</span>
    <span class=""k"">for</span> <span class=""n"">chunk</span> <span class=""ow"">in</span> <span class=""n"">rdr</span><span class=""p"">:</span>
        <span class=""n"">do_something</span><span class=""p"">(</span><span class=""n"">chunk</span><span class=""p"">)</span>
</pre></div>
</div>
<p>The <a class=""reference external"" href=""https://support.sas.com/content/dam/SAS/support/en/technical-papers/record-layout-of-a-sas-version-5-or-6-data-set-in-sas-transport-xport-format.pdf"">specification</a> for the xport file format is available from the SAS
web site.</p>
<p>No official documentation is available for the SAS7BDAT format.</p>
</section>
<section id=""spss-formats"">
<span id=""io-spss-reader""></span><span id=""io-spss""></span><h2>SPSS formats<a class=""headerlink"" href=""#spss-formats"" title=""Link to this heading"">#</a></h2>
<p>The top-level function <a class=""reference internal"" href=""../reference/api/pandas.read_spss.html#pandas.read_spss"" title=""pandas.read_spss""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_spss()</span></code></a> can read (but not write) SPSS
SAV (.sav) and ZSAV (.zsav) format files.</p>
<p>SPSS files contain column names. By default the
whole file is read, categorical columns are converted into <code class=""docutils literal notranslate""><span class=""pre"">pd.Categorical</span></code>,
and a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> with all columns is returned.</p>
<p>Specify the <code class=""docutils literal notranslate""><span class=""pre"">usecols</span></code> parameter to obtain a subset of columns. Specify <code class=""docutils literal notranslate""><span class=""pre"">convert_categoricals=False</span></code>
to avoid converting categorical columns into <code class=""docutils literal notranslate""><span class=""pre"">pd.Categorical</span></code>.</p>
<p>Read an SPSS file:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_spss</span><span class=""p"">(</span><span class=""s2"">""spss_data.sav""</span><span class=""p"">)</span>
</pre></div>
</div>
<p>Extract a subset of columns contained in <code class=""docutils literal notranslate""><span class=""pre"">usecols</span></code> from an SPSS file and
avoid converting categorical columns into <code class=""docutils literal notranslate""><span class=""pre"">pd.Categorical</span></code>:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_spss</span><span class=""p"">(</span>
    <span class=""s2"">""spss_data.sav""</span><span class=""p"">,</span>
    <span class=""n"">usecols</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""foo""</span><span class=""p"">,</span> <span class=""s2"">""bar""</span><span class=""p"">],</span>
    <span class=""n"">convert_categoricals</span><span class=""o"">=</span><span class=""kc"">False</span><span class=""p"">,</span>
<span class=""p"">)</span>
</pre></div>
</div>
<p>More information about the SAV and ZSAV file formats is available <a class=""reference external"" href=""https://www.ibm.com/docs/en/spss-statistics/22.0.0"">here</a>.</p>
</section>
<section id=""other-file-formats"">
<span id=""io-other""></span><h2>Other file formats<a class=""headerlink"" href=""#other-file-formats"" title=""Link to this heading"">#</a></h2>
<p>pandas itself only supports IO with a limited set of file formats that map
cleanly to its tabular data model. For reading and writing other file formats
into and from pandas, we recommend these packages from the broader community.</p>
<section id=""netcdf"">
<h3>netCDF<a class=""headerlink"" href=""#netcdf"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference external"" href=""https://xarray.pydata.org/en/stable/"">xarray</a> provides data structures inspired by the pandas <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> for working
with multi-dimensional datasets, with a focus on the netCDF file format and
easy conversion to and from pandas.</p>
</section>
</section>
<section id=""performance-considerations"">
<span id=""io-perf""></span><h2>Performance considerations<a class=""headerlink"" href=""#performance-considerations"" title=""Link to this heading"">#</a></h2>
<p>This is an informal comparison of various IO methods, using pandas
0.24.2. Timings are machine dependent and small differences should be
ignored.</p>

<p>The following test functions will be used below to compare the performance of several IO methods:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">numpy</span> <span class=""k"">as</span> <span class=""nn"">np</span>

<span class=""kn"">import</span> <span class=""nn"">os</span>

<span class=""n"">sz</span> <span class=""o"">=</span> <span class=""mi"">1000000</span>
<span class=""n"">df</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">({</span><span class=""s2"">""A""</span><span class=""p"">:</span> <span class=""n"">np</span><span class=""o"">.</span><span class=""n"">random</span><span class=""o"">.</span><span class=""n"">randn</span><span class=""p"">(</span><span class=""n"">sz</span><span class=""p"">),</span> <span class=""s2"">""B""</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""mi"">1</span><span class=""p"">]</span> <span class=""o"">*</span> <span class=""n"">sz</span><span class=""p"">})</span>

<span class=""n"">sz</span> <span class=""o"">=</span> <span class=""mi"">1000000</span>
<span class=""n"">np</span><span class=""o"">.</span><span class=""n"">random</span><span class=""o"">.</span><span class=""n"">seed</span><span class=""p"">(</span><span class=""mi"">42</span><span class=""p"">)</span>
<span class=""n"">df</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">({</span><span class=""s2"">""A""</span><span class=""p"">:</span> <span class=""n"">np</span><span class=""o"">.</span><span class=""n"">random</span><span class=""o"">.</span><span class=""n"">randn</span><span class=""p"">(</span><span class=""n"">sz</span><span class=""p"">),</span> <span class=""s2"">""B""</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""mi"">1</span><span class=""p"">]</span> <span class=""o"">*</span> <span class=""n"">sz</span><span class=""p"">})</span>


<span class=""k"">def</span> <span class=""nf"">test_sql_write</span><span class=""p"">(</span><span class=""n"">df</span><span class=""p"">):</span>
    <span class=""k"">if</span> <span class=""n"">os</span><span class=""o"">.</span><span class=""n"">path</span><span class=""o"">.</span><span class=""n"">exists</span><span class=""p"">(</span><span class=""s2"">""test.sql""</span><span class=""p"">):</span>
        <span class=""n"">os</span><span class=""o"">.</span><span class=""n"">remove</span><span class=""p"">(</span><span class=""s2"">""test.sql""</span><span class=""p"">)</span>
    <span class=""n"">sql_db</span> <span class=""o"">=</span> <span class=""n"">sqlite3</span><span class=""o"">.</span><span class=""n"">connect</span><span class=""p"">(</span><span class=""s2"">""test.sql""</span><span class=""p"">)</span>
    <span class=""n"">df</span><span class=""o"">.</span><span class=""n"">to_sql</span><span class=""p"">(</span><span class=""n"">name</span><span class=""o"">=</span><span class=""s2"">""test_table""</span><span class=""p"">,</span> <span class=""n"">con</span><span class=""o"">=</span><span class=""n"">sql_db</span><span class=""p"">)</span>
    <span class=""n"">sql_db</span><span class=""o"">.</span><span class=""n"">close</span><span class=""p"">()</span>


<span class=""k"">def</span> <span class=""nf"">test_sql_read</span><span class=""p"">():</span>
    <span class=""n"">sql_db</span> <span class=""o"">=</span> <span class=""n"">sqlite3</span><span class=""o"">.</span><span class=""n"">connect</span><span class=""p"">(</span><span class=""s2"">""test.sql""</span><span class=""p"">)</span>
    <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_sql_query</span><span class=""p"">(</span><span class=""s2"">""select * from test_table""</span><span class=""p"">,</span> <span class=""n"">sql_db</span><span class=""p"">)</span>
    <span class=""n"">sql_db</span><span class=""o"">.</span><span class=""n"">close</span><span class=""p"">()</span>


<span class=""k"">def</span> <span class=""nf"">test_hdf_fixed_write</span><span class=""p"">(</span><span class=""n"">df</span><span class=""p"">):</span>
    <span class=""n"">df</span><span class=""o"">.</span><span class=""n"">to_hdf</span><span class=""p"">(</span><span class=""s2"">""test_fixed.hdf""</span><span class=""p"">,</span> <span class=""n"">key</span><span class=""o"">=</span><span class=""s2"">""test""</span><span class=""p"">,</span> <span class=""n"">mode</span><span class=""o"">=</span><span class=""s2"">""w""</span><span class=""p"">)</span>


<span class=""k"">def</span> <span class=""nf"">test_hdf_fixed_read</span><span class=""p"">():</span>
    <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_hdf</span><span class=""p"">(</span><span class=""s2"">""test_fixed.hdf""</span><span class=""p"">,</span> <span class=""s2"">""test""</span><span class=""p"">)</span>


<span class=""k"">def</span> <span class=""nf"">test_hdf_fixed_write_compress</span><span class=""p"">(</span><span class=""n"">df</span><span class=""p"">):</span>
    <span class=""n"">df</span><span class=""o"">.</span><span class=""n"">to_hdf</span><span class=""p"">(</span><span class=""s2"">""test_fixed_compress.hdf""</span><span class=""p"">,</span> <span class=""n"">key</span><span class=""o"">=</span><span class=""s2"">""test""</span><span class=""p"">,</span> <span class=""n"">mode</span><span class=""o"">=</span><span class=""s2"">""w""</span><span class=""p"">,</span> <span class=""n"">complib</span><span class=""o"">=</span><span class=""s2"">""blosc""</span><span class=""p"">)</span>


<span class=""k"">def</span> <span class=""nf"">test_hdf_fixed_read_compress</span><span class=""p"">():</span>
    <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_hdf</span><span class=""p"">(</span><span class=""s2"">""test_fixed_compress.hdf""</span><span class=""p"">,</span> <span class=""s2"">""test""</span><span class=""p"">)</span>


<span class=""k"">def</span> <span class=""nf"">test_hdf_table_write</span><span class=""p"">(</span><span class=""n"">df</span><span class=""p"">):</span>
    <span class=""n"">df</span><span class=""o"">.</span><span class=""n"">to_hdf</span><span class=""p"">(</span><span class=""s2"">""test_table.hdf""</span><span class=""p"">,</span> <span class=""n"">key</span><span class=""o"">=</span><span class=""s2"">""test""</span><span class=""p"">,</span> <span class=""n"">mode</span><span class=""o"">=</span><span class=""s2"">""w""</span><span class=""p"">,</span> <span class=""nb"">format</span><span class=""o"">=</span><span class=""s2"">""table""</span><span class=""p"">)</span>


<span class=""k"">def</span> <span class=""nf"">test_hdf_table_read</span><span class=""p"">():</span>
    <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_hdf</span><span class=""p"">(</span><span class=""s2"">""test_table.hdf""</span><span class=""p"">,</span> <span class=""s2"">""test""</span><span class=""p"">)</span>


<span class=""k"">def</span> <span class=""nf"">test_hdf_table_write_compress</span><span class=""p"">(</span><span class=""n"">df</span><span class=""p"">):</span>
    <span class=""n"">df</span><span class=""o"">.</span><span class=""n"">to_hdf</span><span class=""p"">(</span>
        <span class=""s2"">""test_table_compress.hdf""</span><span class=""p"">,</span> <span class=""n"">key</span><span class=""o"">=</span><span class=""s2"">""test""</span><span class=""p"">,</span> <span class=""n"">mode</span><span class=""o"">=</span><span class=""s2"">""w""</span><span class=""p"">,</span> <span class=""n"">complib</span><span class=""o"">=</span><span class=""s2"">""blosc""</span><span class=""p"">,</span> <span class=""nb"">format</span><span class=""o"">=</span><span class=""s2"">""table""</span>
    <span class=""p"">)</span>


<span class=""k"">def</span> <span class=""nf"">test_hdf_table_read_compress</span><span class=""p"">():</span>
    <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_hdf</span><span class=""p"">(</span><span class=""s2"">""test_table_compress.hdf""</span><span class=""p"">,</span> <span class=""s2"">""test""</span><span class=""p"">)</span>


<span class=""k"">def</span> <span class=""nf"">test_csv_write</span><span class=""p"">(</span><span class=""n"">df</span><span class=""p"">):</span>
    <span class=""n"">df</span><span class=""o"">.</span><span class=""n"">to_csv</span><span class=""p"">(</span><span class=""s2"">""test.csv""</span><span class=""p"">,</span> <span class=""n"">mode</span><span class=""o"">=</span><span class=""s2"">""w""</span><span class=""p"">)</span>


<span class=""k"">def</span> <span class=""nf"">test_csv_read</span><span class=""p"">():</span>
    <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_csv</span><span class=""p"">(</span><span class=""s2"">""test.csv""</span><span class=""p"">,</span> <span class=""n"">index_col</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">)</span>


<span class=""k"">def</span> <span class=""nf"">test_feather_write</span><span class=""p"">(</span><span class=""n"">df</span><span class=""p"">):</span>
    <span class=""n"">df</span><span class=""o"">.</span><span class=""n"">to_feather</span><span class=""p"">(</span><span class=""s2"">""test.feather""</span><span class=""p"">)</span>


<span class=""k"">def</span> <span class=""nf"">test_feather_read</span><span class=""p"">():</span>
    <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_feather</span><span class=""p"">(</span><span class=""s2"">""test.feather""</span><span class=""p"">)</span>


<span class=""k"">def</span> <span class=""nf"">test_pickle_write</span><span class=""p"">(</span><span class=""n"">df</span><span class=""p"">):</span>
    <span class=""n"">df</span><span class=""o"">.</span><span class=""n"">to_pickle</span><span class=""p"">(</span><span class=""s2"">""test.pkl""</span><span class=""p"">)</span>


<span class=""k"">def</span> <span class=""nf"">test_pickle_read</span><span class=""p"">():</span>
    <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_pickle</span><span class=""p"">(</span><span class=""s2"">""test.pkl""</span><span class=""p"">)</span>


<span class=""k"">def</span> <span class=""nf"">test_pickle_write_compress</span><span class=""p"">(</span><span class=""n"">df</span><span class=""p"">):</span>
    <span class=""n"">df</span><span class=""o"">.</span><span class=""n"">to_pickle</span><span class=""p"">(</span><span class=""s2"">""test.pkl.compress""</span><span class=""p"">,</span> <span class=""n"">compression</span><span class=""o"">=</span><span class=""s2"">""xz""</span><span class=""p"">)</span>


<span class=""k"">def</span> <span class=""nf"">test_pickle_read_compress</span><span class=""p"">():</span>
    <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_pickle</span><span class=""p"">(</span><span class=""s2"">""test.pkl.compress""</span><span class=""p"">,</span> <span class=""n"">compression</span><span class=""o"">=</span><span class=""s2"">""xz""</span><span class=""p"">)</span>


<span class=""k"">def</span> <span class=""nf"">test_parquet_write</span><span class=""p"">(</span><span class=""n"">df</span><span class=""p"">):</span>
    <span class=""n"">df</span><span class=""o"">.</span><span class=""n"">to_parquet</span><span class=""p"">(</span><span class=""s2"">""test.parquet""</span><span class=""p"">)</span>


<span class=""k"">def</span> <span class=""nf"">test_parquet_read</span><span class=""p"">():</span>
    <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_parquet</span><span class=""p"">(</span><span class=""s2"">""test.parquet""</span><span class=""p"">)</span>
</pre></div>
</div>
<p>When writing, the top three functions in terms of speed are <code class=""docutils literal notranslate""><span class=""pre"">test_feather_write</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">test_hdf_fixed_write</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">test_hdf_fixed_write_compress</span></code>.</p>

<p>When reading, the top three functions in terms of speed are <code class=""docutils literal notranslate""><span class=""pre"">test_feather_read</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">test_pickle_read</span></code> and
<code class=""docutils literal notranslate""><span class=""pre"">test_hdf_fixed_read</span></code>.</p>

<p>The files <code class=""docutils literal notranslate""><span class=""pre"">test.pkl.compress</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">test.parquet</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">test.feather</span></code> took the least space on disk (in bytes).</p>
<div class=""highlight-none notranslate""><div class=""highlight""><pre><span></span>29519500 Oct 10 06:45 test.csv
16000248 Oct 10 06:45 test.feather
8281983  Oct 10 06:49 test.parquet
16000857 Oct 10 06:47 test.pkl
7552144  Oct 10 06:48 test.pkl.compress
34816000 Oct 10 06:42 test.sql
24009288 Oct 10 06:43 test_fixed.hdf
24009288 Oct 10 06:43 test_fixed_compress.hdf
24458940 Oct 10 06:44 test_table.hdf
24458940 Oct 10 06:44 test_table_compress.hdf
</pre></div>
</div>
</section>
</section>
</article>","IO tools (text, CSV, HDF5, …) # The pandas I/O API is a set of top level reader functions accessed like pandas.read_csv() that generally return a pandas object. The corresponding writer functions are object methods that are accessed like DataFrame.to_csv() . Below is a table containing available readers and writers . Here is an informal performance comparison for some of these IO methods. Note For examples that use the StringIO class, make sure you import it with from io import StringIO for Python 3. CSV & text files # The workhorse function for reading text files (a.k.a. flat files) is read_csv() . See the cookbook for some advanced strategies. Parsing options # read_csv() accepts the following common arguments: Basic # filepath_or_buffer various Either a path to a file (a str , pathlib.Path , or py:py._path.local.LocalPath ), URL (including http, ftp, and S3 locations), or any object with a read() method (such as an open file or StringIO ). sep str, defaults to ',' for read_csv() , \t for read_table() Delimiter to use. If sep is None , the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python’s builtin sniffer tool, csv.Sniffer . In addition, separators longer than 1 character and different from '\s+' will be interpreted as regular expressions and will also force the use of the Python parsing engine. Note that regex delimiters are prone to ignoring quoted data. Regex example: '\\r\\t' . delimiter str, default None Alternative argument name for sep. delim_whitespace boolean, default False Specifies whether or not whitespace (e.g. ' ' or '\t' ) will be used as the delimiter. Equivalent to setting sep='\s+' . If this option is set to True , nothing should be passed in for the delimiter parameter. Column and index locations and names # header int or list of ints, default 'infer' Row number(s) to use as the column names, and the start of the data. Default behavior is to infer the column names: if no names are passed the behavior is identical to header=0 and column names are inferred from the first line of the file, if column names are passed explicitly then the behavior is identical to header=None . Explicitly pass header=0 to be able to replace existing names. The header can be a list of ints that specify row locations for a MultiIndex on the columns e.g. [0,1,3] . Intervening rows that are not specified will be skipped (e.g. 2 in this example is skipped). Note that this parameter ignores commented lines and empty lines if skip_blank_lines=True , so header=0 denotes the first line of data rather than the first line of the file. names array-like, default None List of column names to use. If file contains no header row, then you should explicitly pass header=None . Duplicates in this list are not allowed. index_col int, str, sequence of int / str, or False, optional, default None Column(s) to use as the row labels of the DataFrame , either given as string name or column index. If a sequence of int / str is given, a MultiIndex is used. Note index_col=False can be used to force pandas to not use the first column as the index, e.g. when you have a malformed file with delimiters at the end of each line. The default value of None instructs pandas to guess. If the number of fields in the column header row is equal to the number of fields in the body of the data file, then a default index is used. If it is larger, then the first columns are used as index so that the remaining number of fields in the body are equal to the number of fields in the header. The first row after the header is used to determine the number of columns, which will go into the index. If the subsequent rows contain less columns than the first row, they are filled with NaN . This can be avoided through usecols . This ensures that the columns are taken as is and the trailing data are ignored. usecols list-like or callable, default None Return a subset of the columns. If list-like, all elements must either be positional (i.e. integer indices into the document columns) or strings that correspond to column names provided either by the user in names or inferred from the document header row(s). If names are given, the document header row(s) are not taken into account. For example, a valid list-like usecols parameter would be [0, 1, 2] or ['foo', 'bar', 'baz'] . Element order is ignored, so usecols=[0, 1] is the same as [1, 0] . To instantiate a DataFrame from data with element order preserved use pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']] for columns in ['foo', 'bar'] order or pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']] for ['bar', 'foo'] order. If callable, the callable function will be evaluated against the column names, returning names where the callable function evaluates to True: Using this parameter results in much faster parsing time and lower memory usage when using the c engine. The Python engine loads the data first before deciding which columns to drop. General parsing configuration # dtype Type name or dict of column -> type, default None Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32, 'c': 'Int64'} Use str or object together with suitable na_values settings to preserve and not interpret dtype. If converters are specified, they will be applied INSTEAD of dtype conversion. New in version 1.5.0: Support for defaultdict was added. Specify a defaultdict as input where the default determines the dtype of the columns which are not explicitly listed. dtype_backend {“numpy_nullable”, “pyarrow”}, defaults to NumPy backed DataFrames Which dtype_backend to use, e.g. whether a DataFrame should have NumPy arrays, nullable dtypes are used for all dtypes that have a nullable implementation when “numpy_nullable” is set, pyarrow is used for all dtypes if “pyarrow” is set. The dtype_backends are still experimential. New in version 2.0. engine { 'c' , 'python' , 'pyarrow' } Parser engine to use. The C and pyarrow engines are faster, while the python engine is currently more feature-complete. Multithreading is currently only supported by the pyarrow engine. New in version 1.4.0: The “pyarrow” engine was added as an experimental engine, and some features are unsupported, or may not work correctly, with this engine. converters dict, default None Dict of functions for converting values in certain columns. Keys can either be integers or column labels. true_values list, default None Values to consider as True . false_values list, default None Values to consider as False . skipinitialspace boolean, default False Skip spaces after delimiter. skiprows list-like or integer, default None Line numbers to skip (0-indexed) or number of lines to skip (int) at the start of the file. If callable, the callable function will be evaluated against the row indices, returning True if the row should be skipped and False otherwise: skipfooter int, default 0 Number of lines at bottom of file to skip (unsupported with engine=’c’). nrows int, default None Number of rows of file to read. Useful for reading pieces of large files. low_memory boolean, default True Internally process the file in chunks, resulting in lower memory use while parsing, but possibly mixed type inference. To ensure no mixed types either set False , or specify the type with the dtype parameter. Note that the entire file is read into a single DataFrame regardless, use the chunksize or iterator parameter to return the data in chunks. (Only valid with C parser) memory_map boolean, default False If a filepath is provided for filepath_or_buffer , map the file object directly onto memory and access the data directly from there. Using this option can improve performance because there is no longer any I/O overhead. NA and missing data handling # na_values scalar, str, list-like, or dict, default None Additional strings to recognize as NA/NaN. If dict passed, specific per-column NA values. See na values const below for a list of the values interpreted as NaN by default. keep_default_na boolean, default True Whether or not to include the default NaN values when parsing the data. Depending on whether na_values is passed in, the behavior is as follows: If keep_default_na is True , and na_values are specified, na_values is appended to the default NaN values used for parsing. If keep_default_na is True , and na_values are not specified, only the default NaN values are used for parsing. If keep_default_na is False , and na_values are specified, only the NaN values specified na_values are used for parsing. If keep_default_na is False , and na_values are not specified, no strings will be parsed as NaN. Note that if na_filter is passed in as False , the keep_default_na and na_values parameters will be ignored. na_filter boolean, default True Detect missing value markers (empty strings and the value of na_values). In data without any NAs, passing na_filter=False can improve the performance of reading a large file. verbose boolean, default False Indicate number of NA values placed in non-numeric columns. skip_blank_lines boolean, default True If True , skip over blank lines rather than interpreting as NaN values. Datetime handling # parse_dates boolean or list of ints or names or list of lists or dict, default False . If True -> try parsing the index. If [1, 2, 3] -> try parsing columns 1, 2, 3 each as a separate date column. If [[1, 3]] -> combine columns 1 and 3 and parse as a single date column. If {'foo': [1, 3]} -> parse columns 1, 3 as date and call result ‘foo’. Note A fast-path exists for iso8601-formatted dates. infer_datetime_format boolean, default False If True and parse_dates is enabled for a column, attempt to infer the datetime format to speed up the processing. Deprecated since version 2.0.0: A strict version of this argument is now the default, passing it has no effect. keep_date_col boolean, default False If True and parse_dates specifies combining multiple columns then keep the original columns. date_parser function, default None Function to use for converting a sequence of string columns to an array of datetime instances. The default uses dateutil.parser.parser to do the conversion. pandas will try to call date_parser in three different ways, advancing to the next if an exception occurs: 1) Pass one or more arrays (as defined by parse_dates) as arguments; 2) concatenate (row-wise) the string values from the columns defined by parse_dates into a single array and pass that; and 3) call date_parser once for each row using one or more strings (corresponding to the columns defined by parse_dates) as arguments. Deprecated since version 2.0.0: Use date_format instead, or read in as object and then apply to_datetime() as-needed. date_format str or dict of column -> format, default None If used in conjunction with parse_dates , will parse dates according to this format. For anything more complex, please read in as object and then apply to_datetime() as-needed. New in version 2.0.0. dayfirst boolean, default False DD/MM format dates, international and European format. cache_dates boolean, default True If True, use a cache of unique, converted dates to apply the datetime conversion. May produce significant speed-up when parsing duplicate date strings, especially ones with timezone offsets. Iteration # iterator boolean, default False Return TextFileReader object for iteration or getting chunks with get_chunk() . chunksize int, default None Return TextFileReader object for iteration. See iterating and chunking below. Quoting, compression, and file format # compression { 'infer' , 'gzip' , 'bz2' , 'zip' , 'xz' , 'zstd' , None , dict }, default 'infer' For on-the-fly decompression of on-disk data. If ‘infer’, then use gzip, bz2, zip, xz, or zstandard if filepath_or_buffer is path-like ending in ‘.gz’, ‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, respectively, and no decompression otherwise. If using ‘zip’, the ZIP file must contain only one data file to be read in. Set to None for no decompression. Can also be a dict with key 'method' set to one of { 'zip' , 'gzip' , 'bz2' , 'zstd' } and other key-value pairs are forwarded to zipfile.ZipFile , gzip.GzipFile , bz2.BZ2File , or zstandard.ZstdDecompressor . As an example, the following could be passed for faster compression and to create a reproducible gzip archive: compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1} . Changed in version 1.2.0: Previous versions forwarded dict entries for ‘gzip’ to gzip.open . thousands str, default None Thousands separator. decimal str, default '.' Character to recognize as decimal point. E.g. use ',' for European data. float_precision string, default None Specifies which converter the C engine should use for floating-point values. The options are None for the ordinary converter, high for the high-precision converter, and round_trip for the round-trip converter. lineterminator str (length 1), default None Character to break file into lines. Only valid with C parser. quotechar str (length 1) The character used to denote the start and end of a quoted item. Quoted items can include the delimiter and it will be ignored. quoting int or csv.QUOTE_* instance, default 0 Control field quoting behavior per csv.QUOTE_* constants. Use one of QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3). doublequote boolean, default True When quotechar is specified and quoting is not QUOTE_NONE , indicate whether or not to interpret two consecutive quotechar elements inside a field as a single quotechar element. escapechar str (length 1), default None One-character string used to escape delimiter when quoting is QUOTE_NONE . comment str, default None Indicates remainder of line should not be parsed. If found at the beginning of a line, the line will be ignored altogether. This parameter must be a single character. Like empty lines (as long as skip_blank_lines=True ), fully commented lines are ignored by the parameter header but not by skiprows . For example, if comment='#' , parsing ‘#empty\na,b,c\n1,2,3’ with header=0 will result in ‘a,b,c’ being treated as the header. encoding str, default None Encoding to use for UTF when reading/writing (e.g. 'utf-8' ). List of Python standard encodings . dialect str or csv.Dialect instance, default None If provided, this parameter will override values (default or not) for the following parameters: delimiter , doublequote , escapechar , skipinitialspace , quotechar , and quoting . If it is necessary to override values, a ParserWarning will be issued. See csv.Dialect documentation for more details. Error handling # on_bad_lines (‘error’, ‘warn’, ‘skip’), default ‘error’ Specifies what to do upon encountering a bad line (a line with too many fields). Allowed values are : ‘error’, raise an ParserError when a bad line is encountered. ‘warn’, print a warning when a bad line is encountered and skip that line. ‘skip’, skip bad lines without raising or warning when they are encountered. New in version 1.3.0. Specifying column data types # You can indicate the data type for the whole DataFrame or individual columns: Fortunately, pandas offers more than one way to ensure that your column(s) contain only one dtype . If you’re unfamiliar with these concepts, you can see here to learn more about dtypes, and here to learn more about object conversion in pandas. For instance, you can use the converters argument of read_csv() : Or you can use the to_numeric() function to coerce the dtypes after reading in the data, which will convert all valid parsing to floats, leaving the invalid parsing as NaN . Ultimately, how you deal with reading in columns containing mixed dtypes depends on your specific needs. In the case above, if you wanted to NaN out the data anomalies, then to_numeric() is probably your best option. However, if you wanted for all the data to be coerced, no matter the type, then using the converters argument of read_csv() would certainly be worth trying. Note In some cases, reading in abnormal data with columns containing mixed dtypes will result in an inconsistent dataset. If you rely on pandas to infer the dtypes of your columns, the parsing engine will go and infer the dtypes for different chunks of the data, rather than the whole dataset at once. Consequently, you can end up with column(s) with mixed dtypes. For example, will result with mixed_df containing an int dtype for certain chunks of the column, and str for others due to the mixed dtypes from the data that was read in. It is important to note that the overall column will be marked with a dtype of object , which is used for columns with mixed dtypes. Setting dtype_backend=""numpy_nullable"" will result in nullable dtypes for every column. Specifying categorical dtype # Categorical columns can be parsed directly by specifying dtype='category' or dtype=CategoricalDtype(categories, ordered) . Individual columns can be parsed as a Categorical using a dict specification: Specifying dtype='category' will result in an unordered Categorical whose categories are the unique values observed in the data. For more control on the categories and order, create a CategoricalDtype ahead of time, and pass that for that column’s dtype . When using dtype=CategoricalDtype , “unexpected” values outside of dtype.categories are treated as missing values. This matches the behavior of Categorical.set_categories() . Note With dtype='category' , the resulting categories will always be parsed as strings (object dtype). If the categories are numeric they can be converted using the to_numeric() function, or as appropriate, another converter such as to_datetime() . When dtype is a CategoricalDtype with homogeneous categories ( all numeric, all datetimes, etc.), the conversion is done automatically. Naming and using columns # Handling column names # A file may or may not have a header row. pandas assumes the first row should be used as the column names: By specifying the names argument in conjunction with header you can indicate other names to use and whether or not to throw away the header row (if any): If the header is in a row other than the first, pass the row number to header . This will skip the preceding rows: Note Default behavior is to infer the column names: if no names are passed the behavior is identical to header=0 and column names are inferred from the first non-blank line of the file, if column names are passed explicitly then the behavior is identical to header=None . Duplicate names parsing # If the file or header contains duplicate names, pandas will by default distinguish between them so as to prevent overwriting data: There is no more duplicate data because duplicate columns ‘X’, …, ‘X’ become ‘X’, ‘X.1’, …, ‘X.N’. Filtering columns ( usecols ) # The usecols argument allows you to select any subset of the columns in a file, either using the column names, position numbers or a callable: The usecols argument can also be used to specify which columns not to use in the final result: In this case, the callable is specifying that we exclude the “a” and “c” columns from the output. Comments and empty lines # Ignoring line comments and empty lines # If the comment parameter is specified, then completely commented lines will be ignored. By default, completely blank lines will be ignored as well. If skip_blank_lines=False , then read_csv will not ignore blank lines: Warning The presence of ignored lines might create ambiguities involving line numbers; the parameter header uses row numbers (ignoring commented/empty lines), while skiprows uses line numbers (including commented/empty lines): If both header and skiprows are specified, header will be relative to the end of skiprows . For example: Comments # Sometimes comments or meta data may be included in a file: By default, the parser includes the comments in the output: We can suppress the comments using the comment keyword: Dealing with Unicode data # The encoding argument should be used for encoded unicode data, which will result in byte strings being decoded to unicode in the result: Some formats which encode all characters as multiple bytes, like UTF-16, won’t parse correctly at all without specifying the encoding. Full list of Python standard encodings . Index columns and trailing delimiters # If a file has one more column of data than the number of column names, the first column will be used as the DataFrame ’s row names: Ordinarily, you can achieve this behavior using the index_col option. There are some exception cases when a file has been prepared with delimiters at the end of each data line, confusing the parser. To explicitly disable the index column inference and discard the last column, pass index_col=False : If a subset of data is being parsed using the usecols option, the index_col specification is based on that subset, not the original data. Date Handling # Specifying date columns # To better facilitate working with datetime data, read_csv() uses the keyword arguments parse_dates and date_format to allow users to specify a variety of columns and date/time formats to turn the input text data into datetime objects. The simplest case is to just pass in parse_dates=True : It is often the case that we may want to store date and time data separately, or store various date fields separately. the parse_dates keyword can be used to specify a combination of columns to parse the dates and/or times from. You can specify a list of column lists to parse_dates , the resulting date columns will be prepended to the output (so as to not affect the existing column order) and the new column names will be the concatenation of the component column names: By default the parser removes the component date columns, but you can choose to retain them via the keep_date_col keyword: Note that if you wish to combine multiple columns into a single date column, a nested list must be used. In other words, parse_dates=[1, 2] indicates that the second and third columns should each be parsed as separate date columns while parse_dates=[[1, 2]] means the two columns should be parsed into a single column. You can also use a dict to specify custom name columns: It is important to remember that if multiple text columns are to be parsed into a single date column, then a new column is prepended to the data. The index_col specification is based off of this new set of columns rather than the original data columns: Note If a column or index contains an unparsable date, the entire column or index will be returned unaltered as an object data type. For non-standard datetime parsing, use to_datetime() after pd.read_csv . Note read_csv has a fast_path for parsing datetime strings in iso8601 format, e.g “2000-01-01T00:01:02+00:00” and similar variations. If you can arrange for your data to store datetimes in this format, load times will be significantly faster, ~20x has been observed. Deprecated since version 2.2.0: Combining date columns inside read_csv is deprecated. Use pd.to_datetime on the relevant result columns instead. Date parsing functions # Finally, the parser allows you to specify a custom date_format . Performance-wise, you should try these methods of parsing dates in order: If you know the format, use date_format , e.g.: date_format=""%d/%m/%Y"" or date_format={column_name: ""%d/%m/%Y""} . If you different formats for different columns, or want to pass any extra options (such as utc ) to to_datetime , then you should read in your data as object dtype, and then use to_datetime . Parsing a CSV with mixed timezones # pandas cannot natively represent a column or index with mixed timezones. If your CSV file contains columns with a mixture of timezones, the default result will be an object-dtype column with strings, even with parse_dates . To parse the mixed-timezone values as a datetime column, read in as object dtype and then call to_datetime() with utc=True . Inferring datetime format # Here are some examples of datetime strings that can be guessed (all representing December 30th, 2011 at 00:00:00): “20111230” “2011/12/30” “20111230 00:00:00” “12/30/2011 00:00:00” “30/Dec/2011 00:00:00” “30/December/2011 00:00:00” Note that format inference is sensitive to dayfirst . With dayfirst=True , it will guess “01/12/2011” to be December 1st. With dayfirst=False (default) it will guess “01/12/2011” to be January 12th. If you try to parse a column of date strings, pandas will attempt to guess the format from the first non-NaN element, and will then parse the rest of the column with that format. If pandas fails to guess the format (for example if your first string is '01 December US/Pacific 2000' ), then a warning will be raised and each row will be parsed individually by dateutil.parser.parse . The safest way to parse dates is to explicitly set format= . In the case that you have mixed datetime formats within the same column, you can pass format='mixed' or, if your datetime formats are all ISO8601 (possibly not identically-formatted): International date formats # While US date formats tend to be MM/DD/YYYY, many international formats use DD/MM/YYYY instead. For convenience, a dayfirst keyword is provided: Writing CSVs to binary file objects # New in version 1.2.0. df.to_csv(..., mode=""wb"") allows writing a CSV to a file object opened binary mode. In most cases, it is not necessary to specify mode as Pandas will auto-detect whether the file object is opened in text or binary mode. Specifying method for floating-point conversion # The parameter float_precision can be specified in order to use a specific floating-point converter during parsing with the C engine. The options are the ordinary converter, the high-precision converter, and the round-trip converter (which is guaranteed to round-trip values after writing to a file). For example: Thousand separators # For large numbers that have been written with a thousands separator, you can set the thousands keyword to a string of length 1 so that integers will be parsed correctly: By default, numbers with a thousands separator will be parsed as strings: The thousands keyword allows integers to be parsed correctly: NA values # To control which values are parsed as missing values (which are signified by NaN ), specify a string in na_values . If you specify a list of strings, then all values in it are considered to be missing values. If you specify a number (a float , like 5.0 or an integer like 5 ), the corresponding equivalent values will also imply a missing value (in this case effectively [5.0, 5] are recognized as NaN ). To completely override the default values that are recognized as missing, specify keep_default_na=False . The default NaN recognized values are ['-1.#IND', '1.#QNAN', '1.#IND', '-1.#QNAN', '#N/A N/A', '#N/A', 'N/A', 'n/a', 'NA', '<NA>', '#NA', 'NULL', 'null', 'NaN', '-NaN', 'nan', '-nan', 'None', ''] . Let us consider some examples: pd . read_csv ( ""path_to_file.csv"" , na_values = [ 5 ]) In the example above 5 and 5.0 will be recognized as NaN , in addition to the defaults. A string will first be interpreted as a numerical 5 , then as a NaN . pd . read_csv ( ""path_to_file.csv"" , keep_default_na = False , na_values = [ """" ]) Above, only an empty field will be recognized as NaN . pd . read_csv ( ""path_to_file.csv"" , keep_default_na = False , na_values = [ ""NA"" , ""0"" ]) Above, both NA and 0 as strings are NaN . pd . read_csv ( ""path_to_file.csv"" , na_values = [ ""Nope"" ]) The default values, in addition to the string ""Nope"" are recognized as NaN . Infinity # inf like values will be parsed as np.inf (positive infinity), and -inf as -np.inf (negative infinity). These will ignore the case of the value, meaning Inf , will also be parsed as np.inf . Boolean values # The common values True , False , TRUE , and FALSE are all recognized as boolean. Occasionally you might want to recognize other values as being boolean. To do this, use the true_values and false_values options as follows: Handling “bad” lines # Some files may have malformed lines with too few fields or too many. Lines with too few fields will have NA values filled in the trailing fields. Lines with too many fields will raise an error by default: You can elect to skip bad lines: New in version 1.4.0. Or pass a callable function to handle the bad line if engine=""python"" . The bad line will be a list of strings that was split by the sep : Note The callable function will handle only a line with too many fields. Bad lines caused by other errors will be silently skipped. The line was not processed in this case, as a “bad line” here is caused by an escape character. You can also use the usecols parameter to eliminate extraneous column data that appear in some lines but not others: In case you want to keep all data including the lines with too many fields, you can specify a sufficient number of names . This ensures that lines with not enough fields are filled with NaN . Dialect # The dialect keyword gives greater flexibility in specifying the file format. By default it uses the Excel dialect but you can specify either the dialect name or a csv.Dialect instance. Suppose you had data with unenclosed quotes: By default, read_csv uses the Excel dialect and treats the double quote as the quote character, which causes it to fail when it finds a newline before it finds the closing double quote. We can get around this using dialect : All of the dialect options can be specified separately by keyword arguments: Another common dialect option is skipinitialspace , to skip any whitespace after a delimiter: The parsers make every attempt to “do the right thing” and not be fragile. Type inference is a pretty big deal. If a column can be coerced to integer dtype without altering the contents, the parser will do so. Any non-numeric columns will come through as object dtype as with the rest of pandas objects. Quoting and Escape Characters # Quotes (and other escape characters) in embedded fields can be handled in any number of ways. One way is to use backslashes; to properly parse this data, you should pass the escapechar option: Files with fixed width columns # While read_csv() reads delimited data, the read_fwf() function works with data files that have known and fixed column widths. The function parameters to read_fwf are largely the same as read_csv with two extra parameters, and a different usage of the delimiter parameter: colspecs : A list of pairs (tuples) giving the extents of the fixed-width fields of each line as half-open intervals (i.e., [from, to[ ). String value ‘infer’ can be used to instruct the parser to try detecting the column specifications from the first 100 rows of the data. Default behavior, if not specified, is to infer. widths : A list of field widths which can be used instead of ‘colspecs’ if the intervals are contiguous. delimiter : Characters to consider as filler characters in the fixed-width file. Can be used to specify the filler character of the fields if it is not spaces (e.g., ‘~’). Consider a typical fixed-width data file: In order to parse this file into a DataFrame , we simply need to supply the column specifications to the read_fwf function along with the file name: Note how the parser automatically picks column names X.<column number> when header=None argument is specified. Alternatively, you can supply just the column widths for contiguous columns: The parser will take care of extra white spaces around the columns so it’s ok to have extra separation between the columns in the file. By default, read_fwf will try to infer the file’s colspecs by using the first 100 rows of the file. It can do it only in cases when the columns are aligned and correctly separated by the provided delimiter (default delimiter is whitespace). read_fwf supports the dtype parameter for specifying the types of parsed columns to be different from the inferred type. Indexes # Files with an “implicit” index column # Consider a file with one less entry in the header than the number of data column: In this special case, read_csv assumes that the first column is to be used as the index of the DataFrame : Note that the dates weren’t automatically parsed. In that case you would need to do as before: Reading an index with a MultiIndex # Suppose you have data indexed by two columns: The index_col argument to read_csv can take a list of column numbers to turn multiple columns into a MultiIndex for the index of the returned object: Reading columns with a MultiIndex # By specifying list of row locations for the header argument, you can read in a MultiIndex for the columns. Specifying non-consecutive rows will skip the intervening rows. read_csv is also able to interpret a more common format of multi-columns indices. Note If an index_col is not specified (e.g. you don’t have an index, or wrote it with df.to_csv(..., index=False) , then any names on the columns index will be lost . Automatically “sniffing” the delimiter # read_csv is capable of inferring delimited (not necessarily comma-separated) files, as pandas uses the csv.Sniffer class of the csv module. For this, you have to specify sep=None . Reading multiple files to create a single DataFrame # It’s best to use concat() to combine multiple files. See the cookbook for an example. Iterating through files chunk by chunk # Suppose you wish to iterate through a (potentially very large) file lazily rather than reading the entire file into memory, such as the following: By specifying a chunksize to read_csv , the return value will be an iterable object of type TextFileReader : Changed in version 1.2: read_csv/json/sas return a context-manager when iterating through a file. Specifying iterator=True will also return the TextFileReader object: Specifying the parser engine # Pandas currently supports three engines, the C engine, the python engine, and an experimental pyarrow engine (requires the pyarrow package). In general, the pyarrow engine is fastest on larger workloads and is equivalent in speed to the C engine on most other workloads. The python engine tends to be slower than the pyarrow and C engines on most workloads. However, the pyarrow engine is much less robust than the C engine, which lacks a few features compared to the Python engine. Where possible, pandas uses the C parser (specified as engine='c' ), but it may fall back to Python if C-unsupported options are specified. Currently, options unsupported by the C and pyarrow engines include: sep other than a single character (e.g. regex separators) skipfooter sep=None with delim_whitespace=False Specifying any of the above options will produce a ParserWarning unless the python engine is selected explicitly using engine='python' . Options that are unsupported by the pyarrow engine which are not covered by the list above include: float_precision chunksize comment nrows thousands memory_map dialect on_bad_lines delim_whitespace quoting lineterminator converters decimal iterator dayfirst infer_datetime_format verbose skipinitialspace low_memory Specifying these options with engine='pyarrow' will raise a ValueError . Reading/writing remote files # You can pass in a URL to read or write remote files to many of pandas’ IO functions - the following example shows reading a CSV file: df = pd . read_csv ( ""https://download.bls.gov/pub/time.series/cu/cu.item"" , sep = "" \t "" ) New in version 1.3.0. A custom header can be sent alongside HTTP(s) requests by passing a dictionary of header key value mappings to the storage_options keyword argument as shown below: headers = { ""User-Agent"" : ""pandas"" } df = pd . read_csv ( ""https://download.bls.gov/pub/time.series/cu/cu.item"" , sep = "" \t "" , storage_options = headers ) All URLs which are not local files or HTTP(s) are handled by fsspec , if installed, and its various filesystem implementations (including Amazon S3, Google Cloud, SSH, FTP, webHDFS…). Some of these implementations will require additional packages to be installed, for example S3 URLs require the s3fs library: df = pd . read_json ( ""s3://pandas-test/adatafile.json"" ) When dealing with remote storage systems, you might need extra configuration with environment variables or config files in special locations. For example, to access data in your S3 bucket, you will need to define credentials in one of the several ways listed in the S3Fs documentation . The same is true for several of the storage backends, and you should follow the links at fsimpl1 for implementations built into fsspec and fsimpl2 for those not included in the main fsspec distribution. You can also pass parameters directly to the backend driver. Since fsspec does not utilize the AWS_S3_HOST environment variable, we can directly define a dictionary containing the endpoint_url and pass the object into the storage option parameter: storage_options = { ""client_kwargs"" : { ""endpoint_url"" : ""http://127.0.0.1:5555"" }}} df = pd . read_json ( ""s3://pandas-test/test-1"" , storage_options = storage_options ) More sample configurations and documentation can be found at S3Fs documentation . If you do not have S3 credentials, you can still access public data by specifying an anonymous connection, such as New in version 1.2.0. pd . read_csv ( ""s3://ncei-wcsd-archive/data/processed/SH1305/18kHz/SaKe2013"" ""-D20130523-T080854_to_SaKe2013-D20130523-T085643.csv"" , storage_options = { ""anon"" : True }, ) fsspec also allows complex URLs, for accessing data in compressed archives, local caching of files, and more. To locally cache the above example, you would modify the call to pd . read_csv ( ""simplecache::s3://ncei-wcsd-archive/data/processed/SH1305/18kHz/"" ""SaKe2013-D20130523-T080854_to_SaKe2013-D20130523-T085643.csv"" , storage_options = { ""s3"" : { ""anon"" : True }}, ) where we specify that the “anon” parameter is meant for the “s3” part of the implementation, not to the caching implementation. Note that this caches to a temporary directory for the duration of the session only, but you can also specify a permanent store. Writing out data # Writing to CSV format # The Series and DataFrame objects have an instance method to_csv which allows storing the contents of the object as a comma-separated-values file. The function takes a number of arguments. Only the first is required. path_or_buf : A string path to the file to write or a file object. If a file object it must be opened with newline='' sep : Field delimiter for the output file (default “,”) na_rep : A string representation of a missing value (default ‘’) float_format : Format string for floating point numbers columns : Columns to write (default None) header : Whether to write out the column names (default True) index : whether to write row (index) names (default True) index_label : Column label(s) for index column(s) if desired. If None (default), and header and index are True, then the index names are used. (A sequence should be given if the DataFrame uses MultiIndex). mode : Python write mode, default ‘w’ encoding : a string representing the encoding to use if the contents are non-ASCII, for Python versions prior to 3 lineterminator : Character sequence denoting line end (default os.linesep ) quoting : Set quoting rules as in csv module (default csv.QUOTE_MINIMAL). Note that if you have set a float_format then floats are converted to strings and csv.QUOTE_NONNUMERIC will treat them as non-numeric quotechar : Character used to quote fields (default ‘”’) doublequote : Control quoting of quotechar in fields (default True) escapechar : Character used to escape sep and quotechar when appropriate (default None) chunksize : Number of rows to write at a time date_format : Format string for datetime objects Writing a formatted string # The DataFrame object has an instance method to_string which allows control over the string representation of the object. All arguments are optional: buf default None, for example a StringIO object columns default None, which columns to write col_space default None, minimum width of each column. na_rep default NaN , representation of NA value formatters default None, a dictionary (by column) of functions each of which takes a single argument and returns a formatted string float_format default None, a function which takes a single (float) argument and returns a formatted string; to be applied to floats in the DataFrame . sparsify default True, set to False for a DataFrame with a hierarchical index to print every MultiIndex key at each row. index_names default True, will print the names of the indices index default True, will print the index (ie, row labels) header default True, will print the column labels justify default left , will print column headers left- or right-justified The Series object also has a to_string method, but with only the buf , na_rep , float_format arguments. There is also a length argument which, if set to True , will additionally output the length of the Series. JSON # Read and write JSON format files and strings. Writing JSON # A Series or DataFrame can be converted to a valid JSON string. Use to_json with optional parameters: path_or_buf : the pathname or buffer to write the output. This can be None in which case a JSON string is returned. orient : Series : default is index allowed values are { split , records , index } DataFrame : default is columns allowed values are { split , records , index , columns , values , table } The format of the JSON string date_format : string, type of date conversion, ‘epoch’ for timestamp, ‘iso’ for ISO8601. double_precision : The number of decimal places to use when encoding floating point values, default 10. force_ascii : force encoded string to be ASCII, default True. date_unit : The time unit to encode to, governs timestamp and ISO8601 precision. One of ‘s’, ‘ms’, ‘us’ or ‘ns’ for seconds, milliseconds, microseconds and nanoseconds respectively. Default ‘ms’. default_handler : The handler to call if an object cannot otherwise be converted to a suitable format for JSON. Takes a single argument, which is the object to convert, and returns a serializable object. lines : If records orient, then will write each record per line as json. mode : string, writer mode when writing to path. ‘w’ for write, ‘a’ for append. Default ‘w’ Note NaN ’s, NaT ’s and None will be converted to null and datetime objects will be converted based on the date_format and date_unit parameters. Orient options # There are a number of different options for the format of the resulting JSON file / string. Consider the following DataFrame and Series : Column oriented (the default for DataFrame ) serializes the data as nested JSON objects with column labels acting as the primary index: Index oriented (the default for Series ) similar to column oriented but the index labels are now primary: Record oriented serializes the data to a JSON array of column -> value records, index labels are not included. This is useful for passing DataFrame data to plotting libraries, for example the JavaScript library d3.js : Value oriented is a bare-bones option which serializes to nested JSON arrays of values only, column and index labels are not included: Split oriented serializes to a JSON object containing separate entries for values, index and columns. Name is also included for Series : Table oriented serializes to the JSON Table Schema , allowing for the preservation of metadata including but not limited to dtypes and index names. Note Any orient option that encodes to a JSON object will not preserve the ordering of index and column labels during round-trip serialization. If you wish to preserve label ordering use the split option as it uses ordered containers. Date handling # Writing in ISO date format: Writing in ISO date format, with microseconds: Epoch timestamps, in seconds: Writing to a file, with a date index and a date column: Fallback behavior # If the JSON serializer cannot handle the container contents directly it will fall back in the following manner: if the dtype is unsupported (e.g. np.complex_ ) then the default_handler , if provided, will be called for each value, otherwise an exception is raised. if an object is unsupported it will attempt the following: check if the object has defined a toDict method and call it. A toDict method should return a dict which will then be JSON serialized. invoke the default_handler if one was provided. convert the object to a dict by traversing its contents. However this will often fail with an OverflowError or give unexpected results. In general the best approach for unsupported objects or dtypes is to provide a default_handler . For example: >>> DataFrame ([ 1.0 , 2.0 , complex ( 1.0 , 2.0 )]) . to_json () # raises RuntimeError: Unhandled numpy dtype 15 can be dealt with by specifying a simple default_handler : Reading JSON # Reading a JSON string to pandas object can take a number of parameters. The parser will try to parse a DataFrame if typ is not supplied or is None . To explicitly force Series parsing, pass typ=series filepath_or_buffer : a VALID JSON string or file handle / StringIO. The string could be a URL. Valid URL schemes include http, ftp, S3, and file. For file URLs, a host is expected. For instance, a local file could be file ://localhost/path/to/table.json typ : type of object to recover (series or frame), default ‘frame’ orient : Series : default is index allowed values are { split , records , index } DataFrame default is columns allowed values are { split , records , index , columns , values , table } The format of the JSON string dtype : if True, infer dtypes, if a dict of column to dtype, then use those, if False , then don’t infer dtypes at all, default is True, apply only to the data. convert_axes : boolean, try to convert the axes to the proper dtypes, default is True convert_dates : a list of columns to parse for dates; If True , then try to parse date-like columns, default is True . keep_default_dates : boolean, default True . If parsing dates, then parse the default date-like columns. precise_float : boolean, default False . Set to enable usage of higher precision (strtod) function when decoding string to double values. Default ( False ) is to use fast but less precise builtin functionality. date_unit : string, the timestamp unit to detect if converting dates. Default None. By default the timestamp precision will be detected, if this is not desired then pass one of ‘s’, ‘ms’, ‘us’ or ‘ns’ to force timestamp precision to seconds, milliseconds, microseconds or nanoseconds respectively. lines : reads file as one json object per line. encoding : The encoding to use to decode py3 bytes. chunksize : when used in combination with lines=True , return a pandas.api.typing.JsonReader which reads in chunksize lines per iteration. engine : Either ""ujson"" , the built-in JSON parser, or ""pyarrow"" which dispatches to pyarrow’s pyarrow.json.read_json . The ""pyarrow"" is only available when lines=True The parser will raise one of ValueError/TypeError/AssertionError if the JSON is not parseable. If a non-default orient was used when encoding to JSON be sure to pass the same option here so that decoding produces sensible results, see Orient Options for an overview. Data conversion # The default of convert_axes=True , dtype=True , and convert_dates=True will try to parse the axes, and all of the data into appropriate types, including dates. If you need to override specific dtypes, pass a dict to dtype . convert_axes should only be set to False if you need to preserve string-like numbers (e.g. ‘1’, ‘2’) in an axes. Note Large integer values may be converted to dates if convert_dates=True and the data and / or column labels appear ‘date-like’. The exact threshold depends on the date_unit specified. ‘date-like’ means that the column label meets one of the following criteria: it ends with '_at' it ends with '_time' it begins with 'timestamp' it is 'modified' it is 'date' Warning When reading JSON data, automatic coercing into dtypes has some quirks: an index can be reconstructed in a different order from serialization, that is, the returned order is not guaranteed to be the same as before serialization a column that was float data will be converted to integer if it can be done safely, e.g. a column of 1. bool columns will be converted to integer on reconstruction Thus there are times where you may want to specify specific dtypes via the dtype keyword argument. Reading from a JSON string: Reading from a file: Don’t convert any data (but still convert axes and dates): Specify dtypes for conversion: Preserve string indices: Dates written in nanoseconds need to be read back in nanoseconds: By setting the dtype_backend argument you can control the default dtypes used for the resulting DataFrame. Normalization # pandas provides a utility function to take a dict or list of dicts and normalize this semi-structured data into a flat table. The max_level parameter provides more control over which level to end normalization. With max_level=1 the following snippet normalizes until 1st nesting level of the provided dict. Line delimited json # pandas is able to read and write line-delimited json files that are common in data processing pipelines using Hadoop or Spark. For line-delimited json files, pandas can also return an iterator which reads in chunksize lines at a time. This can be useful for large files or to read from a stream. Line-limited json can also be read using the pyarrow reader by specifying engine=""pyarrow"" . New in version 2.0.0. Table schema # Table Schema is a spec for describing tabular datasets as a JSON object. The JSON includes information on the field names, types, and other attributes. You can use the orient table to build a JSON string with two fields, schema and data . The schema field contains the fields key, which itself contains a list of column name to type pairs, including the Index or MultiIndex (see below for a list of types). The schema field also contains a primaryKey field if the (Multi)index is unique. The second field, data , contains the serialized data with the records orient. The index is included, and any datetimes are ISO 8601 formatted, as required by the Table Schema spec. The full list of types supported are described in the Table Schema spec. This table shows the mapping from pandas types: A few notes on the generated table schema: The schema object contains a pandas_version field. This contains the version of pandas’ dialect of the schema, and will be incremented with each revision. All dates are converted to UTC when serializing. Even timezone naive values, which are treated as UTC with an offset of 0. datetimes with a timezone (before serializing), include an additional field tz with the time zone name (e.g. 'US/Central' ). Periods are converted to timestamps before serialization, and so have the same behavior of being converted to UTC. In addition, periods will contain and additional field freq with the period’s frequency, e.g. 'A-DEC' . Categoricals use the any type and an enum constraint listing the set of possible values. Additionally, an ordered field is included: A primaryKey field, containing an array of labels, is included if the index is unique : The primaryKey behavior is the same with MultiIndexes, but in this case the primaryKey is an array: The default naming roughly follows these rules: For series, the object.name is used. If that’s none, then the name is values For DataFrames , the stringified version of the column name is used For Index (not MultiIndex ), index.name is used, with a fallback to index if that is None. For MultiIndex , mi.names is used. If any level has no name, then level_<i> is used. read_json also accepts orient='table' as an argument. This allows for the preservation of metadata such as dtypes and index names in a round-trippable manner. Please note that the literal string ‘index’ as the name of an Index is not round-trippable, nor are any names beginning with 'level_' within a MultiIndex . These are used by default in DataFrame.to_json() to indicate missing values and the subsequent read cannot distinguish the intent. When using orient='table' along with user-defined ExtensionArray , the generated schema will contain an additional extDtype key in the respective fields element. This extra key is not standard but does enable JSON roundtrips for extension types (e.g. read_json(df.to_json(orient=""table""), orient=""table"") ). The extDtype key carries the name of the extension, if you have properly registered the ExtensionDtype , pandas will use said name to perform a lookup into the registry and re-convert the serialized data into your custom dtype. HTML # Reading HTML content # Warning We highly encourage you to read the HTML Table Parsing gotchas below regarding the issues surrounding the BeautifulSoup4/html5lib/lxml parsers. The top-level read_html() function can accept an HTML string/file/URL and will parse HTML tables into list of pandas DataFrames . Let’s look at a few examples. Note read_html returns a list of DataFrame objects, even if there is only a single table contained in the HTML content. Read a URL with no options: Note The data from the above URL changes every Monday so the resulting data above may be slightly different. Read a URL while passing headers alongside the HTTP request: Note We see above that the headers we passed are reflected in the HTTP request. Read in the content of the file from the above URL and pass it to read_html as a string: You can even pass in an instance of StringIO if you so desire: Note The following examples are not run by the IPython evaluator due to the fact that having so many network-accessing functions slows down the documentation build. If you spot an error or an example that doesn’t run, please do not hesitate to report it over on pandas GitHub issues page . Read a URL and match a table that contains specific text: match = ""Metcalf Bank"" df_list = pd . read_html ( url , match = match ) Specify a header row (by default <th> or <td> elements located within a <thead> are used to form the column index, if multiple rows are contained within <thead> then a MultiIndex is created); if specified, the header row is taken from the data minus the parsed header elements ( <th> elements). dfs = pd . read_html ( url , header = 0 ) Specify an index column: dfs = pd . read_html ( url , index_col = 0 ) Specify a number of rows to skip: dfs = pd . read_html ( url , skiprows = 0 ) Specify a number of rows to skip using a list ( range works as well): dfs = pd . read_html ( url , skiprows = range ( 2 )) Specify an HTML attribute: dfs1 = pd . read_html ( url , attrs = { ""id"" : ""table"" }) dfs2 = pd . read_html ( url , attrs = { ""class"" : ""sortable"" }) print ( np . array_equal ( dfs1 [ 0 ], dfs2 [ 0 ])) # Should be True Specify values that should be converted to NaN: dfs = pd . read_html ( url , na_values = [ ""No Acquirer"" ]) Specify whether to keep the default set of NaN values: dfs = pd . read_html ( url , keep_default_na = False ) Specify converters for columns. This is useful for numerical text data that has leading zeros. By default columns that are numerical are cast to numeric types and the leading zeros are lost. To avoid this, we can convert these columns to strings. url_mcc = ""https://en.wikipedia.org/wiki/Mobile_country_code?oldid=899173761"" dfs = pd . read_html ( url_mcc , match = ""Telekom Albania"" , header = 0 , converters = { ""MNC"" : str }, ) Use some combination of the above: dfs = pd . read_html ( url , match = ""Metcalf Bank"" , index_col = 0 ) Read in pandas to_html output (with some loss of floating point precision): df = pd . DataFrame ( np . random . randn ( 2 , 2 )) s = df . to_html ( float_format = "" {0:.40g} "" . format ) dfin = pd . read_html ( s , index_col = 0 ) The lxml backend will raise an error on a failed parse if that is the only parser you provide. If you only have a single parser you can provide just a string, but it is considered good practice to pass a list with one string if, for example, the function expects a sequence of strings. You may use: dfs = pd . read_html ( url , ""Metcalf Bank"" , index_col = 0 , flavor = [ ""lxml"" ]) Or you could pass flavor='lxml' without a list: dfs = pd . read_html ( url , ""Metcalf Bank"" , index_col = 0 , flavor = ""lxml"" ) However, if you have bs4 and html5lib installed and pass None or ['lxml', 'bs4'] then the parse will most likely succeed. Note that as soon as a parse succeeds, the function will return . dfs = pd . read_html ( url , ""Metcalf Bank"" , index_col = 0 , flavor = [ ""lxml"" , ""bs4"" ]) Links can be extracted from cells along with the text using extract_links=""all"" . New in version 1.5.0. Writing to HTML files # DataFrame objects have an instance method to_html which renders the contents of the DataFrame as an HTML table. The function arguments are as in the method to_string described above. Note Not all of the possible options for DataFrame.to_html are shown here for brevity’s sake. See DataFrame.to_html() for the full set of options. Note In an HTML-rendering supported environment like a Jupyter Notebook, display(HTML(...))` will render the raw HTML into the environment. The columns argument will limit the columns shown: float_format takes a Python callable to control the precision of floating point values: bold_rows will make the row labels bold by default, but you can turn that off: The classes argument provides the ability to give the resulting HTML table CSS classes. Note that these classes are appended to the existing 'dataframe' class. The render_links argument provides the ability to add hyperlinks to cells that contain URLs. Finally, the escape argument allows you to control whether the “<”, “>” and “&” characters escaped in the resulting HTML (by default it is True ). So to get the HTML without escaped characters pass escape=False Escaped: Not escaped: Note Some browsers may not show a difference in the rendering of the previous two HTML tables. HTML Table Parsing Gotchas # There are some versioning issues surrounding the libraries that are used to parse HTML tables in the top-level pandas io function read_html . Issues with lxml Benefits lxml is very fast. lxml requires Cython to install correctly. Drawbacks lxml does not make any guarantees about the results of its parse unless it is given strictly valid markup . In light of the above, we have chosen to allow you, the user, to use the lxml backend, but this backend will use html5lib if lxml fails to parse It is therefore highly recommended that you install both BeautifulSoup4 and html5lib , so that you will still get a valid result (provided everything else is valid) even if lxml fails. Issues with BeautifulSoup4 using lxml as a backend The above issues hold here as well since BeautifulSoup4 is essentially just a wrapper around a parser backend. Issues with BeautifulSoup4 using html5lib as a backend Benefits html5lib is far more lenient than lxml and consequently deals with real-life markup in a much saner way rather than just, e.g., dropping an element without notifying you. html5lib generates valid HTML5 markup from invalid markup automatically . This is extremely important for parsing HTML tables, since it guarantees a valid document. However, that does NOT mean that it is “correct”, since the process of fixing markup does not have a single definition. html5lib is pure Python and requires no additional build steps beyond its own installation. Drawbacks The biggest drawback to using html5lib is that it is slow as molasses. However consider the fact that many tables on the web are not big enough for the parsing algorithm runtime to matter. It is more likely that the bottleneck will be in the process of reading the raw text from the URL over the web, i.e., IO (input-output). For very large tables, this might not be true. LaTeX # New in version 1.3.0. Currently there are no methods to read from LaTeX, only output methods. Writing to LaTeX files # Note DataFrame and Styler objects currently have a to_latex method. We recommend using the Styler.to_latex() method over DataFrame.to_latex() due to the former’s greater flexibility with conditional styling, and the latter’s possible future deprecation. Review the documentation for Styler.to_latex , which gives examples of conditional styling and explains the operation of its keyword arguments. For simple application the following pattern is sufficient. To format values before output, chain the Styler.format method. XML # Reading XML # New in version 1.3.0. The top-level read_xml() function can accept an XML string/file/URL and will parse nodes and attributes into a pandas DataFrame . Note Since there is no standard XML structure where design types can vary in many ways, read_xml works best with flatter, shallow versions. If an XML document is deeply nested, use the stylesheet feature to transform XML into a flatter version. Let’s look at a few examples. Read an XML string: Read a URL with no options: Read in the content of the “books.xml” file and pass it to read_xml as a string: Read in the content of the “books.xml” as instance of StringIO or BytesIO and pass it to read_xml : Even read XML from AWS S3 buckets such as NIH NCBI PMC Article Datasets providing Biomedical and Life Science Jorurnals: With lxml as default parser , you access the full-featured XML library that extends Python’s ElementTree API. One powerful tool is ability to query nodes selectively or conditionally with more expressive XPath: Specify only elements or only attributes to parse: XML documents can have namespaces with prefixes and default namespaces without prefixes both of which are denoted with a special attribute xmlns . In order to parse by node under a namespace context, xpath must reference a prefix. For example, below XML contains a namespace with prefix, doc , and URI at https://example.com . In order to parse doc:row nodes, namespaces must be used. Similarly, an XML document can have a default namespace without prefix. Failing to assign a temporary prefix will return no nodes and raise a ValueError . But assigning any temporary name to correct URI allows parsing by nodes. However, if XPath does not reference node names such as default, /* , then namespaces is not required. Note Since xpath identifies the parent of content to be parsed, only immediate desendants which include child nodes or current attributes are parsed. Therefore, read_xml will not parse the text of grandchildren or other descendants and will not parse attributes of any descendant. To retrieve lower level content, adjust xpath to lower level. For example, shows the attribute sides on shape element was not parsed as expected since this attribute resides on the child of row element and not row element itself. In other words, sides attribute is a grandchild level descendant of row element. However, the xpath targets row element which covers only its children and attributes. With lxml as parser, you can flatten nested XML documents with an XSLT script which also can be string/file/URL types. As background, XSLT is a special-purpose language written in a special XML file that can transform original XML documents into other XML, HTML, even text (CSV, JSON, etc.) using an XSLT processor. For example, consider this somewhat nested structure of Chicago “L” Rides where station and rides elements encapsulate data in their own sections. With below XSLT, lxml can transform original nested document into a flatter output (as shown below for demonstration) for easier parse into DataFrame : For very large XML files that can range in hundreds of megabytes to gigabytes, pandas.read_xml() supports parsing such sizeable files using lxml’s iterparse and etree’s iterparse which are memory-efficient methods to iterate through an XML tree and extract specific elements and attributes. without holding entire tree in memory. New in version 1.5.0. To use this feature, you must pass a physical XML file path into read_xml and use the iterparse argument. Files should not be compressed or point to online sources but stored on local disk. Also, iterparse should be a dictionary where the key is the repeating nodes in document (which become the rows) and the value is a list of any element or attribute that is a descendant (i.e., child, grandchild) of repeating node. Since XPath is not used in this method, descendants do not need to share same relationship with one another. Below shows example of reading in Wikipedia’s very large (12 GB+) latest article data dump. Writing XML # New in version 1.3.0. DataFrame objects have an instance method to_xml which renders the contents of the DataFrame as an XML document. Note This method does not support special properties of XML including DTD, CData, XSD schemas, processing instructions, comments, and others. Only namespaces at the root level is supported. However, stylesheet allows design changes after initial output. Let’s look at a few examples. Write an XML without options: Write an XML with new root and row name: Write an attribute-centric XML: Write a mix of elements and attributes: Any DataFrames with hierarchical columns will be flattened for XML element names with levels delimited by underscores: Write an XML with default namespace: Write an XML with namespace prefix: Write an XML without declaration or pretty print: Write an XML and transform with stylesheet: XML Final Notes # All XML documents adhere to W3C specifications . Both etree and lxml parsers will fail to parse any markup document that is not well-formed or follows XML syntax rules. Do be aware HTML is not an XML document unless it follows XHTML specs. However, other popular markup types including KML, XAML, RSS, MusicML, MathML are compliant XML schemas . For above reason, if your application builds XML prior to pandas operations, use appropriate DOM libraries like etree and lxml to build the necessary document and not by string concatenation or regex adjustments. Always remember XML is a special text file with markup rules. With very large XML files (several hundred MBs to GBs), XPath and XSLT can become memory-intensive operations. Be sure to have enough available RAM for reading and writing to large XML files (roughly about 5 times the size of text). Because XSLT is a programming language, use it with caution since such scripts can pose a security risk in your environment and can run large or infinite recursive operations. Always test scripts on small fragments before full run. The etree parser supports all functionality of both read_xml and to_xml except for complex XPath and any XSLT. Though limited in features, etree is still a reliable and capable parser and tree builder. Its performance may trail lxml to a certain degree for larger files but relatively unnoticeable on small to medium size files. Excel files # The read_excel() method can read Excel 2007+ ( .xlsx ) files using the openpyxl Python module. Excel 2003 ( .xls ) files can be read using xlrd . Binary Excel ( .xlsb ) files can be read using pyxlsb . All formats can be read using calamine engine. The to_excel() instance method is used for saving a DataFrame to Excel. Generally the semantics are similar to working with csv data. See the cookbook for some advanced strategies. Note When engine=None , the following logic will be used to determine the engine: If path_or_buffer is an OpenDocument format (.odf, .ods, .odt), then odf will be used. Otherwise if path_or_buffer is an xls format, xlrd will be used. Otherwise if path_or_buffer is in xlsb format, pyxlsb will be used. Otherwise openpyxl will be used. Reading Excel files # In the most basic use-case, read_excel takes a path to an Excel file, and the sheet_name indicating which sheet to parse. When using the engine_kwargs parameter, pandas will pass these arguments to the engine. For this, it is important to know which function pandas is using internally. For the engine openpyxl, pandas is using openpyxl.load_workbook() to read in ( .xlsx ) and ( .xlsm ) files. For the engine xlrd, pandas is using xlrd.open_workbook() to read in ( .xls ) files. For the engine pyxlsb, pandas is using pyxlsb.open_workbook() to read in ( .xlsb ) files. For the engine odf, pandas is using odf.opendocument.load() to read in ( .ods ) files. For the engine calamine, pandas is using python_calamine.load_workbook() to read in ( .xlsx ), ( .xlsm ), ( .xls ), ( .xlsb ), ( .ods ) files. # Returns a DataFrame pd . read_excel ( ""path_to_file.xls"" , sheet_name = ""Sheet1"" ) ExcelFile class # To facilitate working with multiple sheets from the same file, the ExcelFile class can be used to wrap the file and can be passed into read_excel There will be a performance benefit for reading multiple sheets as the file is read into memory only once. xlsx = pd . ExcelFile ( ""path_to_file.xls"" ) df = pd . read_excel ( xlsx , ""Sheet1"" ) The ExcelFile class can also be used as a context manager. with pd . ExcelFile ( ""path_to_file.xls"" ) as xls : df1 = pd . read_excel ( xls , ""Sheet1"" ) df2 = pd . read_excel ( xls , ""Sheet2"" ) The sheet_names property will generate a list of the sheet names in the file. The primary use-case for an ExcelFile is parsing multiple sheets with different parameters: data = {} # For when Sheet1's format differs from Sheet2 with pd . ExcelFile ( ""path_to_file.xls"" ) as xls : data [ ""Sheet1"" ] = pd . read_excel ( xls , ""Sheet1"" , index_col = None , na_values = [ ""NA"" ]) data [ ""Sheet2"" ] = pd . read_excel ( xls , ""Sheet2"" , index_col = 1 ) Note that if the same parsing parameters are used for all sheets, a list of sheet names can simply be passed to read_excel with no loss in performance. # using the ExcelFile class data = {} with pd . ExcelFile ( ""path_to_file.xls"" ) as xls : data [ ""Sheet1"" ] = pd . read_excel ( xls , ""Sheet1"" , index_col = None , na_values = [ ""NA"" ]) data [ ""Sheet2"" ] = pd . read_excel ( xls , ""Sheet2"" , index_col = None , na_values = [ ""NA"" ]) # equivalent using the read_excel function data = pd . read_excel ( ""path_to_file.xls"" , [ ""Sheet1"" , ""Sheet2"" ], index_col = None , na_values = [ ""NA"" ] ) ExcelFile can also be called with a xlrd.book.Book object as a parameter. This allows the user to control how the excel file is read. For example, sheets can be loaded on demand by calling xlrd.open_workbook() with on_demand=True . import xlrd xlrd_book = xlrd . open_workbook ( ""path_to_file.xls"" , on_demand = True ) with pd . ExcelFile ( xlrd_book ) as xls : df1 = pd . read_excel ( xls , ""Sheet1"" ) df2 = pd . read_excel ( xls , ""Sheet2"" ) Specifying sheets # Note The second argument is sheet_name , not to be confused with ExcelFile.sheet_names . Note An ExcelFile’s attribute sheet_names provides access to a list of sheets. The arguments sheet_name allows specifying the sheet or sheets to read. The default value for sheet_name is 0, indicating to read the first sheet Pass a string to refer to the name of a particular sheet in the workbook. Pass an integer to refer to the index of a sheet. Indices follow Python convention, beginning at 0. Pass a list of either strings or integers, to return a dictionary of specified sheets. Pass a None to return a dictionary of all available sheets. # Returns a DataFrame pd . read_excel ( ""path_to_file.xls"" , ""Sheet1"" , index_col = None , na_values = [ ""NA"" ]) Using the sheet index: # Returns a DataFrame pd . read_excel ( ""path_to_file.xls"" , 0 , index_col = None , na_values = [ ""NA"" ]) Using all default values: # Returns a DataFrame pd . read_excel ( ""path_to_file.xls"" ) Using None to get all sheets: # Returns a dictionary of DataFrames pd . read_excel ( ""path_to_file.xls"" , sheet_name = None ) Using a list to get multiple sheets: # Returns the 1st and 4th sheet, as a dictionary of DataFrames. pd . read_excel ( ""path_to_file.xls"" , sheet_name = [ ""Sheet1"" , 3 ]) read_excel can read more than one sheet, by setting sheet_name to either a list of sheet names, a list of sheet positions, or None to read all sheets. Sheets can be specified by sheet index or sheet name, using an integer or string, respectively. Reading a MultiIndex # read_excel can read a MultiIndex index, by passing a list of columns to index_col and a MultiIndex column by passing a list of rows to header . If either the index or columns have serialized level names those will be read in as well by specifying the rows/columns that make up the levels. For example, to read in a MultiIndex index without names: If the index has level names, they will parsed as well, using the same parameters. If the source file has both MultiIndex index and columns, lists specifying each should be passed to index_col and header : Missing values in columns specified in index_col will be forward filled to allow roundtripping with to_excel for merged_cells=True . To avoid forward filling the missing values use set_index after reading the data instead of index_col . Parsing specific columns # It is often the case that users will insert columns to do temporary computations in Excel and you may not want to read in those columns. read_excel takes a usecols keyword to allow you to specify a subset of columns to parse. You can specify a comma-delimited set of Excel columns and ranges as a string: pd . read_excel ( ""path_to_file.xls"" , ""Sheet1"" , usecols = ""A,C:E"" ) If usecols is a list of integers, then it is assumed to be the file column indices to be parsed. pd . read_excel ( ""path_to_file.xls"" , ""Sheet1"" , usecols = [ 0 , 2 , 3 ]) Element order is ignored, so usecols=[0, 1] is the same as [1, 0] . If usecols is a list of strings, it is assumed that each string corresponds to a column name provided either by the user in names or inferred from the document header row(s). Those strings define which columns will be parsed: pd . read_excel ( ""path_to_file.xls"" , ""Sheet1"" , usecols = [ ""foo"" , ""bar"" ]) Element order is ignored, so usecols=['baz', 'joe'] is the same as ['joe', 'baz'] . If usecols is callable, the callable function will be evaluated against the column names, returning names where the callable function evaluates to True . pd . read_excel ( ""path_to_file.xls"" , ""Sheet1"" , usecols = lambda x : x . isalpha ()) Parsing dates # Datetime-like values are normally automatically converted to the appropriate dtype when reading the excel file. But if you have a column of strings that look like dates (but are not actually formatted as dates in excel), you can use the parse_dates keyword to parse those strings to datetimes: pd . read_excel ( ""path_to_file.xls"" , ""Sheet1"" , parse_dates = [ ""date_strings"" ]) Cell converters # It is possible to transform the contents of Excel cells via the converters option. For instance, to convert a column to boolean: pd . read_excel ( ""path_to_file.xls"" , ""Sheet1"" , converters = { ""MyBools"" : bool }) This options handles missing values and treats exceptions in the converters as missing data. Transformations are applied cell by cell rather than to the column as a whole, so the array dtype is not guaranteed. For instance, a column of integers with missing values cannot be transformed to an array with integer dtype, because NaN is strictly a float. You can manually mask missing data to recover integer dtype: def cfun ( x ): return int ( x ) if x else - 1 pd . read_excel ( ""path_to_file.xls"" , ""Sheet1"" , converters = { ""MyInts"" : cfun }) Dtype specifications # As an alternative to converters, the type for an entire column can be specified using the dtype keyword, which takes a dictionary mapping column names to types. To interpret data with no type inference, use the type str or object . pd . read_excel ( ""path_to_file.xls"" , dtype = { ""MyInts"" : ""int64"" , ""MyText"" : str }) Writing Excel files # Writing Excel files to disk # To write a DataFrame object to a sheet of an Excel file, you can use the to_excel instance method. The arguments are largely the same as to_csv described above, the first argument being the name of the excel file, and the optional second argument the name of the sheet to which the DataFrame should be written. For example: df . to_excel ( ""path_to_file.xlsx"" , sheet_name = ""Sheet1"" ) Files with a .xlsx extension will be written using xlsxwriter (if available) or openpyxl . The DataFrame will be written in a way that tries to mimic the REPL output. The index_label will be placed in the second row instead of the first. You can place it in the first row by setting the merge_cells option in to_excel() to False : df . to_excel ( ""path_to_file.xlsx"" , index_label = ""label"" , merge_cells = False ) In order to write separate DataFrames to separate sheets in a single Excel file, one can pass an ExcelWriter . with pd . ExcelWriter ( ""path_to_file.xlsx"" ) as writer : df1 . to_excel ( writer , sheet_name = ""Sheet1"" ) df2 . to_excel ( writer , sheet_name = ""Sheet2"" ) When using the engine_kwargs parameter, pandas will pass these arguments to the engine. For this, it is important to know which function pandas is using internally. For the engine openpyxl, pandas is using openpyxl.Workbook() to create a new sheet and openpyxl.load_workbook() to append data to an existing sheet. The openpyxl engine writes to ( .xlsx ) and ( .xlsm ) files. For the engine xlsxwriter, pandas is using xlsxwriter.Workbook() to write to ( .xlsx ) files. For the engine odf, pandas is using odf.opendocument.OpenDocumentSpreadsheet() to write to ( .ods ) files. Writing Excel files to memory # pandas supports writing Excel files to buffer-like objects such as StringIO or BytesIO using ExcelWriter . from io import BytesIO bio = BytesIO () # By setting the 'engine' in the ExcelWriter constructor. writer = pd . ExcelWriter ( bio , engine = ""xlsxwriter"" ) df . to_excel ( writer , sheet_name = ""Sheet1"" ) # Save the workbook writer . save () # Seek to the beginning and read to copy the workbook to a variable in memory bio . seek ( 0 ) workbook = bio . read () Note engine is optional but recommended. Setting the engine determines the version of workbook produced. Setting engine='xlrd' will produce an Excel 2003-format workbook (xls). Using either 'openpyxl' or 'xlsxwriter' will produce an Excel 2007-format workbook (xlsx). If omitted, an Excel 2007-formatted workbook is produced. Excel writer engines # pandas chooses an Excel writer via two methods: the engine keyword argument the filename extension (via the default specified in config options) By default, pandas uses the XlsxWriter for .xlsx , openpyxl for .xlsm . If you have multiple engines installed, you can set the default engine through setting the config options io.excel.xlsx.writer and io.excel.xls.writer . pandas will fall back on openpyxl for .xlsx files if Xlsxwriter is not available. To specify which writer you want to use, you can pass an engine keyword argument to to_excel and to ExcelWriter . The built-in engines are: openpyxl : version 2.4 or higher is required xlsxwriter # By setting the 'engine' in the DataFrame 'to_excel()' methods. df . to_excel ( ""path_to_file.xlsx"" , sheet_name = ""Sheet1"" , engine = ""xlsxwriter"" ) # By setting the 'engine' in the ExcelWriter constructor. writer = pd . ExcelWriter ( ""path_to_file.xlsx"" , engine = ""xlsxwriter"" ) # Or via pandas configuration. from pandas import options # noqa: E402 options . io . excel . xlsx . writer = ""xlsxwriter"" df . to_excel ( ""path_to_file.xlsx"" , sheet_name = ""Sheet1"" ) Style and formatting # The look and feel of Excel worksheets created from pandas can be modified using the following parameters on the DataFrame ’s to_excel method. float_format : Format string for floating point numbers (default None ). freeze_panes : A tuple of two integers representing the bottommost row and rightmost column to freeze. Each of these parameters is one-based, so (1, 1) will freeze the first row and first column (default None ). Using the Xlsxwriter engine provides many options for controlling the format of an Excel worksheet created with the to_excel method. Excellent examples can be found in the Xlsxwriter documentation here: https://xlsxwriter.readthedocs.io/working_with_pandas.html OpenDocument Spreadsheets # The io methods for Excel files also support reading and writing OpenDocument spreadsheets using the odfpy module. The semantics and features for reading and writing OpenDocument spreadsheets match what can be done for Excel files using engine='odf' . The optional dependency ‘odfpy’ needs to be installed. The read_excel() method can read OpenDocument spreadsheets # Returns a DataFrame pd . read_excel ( ""path_to_file.ods"" , engine = ""odf"" ) Similarly, the to_excel() method can write OpenDocument spreadsheets # Writes DataFrame to a .ods file df . to_excel ( ""path_to_file.ods"" , engine = ""odf"" ) Binary Excel (.xlsb) files # The read_excel() method can also read binary Excel files using the pyxlsb module. The semantics and features for reading binary Excel files mostly match what can be done for Excel files using engine='pyxlsb' . pyxlsb does not recognize datetime types in files and will return floats instead (you can use calamine if you need recognize datetime types). # Returns a DataFrame pd . read_excel ( ""path_to_file.xlsb"" , engine = ""pyxlsb"" ) Note Currently pandas only supports reading binary Excel files. Writing is not implemented. Calamine (Excel and ODS files) # The read_excel() method can read Excel file ( .xlsx , .xlsm , .xls , .xlsb ) and OpenDocument spreadsheets ( .ods ) using the python-calamine module. This module is a binding for Rust library calamine and is faster than other engines in most cases. The optional dependency ‘python-calamine’ needs to be installed. # Returns a DataFrame pd . read_excel ( ""path_to_file.xlsb"" , engine = ""calamine"" ) Clipboard # A handy way to grab data is to use the read_clipboard() method, which takes the contents of the clipboard buffer and passes them to the read_csv method. For instance, you can copy the following text to the clipboard (CTRL-C on many operating systems): A B C x 1 4 p y 2 5 q z 3 6 r And then import the data directly to a DataFrame by calling: >>> clipdf = pd . read_clipboard () >>> clipdf A B C x 1 4 p y 2 5 q z 3 6 r The to_clipboard method can be used to write the contents of a DataFrame to the clipboard. Following which you can paste the clipboard contents into other applications (CTRL-V on many operating systems). Here we illustrate writing a DataFrame into clipboard and reading it back. >>> df = pd . DataFrame ( ... { ""A"" : [ 1 , 2 , 3 ], ""B"" : [ 4 , 5 , 6 ], ""C"" : [ ""p"" , ""q"" , ""r"" ]}, index = [ ""x"" , ""y"" , ""z"" ] ... ) >>> df A B C x 1 4 p y 2 5 q z 3 6 r >>> df . to_clipboard () >>> pd . read_clipboard () A B C x 1 4 p y 2 5 q z 3 6 r We can see that we got the same content back, which we had earlier written to the clipboard. Note You may need to install xclip or xsel (with PyQt5, PyQt4 or qtpy) on Linux to use these methods. Pickling # All pandas objects are equipped with to_pickle methods which use Python’s cPickle module to save data structures to disk using the pickle format. The read_pickle function in the pandas namespace can be used to load any pickled pandas object (or any other pickled object) from file: Warning Loading pickled data received from untrusted sources can be unsafe. See: https://docs.python.org/3/library/pickle.html Warning read_pickle() is only guaranteed backwards compatible back to a few minor release. Compressed pickle files # read_pickle() , DataFrame.to_pickle() and Series.to_pickle() can read and write compressed pickle files. The compression types of gzip , bz2 , xz , zstd are supported for reading and writing. The zip file format only supports reading and must contain only one data file to be read. The compression type can be an explicit parameter or be inferred from the file extension. If ‘infer’, then use gzip , bz2 , zip , xz , zstd if filename ends in '.gz' , '.bz2' , '.zip' , '.xz' , or '.zst' , respectively. The compression parameter can also be a dict in order to pass options to the compression protocol. It must have a 'method' key set to the name of the compression protocol, which must be one of { 'zip' , 'gzip' , 'bz2' , 'xz' , 'zstd' }. All other key-value pairs are passed to the underlying compression library. Using an explicit compression type: Inferring compression type from the extension: The default is to ‘infer’: Passing options to the compression protocol in order to speed up compression: msgpack # pandas support for msgpack has been removed in version 1.0.0. It is recommended to use pickle instead. Alternatively, you can also the Arrow IPC serialization format for on-the-wire transmission of pandas objects. For documentation on pyarrow, see here . HDF5 (PyTables) # HDFStore is a dict-like object which reads and writes pandas using the high performance HDF5 format using the excellent PyTables library. See the cookbook for some advanced strategies Warning pandas uses PyTables for reading and writing HDF5 files, which allows serializing object-dtype data with pickle. Loading pickled data received from untrusted sources can be unsafe. See: https://docs.python.org/3/library/pickle.html for more. Objects can be written to the file just like adding key-value pairs to a dict: In a current or later Python session, you can retrieve stored objects: Deletion of the object specified by the key: Closing a Store and using a context manager: Read/write API # HDFStore supports a top-level API using read_hdf for reading and to_hdf for writing, similar to how read_csv and to_csv work. HDFStore will by default not drop rows that are all missing. This behavior can be changed by setting dropna=True . Fixed format # The examples above show storing using put , which write the HDF5 to PyTables in a fixed array format, called the fixed format. These types of stores are not appendable once written (though you can simply remove them and rewrite). Nor are they queryable ; they must be retrieved in their entirety. They also do not support dataframes with non-unique column names. The fixed format stores offer very fast writing and slightly faster reading than table stores. This format is specified by default when using put or to_hdf or by format='fixed' or format='f' . Warning A fixed format will raise a TypeError if you try to retrieve using a where : Table format # HDFStore supports another PyTables format on disk, the table format. Conceptually a table is shaped very much like a DataFrame, with rows and columns. A table may be appended to in the same or other sessions. In addition, delete and query type operations are supported. This format is specified by format='table' or format='t' to append or put or to_hdf . This format can be set as an option as well pd.set_option('io.hdf.default_format','table') to enable put/append/to_hdf to by default store in the table format. Note You can also create a table by passing format='table' or format='t' to a put operation. Hierarchical keys # Keys to a store can be specified as a string. These can be in a hierarchical path-name like format (e.g. foo/bar/bah ), which will generate a hierarchy of sub-stores (or Groups in PyTables parlance). Keys can be specified without the leading ‘/’ and are always absolute (e.g. ‘foo’ refers to ‘/foo’). Removal operations can remove everything in the sub-store and below , so be careful . You can walk through the group hierarchy using the walk method which will yield a tuple for each group key along with the relative keys of its contents. Warning Hierarchical keys cannot be retrieved as dotted (attribute) access as described above for items stored under the root node. Instead, use explicit string based keys: Storing types # Storing mixed types in a table # Storing mixed-dtype data is supported. Strings are stored as a fixed-width using the maximum size of the appended column. Subsequent attempts at appending longer strings will raise a ValueError . Passing min_itemsize={`values`: size} as a parameter to append will set a larger minimum for the string columns. Storing floats, strings, ints, bools, datetime64 are currently supported. For string columns, passing nan_rep = 'nan' to append will change the default nan representation on disk (which converts to/from np.nan ), this defaults to nan . Storing MultiIndex DataFrames # Storing MultiIndex DataFrames as tables is very similar to storing/selecting from homogeneous index DataFrames . Note The index keyword is reserved and cannot be use as a level name. Querying # Querying a table # select and delete operations have an optional criterion that can be specified to select/delete only a subset of the data. This allows one to have a very large on-disk table and retrieve only a portion of the data. A query is specified using the Term class under the hood, as a boolean expression. index and columns are supported indexers of DataFrames . if data_columns are specified, these can be used as additional indexers. level name in a MultiIndex, with default name level_0 , level_1 , … if not provided. Valid comparison operators are: =, ==, !=, >, >=, <, <= Valid boolean expressions are combined with: | : or & : and ( and ) : for grouping These rules are similar to how boolean expressions are used in pandas for indexing. Note = will be automatically expanded to the comparison operator == ~ is the not operator, but can only be used in very limited circumstances If a list/tuple of expressions is passed they will be combined via & The following are valid expressions: 'index >= date' ""columns = ['A', 'D']"" ""columns in ['A', 'D']"" 'columns = A' 'columns == A' ""~(columns = ['A', 'B'])"" 'index > df.index[3] & string = ""bar""' '(index > df.index[3] & index <= df.index[6]) | string = ""bar""' ""ts >= Timestamp('2012-02-01')"" ""major_axis>=20130101"" The indexers are on the left-hand side of the sub-expression: columns , major_axis , ts The right-hand side of the sub-expression (after a comparison operator) can be: functions that will be evaluated, e.g. Timestamp('2012-02-01') strings, e.g. ""bar"" date-like, e.g. 20130101 , or ""20130101"" lists, e.g. ""['A', 'B']"" variables that are defined in the local names space, e.g. date Note Passing a string to a query by interpolating it into the query expression is not recommended. Simply assign the string of interest to a variable and use that variable in an expression. For example, do this string = ""HolyMoly'"" store . select ( ""df"" , ""index == string"" ) instead of this string = ""HolyMoly'"" store . select ( 'df' , f 'index == { string } ' ) The latter will not work and will raise a SyntaxError .Note that there’s a single quote followed by a double quote in the string variable. If you must interpolate, use the '%r' format specifier store . select ( ""df"" , ""index == %r "" % string ) which will quote string . Here are some examples: Use boolean expressions, with in-line function evaluation. Use inline column reference. The columns keyword can be supplied to select a list of columns to be returned, this is equivalent to passing a 'columns=list_of_columns_to_filter' : start and stop parameters can be specified to limit the total search space. These are in terms of the total number of rows in a table. Note select will raise a ValueError if the query expression has an unknown variable reference. Usually this means that you are trying to select on a column that is not a data_column. select will raise a SyntaxError if the query expression is not valid. Query timedelta64[ns] # You can store and query using the timedelta64[ns] type. Terms can be specified in the format: <float>(<unit>) , where float may be signed (and fractional), and unit can be D,s,ms,us,ns for the timedelta. Here’s an example: Query MultiIndex # Selecting from a MultiIndex can be achieved by using the name of the level. If the MultiIndex levels names are None , the levels are automatically made available via the level_n keyword with n the level of the MultiIndex you want to select from. Indexing # You can create/modify an index for a table with create_table_index after data is already in the table (after and append/put operation). Creating a table index is highly encouraged. This will speed your queries a great deal when you use a select with the indexed dimension as the where . Note Indexes are automagically created on the indexables and any data columns you specify. This behavior can be turned off by passing index=False to append . Oftentimes when appending large amounts of data to a store, it is useful to turn off index creation for each append, then recreate at the end. Then create the index when finished appending. See here for how to create a completely-sorted-index (CSI) on an existing store. Query via data columns # You can designate (and index) certain columns that you want to be able to perform queries (other than the indexable columns, which you can always query). For instance say you want to perform this common operation, on-disk, and return just the frame that matches this query. You can specify data_columns = True to force all columns to be data_columns . There is some performance degradation by making lots of columns into data columns , so it is up to the user to designate these. In addition, you cannot change data columns (nor indexables) after the first append/put operation (Of course you can simply read in the data and create a new table!). Iterator # You can pass iterator=True or chunksize=number_in_a_chunk to select and select_as_multiple to return an iterator on the results. The default is 50,000 rows returned in a chunk. Note You can also use the iterator with read_hdf which will open, then automatically close the store when finished iterating. for df in pd . read_hdf ( ""store.h5"" , ""df"" , chunksize = 3 ): print ( df ) Note, that the chunksize keyword applies to the source rows. So if you are doing a query, then the chunksize will subdivide the total rows in the table and the query applied, returning an iterator on potentially unequal sized chunks. Here is a recipe for generating a query and using it to create equal sized return chunks. Advanced queries # Select a single column # To retrieve a single indexable or data column, use the method select_column . This will, for example, enable you to get the index very quickly. These return a Series of the result, indexed by the row number. These do not currently accept the where selector. Selecting coordinates # Sometimes you want to get the coordinates (a.k.a the index locations) of your query. This returns an Index of the resulting locations. These coordinates can also be passed to subsequent where operations. Selecting using a where mask # Sometime your query can involve creating a list of rows to select. Usually this mask would be a resulting index from an indexing operation. This example selects the months of a datetimeindex which are 5. Storer object # If you want to inspect the stored object, retrieve via get_storer . You could use this programmatically to say get the number of rows in an object. Multiple table queries # The methods append_to_multiple and select_as_multiple can perform appending/selecting from multiple tables at once. The idea is to have one table (call it the selector table) that you index most/all of the columns, and perform your queries. The other table(s) are data tables with an index matching the selector table’s index. You can then perform a very fast query on the selector table, yet get lots of data back. This method is similar to having a very wide table, but enables more efficient queries. The append_to_multiple method splits a given single DataFrame into multiple tables according to d , a dictionary that maps the table names to a list of ‘columns’ you want in that table. If None is used in place of a list, that table will have the remaining unspecified columns of the given DataFrame. The argument selector defines which table is the selector table (which you can make queries from). The argument dropna will drop rows from the input DataFrame to ensure tables are synchronized. This means that if a row for one of the tables being written to is entirely np.nan , that row will be dropped from all tables. If dropna is False, THE USER IS RESPONSIBLE FOR SYNCHRONIZING THE TABLES . Remember that entirely np.Nan rows are not written to the HDFStore, so if you choose to call dropna=False , some tables may have more rows than others, and therefore select_as_multiple may not work or it may return unexpected results. Delete from a table # You can delete from a table selectively by specifying a where . In deleting rows, it is important to understand the PyTables deletes rows by erasing the rows, then moving the following data. Thus deleting can potentially be a very expensive operation depending on the orientation of your data. To get optimal performance, it’s worthwhile to have the dimension you are deleting be the first of the indexables . Data is ordered (on the disk) in terms of the indexables . Here’s a simple use case. You store panel-type data, with dates in the major_axis and ids in the minor_axis . The data is then interleaved like this: date_1 id_1 id_2 . id_n date_2 id_1 . id_n It should be clear that a delete operation on the major_axis will be fairly quick, as one chunk is removed, then the following data moved. On the other hand a delete operation on the minor_axis will be very expensive. In this case it would almost certainly be faster to rewrite the table using a where that selects all but the missing data. Warning Please note that HDF5 DOES NOT RECLAIM SPACE in the h5 files automatically. Thus, repeatedly deleting (or removing nodes) and adding again, WILL TEND TO INCREASE THE FILE SIZE . To repack and clean the file, use ptrepack . Notes & caveats # Compression # PyTables allows the stored data to be compressed. This applies to all kinds of stores, not just tables. Two parameters are used to control compression: complevel and complib . complevel specifies if and how hard data is to be compressed. complevel=0 and complevel=None disables compression and 0<complevel<10 enables compression. complib specifies which compression library to use. If nothing is specified the default library zlib is used. A compression library usually optimizes for either good compression rates or speed and the results will depend on the type of data. Which type of compression to choose depends on your specific needs and data. The list of supported compression libraries: zlib : The default compression library. A classic in terms of compression, achieves good compression rates but is somewhat slow. lzo : Fast compression and decompression. bzip2 : Good compression rates. blosc : Fast compression and decompression. Support for alternative blosc compressors: blosc:blosclz This is the default compressor for blosc blosc:lz4 : A compact, very popular and fast compressor. blosc:lz4hc : A tweaked version of LZ4, produces better compression ratios at the expense of speed. blosc:snappy : A popular compressor used in many places. blosc:zlib : A classic; somewhat slower than the previous ones, but achieving better compression ratios. blosc:zstd : An extremely well balanced codec; it provides the best compression ratios among the others above, and at reasonably fast speed. If complib is defined as something other than the listed libraries a ValueError exception is issued. Note If the library specified with the complib option is missing on your platform, compression defaults to zlib without further ado. Enable compression for all objects within the file: store_compressed = pd . HDFStore ( ""store_compressed.h5"" , complevel = 9 , complib = ""blosc:blosclz"" ) Or on-the-fly compression (this only applies to tables) in stores where compression is not enabled: store . append ( ""df"" , df , complib = ""zlib"" , complevel = 5 ) ptrepack # PyTables offers better write performance when tables are compressed after they are written, as opposed to turning on compression at the very beginning. You can use the supplied PyTables utility ptrepack . In addition, ptrepack can change compression levels after the fact. ptrepack --chunkshape=auto --propindexes --complevel=9 --complib=blosc in.h5 out.h5 Furthermore ptrepack in.h5 out.h5 will repack the file to allow you to reuse previously deleted space. Alternatively, one can simply remove the file and write again, or use the copy method. Caveats # Warning HDFStore is not-threadsafe for writing . The underlying PyTables only supports concurrent reads (via threading or processes). If you need reading and writing at the same time , you need to serialize these operations in a single thread in a single process. You will corrupt your data otherwise. See the ( GH 2397 ) for more information. If you use locks to manage write access between multiple processes, you may want to use fsync() before releasing write locks. For convenience you can use store.flush(fsync=True) to do this for you. Once a table is created columns (DataFrame) are fixed; only exactly the same columns can be appended Be aware that timezones (e.g., pytz.timezone('US/Eastern') ) are not necessarily equal across timezone versions. So if data is localized to a specific timezone in the HDFStore using one version of a timezone library and that data is updated with another version, the data will be converted to UTC since these timezones are not considered equal. Either use the same version of timezone library or use tz_convert with the updated timezone definition. Warning PyTables will show a NaturalNameWarning if a column name cannot be used as an attribute selector. Natural identifiers contain only letters, numbers, and underscores, and may not begin with a number. Other identifiers cannot be used in a where clause and are generally a bad idea. DataTypes # HDFStore will map an object dtype to the PyTables underlying dtype. This means the following types are known to work: unicode columns are not supported, and WILL FAIL . Categorical data # You can write data that contains category dtypes to a HDFStore . Queries work the same as if it was an object array. However, the category dtyped data is stored in a more efficient manner. String columns # min_itemsize The underlying implementation of HDFStore uses a fixed column width (itemsize) for string columns. A string column itemsize is calculated as the maximum of the length of data (for that column) that is passed to the HDFStore , in the first append . Subsequent appends, may introduce a string for a column larger than the column can hold, an Exception will be raised (otherwise you could have a silent truncation of these columns, leading to loss of information). In the future we may relax this and allow a user-specified truncation to occur. Pass min_itemsize on the first table creation to a-priori specify the minimum length of a particular string column. min_itemsize can be an integer, or a dict mapping a column name to an integer. You can pass values as a key to allow all indexables or data_columns to have this min_itemsize. Passing a min_itemsize dict will cause all passed columns to be created as data_columns automatically. Note If you are not passing any data_columns , then the min_itemsize will be the maximum of the length of any string passed nan_rep String columns will serialize a np.nan (a missing value) with the nan_rep string representation. This defaults to the string value nan . You could inadvertently turn an actual nan value into a missing value. Performance # tables format come with a writing performance penalty as compared to fixed stores. The benefit is the ability to append/delete and query (potentially very large amounts of data). Write times are generally longer as compared with regular stores. Query times can be quite fast, especially on an indexed axis. You can pass chunksize=<int> to append , specifying the write chunksize (default is 50000). This will significantly lower your memory usage on writing. You can pass expectedrows=<int> to the first append , to set the TOTAL number of rows that PyTables will expect. This will optimize read/write performance. Duplicate rows can be written to tables, but are filtered out in selection (with the last items being selected; thus a table is unique on major, minor pairs) A PerformanceWarning will be raised if you are attempting to store types that will be pickled by PyTables (rather than stored as endemic types). See Here for more information and some solutions. Feather # Feather provides binary columnar serialization for data frames. It is designed to make reading and writing data frames efficient, and to make sharing data across data analysis languages easy. Feather is designed to faithfully serialize and de-serialize DataFrames, supporting all of the pandas dtypes, including extension dtypes such as categorical and datetime with tz. Several caveats: The format will NOT write an Index , or MultiIndex for the DataFrame and will raise an error if a non-default one is provided. You can .reset_index() to store the index or .reset_index(drop=True) to ignore it. Duplicate column names and non-string columns names are not supported Actual Python objects in object dtype columns are not supported. These will raise a helpful error message on an attempt at serialization. See the Full Documentation . Write to a feather file. Read from a feather file. Parquet # Apache Parquet provides a partitioned binary columnar serialization for data frames. It is designed to make reading and writing data frames efficient, and to make sharing data across data analysis languages easy. Parquet can use a variety of compression techniques to shrink the file size as much as possible while still maintaining good read performance. Parquet is designed to faithfully serialize and de-serialize DataFrame s, supporting all of the pandas dtypes, including extension dtypes such as datetime with tz. Several caveats. Duplicate column names and non-string columns names are not supported. The pyarrow engine always writes the index to the output, but fastparquet only writes non-default indexes. This extra column can cause problems for non-pandas consumers that are not expecting it. You can force including or omitting indexes with the index argument, regardless of the underlying engine. Index level names, if specified, must be strings. In the pyarrow engine, categorical dtypes for non-string types can be serialized to parquet, but will de-serialize as their primitive dtype. The pyarrow engine preserves the ordered flag of categorical dtypes with string types. fastparquet does not preserve the ordered flag. Non supported types include Interval and actual Python object types. These will raise a helpful error message on an attempt at serialization. Period type is supported with pyarrow >= 0.16.0. The pyarrow engine preserves extension data types such as the nullable integer and string data type (requiring pyarrow >= 0.16.0, and requiring the extension type to implement the needed protocols, see the extension types documentation ). You can specify an engine to direct the serialization. This can be one of pyarrow , or fastparquet , or auto . If the engine is NOT specified, then the pd.options.io.parquet.engine option is checked; if this is also auto , then pyarrow is tried, and falling back to fastparquet . See the documentation for pyarrow and fastparquet . Note These engines are very similar and should read/write nearly identical parquet format files. pyarrow>=8.0.0 supports timedelta data, fastparquet>=0.1.4 supports timezone aware datetimes. These libraries differ by having different underlying dependencies ( fastparquet by using numba , while pyarrow uses a c-library). Write to a parquet file. Read from a parquet file. By setting the dtype_backend argument you can control the default dtypes used for the resulting DataFrame. Note Note that this is not supported for fastparquet . Read only certain columns of a parquet file. Handling indexes # Serializing a DataFrame to parquet may include the implicit index as one or more columns in the output file. Thus, this code: creates a parquet file with three columns if you use pyarrow for serialization: a , b , and __index_level_0__ . If you’re using fastparquet , the index may or may not be written to the file. This unexpected extra column causes some databases like Amazon Redshift to reject the file, because that column doesn’t exist in the target table. If you want to omit a dataframe’s indexes when writing, pass index=False to to_parquet() : This creates a parquet file with just the two expected columns, a and b . If your DataFrame has a custom index, you won’t get it back when you load this file into a DataFrame . Passing index=True will always write the index, even if that’s not the underlying engine’s default behavior. Partitioning Parquet files # Parquet supports partitioning of data based on the values of one or more columns. The path specifies the parent directory to which data will be saved. The partition_cols are the column names by which the dataset will be partitioned. Columns are partitioned in the order they are given. The partition splits are determined by the unique values in the partition columns. The above example creates a partitioned dataset that may look like: test ├── a=0 │   ├── 0bac803e32dc42ae83fddfd029cbdebc.parquet │   └──  ... └── a=1     ├── e6ab24a4f45147b49b54a662f0c412a3.parquet     └── ... ORC # Similar to the parquet format, the ORC Format is a binary columnar serialization for data frames. It is designed to make reading data frames efficient. pandas provides both the reader and the writer for the ORC format, read_orc() and to_orc() . This requires the pyarrow library. Warning It is highly recommended to install pyarrow using conda due to some issues occurred by pyarrow. to_orc() requires pyarrow>=7.0.0. read_orc() and to_orc() are not supported on Windows yet, you can find valid environments on install optional dependencies . For supported dtypes please refer to supported ORC features in Arrow . Currently timezones in datetime columns are not preserved when a dataframe is converted into ORC files. Write to an orc file. Read from an orc file. Read only certain columns of an orc file. SQL queries # The pandas.io.sql module provides a collection of query wrappers to both facilitate data retrieval and to reduce dependency on DB-specific API. Where available, users may first want to opt for Apache Arrow ADBC drivers. These drivers should provide the best performance, null handling, and type detection. New in version 2.2.0: Added native support for ADBC drivers For a full list of ADBC drivers and their development status, see the ADBC Driver Implementation Status documentation. Where an ADBC driver is not available or may be missing functionality, users should opt for installing SQLAlchemy alongside their database driver library. Examples of such drivers are psycopg2 for PostgreSQL or pymysql for MySQL. For SQLite this is included in Python’s standard library by default. You can find an overview of supported drivers for each SQL dialect in the SQLAlchemy docs . If SQLAlchemy is not installed, you can use a sqlite3.Connection in place of a SQLAlchemy engine, connection, or URI string. See also some cookbook examples for some advanced strategies. The key functions are: Note The function read_sql() is a convenience wrapper around read_sql_table() and read_sql_query() (and for backward compatibility) and will delegate to specific function depending on the provided input (database table name or sql query). Table names do not need to be quoted if they have special characters. In the following example, we use the SQlite SQL database engine. You can use a temporary SQLite database where data are stored in “memory”. To connect using an ADBC driver you will want to install the adbc_driver_sqlite using your package manager. Once installed, you can use the DBAPI interface provided by the ADBC driver to connect to your database. import adbc_driver_sqlite.dbapi as sqlite_dbapi # Create the connection with sqlite_dbapi . connect ( ""sqlite:///:memory:"" ) as conn : df = pd . read_sql_table ( ""data"" , conn ) To connect with SQLAlchemy you use the create_engine() function to create an engine object from database URI. You only need to create the engine once per database you are connecting to. For more information on create_engine() and the URI formatting, see the examples below and the SQLAlchemy documentation If you want to manage your own connections you can pass one of those instead. The example below opens a connection to the database using a Python context manager that automatically closes the connection after the block has completed. See the SQLAlchemy docs for an explanation of how the database connection is handled. with engine . connect () as conn , conn . begin (): data = pd . read_sql_table ( ""data"" , conn ) Warning When you open a connection to a database you are also responsible for closing it. Side effects of leaving a connection open may include locking the database or other breaking behaviour. Writing DataFrames # Assuming the following data is in a DataFrame data , we can insert it into the database using to_sql() . With some databases, writing large DataFrames can result in errors due to packet size limitations being exceeded. This can be avoided by setting the chunksize parameter when calling to_sql . For example, the following writes data to the database in batches of 1000 rows at a time: SQL data types # Ensuring consistent data type management across SQL databases is challenging. Not every SQL database offers the same types, and even when they do the implementation of a given type can vary in ways that have subtle effects on how types can be preserved. For the best odds at preserving database types users are advised to use ADBC drivers when available. The Arrow type system offers a wider array of types that more closely match database types than the historical pandas/NumPy type system. To illustrate, note this (non-exhaustive) listing of types available in different databases and pandas backends: Footnotes [ 1 ] ( 1 , 2 , 3 ) Not implemented as of writing, but theoretically possible If you are interested in preserving database types as best as possible throughout the lifecycle of your DataFrame, users are encouraged to leverage the dtype_backend=""pyarrow"" argument of read_sql() This will prevent your data from being converted to the traditional pandas/NumPy type system, which often converts SQL types in ways that make them impossible to round-trip. In case an ADBC driver is not available, to_sql() will try to map your data to an appropriate SQL data type based on the dtype of the data. When you have columns of dtype object , pandas will try to infer the data type. You can always override the default type by specifying the desired SQL type of any of the columns by using the dtype argument. This argument needs a dictionary mapping column names to SQLAlchemy types (or strings for the sqlite3 fallback mode). For example, specifying to use the sqlalchemy String type instead of the default Text type for string columns: Note Due to the limited support for timedelta’s in the different database flavors, columns with type timedelta64 will be written as integer values as nanoseconds to the database and a warning will be raised. The only exception to this is when using the ADBC PostgreSQL driver in which case a timedelta will be written to the database as an INTERVAL Note Columns of category dtype will be converted to the dense representation as you would get with np.asarray(categorical) (e.g. for string categories this gives an array of strings). Because of this, reading the database table back in does not generate a categorical. Datetime data types # Using ADBC or SQLAlchemy, to_sql() is capable of writing datetime data that is timezone naive or timezone aware. However, the resulting data stored in the database ultimately depends on the supported data type for datetime data of the database system being used. The following table lists supported data types for datetime data for some common databases. Other database dialects may have different data types for datetime data. When writing timezone aware data to databases that do not support timezones, the data will be written as timezone naive timestamps that are in local time with respect to the timezone. read_sql_table() is also capable of reading datetime data that is timezone aware or naive. When reading TIMESTAMP WITH TIME ZONE types, pandas will convert the data to UTC. Insertion method # The parameter method controls the SQL insertion clause used. Possible values are: None : Uses standard SQL INSERT clause (one per row). 'multi' : Pass multiple values in a single INSERT clause. It uses a special SQL syntax not supported by all backends. This usually provides better performance for analytic databases like Presto and Redshift , but has worse performance for traditional SQL backend if the table contains many columns. For more information check the SQLAlchemy documentation . callable with signature (pd_table, conn, keys, data_iter) : This can be used to implement a more performant insertion method based on specific backend dialect features. Example of a callable using PostgreSQL COPY clause : # Alternative to_sql() *method* for DBs that support COPY FROM import csv from io import StringIO def psql_insert_copy ( table , conn , keys , data_iter ): """""" Execute SQL statement inserting data Parameters ---------- table : pandas.io.sql.SQLTable conn : sqlalchemy.engine.Engine or sqlalchemy.engine.Connection keys : list of str Column names data_iter : Iterable that iterates the values to be inserted """""" # gets a DBAPI connection that can provide a cursor dbapi_conn = conn . connection with dbapi_conn . cursor () as cur : s_buf = StringIO () writer = csv . writer ( s_buf ) writer . writerows ( data_iter ) s_buf . seek ( 0 ) columns = ', ' . join ([ '"" {} ""' . format ( k ) for k in keys ]) if table . schema : table_name = ' {} . {} ' . format ( table . schema , table . name ) else : table_name = table . name sql = 'COPY {} ( {} ) FROM STDIN WITH CSV' . format ( table_name , columns ) cur . copy_expert ( sql = sql , file = s_buf ) Reading tables # read_sql_table() will read a database table given the table name and optionally a subset of columns to read. Note In order to use read_sql_table() , you must have the ADBC driver or SQLAlchemy optional dependency installed. Note ADBC drivers will map database types directly back to arrow types. For other drivers note that pandas infers column dtypes from query outputs, and not by looking up data types in the physical database schema. For example, assume userid is an integer column in a table. Then, intuitively, select userid ... will return integer-valued series, while select cast(userid as text) ... will return object-valued (str) series. Accordingly, if the query output is empty, then all resulting columns will be returned as object-valued (since they are most general). If you foresee that your query will sometimes generate an empty result, you may want to explicitly typecast afterwards to ensure dtype integrity. You can also specify the name of the column as the DataFrame index, and specify a subset of columns to be read. And you can explicitly force columns to be parsed as dates: If needed you can explicitly specify a format string, or a dict of arguments to pass to pandas.to_datetime() : pd . read_sql_table ( ""data"" , engine , parse_dates = { ""Date"" : ""%Y-%m- %d "" }) pd . read_sql_table ( ""data"" , engine , parse_dates = { ""Date"" : { ""format"" : ""%Y-%m- %d %H:%M:%S"" }}, ) You can check if a table exists using has_table() Schema support # Reading from and writing to different schema’s is supported through the schema keyword in the read_sql_table() and to_sql() functions. Note however that this depends on the database flavor (sqlite does not have schema’s). For example: df . to_sql ( name = ""table"" , con = engine , schema = ""other_schema"" ) pd . read_sql_table ( ""table"" , engine , schema = ""other_schema"" ) Querying # You can query using raw SQL in the read_sql_query() function. In this case you must use the SQL variant appropriate for your database. When using SQLAlchemy, you can also pass SQLAlchemy Expression language constructs, which are database-agnostic. Of course, you can specify a more “complex” query. The read_sql_query() function supports a chunksize argument. Specifying this will return an iterator through chunks of the query result: Engine connection examples # To connect with SQLAlchemy you use the create_engine() function to create an engine object from database URI. You only need to create the engine once per database you are connecting to. from sqlalchemy import create_engine engine = create_engine ( ""postgresql://scott:tiger@localhost:5432/mydatabase"" ) engine = create_engine ( ""mysql+mysqldb://scott:tiger@localhost/foo"" ) engine = create_engine ( ""oracle://scott: [email protected] :1521/sidname"" ) engine = create_engine ( ""mssql+pyodbc://mydsn"" ) # sqlite://<nohostname>/<path> # where <path> is relative: engine = create_engine ( ""sqlite:///foo.db"" ) # or absolute, starting with a slash: engine = create_engine ( ""sqlite:////absolute/path/to/foo.db"" ) For more information see the examples the SQLAlchemy documentation Advanced SQLAlchemy queries # You can use SQLAlchemy constructs to describe your query. Use sqlalchemy.text() to specify query parameters in a backend-neutral way If you have an SQLAlchemy description of your database you can express where conditions using SQLAlchemy expressions You can combine SQLAlchemy expressions with parameters passed to read_sql() using sqlalchemy.bindparam() Sqlite fallback # The use of sqlite is supported without using SQLAlchemy. This mode requires a Python database adapter which respect the Python DB-API . You can create connections like so: import sqlite3 con = sqlite3 . connect ( "":memory:"" ) And then issue the following queries: data . to_sql ( ""data"" , con ) pd . read_sql_query ( ""SELECT * FROM data"" , con ) Google BigQuery # The pandas-gbq package provides functionality to read/write from Google BigQuery. pandas integrates with this external package. if pandas-gbq is installed, you can use the pandas methods pd.read_gbq and DataFrame.to_gbq , which will call the respective functions from pandas-gbq . Full documentation can be found here . Stata format # Writing to stata format # The method DataFrame.to_stata() will write a DataFrame into a .dta file. The format version of this file is always 115 (Stata 12). Stata data files have limited data type support; only strings with 244 or fewer characters, int8 , int16 , int32 , float32 and float64 can be stored in .dta files. Additionally, Stata reserves certain values to represent missing data. Exporting a non-missing value that is outside of the permitted range in Stata for a particular data type will retype the variable to the next larger size. For example, int8 values are restricted to lie between -127 and 100 in Stata, and so variables with values above 100 will trigger a conversion to int16 . nan values in floating points data types are stored as the basic missing data type ( . in Stata ). Note It is not possible to export missing data values for integer data types. The Stata writer gracefully handles other data types including int64 , bool , uint8 , uint16 , uint32 by casting to the smallest supported type that can represent the data. For example, data with a type of uint8 will be cast to int8 if all values are less than 100 (the upper bound for non-missing int8 data in Stata ), or, if values are outside of this range, the variable is cast to int16 . Warning Conversion from int64 to float64 may result in a loss of precision if int64 values are larger than 2**53. Warning StataWriter and DataFrame.to_stata() only support fixed width strings containing up to 244 characters, a limitation imposed by the version 115 dta file format. Attempting to write Stata dta files with strings longer than 244 characters raises a ValueError . Reading from Stata format # The top-level function read_stata will read a dta file and return either a DataFrame or a pandas.api.typing.StataReader that can be used to read the file incrementally. Specifying a chunksize yields a pandas.api.typing.StataReader instance that can be used to read chunksize lines from the file at a time. The StataReader object can be used as an iterator. For more fine-grained control, use iterator=True and specify chunksize with each call to read() . Currently the index is retrieved as a column. The parameter convert_categoricals indicates whether value labels should be read and used to create a Categorical variable from them. Value labels can also be retrieved by the function value_labels , which requires read() to be called before use. The parameter convert_missing indicates whether missing value representations in Stata should be preserved. If False (the default), missing values are represented as np.nan . If True , missing values are represented using StataMissingValue objects, and columns containing missing values will have object data type. Note read_stata() and StataReader support .dta formats 113-115 (Stata 10-12), 117 (Stata 13), and 118 (Stata 14). Note Setting preserve_dtypes=False will upcast to the standard pandas data types: int64 for all integer types and float64 for floating point data. By default, the Stata data types are preserved when importing. Note All StataReader objects, whether created by read_stata() (when using iterator=True or chunksize ) or instantiated by hand, must be used as context managers (e.g. the with statement). While the close() method is available, its use is unsupported. It is not part of the public API and will be removed in with future without warning. Categorical data # Categorical data can be exported to Stata data files as value labeled data. The exported data consists of the underlying category codes as integer data values and the categories as value labels. Stata does not have an explicit equivalent to a Categorical and information about whether the variable is ordered is lost when exporting. Warning Stata only supports string value labels, and so str is called on the categories when exporting data. Exporting Categorical variables with non-string categories produces a warning, and can result a loss of information if the str representations of the categories are not unique. Labeled data can similarly be imported from Stata data files as Categorical variables using the keyword argument convert_categoricals ( True by default). The keyword argument order_categoricals ( True by default) determines whether imported Categorical variables are ordered. Note When importing categorical data, the values of the variables in the Stata data file are not preserved since Categorical variables always use integer data types between -1 and n-1 where n is the number of categories. If the original values in the Stata data file are required, these can be imported by setting convert_categoricals=False , which will import original data (but not the variable labels). The original values can be matched to the imported categorical data since there is a simple mapping between the original Stata data values and the category codes of imported Categorical variables: missing values are assigned code -1 , and the smallest original value is assigned 0 , the second smallest is assigned 1 and so on until the largest original value is assigned the code n-1 . Note Stata supports partially labeled series. These series have value labels for some but not all data values. Importing a partially labeled series will produce a Categorical with string categories for the values that are labeled and numeric categories for values with no label. SAS formats # The top-level function read_sas() can read (but not write) SAS XPORT (.xpt) and SAS7BDAT (.sas7bdat) format files. SAS files only contain two value types: ASCII text and floating point values (usually 8 bytes but sometimes truncated). For xport files, there is no automatic type conversion to integers, dates, or categoricals. For SAS7BDAT files, the format codes may allow date variables to be automatically converted to dates. By default the whole file is read and returned as a DataFrame . Specify a chunksize or use iterator=True to obtain reader objects ( XportReader or SAS7BDATReader ) for incrementally reading the file. The reader objects also have attributes that contain additional information about the file and its variables. Read a SAS7BDAT file: df = pd . read_sas ( ""sas_data.sas7bdat"" ) Obtain an iterator and read an XPORT file 100,000 lines at a time: def do_something ( chunk ): pass with pd . read_sas ( ""sas_xport.xpt"" , chunk = 100000 ) as rdr : for chunk in rdr : do_something ( chunk ) The specification for the xport file format is available from the SAS web site. No official documentation is available for the SAS7BDAT format. SPSS formats # The top-level function read_spss() can read (but not write) SPSS SAV (.sav) and ZSAV (.zsav) format files. SPSS files contain column names. By default the whole file is read, categorical columns are converted into pd.Categorical , and a DataFrame with all columns is returned. Specify the usecols parameter to obtain a subset of columns. Specify convert_categoricals=False to avoid converting categorical columns into pd.Categorical . Read an SPSS file: df = pd . read_spss ( ""spss_data.sav"" ) Extract a subset of columns contained in usecols from an SPSS file and avoid converting categorical columns into pd.Categorical : df = pd . read_spss ( ""spss_data.sav"" , usecols = [ ""foo"" , ""bar"" ], convert_categoricals = False , ) More information about the SAV and ZSAV file formats is available here . Other file formats # pandas itself only supports IO with a limited set of file formats that map cleanly to its tabular data model. For reading and writing other file formats into and from pandas, we recommend these packages from the broader community. netCDF # xarray provides data structures inspired by the pandas DataFrame for working with multi-dimensional datasets, with a focus on the netCDF file format and easy conversion to and from pandas. Performance considerations # This is an informal comparison of various IO methods, using pandas 0.24.2. Timings are machine dependent and small differences should be ignored. The following test functions will be used below to compare the performance of several IO methods: import numpy as np import os sz = 1000000 df = pd . DataFrame ({ ""A"" : np . random . randn ( sz ), ""B"" : [ 1 ] * sz }) sz = 1000000 np . random . seed ( 42 ) df = pd . DataFrame ({ ""A"" : np . random . randn ( sz ), ""B"" : [ 1 ] * sz }) def test_sql_write ( df ): if os . path . exists ( ""test.sql"" ): os . remove ( ""test.sql"" ) sql_db = sqlite3 . connect ( ""test.sql"" ) df . to_sql ( name = ""test_table"" , con = sql_db ) sql_db . close () def test_sql_read (): sql_db = sqlite3 . connect ( ""test.sql"" ) pd . read_sql_query ( ""select * from test_table"" , sql_db ) sql_db . close () def test_hdf_fixed_write ( df ): df . to_hdf ( ""test_fixed.hdf"" , key = ""test"" , mode = ""w"" ) def test_hdf_fixed_read (): pd . read_hdf ( ""test_fixed.hdf"" , ""test"" ) def test_hdf_fixed_write_compress ( df ): df . to_hdf ( ""test_fixed_compress.hdf"" , key = ""test"" , mode = ""w"" , complib = ""blosc"" ) def test_hdf_fixed_read_compress (): pd . read_hdf ( ""test_fixed_compress.hdf"" , ""test"" ) def test_hdf_table_write ( df ): df . to_hdf ( ""test_table.hdf"" , key = ""test"" , mode = ""w"" , format = ""table"" ) def test_hdf_table_read (): pd . read_hdf ( ""test_table.hdf"" , ""test"" ) def test_hdf_table_write_compress ( df ): df . to_hdf ( ""test_table_compress.hdf"" , key = ""test"" , mode = ""w"" , complib = ""blosc"" , format = ""table"" ) def test_hdf_table_read_compress (): pd . read_hdf ( ""test_table_compress.hdf"" , ""test"" ) def test_csv_write ( df ): df . to_csv ( ""test.csv"" , mode = ""w"" ) def test_csv_read (): pd . read_csv ( ""test.csv"" , index_col = 0 ) def test_feather_write ( df ): df . to_feather ( ""test.feather"" ) def test_feather_read (): pd . read_feather ( ""test.feather"" ) def test_pickle_write ( df ): df . to_pickle ( ""test.pkl"" ) def test_pickle_read (): pd . read_pickle ( ""test.pkl"" ) def test_pickle_write_compress ( df ): df . to_pickle ( ""test.pkl.compress"" , compression = ""xz"" ) def test_pickle_read_compress (): pd . read_pickle ( ""test.pkl.compress"" , compression = ""xz"" ) def test_parquet_write ( df ): df . to_parquet ( ""test.parquet"" ) def test_parquet_read (): pd . read_parquet ( ""test.parquet"" ) When writing, the top three functions in terms of speed are test_feather_write , test_hdf_fixed_write and test_hdf_fixed_write_compress . When reading, the top three functions in terms of speed are test_feather_read , test_pickle_read and test_hdf_fixed_read . The files test.pkl.compress , test.parquet and test.feather took the least space on disk (in bytes). 29519500 Oct 10 06:45 test.csv 16000248 Oct 10 06:45 test.feather 8281983  Oct 10 06:49 test.parquet 16000857 Oct 10 06:47 test.pkl 7552144  Oct 10 06:48 test.pkl.compress 34816000 Oct 10 06:42 test.sql 24009288 Oct 10 06:43 test_fixed.hdf 24009288 Oct 10 06:43 test_fixed_compress.hdf 24458940 Oct 10 06:44 test_table.hdf 24458940 Oct 10 06:44 test_table_compress.hdf"
https://pandas.pydata.org/docs/user_guide/pyarrow.html,PyArrow Functionality,"<article class=""bd-article"" role=""main"">
<section id=""pyarrow-functionality"">
<span id=""pyarrow""></span><h1>PyArrow Functionality<a class=""headerlink"" href=""#pyarrow-functionality"" title=""Link to this heading"">#</a></h1>
<p>pandas can utilize <a class=""reference external"" href=""https://arrow.apache.org/docs/python/index.html"">PyArrow</a> to extend functionality and improve the performance
of various APIs. This includes:</p>
<ul class=""simple"">
<li><p>More extensive <a class=""reference external"" href=""https://arrow.apache.org/docs/python/api/datatypes.html"">data types</a> compared to NumPy</p></li>
<li><p>Missing data support (NA) for all data types</p></li>
<li><p>Performant IO reader integration</p></li>
<li><p>Facilitate interoperability with other dataframe libraries based on the Apache Arrow specification (e.g. polars, cuDF)</p></li>
</ul>
<p>To use this functionality, please ensure you have <a class=""reference internal"" href=""../getting_started/install.html#install-optional-dependencies""><span class=""std std-ref"">installed the minimum supported PyArrow version.</span></a></p>
<section id=""data-structure-integration"">
<h2>Data Structure Integration<a class=""headerlink"" href=""#data-structure-integration"" title=""Link to this heading"">#</a></h2>
<p>A <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a>, or the columns of a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> can be directly backed by a <a class=""reference external"" href=""https://arrow.apache.org/docs/python/generated/pyarrow.ChunkedArray.html#pyarrow.ChunkedArray"" title=""(in Apache Arrow v15.0.2)""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">pyarrow.ChunkedArray</span></code></a>
which is similar to a NumPy array. To construct these from the main pandas data structures, you can pass in a string of the type followed by
<code class=""docutils literal notranslate""><span class=""pre"">[pyarrow]</span></code>, e.g. <code class=""docutils literal notranslate""><span class=""pre"">""int64[pyarrow]""""</span></code> into the <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code> parameter</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The string alias <code class=""docutils literal notranslate""><span class=""pre"">""string[pyarrow]""</span></code> maps to <code class=""docutils literal notranslate""><span class=""pre"">pd.StringDtype(""pyarrow"")</span></code> which is not equivalent to
specifying <code class=""docutils literal notranslate""><span class=""pre"">dtype=pd.ArrowDtype(pa.string())</span></code>. Generally, operations on the data will behave similarly
except <code class=""docutils literal notranslate""><span class=""pre"">pd.StringDtype(""pyarrow"")</span></code> can return NumPy-backed nullable types while <code class=""docutils literal notranslate""><span class=""pre"">pd.ArrowDtype(pa.string())</span></code>
will return <a class=""reference internal"" href=""../reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"" title=""pandas.ArrowDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">ArrowDtype</span></code></a>.</p>

</div>
<p>For PyArrow types that accept parameters, you can pass in a PyArrow type with those parameters
into <a class=""reference internal"" href=""../reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"" title=""pandas.ArrowDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">ArrowDtype</span></code></a> to use in the <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code> parameter.</p>



<p>If you already have an <a class=""reference external"" href=""https://arrow.apache.org/docs/python/generated/pyarrow.Array.html#pyarrow.Array"" title=""(in Apache Arrow v15.0.2)""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">pyarrow.Array</span></code></a> or <a class=""reference external"" href=""https://arrow.apache.org/docs/python/generated/pyarrow.ChunkedArray.html#pyarrow.ChunkedArray"" title=""(in Apache Arrow v15.0.2)""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">pyarrow.ChunkedArray</span></code></a>,
you can pass it into <a class=""reference internal"" href=""../reference/api/pandas.arrays.ArrowExtensionArray.html#pandas.arrays.ArrowExtensionArray"" title=""pandas.arrays.ArrowExtensionArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">arrays.ArrowExtensionArray</span></code></a> to construct the associated <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a>
or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> object.</p>

<p>To retrieve a pyarrow <a class=""reference external"" href=""https://arrow.apache.org/docs/python/generated/pyarrow.ChunkedArray.html#pyarrow.ChunkedArray"" title=""(in Apache Arrow v15.0.2)""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">pyarrow.ChunkedArray</span></code></a> from a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a>, you can call
the pyarrow array constructor on the <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a>.</p>

<p>To convert a <a class=""reference external"" href=""https://arrow.apache.org/docs/python/generated/pyarrow.Table.html#pyarrow.Table"" title=""(in Apache Arrow v15.0.2)""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">pyarrow.Table</span></code></a> to a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>, you can call the
<a class=""reference external"" href=""https://arrow.apache.org/docs/python/generated/pyarrow.Table.html#pyarrow.Table.to_pandas"" title=""(in Apache Arrow v15.0.2)""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">pyarrow.Table.to_pandas()</span></code></a> method with <code class=""docutils literal notranslate""><span class=""pre"">types_mapper=pd.ArrowDtype</span></code>.</p>

</section>
<section id=""operations"">
<h2>Operations<a class=""headerlink"" href=""#operations"" title=""Link to this heading"">#</a></h2>
<p>PyArrow data structure integration is implemented through pandas’ <a class=""reference internal"" href=""../reference/api/pandas.api.extensions.ExtensionArray.html#pandas.api.extensions.ExtensionArray"" title=""pandas.api.extensions.ExtensionArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">ExtensionArray</span></code></a> <a class=""reference internal"" href=""../development/extending.html#extending-extension-types""><span class=""std std-ref"">interface</span></a>;
therefore, supported functionality exists where this interface is integrated within the pandas API. Additionally, this functionality
is accelerated with PyArrow <a class=""reference external"" href=""https://arrow.apache.org/docs/python/api/compute.html"">compute functions</a> where available. This includes:</p>
<ul class=""simple"">
<li><p>Numeric aggregations</p></li>
<li><p>Numeric arithmetic</p></li>
<li><p>Numeric rounding</p></li>
<li><p>Logical and comparison functions</p></li>
<li><p>String functionality</p></li>
<li><p>Datetime functionality</p></li>
</ul>
<p>The following are just some examples of operations that are accelerated by native PyArrow compute functions.</p>



</section>
<section id=""i-o-reading"">
<h2>I/O Reading<a class=""headerlink"" href=""#i-o-reading"" title=""Link to this heading"">#</a></h2>
<p>PyArrow also provides IO reading functionality that has been integrated into several pandas IO readers. The following
functions provide an <code class=""docutils literal notranslate""><span class=""pre"">engine</span></code> keyword that can dispatch to PyArrow to accelerate reading from an IO source.</p>
<ul class=""simple"">
<li><p><a class=""reference internal"" href=""../reference/api/pandas.read_csv.html#pandas.read_csv"" title=""pandas.read_csv""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_csv()</span></code></a></p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.read_json.html#pandas.read_json"" title=""pandas.read_json""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_json()</span></code></a></p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.read_orc.html#pandas.read_orc"" title=""pandas.read_orc""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_orc()</span></code></a></p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.read_feather.html#pandas.read_feather"" title=""pandas.read_feather""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">read_feather()</span></code></a></p></li>
</ul>

<p>By default, these functions and all other IO reader functions return NumPy-backed data. These readers can return
PyArrow-backed data by specifying the parameter <code class=""docutils literal notranslate""><span class=""pre"">dtype_backend=""pyarrow""</span></code>. A reader does not need to set
<code class=""docutils literal notranslate""><span class=""pre"">engine=""pyarrow""</span></code> to necessarily return PyArrow-backed data.</p>

<p>Several non-IO reader functions can also use the <code class=""docutils literal notranslate""><span class=""pre"">dtype_backend</span></code> argument to return PyArrow-backed data including:</p>
<ul class=""simple"">
<li><p><a class=""reference internal"" href=""../reference/api/pandas.to_numeric.html#pandas.to_numeric"" title=""pandas.to_numeric""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">to_numeric()</span></code></a></p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.convert_dtypes.html#pandas.DataFrame.convert_dtypes"" title=""pandas.DataFrame.convert_dtypes""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.convert_dtypes()</span></code></a></p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.Series.convert_dtypes.html#pandas.Series.convert_dtypes"" title=""pandas.Series.convert_dtypes""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.convert_dtypes()</span></code></a></p></li>
</ul>
</section>
</section>
</article>","PyArrow Functionality # pandas can utilize PyArrow to extend functionality and improve the performance of various APIs. This includes: More extensive data types compared to NumPy Missing data support (NA) for all data types Performant IO reader integration Facilitate interoperability with other dataframe libraries based on the Apache Arrow specification (e.g. polars, cuDF) To use this functionality, please ensure you have installed the minimum supported PyArrow version. Data Structure Integration # A Series , Index , or the columns of a DataFrame can be directly backed by a pyarrow.ChunkedArray which is similar to a NumPy array. To construct these from the main pandas data structures, you can pass in a string of the type followed by [pyarrow] , e.g. ""int64[pyarrow]"""" into the dtype parameter Note The string alias ""string[pyarrow]"" maps to pd.StringDtype(""pyarrow"") which is not equivalent to specifying dtype=pd.ArrowDtype(pa.string()) . Generally, operations on the data will behave similarly except pd.StringDtype(""pyarrow"") can return NumPy-backed nullable types while pd.ArrowDtype(pa.string()) will return ArrowDtype . For PyArrow types that accept parameters, you can pass in a PyArrow type with those parameters into ArrowDtype to use in the dtype parameter. If you already have an pyarrow.Array or pyarrow.ChunkedArray , you can pass it into arrays.ArrowExtensionArray to construct the associated Series , Index or DataFrame object. To retrieve a pyarrow pyarrow.ChunkedArray from a Series or Index , you can call the pyarrow array constructor on the Series or Index . To convert a pyarrow.Table to a DataFrame , you can call the pyarrow.Table.to_pandas() method with types_mapper=pd.ArrowDtype . Operations # PyArrow data structure integration is implemented through pandas’ ExtensionArray interface ; therefore, supported functionality exists where this interface is integrated within the pandas API. Additionally, this functionality is accelerated with PyArrow compute functions where available. This includes: Numeric aggregations Numeric arithmetic Numeric rounding Logical and comparison functions String functionality Datetime functionality The following are just some examples of operations that are accelerated by native PyArrow compute functions. I/O Reading # PyArrow also provides IO reading functionality that has been integrated into several pandas IO readers. The following functions provide an engine keyword that can dispatch to PyArrow to accelerate reading from an IO source. read_csv() read_json() read_orc() read_feather() By default, these functions and all other IO reader functions return NumPy-backed data. These readers can return PyArrow-backed data by specifying the parameter dtype_backend=""pyarrow"" . A reader does not need to set engine=""pyarrow"" to necessarily return PyArrow-backed data. Several non-IO reader functions can also use the dtype_backend argument to return PyArrow-backed data including: to_numeric() DataFrame.convert_dtypes() Series.convert_dtypes()"
https://pandas.pydata.org/docs/user_guide/indexing.html,Indexing and selecting data,"<article class=""bd-article"" role=""main"">
<section id=""indexing-and-selecting-data"">
<span id=""indexing""></span><h1>Indexing and selecting data<a class=""headerlink"" href=""#indexing-and-selecting-data"" title=""Link to this heading"">#</a></h1>
<p>The axis labeling information in pandas objects serves many purposes:</p>
<ul class=""simple"">
<li><p>Identifies data (i.e. provides <em>metadata</em>) using known indicators,
important for analysis, visualization, and interactive console display.</p></li>
<li><p>Enables automatic and explicit data alignment.</p></li>
<li><p>Allows intuitive getting and setting of subsets of the data set.</p></li>
</ul>
<p>In this section, we will focus on the final point: namely, how to slice, dice,
and generally get and set subsets of pandas objects. The primary focus will be
on Series and DataFrame as they have received more development attention in
this area.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The Python and NumPy indexing operators <code class=""docutils literal notranslate""><span class=""pre"">[]</span></code> and attribute operator <code class=""docutils literal notranslate""><span class=""pre"">.</span></code>
provide quick and easy access to pandas data structures across a wide range
of use cases. This makes interactive work intuitive, as there’s little new
to learn if you already know how to deal with Python dictionaries and NumPy
arrays. However, since the type of the data to be accessed isn’t known in
advance, directly using standard operators has some optimization limits. For
production code, we recommended that you take advantage of the optimized
pandas data access methods exposed in this chapter.</p>
</div>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Whether a copy or a reference is returned for a setting operation, may
depend on the context. This is sometimes called <code class=""docutils literal notranslate""><span class=""pre"">chained</span> <span class=""pre"">assignment</span></code> and
should be avoided. See <a class=""reference internal"" href=""#indexing-view-versus-copy""><span class=""std std-ref"">Returning a View versus Copy</span></a>.</p>
</div>
<p>See the <a class=""reference internal"" href=""advanced.html#advanced""><span class=""std std-ref"">MultiIndex / Advanced Indexing</span></a> for <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> and more advanced indexing documentation.</p>
<p>See the <a class=""reference internal"" href=""cookbook.html#cookbook-selection""><span class=""std std-ref"">cookbook</span></a> for some advanced strategies.</p>
<section id=""different-choices-for-indexing"">
<span id=""indexing-choice""></span><h2>Different choices for indexing<a class=""headerlink"" href=""#different-choices-for-indexing"" title=""Link to this heading"">#</a></h2>
<p>Object selection has had a number of user-requested additions in order to
support more explicit location based indexing. pandas now supports three types
of multi-axis indexing.</p>
<ul>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code> is primarily label based, but may also be used with a boolean array. <code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code> will raise <code class=""docutils literal notranslate""><span class=""pre"">KeyError</span></code> when the items are not found. Allowed inputs are:</p>
<blockquote>
<div><ul class=""simple"">
<li><p>A single label, e.g. <code class=""docutils literal notranslate""><span class=""pre"">5</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">'a'</span></code> (Note that <code class=""docutils literal notranslate""><span class=""pre"">5</span></code> is interpreted as a
<em>label</em> of the index. This use is <strong>not</strong> an integer position along the
index.).</p></li>
<li><p>A list or array of labels <code class=""docutils literal notranslate""><span class=""pre"">['a',</span> <span class=""pre"">'b',</span> <span class=""pre"">'c']</span></code>.</p></li>
<li><p>A slice object with labels <code class=""docutils literal notranslate""><span class=""pre"">'a':'f'</span></code> (Note that contrary to usual Python
slices, <strong>both</strong> the start and the stop are included, when present in the
index! See <a class=""reference internal"" href=""#indexing-slicing-with-labels""><span class=""std std-ref"">Slicing with labels</span></a>
and <a class=""reference internal"" href=""advanced.html#advanced-endpoints-are-inclusive""><span class=""std std-ref"">Endpoints are inclusive</span></a>.)</p></li>
<li><p>A boolean array (any <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> values will be treated as <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>).</p></li>
<li><p>A <code class=""docutils literal notranslate""><span class=""pre"">callable</span></code> function with one argument (the calling Series or DataFrame) and
that returns valid output for indexing (one of the above).</p></li>
<li><p>A tuple of row (and column) indices whose elements are one of the
above inputs.</p></li>
</ul>
</div></blockquote>
<p>See more at <a class=""reference internal"" href=""#indexing-label""><span class=""std std-ref"">Selection by Label</span></a>.</p>
</li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">.iloc</span></code> is primarily integer position based (from <code class=""docutils literal notranslate""><span class=""pre"">0</span></code> to
<code class=""docutils literal notranslate""><span class=""pre"">length-1</span></code> of the axis), but may also be used with a boolean
array. <code class=""docutils literal notranslate""><span class=""pre"">.iloc</span></code> will raise <code class=""docutils literal notranslate""><span class=""pre"">IndexError</span></code> if a requested
indexer is out-of-bounds, except <em>slice</em> indexers which allow
out-of-bounds indexing. (this conforms with Python/NumPy <em>slice</em>
semantics). Allowed inputs are:</p>
<blockquote>
<div><ul class=""simple"">
<li><p>An integer e.g. <code class=""docutils literal notranslate""><span class=""pre"">5</span></code>.</p></li>
<li><p>A list or array of integers <code class=""docutils literal notranslate""><span class=""pre"">[4,</span> <span class=""pre"">3,</span> <span class=""pre"">0]</span></code>.</p></li>
<li><p>A slice object with ints <code class=""docutils literal notranslate""><span class=""pre"">1:7</span></code>.</p></li>
<li><p>A boolean array (any <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> values will be treated as <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>).</p></li>
<li><p>A <code class=""docutils literal notranslate""><span class=""pre"">callable</span></code> function with one argument (the calling Series or DataFrame) and
that returns valid output for indexing (one of the above).</p></li>
<li><p>A tuple of row (and column) indices whose elements are one of the
above inputs.</p></li>
</ul>
</div></blockquote>
<p>See more at <a class=""reference internal"" href=""#indexing-integer""><span class=""std std-ref"">Selection by Position</span></a>,
<a class=""reference internal"" href=""advanced.html#advanced""><span class=""std std-ref"">Advanced Indexing</span></a> and <a class=""reference internal"" href=""advanced.html#advanced-advanced-hierarchical""><span class=""std std-ref"">Advanced
Hierarchical</span></a>.</p>
</li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">.iloc</span></code>, and also <code class=""docutils literal notranslate""><span class=""pre"">[]</span></code> indexing can accept a <code class=""docutils literal notranslate""><span class=""pre"">callable</span></code> as indexer. See more at <a class=""reference internal"" href=""#indexing-callable""><span class=""std std-ref"">Selection By Callable</span></a>.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Destructuring tuple keys into row (and column) indexes occurs
<em>before</em> callables are applied, so you cannot return a tuple from
a callable to index both rows and columns.</p>
</div>
</li>
</ul>
<p>Getting values from an object with multi-axes selection uses the following
notation (using <code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code> as an example, but the following applies to <code class=""docutils literal notranslate""><span class=""pre"">.iloc</span></code> as
well). Any of the axes accessors may be the null slice <code class=""docutils literal notranslate""><span class=""pre"">:</span></code>. Axes left out of
the specification are assumed to be <code class=""docutils literal notranslate""><span class=""pre"">:</span></code>, e.g. <code class=""docutils literal notranslate""><span class=""pre"">p.loc['a']</span></code> is equivalent to
<code class=""docutils literal notranslate""><span class=""pre"">p.loc['a',</span> <span class=""pre"">:]</span></code>.</p>

</section>
<section id=""basics"">
<span id=""indexing-basics""></span><h2>Basics<a class=""headerlink"" href=""#basics"" title=""Link to this heading"">#</a></h2>
<p>As mentioned when introducing the data structures in the <a class=""reference internal"" href=""basics.html#basics""><span class=""std std-ref"">last section</span></a>, the primary function of indexing with <code class=""docutils literal notranslate""><span class=""pre"">[]</span></code> (a.k.a. <code class=""docutils literal notranslate""><span class=""pre"">__getitem__</span></code>
for those familiar with implementing class behavior in Python) is selecting out
lower-dimensional slices. The following table shows return type values when
indexing pandas objects with <code class=""docutils literal notranslate""><span class=""pre"">[]</span></code>:</p>

<p>Here we construct a simple time series data set to use for illustrating the
indexing functionality:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>None of the indexing functionality is time series specific unless
specifically stated.</p>
</div>
<p>Thus, as per above, we have the most basic indexing using <code class=""docutils literal notranslate""><span class=""pre"">[]</span></code>:</p>

<p>You can pass a list of columns to <code class=""docutils literal notranslate""><span class=""pre"">[]</span></code> to select columns in that order.
If a column is not contained in the DataFrame, an exception will be
raised. Multiple columns can also be set in this manner:</p>

<p>You may find this useful for applying a transform (in-place) to a subset of the
columns.</p>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>pandas aligns all AXES when setting <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> from <code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code>.</p>
<p>This will <strong>not</strong> modify <code class=""docutils literal notranslate""><span class=""pre"">df</span></code> because the column alignment is before value assignment.</p>

<p>The correct way to swap column values is by using raw values:</p>

<p>However, pandas does not align AXES when setting <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> from <code class=""docutils literal notranslate""><span class=""pre"">.iloc</span></code>
because <code class=""docutils literal notranslate""><span class=""pre"">.iloc</span></code> operates by position.</p>
<p>This will modify <code class=""docutils literal notranslate""><span class=""pre"">df</span></code> because the column alignment is not done before value assignment.</p>

</div>
</section>
<section id=""attribute-access"">
<h2>Attribute access<a class=""headerlink"" href=""#attribute-access"" title=""Link to this heading"">#</a></h2>
<p id=""indexing-attribute-access""><span id=""indexing-df-cols""></span><span id=""indexing-columns-multiple""></span>You may access an index on a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> or column on a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> directly
as an attribute:</p>



<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<ul class=""simple"">
<li><p>You can use this access only if the index element is a valid Python identifier, e.g. <code class=""docutils literal notranslate""><span class=""pre"">s.1</span></code> is not allowed.
See <a class=""reference external"" href=""https://docs.python.org/3/reference/lexical_analysis.html#identifiers"">here for an explanation of valid identifiers</a>.</p></li>
<li><p>The attribute will not be available if it conflicts with an existing method name, e.g. <code class=""docutils literal notranslate""><span class=""pre"">s.min</span></code> is not allowed, but <code class=""docutils literal notranslate""><span class=""pre"">s['min']</span></code> is possible.</p></li>
<li><p>Similarly, the attribute will not be available if it conflicts with any of the following list: <code class=""docutils literal notranslate""><span class=""pre"">index</span></code>,
<code class=""docutils literal notranslate""><span class=""pre"">major_axis</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">minor_axis</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">items</span></code>.</p></li>
<li><p>In any of these cases, standard indexing will still work, e.g. <code class=""docutils literal notranslate""><span class=""pre"">s['1']</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">s['min']</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">s['index']</span></code> will
access the corresponding element or column.</p></li>
</ul>
</div>
<p>If you are using the IPython environment, you may also use tab-completion to
see these accessible attributes.</p>
<p>You can also assign a <code class=""docutils literal notranslate""><span class=""pre"">dict</span></code> to a row of a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>:</p>

<p>You can use attribute access to modify an existing element of a Series or column of a DataFrame, but be careful;
if you try to use attribute access to create a new column, it creates a new attribute rather than a
new column and will this raise a <code class=""docutils literal notranslate""><span class=""pre"">UserWarning</span></code>:</p>

</section>
<section id=""slicing-ranges"">
<h2>Slicing ranges<a class=""headerlink"" href=""#slicing-ranges"" title=""Link to this heading"">#</a></h2>
<p>The most robust and consistent way of slicing ranges along arbitrary axes is
described in the <a class=""reference internal"" href=""#indexing-integer""><span class=""std std-ref"">Selection by Position</span></a> section
detailing the <code class=""docutils literal notranslate""><span class=""pre"">.iloc</span></code> method. For now, we explain the semantics of slicing using the <code class=""docutils literal notranslate""><span class=""pre"">[]</span></code> operator.</p>
<p>With Series, the syntax works exactly as with an ndarray, returning a slice of
the values and the corresponding labels:</p>

<p>Note that setting works as well:</p>

<p>With DataFrame, slicing inside of <code class=""docutils literal notranslate""><span class=""pre"">[]</span></code> <strong>slices the rows</strong>. This is provided
largely as a convenience since it is such a common operation.</p>

</section>
<section id=""selection-by-label"">
<span id=""indexing-label""></span><h2>Selection by label<a class=""headerlink"" href=""#selection-by-label"" title=""Link to this heading"">#</a></h2>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Whether a copy or a reference is returned for a setting operation, may depend on the context.
This is sometimes called <code class=""docutils literal notranslate""><span class=""pre"">chained</span> <span class=""pre"">assignment</span></code> and should be avoided.
See <a class=""reference internal"" href=""#indexing-view-versus-copy""><span class=""std std-ref"">Returning a View versus Copy</span></a>.</p>
</div>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<blockquote>
<div><p><code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code> is strict when you present slicers that are not compatible (or convertible) with the index type. For example
using integers in a <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code>. These will raise a <code class=""docutils literal notranslate""><span class=""pre"">TypeError</span></code>.</p>

</div></blockquote>
<p>String likes in slicing <em>can</em> be convertible to the type of the index and lead to natural slicing.</p>

</div>
<p>pandas provides a suite of methods in order to have <strong>purely label based indexing</strong>. This is a strict inclusion based protocol.
Every label asked for must be in the index, or a <code class=""docutils literal notranslate""><span class=""pre"">KeyError</span></code> will be raised.
When slicing, both the start bound <strong>AND</strong> the stop bound are <em>included</em>, if present in the index.
Integers are valid labels, but they refer to the label <strong>and not the position</strong>.</p>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code> attribute is the primary access method. The following are valid inputs:</p>
<ul class=""simple"">
<li><p>A single label, e.g. <code class=""docutils literal notranslate""><span class=""pre"">5</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">'a'</span></code> (Note that <code class=""docutils literal notranslate""><span class=""pre"">5</span></code> is interpreted as a <em>label</em> of the index. This use is <strong>not</strong> an integer position along the index.).</p></li>
<li><p>A list or array of labels <code class=""docutils literal notranslate""><span class=""pre"">['a',</span> <span class=""pre"">'b',</span> <span class=""pre"">'c']</span></code>.</p></li>
<li><p>A slice object with labels <code class=""docutils literal notranslate""><span class=""pre"">'a':'f'</span></code> (Note that contrary to usual Python
slices, <strong>both</strong> the start and the stop are included, when present in the
index! See <a class=""reference internal"" href=""#indexing-slicing-with-labels""><span class=""std std-ref"">Slicing with labels</span></a>.</p></li>
<li><p>A boolean array.</p></li>
<li><p>A <code class=""docutils literal notranslate""><span class=""pre"">callable</span></code>, see <a class=""reference internal"" href=""#indexing-callable""><span class=""std std-ref"">Selection By Callable</span></a>.</p></li>
</ul>

<p>Note that setting works as well:</p>

<p>With a DataFrame:</p>

<p>Accessing via label slices:</p>

<p>For getting a cross section using a label (equivalent to <code class=""docutils literal notranslate""><span class=""pre"">df.xs('a')</span></code>):</p>

<p>For getting values with a boolean array:</p>

<p>NA values in a boolean array propagate as <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>:</p>

<p>For getting a value explicitly:</p>

<section id=""slicing-with-labels"">
<span id=""indexing-slicing-with-labels""></span><h3>Slicing with labels<a class=""headerlink"" href=""#slicing-with-labels"" title=""Link to this heading"">#</a></h3>
<p>When using <code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code> with slices, if both the start and the stop labels are
present in the index, then elements <em>located</em> between the two (including them)
are returned:</p>

<p>If at least one of the two is absent, but the index is sorted, and can be
compared against start and stop labels, then slicing will still work as
expected, by selecting labels which <em>rank</em> between the two:</p>

<p>However, if at least one of the two is absent <em>and</em> the index is not sorted, an
error will be raised (since doing otherwise would be computationally expensive,
as well as potentially ambiguous for mixed type indexes). For instance, in the
above example, <code class=""docutils literal notranslate""><span class=""pre"">s.loc[1:6]</span></code> would raise <code class=""docutils literal notranslate""><span class=""pre"">KeyError</span></code>.</p>
<p>For the rationale behind this behavior, see
<a class=""reference internal"" href=""advanced.html#advanced-endpoints-are-inclusive""><span class=""std std-ref"">Endpoints are inclusive</span></a>.</p>

<p>Also, if the index has duplicate labels <em>and</em> either the start or the stop label is duplicated,
an error will be raised. For instance, in the above example, <code class=""docutils literal notranslate""><span class=""pre"">s.loc[2:5]</span></code> would raise a <code class=""docutils literal notranslate""><span class=""pre"">KeyError</span></code>.</p>
<p>For more information about duplicate labels, see
<a class=""reference internal"" href=""duplicates.html#duplicates""><span class=""std std-ref"">Duplicate Labels</span></a>.</p>
</section>
</section>
<section id=""selection-by-position"">
<span id=""indexing-integer""></span><h2>Selection by position<a class=""headerlink"" href=""#selection-by-position"" title=""Link to this heading"">#</a></h2>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Whether a copy or a reference is returned for a setting operation, may depend on the context.
This is sometimes called <code class=""docutils literal notranslate""><span class=""pre"">chained</span> <span class=""pre"">assignment</span></code> and should be avoided.
See <a class=""reference internal"" href=""#indexing-view-versus-copy""><span class=""std std-ref"">Returning a View versus Copy</span></a>.</p>
</div>
<p>pandas provides a suite of methods in order to get <strong>purely integer based indexing</strong>. The semantics follow closely Python and NumPy slicing. These are <code class=""docutils literal notranslate""><span class=""pre"">0-based</span></code> indexing. When slicing, the start bound is <em>included</em>, while the upper bound is <em>excluded</em>. Trying to use a non-integer, even a <strong>valid</strong> label will raise an <code class=""docutils literal notranslate""><span class=""pre"">IndexError</span></code>.</p>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">.iloc</span></code> attribute is the primary access method. The following are valid inputs:</p>
<ul class=""simple"">
<li><p>An integer e.g. <code class=""docutils literal notranslate""><span class=""pre"">5</span></code>.</p></li>
<li><p>A list or array of integers <code class=""docutils literal notranslate""><span class=""pre"">[4,</span> <span class=""pre"">3,</span> <span class=""pre"">0]</span></code>.</p></li>
<li><p>A slice object with ints <code class=""docutils literal notranslate""><span class=""pre"">1:7</span></code>.</p></li>
<li><p>A boolean array.</p></li>
<li><p>A <code class=""docutils literal notranslate""><span class=""pre"">callable</span></code>, see <a class=""reference internal"" href=""#indexing-callable""><span class=""std std-ref"">Selection By Callable</span></a>.</p></li>
<li><p>A tuple of row (and column) indexes, whose elements are one of the
above types.</p></li>
</ul>

<p>Note that setting works as well:</p>

<p>With a DataFrame:</p>

<p>Select via integer slicing:</p>

<p>Select via integer list:</p>




<p>For getting a cross section using an integer position (equiv to <code class=""docutils literal notranslate""><span class=""pre"">df.xs(1)</span></code>):</p>

<p>Out of range slice indexes are handled gracefully just as in Python/NumPy.</p>

<p>Note that using slices that go out of bounds can result in
an empty axis (e.g. an empty DataFrame being returned).</p>

<p>A single indexer that is out of bounds will raise an <code class=""docutils literal notranslate""><span class=""pre"">IndexError</span></code>.
A list of indexers where any element is out of bounds will raise an
<code class=""docutils literal notranslate""><span class=""pre"">IndexError</span></code>.</p>


</section>
<section id=""selection-by-callable"">
<span id=""indexing-callable""></span><h2>Selection by callable<a class=""headerlink"" href=""#selection-by-callable"" title=""Link to this heading"">#</a></h2>
<p><code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">.iloc</span></code>, and also <code class=""docutils literal notranslate""><span class=""pre"">[]</span></code> indexing can accept a <code class=""docutils literal notranslate""><span class=""pre"">callable</span></code> as indexer.
The <code class=""docutils literal notranslate""><span class=""pre"">callable</span></code> must be a function with one argument (the calling Series or DataFrame) that returns valid output for indexing.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>For <code class=""docutils literal notranslate""><span class=""pre"">.iloc</span></code> indexing, returning a tuple from the callable is
not supported, since tuple destructuring for row and column indexes
occurs <em>before</em> applying callables.</p>
</div>

<p>You can use callable indexing in <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>.</p>

<p>Using these methods / indexers, you can chain data selection operations
without using a temporary variable.</p>

</section>
<section id=""combining-positional-and-label-based-indexing"">
<span id=""id1""></span><h2>Combining positional and label-based indexing<a class=""headerlink"" href=""#combining-positional-and-label-based-indexing"" title=""Link to this heading"">#</a></h2>
<p>If you wish to get the 0th and the 2nd elements from the index in the ‘A’ column, you can do:</p>

<p>This can also be expressed using <code class=""docutils literal notranslate""><span class=""pre"">.iloc</span></code>, by explicitly getting locations on the indexers, and using
<em>positional</em> indexing to select things.</p>

<p>For getting <em>multiple</em> indexers, using <code class=""docutils literal notranslate""><span class=""pre"">.get_indexer</span></code>:</p>

<section id=""reindexing"">
<h3>Reindexing<a class=""headerlink"" href=""#reindexing"" title=""Link to this heading"">#</a></h3>
<p>The idiomatic way to achieve selecting potentially not-found elements is via <code class=""docutils literal notranslate""><span class=""pre"">.reindex()</span></code>. See also the section on <a class=""reference internal"" href=""basics.html#basics-reindexing""><span class=""std std-ref"">reindexing</span></a>.</p>

<p>Alternatively, if you want to select only <em>valid</em> keys, the following is idiomatic and efficient; it is guaranteed to preserve the dtype of the selection.</p>

<p>Having a duplicated index will raise for a <code class=""docutils literal notranslate""><span class=""pre"">.reindex()</span></code>:</p>

<p>Generally, you can intersect the desired labels with the current
axis, and then reindex.</p>

<p>However, this would <em>still</em> raise if your resulting index is duplicated.</p>

</section>
</section>
<section id=""selecting-random-samples"">
<span id=""indexing-basics-partial-setting""></span><h2>Selecting random samples<a class=""headerlink"" href=""#selecting-random-samples"" title=""Link to this heading"">#</a></h2>
<p>A random selection of rows or columns from a Series or DataFrame with the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.sample.html#pandas.DataFrame.sample"" title=""pandas.DataFrame.sample""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">sample()</span></code></a> method. The method will sample rows by default, and accepts a specific number of rows/columns to return, or a fraction of rows.</p>

<p>By default, <code class=""docutils literal notranslate""><span class=""pre"">sample</span></code> will return each row at most once, but one can also sample with replacement
using the <code class=""docutils literal notranslate""><span class=""pre"">replace</span></code> option:</p>

<p>By default, each row has an equal probability of being selected, but if you want rows
to have different probabilities, you can pass the <code class=""docutils literal notranslate""><span class=""pre"">sample</span></code> function sampling weights as
<code class=""docutils literal notranslate""><span class=""pre"">weights</span></code>. These weights can be a list, a NumPy array, or a Series, but they must be of the same length as the object you are sampling. Missing values will be treated as a weight of zero, and inf values are not allowed. If weights do not sum to 1, they will be re-normalized by dividing all weights by the sum of the weights. For example:</p>

<p>When applied to a DataFrame, you can use a column of the DataFrame as sampling weights
(provided you are sampling rows and not columns) by simply passing the name of the column
as a string.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">sample</span></code> also allows users to sample columns instead of rows using the <code class=""docutils literal notranslate""><span class=""pre"">axis</span></code> argument.</p>

<p>Finally, one can also set a seed for <code class=""docutils literal notranslate""><span class=""pre"">sample</span></code>’s random number generator using the <code class=""docutils literal notranslate""><span class=""pre"">random_state</span></code> argument, which will accept either an integer (as a seed) or a NumPy RandomState object.</p>

</section>
<section id=""setting-with-enlargement"">
<h2>Setting with enlargement<a class=""headerlink"" href=""#setting-with-enlargement"" title=""Link to this heading"">#</a></h2>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">.loc/[]</span></code> operations can perform enlargement when setting a non-existent key for that axis.</p>
<p>In the <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> case this is effectively an appending operation.</p>

<p>A <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> can be enlarged on either axis via <code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code>.</p>

<p>This is like an <code class=""docutils literal notranslate""><span class=""pre"">append</span></code> operation on the <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>.</p>

</section>
<section id=""fast-scalar-value-getting-and-setting"">
<span id=""indexing-basics-get-value""></span><h2>Fast scalar value getting and setting<a class=""headerlink"" href=""#fast-scalar-value-getting-and-setting"" title=""Link to this heading"">#</a></h2>
<p>Since indexing with <code class=""docutils literal notranslate""><span class=""pre"">[]</span></code> must handle a lot of cases (single-label access,
slicing, boolean indexing, etc.), it has a bit of overhead in order to figure
out what you’re asking for. If you only want to access a scalar value, the
fastest way is to use the <code class=""docutils literal notranslate""><span class=""pre"">at</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">iat</span></code> methods, which are implemented on
all of the data structures.</p>
<p>Similarly to <code class=""docutils literal notranslate""><span class=""pre"">loc</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">at</span></code> provides <strong>label</strong> based scalar lookups, while, <code class=""docutils literal notranslate""><span class=""pre"">iat</span></code> provides <strong>integer</strong> based lookups analogously to <code class=""docutils literal notranslate""><span class=""pre"">iloc</span></code></p>

<p>You can also set using these same indexers.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">at</span></code> may enlarge the object in-place as above if the indexer is missing.</p>

</section>
<section id=""boolean-indexing"">
<h2>Boolean indexing<a class=""headerlink"" href=""#boolean-indexing"" title=""Link to this heading"">#</a></h2>
<p id=""indexing-boolean"">Another common operation is the use of boolean vectors to filter the data.
The operators are: <code class=""docutils literal notranslate""><span class=""pre"">|</span></code> for <code class=""docutils literal notranslate""><span class=""pre"">or</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">&amp;</span></code> for <code class=""docutils literal notranslate""><span class=""pre"">and</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">~</span></code> for <code class=""docutils literal notranslate""><span class=""pre"">not</span></code>.
These <strong>must</strong> be grouped by using parentheses, since by default Python will
evaluate an expression such as <code class=""docutils literal notranslate""><span class=""pre"">df['A']</span> <span class=""pre"">&gt;</span> <span class=""pre"">2</span> <span class=""pre"">&amp;</span> <span class=""pre"">df['B']</span> <span class=""pre"">&lt;</span> <span class=""pre"">3</span></code> as
<code class=""docutils literal notranslate""><span class=""pre"">df['A']</span> <span class=""pre"">&gt;</span> <span class=""pre"">(2</span> <span class=""pre"">&amp;</span> <span class=""pre"">df['B'])</span> <span class=""pre"">&lt;</span> <span class=""pre"">3</span></code>, while the desired evaluation order is
<code class=""docutils literal notranslate""><span class=""pre"">(df['A']</span> <span class=""pre"">&gt;</span> <span class=""pre"">2)</span> <span class=""pre"">&amp;</span> <span class=""pre"">(df['B']</span> <span class=""pre"">&lt;</span> <span class=""pre"">3)</span></code>.</p>
<p>Using a boolean vector to index a Series works exactly as in a NumPy ndarray:</p>

<p>You may select rows from a DataFrame using a boolean vector the same length as
the DataFrame’s index (for example, something derived from one of the columns
of the DataFrame):</p>

<p>List comprehensions and the <code class=""docutils literal notranslate""><span class=""pre"">map</span></code> method of Series can also be used to produce
more complex criteria:</p>

<p>With the choice methods <a class=""reference internal"" href=""#indexing-label""><span class=""std std-ref"">Selection by Label</span></a>, <a class=""reference internal"" href=""#indexing-integer""><span class=""std std-ref"">Selection by Position</span></a>,
and <a class=""reference internal"" href=""advanced.html#advanced""><span class=""std std-ref"">Advanced Indexing</span></a> you may select along more than one axis using boolean vectors combined with other indexing expressions.</p>

<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">iloc</span></code> supports two kinds of boolean indexing. If the indexer is a boolean <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>,
an error will be raised. For instance, in the following example, <code class=""docutils literal notranslate""><span class=""pre"">df.iloc[s.values,</span> <span class=""pre"">1]</span></code> is ok.
The boolean indexer is an array. But <code class=""docutils literal notranslate""><span class=""pre"">df.iloc[s,</span> <span class=""pre"">1]</span></code> would raise <code class=""docutils literal notranslate""><span class=""pre"">ValueError</span></code>.</p>

</div>
</section>
<section id=""indexing-with-isin"">
<span id=""indexing-basics-indexing-isin""></span><h2>Indexing with isin<a class=""headerlink"" href=""#indexing-with-isin"" title=""Link to this heading"">#</a></h2>
<p>Consider the <a class=""reference internal"" href=""../reference/api/pandas.Series.isin.html#pandas.Series.isin"" title=""pandas.Series.isin""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">isin()</span></code></a> method of <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>, which returns a boolean
vector that is true wherever the <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> elements exist in the passed list.
This allows you to select rows where one or more columns have values you want:</p>

<p>The same method is available for <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> objects and is useful for the cases
when you don’t know which of the sought labels are in fact present:</p>

<p>In addition to that, <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> allows selecting a separate level to use
in the membership check:</p>

<p>DataFrame also has an <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.isin.html#pandas.DataFrame.isin"" title=""pandas.DataFrame.isin""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">isin()</span></code></a> method. When calling <code class=""docutils literal notranslate""><span class=""pre"">isin</span></code>, pass a set of
values as either an array or dict. If values is an array, <code class=""docutils literal notranslate""><span class=""pre"">isin</span></code> returns
a DataFrame of booleans that is the same shape as the original DataFrame, with True
wherever the element is in the sequence of values.</p>

<p>Oftentimes you’ll want to match certain values with certain columns.
Just make values a <code class=""docutils literal notranslate""><span class=""pre"">dict</span></code> where the key is the column, and the value is
a list of items you want to check for.</p>

<p>To return the DataFrame of booleans where the values are <em>not</em> in the original DataFrame,
use the <code class=""docutils literal notranslate""><span class=""pre"">~</span></code> operator:</p>

<p>Combine DataFrame’s <code class=""docutils literal notranslate""><span class=""pre"">isin</span></code> with the <code class=""docutils literal notranslate""><span class=""pre"">any()</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">all()</span></code> methods to
quickly select subsets of your data that meet a given criteria.
To select a row where each column meets its own criterion:</p>

</section>
<section id=""the-where-method-and-masking"">
<span id=""indexing-where-mask""></span><h2>The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.where.html#pandas.DataFrame.where"" title=""pandas.DataFrame.where""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">where()</span></code></a> Method and Masking<a class=""headerlink"" href=""#the-where-method-and-masking"" title=""Link to this heading"">#</a></h2>
<p>Selecting values from a Series with a boolean vector generally returns a
subset of the data. To guarantee that selection output has the same shape as
the original data, you can use the <code class=""docutils literal notranslate""><span class=""pre"">where</span></code> method in <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>.</p>
<p>To return only the selected rows:</p>

<p>To return a Series of the same shape as the original:</p>

<p>Selecting values from a DataFrame with a boolean criterion now also preserves
input data shape. <code class=""docutils literal notranslate""><span class=""pre"">where</span></code> is used under the hood as the implementation.
The code below is equivalent to <code class=""docutils literal notranslate""><span class=""pre"">df.where(df</span> <span class=""pre"">&lt;</span> <span class=""pre"">0)</span></code>.</p>

<p>In addition, <code class=""docutils literal notranslate""><span class=""pre"">where</span></code> takes an optional <code class=""docutils literal notranslate""><span class=""pre"">other</span></code> argument for replacement of
values where the condition is False, in the returned copy.</p>

<p>You may wish to set values based on some boolean criteria.
This can be done intuitively like so:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">where</span></code> returns a modified copy of the data.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The signature for <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.where.html#pandas.DataFrame.where"" title=""pandas.DataFrame.where""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">DataFrame.where()</span></code></a> differs from <a class=""reference external"" href=""https://numpy.org/doc/stable/reference/generated/numpy.where.html#numpy.where"" title=""(in NumPy v1.26)""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">numpy.where()</span></code></a>.
Roughly <code class=""docutils literal notranslate""><span class=""pre"">df1.where(m,</span> <span class=""pre"">df2)</span></code> is equivalent to <code class=""docutils literal notranslate""><span class=""pre"">np.where(m,</span> <span class=""pre"">df1,</span> <span class=""pre"">df2)</span></code>.</p>

</div>
<p><strong>Alignment</strong></p>
<p>Furthermore, <code class=""docutils literal notranslate""><span class=""pre"">where</span></code> aligns the input boolean condition (ndarray or DataFrame),
such that partial selection with setting is possible. This is analogous to
partial setting via <code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code> (but on the contents rather than the axis labels).</p>

<p>Where can also accept <code class=""docutils literal notranslate""><span class=""pre"">axis</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">level</span></code> parameters to align the input when
performing the <code class=""docutils literal notranslate""><span class=""pre"">where</span></code>.</p>

<p>This is equivalent to (but faster than) the following.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">where</span></code> can accept a callable as condition and <code class=""docutils literal notranslate""><span class=""pre"">other</span></code> arguments. The function must
be with one argument (the calling Series or DataFrame) and that returns valid output
as condition and <code class=""docutils literal notranslate""><span class=""pre"">other</span></code> argument.</p>

<section id=""mask"">
<h3>Mask<a class=""headerlink"" href=""#mask"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.mask.html#pandas.DataFrame.mask"" title=""pandas.DataFrame.mask""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">mask()</span></code></a> is the inverse boolean operation of <code class=""docutils literal notranslate""><span class=""pre"">where</span></code>.</p>

</section>
</section>
<section id=""setting-with-enlargement-conditionally-using-numpy"">
<span id=""indexing-np-where""></span><h2>Setting with enlargement conditionally using <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">numpy()</span></code><a class=""headerlink"" href=""#setting-with-enlargement-conditionally-using-numpy"" title=""Link to this heading"">#</a></h2>
<p>An alternative to <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.where.html#pandas.DataFrame.where"" title=""pandas.DataFrame.where""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">where()</span></code></a> is to use <a class=""reference external"" href=""https://numpy.org/doc/stable/reference/generated/numpy.where.html#numpy.where"" title=""(in NumPy v1.26)""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">numpy.where()</span></code></a>.
Combined with setting a new column, you can use it to enlarge a DataFrame where the
values are determined conditionally.</p>
<p>Consider you have two choices to choose from in the following DataFrame. And you want to
set a new column color to ‘green’ when the second column has ‘Z’. You can do the
following:</p>

<p>If you have multiple conditions, you can use <a class=""reference external"" href=""https://numpy.org/doc/stable/reference/generated/numpy.select.html#numpy.select"" title=""(in NumPy v1.26)""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">numpy.select()</span></code></a> to achieve that. Say
corresponding to three conditions there are three choice of colors, with a fourth color
as a fallback, you can do the following.</p>

</section>
<section id=""the-query-method"">
<span id=""indexing-query""></span><h2>The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.query.html#pandas.DataFrame.query"" title=""pandas.DataFrame.query""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">query()</span></code></a> Method<a class=""headerlink"" href=""#the-query-method"" title=""Link to this heading"">#</a></h2>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> objects have a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.query.html#pandas.DataFrame.query"" title=""pandas.DataFrame.query""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">query()</span></code></a>
method that allows selection using an expression.</p>
<p>You can get the value of the frame where column <code class=""docutils literal notranslate""><span class=""pre"">b</span></code> has values
between the values of columns <code class=""docutils literal notranslate""><span class=""pre"">a</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">c</span></code>. For example:</p>

<p>Do the same thing but fall back on a named index if there is no column
with the name <code class=""docutils literal notranslate""><span class=""pre"">a</span></code>.</p>

<p>If instead you don’t want to or cannot name your index, you can use the name
<code class=""docutils literal notranslate""><span class=""pre"">index</span></code> in your query expression:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>If the name of your index overlaps with a column name, the column name is
given precedence. For example,</p>

<p>You can still use the index in a query expression by using the special
identifier ‘index’:</p>

<p>If for some reason you have a column named <code class=""docutils literal notranslate""><span class=""pre"">index</span></code>, then you can refer to
the index as <code class=""docutils literal notranslate""><span class=""pre"">ilevel_0</span></code> as well, but at this point you should consider
renaming your columns to something less ambiguous.</p>
</div>
<section id=""multiindex-query-syntax"">
<h3><a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a> <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.query.html#pandas.DataFrame.query"" title=""pandas.DataFrame.query""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">query()</span></code></a> Syntax<a class=""headerlink"" href=""#multiindex-query-syntax"" title=""Link to this heading"">#</a></h3>
<p>You can also use the levels of a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> with a
<a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a> as if they were columns in the frame:</p>

<p>If the levels of the <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> are unnamed, you can refer to them using
special names:</p>

<p>The convention is <code class=""docutils literal notranslate""><span class=""pre"">ilevel_0</span></code>, which means “index level 0” for the 0th level
of the <code class=""docutils literal notranslate""><span class=""pre"">index</span></code>.</p>
</section>
<section id=""query-use-cases"">
<h3><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.query.html#pandas.DataFrame.query"" title=""pandas.DataFrame.query""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">query()</span></code></a> Use Cases<a class=""headerlink"" href=""#query-use-cases"" title=""Link to this heading"">#</a></h3>
<p>A use case for <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.query.html#pandas.DataFrame.query"" title=""pandas.DataFrame.query""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">query()</span></code></a> is when you have a collection of
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> objects that have a subset of column names (or index
levels/names) in common. You can pass the same query to both frames <em>without</em>
having to specify which frame you’re interested in querying</p>

</section>
<section id=""query-python-versus-pandas-syntax-comparison"">
<h3><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.query.html#pandas.DataFrame.query"" title=""pandas.DataFrame.query""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">query()</span></code></a> Python versus pandas Syntax Comparison<a class=""headerlink"" href=""#query-python-versus-pandas-syntax-comparison"" title=""Link to this heading"">#</a></h3>
<p>Full numpy-like syntax:</p>

<p>Slightly nicer by removing the parentheses (comparison operators bind tighter
than <code class=""docutils literal notranslate""><span class=""pre"">&amp;</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">|</span></code>):</p>

<p>Use English instead of symbols:</p>

<p>Pretty close to how you might write it on paper:</p>

</section>
<section id=""the-in-and-not-in-operators"">
<h3>The <code class=""docutils literal notranslate""><span class=""pre"">in</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">not</span> <span class=""pre"">in</span></code> operators<a class=""headerlink"" href=""#the-in-and-not-in-operators"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.query.html#pandas.DataFrame.query"" title=""pandas.DataFrame.query""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">query()</span></code></a> also supports special use of Python’s <code class=""docutils literal notranslate""><span class=""pre"">in</span></code> and
<code class=""docutils literal notranslate""><span class=""pre"">not</span> <span class=""pre"">in</span></code> comparison operators, providing a succinct syntax for calling the
<code class=""docutils literal notranslate""><span class=""pre"">isin</span></code> method of a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>.</p>

<p>You can combine this with other expressions for very succinct queries:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Note that <code class=""docutils literal notranslate""><span class=""pre"">in</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">not</span> <span class=""pre"">in</span></code> are evaluated in Python, since <code class=""docutils literal notranslate""><span class=""pre"">numexpr</span></code>
has no equivalent of this operation. However, <strong>only the</strong> <code class=""docutils literal notranslate""><span class=""pre"">in</span></code>/<code class=""docutils literal notranslate""><span class=""pre"">not</span> <span class=""pre"">in</span></code>
<strong>expression itself</strong> is evaluated in vanilla Python. For example, in the
expression</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df</span><span class=""o"">.</span><span class=""n"">query</span><span class=""p"">(</span><span class=""s1"">'a in b + c + d'</span><span class=""p"">)</span>
</pre></div>
</div>
<p><code class=""docutils literal notranslate""><span class=""pre"">(b</span> <span class=""pre"">+</span> <span class=""pre"">c</span> <span class=""pre"">+</span> <span class=""pre"">d)</span></code> is evaluated by <code class=""docutils literal notranslate""><span class=""pre"">numexpr</span></code> and <em>then</em> the <code class=""docutils literal notranslate""><span class=""pre"">in</span></code>
operation is evaluated in plain Python. In general, any operations that can
be evaluated using <code class=""docutils literal notranslate""><span class=""pre"">numexpr</span></code> will be.</p>
</div>
</section>
<section id=""special-use-of-the-operator-with-list-objects"">
<h3>Special use of the <code class=""docutils literal notranslate""><span class=""pre"">==</span></code> operator with <code class=""docutils literal notranslate""><span class=""pre"">list</span></code> objects<a class=""headerlink"" href=""#special-use-of-the-operator-with-list-objects"" title=""Link to this heading"">#</a></h3>
<p>Comparing a <code class=""docutils literal notranslate""><span class=""pre"">list</span></code> of values to a column using <code class=""docutils literal notranslate""><span class=""pre"">==</span></code>/<code class=""docutils literal notranslate""><span class=""pre"">!=</span></code> works similarly
to <code class=""docutils literal notranslate""><span class=""pre"">in</span></code>/<code class=""docutils literal notranslate""><span class=""pre"">not</span> <span class=""pre"">in</span></code>.</p>

</section>
<section id=""boolean-operators"">
<h3>Boolean operators<a class=""headerlink"" href=""#boolean-operators"" title=""Link to this heading"">#</a></h3>
<p>You can negate boolean expressions with the word <code class=""docutils literal notranslate""><span class=""pre"">not</span></code> or the <code class=""docutils literal notranslate""><span class=""pre"">~</span></code> operator.</p>

<p>Of course, expressions can be arbitrarily complex too:</p>

</section>
<section id=""performance-of-query"">
<h3>Performance of <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.query.html#pandas.DataFrame.query"" title=""pandas.DataFrame.query""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">query()</span></code></a><a class=""headerlink"" href=""#performance-of-query"" title=""Link to this heading"">#</a></h3>
<p><code class=""docutils literal notranslate""><span class=""pre"">DataFrame.query()</span></code> using <code class=""docutils literal notranslate""><span class=""pre"">numexpr</span></code> is slightly faster than Python for
large frames.</p>
<img alt=""../_images/query-perf.png"" src=""../_images/query-perf.png""/>
<p>You will only see the performance benefits of using the <code class=""docutils literal notranslate""><span class=""pre"">numexpr</span></code> engine
with <code class=""docutils literal notranslate""><span class=""pre"">DataFrame.query()</span></code> if your frame has more than approximately 100,000
rows.</p>
<p>This plot was created using a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> with 3 columns each containing
floating point values generated using <code class=""docutils literal notranslate""><span class=""pre"">numpy.random.randn()</span></code>.</p>

</section>
</section>
<section id=""duplicate-data"">
<h2>Duplicate data<a class=""headerlink"" href=""#duplicate-data"" title=""Link to this heading"">#</a></h2>
<p id=""indexing-duplicate"">If you want to identify and remove duplicate rows in a DataFrame, there are
two methods that will help: <code class=""docutils literal notranslate""><span class=""pre"">duplicated</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">drop_duplicates</span></code>. Each
takes as an argument the columns to use to identify duplicated rows.</p>
<ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">duplicated</span></code> returns a boolean vector whose length is the number of rows, and which indicates whether a row is duplicated.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">drop_duplicates</span></code> removes duplicate rows.</p></li>
</ul>
<p>By default, the first observed row of a duplicate set is considered unique, but
each method has a <code class=""docutils literal notranslate""><span class=""pre"">keep</span></code> parameter to specify targets to be kept.</p>
<ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">keep='first'</span></code> (default): mark / drop duplicates except for the first occurrence.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">keep='last'</span></code>: mark / drop duplicates except for the last occurrence.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">keep=False</span></code>: mark / drop all duplicates.</p></li>
</ul>

<p>Also, you can pass a list of columns to identify duplications.</p>

<p>To drop duplicates by index value, use <code class=""docutils literal notranslate""><span class=""pre"">Index.duplicated</span></code> then perform slicing.
The same set of options are available for the <code class=""docutils literal notranslate""><span class=""pre"">keep</span></code> parameter.</p>

</section>
<section id=""dictionary-like-get-method"">
<span id=""indexing-dictionarylike""></span><h2>Dictionary-like <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.get.html#pandas.DataFrame.get"" title=""pandas.DataFrame.get""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">get()</span></code></a> method<a class=""headerlink"" href=""#dictionary-like-get-method"" title=""Link to this heading"">#</a></h2>
<p>Each of Series or DataFrame have a <code class=""docutils literal notranslate""><span class=""pre"">get</span></code> method which can return a
default value.</p>

</section>
<section id=""looking-up-values-by-index-column-labels"">
<span id=""indexing-lookup""></span><h2>Looking up values by index/column labels<a class=""headerlink"" href=""#looking-up-values-by-index-column-labels"" title=""Link to this heading"">#</a></h2>
<p>Sometimes you want to extract a set of values given a sequence of row labels
and column labels, this can be achieved by <code class=""docutils literal notranslate""><span class=""pre"">pandas.factorize</span></code> and NumPy indexing.
For instance:</p>

<p>Formerly this could be achieved with the dedicated <code class=""docutils literal notranslate""><span class=""pre"">DataFrame.lookup</span></code> method
which was deprecated in version 1.2.0 and removed in version 2.0.0.</p>
</section>
<section id=""index-objects"">
<span id=""indexing-class""></span><h2>Index objects<a class=""headerlink"" href=""#index-objects"" title=""Link to this heading"">#</a></h2>
<p>The pandas <a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a> class and its subclasses can be viewed as
implementing an <em>ordered multiset</em>. Duplicates are allowed.</p>
<p><a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a> also provides the infrastructure necessary for
lookups, data alignment, and reindexing. The easiest way to create an
<a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a> directly is to pass a <code class=""docutils literal notranslate""><span class=""pre"">list</span></code> or other sequence to
<a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a>:</p>

<p>or using numbers:</p>

<p>If no dtype is given, <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> tries to infer the dtype from the data.
It is also possible to give an explicit dtype when instantiating an <a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a>:</p>

<p>You can also pass a <code class=""docutils literal notranslate""><span class=""pre"">name</span></code> to be stored in the index:</p>

<p>The name, if set, will be shown in the console display:</p>

<section id=""setting-metadata"">
<span id=""indexing-set-metadata""></span><h3>Setting metadata<a class=""headerlink"" href=""#setting-metadata"" title=""Link to this heading"">#</a></h3>
<p>Indexes are “mostly immutable”, but it is possible to set and change their
<code class=""docutils literal notranslate""><span class=""pre"">name</span></code> attribute. You can use the <code class=""docutils literal notranslate""><span class=""pre"">rename</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">set_names</span></code> to set these attributes
directly, and they default to returning a copy.</p>
<p>See <a class=""reference internal"" href=""advanced.html#advanced""><span class=""std std-ref"">Advanced Indexing</span></a> for usage of MultiIndexes.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">set_names</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">set_levels</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">set_codes</span></code> also take an optional
<code class=""docutils literal notranslate""><span class=""pre"">level</span></code> argument</p>

</section>
<section id=""set-operations-on-index-objects"">
<span id=""indexing-set-ops""></span><h3>Set operations on Index objects<a class=""headerlink"" href=""#set-operations-on-index-objects"" title=""Link to this heading"">#</a></h3>
<p>The two main operations are <code class=""docutils literal notranslate""><span class=""pre"">union</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">intersection</span></code>.
Difference is provided via the <code class=""docutils literal notranslate""><span class=""pre"">.difference()</span></code> method.</p>

<p>Also available is the <code class=""docutils literal notranslate""><span class=""pre"">symmetric_difference</span></code> operation, which returns elements
that appear in either <code class=""docutils literal notranslate""><span class=""pre"">idx1</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">idx2</span></code>, but not in both. This is
equivalent to the Index created by <code class=""docutils literal notranslate""><span class=""pre"">idx1.difference(idx2).union(idx2.difference(idx1))</span></code>,
with duplicates dropped.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The resulting index from a set operation will be sorted in ascending order.</p>
</div>
<p>When performing <a class=""reference internal"" href=""../reference/api/pandas.Index.union.html#pandas.Index.union"" title=""pandas.Index.union""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Index.union()</span></code></a> between indexes with different dtypes, the indexes
must be cast to a common dtype. Typically, though not always, this is object dtype. The
exception is when performing a union between integer and float data. In this case, the
integer values are converted to float</p>

</section>
<section id=""missing-values"">
<span id=""indexing-missing""></span><h3>Missing values<a class=""headerlink"" href=""#missing-values"" title=""Link to this heading"">#</a></h3>
<div class=""admonition important"">
<p class=""admonition-title"">Important</p>
<p>Even though <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> can hold missing values (<code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>), it should be avoided
if you do not want any unexpected results. For example, some operations
exclude missing values implicitly.</p>
</div>
<p><code class=""docutils literal notranslate""><span class=""pre"">Index.fillna</span></code> fills missing values with specified scalar value.</p>

</section>
</section>
<section id=""set-reset-index"">
<h2>Set / reset index<a class=""headerlink"" href=""#set-reset-index"" title=""Link to this heading"">#</a></h2>
<p>Occasionally you will load or create a data set into a DataFrame and want to
add an index after you’ve already done so. There are a couple of different
ways.</p>
<section id=""set-an-index"">
<span id=""indexing-set-index""></span><h3>Set an index<a class=""headerlink"" href=""#set-an-index"" title=""Link to this heading"">#</a></h3>
<p>DataFrame has a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.set_index.html#pandas.DataFrame.set_index"" title=""pandas.DataFrame.set_index""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">set_index()</span></code></a> method which takes a column name
(for a regular <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code>) or a list of column names (for a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code>).
To create a new, re-indexed DataFrame:</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">append</span></code> keyword option allow you to keep the existing index and append
the given columns to a MultiIndex:</p>

<p>Other options in <code class=""docutils literal notranslate""><span class=""pre"">set_index</span></code> allow you not drop the index columns.</p>

</section>
<section id=""reset-the-index"">
<h3>Reset the index<a class=""headerlink"" href=""#reset-the-index"" title=""Link to this heading"">#</a></h3>
<p>As a convenience, there is a new function on DataFrame called
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.reset_index.html#pandas.DataFrame.reset_index"" title=""pandas.DataFrame.reset_index""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">reset_index()</span></code></a> which transfers the index values into the
DataFrame’s columns and sets a simple integer index.
This is the inverse operation of <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.set_index.html#pandas.DataFrame.set_index"" title=""pandas.DataFrame.set_index""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">set_index()</span></code></a>.</p>

<p>The output is more similar to a SQL table or a record array. The names for the
columns derived from the index are the ones stored in the <code class=""docutils literal notranslate""><span class=""pre"">names</span></code> attribute.</p>
<p>You can use the <code class=""docutils literal notranslate""><span class=""pre"">level</span></code> keyword to remove only a portion of the index:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">reset_index</span></code> takes an optional parameter <code class=""docutils literal notranslate""><span class=""pre"">drop</span></code> which if true simply
discards the index, instead of putting index values in the DataFrame’s columns.</p>
</section>
<section id=""adding-an-ad-hoc-index"">
<h3>Adding an ad hoc index<a class=""headerlink"" href=""#adding-an-ad-hoc-index"" title=""Link to this heading"">#</a></h3>
<p>You can assign a custom index to the <code class=""docutils literal notranslate""><span class=""pre"">index</span></code> attribute:</p>

</section>
</section>
<section id=""returning-a-view-versus-a-copy"">
<span id=""indexing-view-versus-copy""></span><h2>Returning a view versus a copy<a class=""headerlink"" href=""#returning-a-view-versus-a-copy"" title=""Link to this heading"">#</a></h2>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p><a class=""reference internal"" href=""copy_on_write.html#copy-on-write""><span class=""std std-ref"">Copy-on-Write</span></a>
will become the new default in pandas 3.0. This means than chained indexing will
never work. As a consequence, the <code class=""docutils literal notranslate""><span class=""pre"">SettingWithCopyWarning</span></code> won’t be necessary
anymore.
See <a class=""reference internal"" href=""copy_on_write.html#copy-on-write-chained-assignment""><span class=""std std-ref"">this section</span></a>
for more context.
We recommend turning Copy-on-Write on to leverage the improvements with</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">`</span>
<span class=""pre"">pd.options.mode.copy_on_write</span> <span class=""pre"">=</span> <span class=""pre"">True</span>
<span class=""pre"">`</span></code></p>
<p>even before pandas 3.0 is available.</p>
</div>
<p>When setting values in a pandas object, care must be taken to avoid what is called
<code class=""docutils literal notranslate""><span class=""pre"">chained</span> <span class=""pre"">indexing</span></code>. Here is an example.</p>

<p>Compare these two access methods:</p>


<p>These both yield the same results, so which should you use? It is instructive to understand the order
of operations on these and why method 2 (<code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code>) is much preferred over method 1 (chained <code class=""docutils literal notranslate""><span class=""pre"">[]</span></code>).</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">dfmi['one']</span></code> selects the first level of the columns and returns a DataFrame that is singly-indexed.
Then another Python operation <code class=""docutils literal notranslate""><span class=""pre"">dfmi_with_one['second']</span></code> selects the series indexed by <code class=""docutils literal notranslate""><span class=""pre"">'second'</span></code>.
This is indicated by the variable <code class=""docutils literal notranslate""><span class=""pre"">dfmi_with_one</span></code> because pandas sees these operations as separate events.
e.g. separate calls to <code class=""docutils literal notranslate""><span class=""pre"">__getitem__</span></code>, so it has to treat them as linear operations, they happen one after another.</p>
<p>Contrast this to <code class=""docutils literal notranslate""><span class=""pre"">df.loc[:,('one','second')]</span></code> which passes a nested tuple of <code class=""docutils literal notranslate""><span class=""pre"">(slice(None),('one','second'))</span></code> to a single call to
<code class=""docutils literal notranslate""><span class=""pre"">__getitem__</span></code>. This allows pandas to deal with this as a single entity. Furthermore this order of operations <em>can</em> be significantly
faster, and allows one to index <em>both</em> axes if so desired.</p>
<section id=""why-does-assignment-fail-when-using-chained-indexing"">
<h3>Why does assignment fail when using chained indexing?<a class=""headerlink"" href=""#why-does-assignment-fail-when-using-chained-indexing"" title=""Link to this heading"">#</a></h3>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p><a class=""reference internal"" href=""copy_on_write.html#copy-on-write""><span class=""std std-ref"">Copy-on-Write</span></a>
will become the new default in pandas 3.0. This means than chained indexing will
never work. As a consequence, the <code class=""docutils literal notranslate""><span class=""pre"">SettingWithCopyWarning</span></code> won’t be necessary
anymore.
See <a class=""reference internal"" href=""copy_on_write.html#copy-on-write-chained-assignment""><span class=""std std-ref"">this section</span></a>
for more context.
We recommend turning Copy-on-Write on to leverage the improvements with</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">`</span>
<span class=""pre"">pd.options.mode.copy_on_write</span> <span class=""pre"">=</span> <span class=""pre"">True</span>
<span class=""pre"">`</span></code></p>
<p>even before pandas 3.0 is available.</p>
</div>
<p>The problem in the previous section is just a performance issue. What’s up with
the <code class=""docutils literal notranslate""><span class=""pre"">SettingWithCopy</span></code> warning? We don’t <strong>usually</strong> throw warnings around when
you do something that might cost a few extra milliseconds!</p>
<p>But it turns out that assigning to the product of chained indexing has
inherently unpredictable results. To see this, think about how the Python
interpreter executes this code:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">dfmi</span><span class=""o"">.</span><span class=""n"">loc</span><span class=""p"">[:,</span> <span class=""p"">(</span><span class=""s1"">'one'</span><span class=""p"">,</span> <span class=""s1"">'second'</span><span class=""p"">)]</span> <span class=""o"">=</span> <span class=""n"">value</span>
<span class=""c1""># becomes</span>
<span class=""n"">dfmi</span><span class=""o"">.</span><span class=""n"">loc</span><span class=""o"">.</span><span class=""fm"">__setitem__</span><span class=""p"">((</span><span class=""nb"">slice</span><span class=""p"">(</span><span class=""kc"">None</span><span class=""p"">),</span> <span class=""p"">(</span><span class=""s1"">'one'</span><span class=""p"">,</span> <span class=""s1"">'second'</span><span class=""p"">)),</span> <span class=""n"">value</span><span class=""p"">)</span>
</pre></div>
</div>
<p>But this code is handled differently:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">dfmi</span><span class=""p"">[</span><span class=""s1"">'one'</span><span class=""p"">][</span><span class=""s1"">'second'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">value</span>
<span class=""c1""># becomes</span>
<span class=""n"">dfmi</span><span class=""o"">.</span><span class=""fm"">__getitem__</span><span class=""p"">(</span><span class=""s1"">'one'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""fm"">__setitem__</span><span class=""p"">(</span><span class=""s1"">'second'</span><span class=""p"">,</span> <span class=""n"">value</span><span class=""p"">)</span>
</pre></div>
</div>
<p>See that <code class=""docutils literal notranslate""><span class=""pre"">__getitem__</span></code> in there? Outside of simple cases, it’s very hard to
predict whether it will return a view or a copy (it depends on the memory layout
of the array, about which pandas makes no guarantees), and therefore whether
the <code class=""docutils literal notranslate""><span class=""pre"">__setitem__</span></code> will modify <code class=""docutils literal notranslate""><span class=""pre"">dfmi</span></code> or a temporary object that gets thrown
out immediately afterward. <strong>That’s</strong> what <code class=""docutils literal notranslate""><span class=""pre"">SettingWithCopy</span></code> is warning you
about!</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>You may be wondering whether we should be concerned about the <code class=""docutils literal notranslate""><span class=""pre"">loc</span></code>
property in the first example. But <code class=""docutils literal notranslate""><span class=""pre"">dfmi.loc</span></code> is guaranteed to be <code class=""docutils literal notranslate""><span class=""pre"">dfmi</span></code>
itself with modified indexing behavior, so <code class=""docutils literal notranslate""><span class=""pre"">dfmi.loc.__getitem__</span></code> /
<code class=""docutils literal notranslate""><span class=""pre"">dfmi.loc.__setitem__</span></code> operate on <code class=""docutils literal notranslate""><span class=""pre"">dfmi</span></code> directly. Of course,
<code class=""docutils literal notranslate""><span class=""pre"">dfmi.loc.__getitem__(idx)</span></code> may be a view or a copy of <code class=""docutils literal notranslate""><span class=""pre"">dfmi</span></code>.</p>
</div>
<p>Sometimes a <code class=""docutils literal notranslate""><span class=""pre"">SettingWithCopy</span></code> warning will arise at times when there’s no
obvious chained indexing going on. <strong>These</strong> are the bugs that
<code class=""docutils literal notranslate""><span class=""pre"">SettingWithCopy</span></code> is designed to catch! pandas is probably trying to warn you
that you’ve done this:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">do_something</span><span class=""p"">(</span><span class=""n"">df</span><span class=""p"">):</span>
    <span class=""n"">foo</span> <span class=""o"">=</span> <span class=""n"">df</span><span class=""p"">[[</span><span class=""s1"">'bar'</span><span class=""p"">,</span> <span class=""s1"">'baz'</span><span class=""p"">]]</span>  <span class=""c1""># Is foo a view? A copy? Nobody knows!</span>
    <span class=""c1""># ... many lines here ...</span>
    <span class=""c1""># We don't know whether this will modify df or not!</span>
    <span class=""n"">foo</span><span class=""p"">[</span><span class=""s1"">'quux'</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">value</span>
    <span class=""k"">return</span> <span class=""n"">foo</span>
</pre></div>
</div>
<p>Yikes!</p>
</section>
<section id=""evaluation-order-matters"">
<span id=""indexing-evaluation-order""></span><h3>Evaluation order matters<a class=""headerlink"" href=""#evaluation-order-matters"" title=""Link to this heading"">#</a></h3>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p><a class=""reference internal"" href=""copy_on_write.html#copy-on-write""><span class=""std std-ref"">Copy-on-Write</span></a>
will become the new default in pandas 3.0. This means than chained indexing will
never work. As a consequence, the <code class=""docutils literal notranslate""><span class=""pre"">SettingWithCopyWarning</span></code> won’t be necessary
anymore.
See <a class=""reference internal"" href=""copy_on_write.html#copy-on-write-chained-assignment""><span class=""std std-ref"">this section</span></a>
for more context.
We recommend turning Copy-on-Write on to leverage the improvements with</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">`</span>
<span class=""pre"">pd.options.mode.copy_on_write</span> <span class=""pre"">=</span> <span class=""pre"">True</span>
<span class=""pre"">`</span></code></p>
<p>even before pandas 3.0 is available.</p>
</div>
<p>When you use chained indexing, the order and type of the indexing operation
partially determine whether the result is a slice into the original object, or
a copy of the slice.</p>
<p>pandas has the <code class=""docutils literal notranslate""><span class=""pre"">SettingWithCopyWarning</span></code> because assigning to a copy of a
slice is frequently not intentional, but a mistake caused by chained indexing
returning a copy where a slice was expected.</p>
<p>If you would like pandas to be more or less trusting about assignment to a
chained indexing expression, you can set the <a class=""reference internal"" href=""options.html#options""><span class=""std std-ref"">option</span></a>
<code class=""docutils literal notranslate""><span class=""pre"">mode.chained_assignment</span></code> to one of these values:</p>
<ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">'warn'</span></code>, the default, means a <code class=""docutils literal notranslate""><span class=""pre"">SettingWithCopyWarning</span></code> is printed.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">'raise'</span></code> means pandas will raise a <code class=""docutils literal notranslate""><span class=""pre"">SettingWithCopyError</span></code>
you have to deal with.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">None</span></code> will suppress the warnings entirely.</p></li>
</ul>

<p>This however is operating on a copy and will not work.</p>

<p>A chained assignment can also crop up in setting in a mixed dtype frame.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>These setting rules apply to all of <code class=""docutils literal notranslate""><span class=""pre"">.loc/.iloc</span></code>.</p>
</div>
<p>The following is the recommended access method using <code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code> for multiple items (using <code class=""docutils literal notranslate""><span class=""pre"">mask</span></code>) and a single item using a fixed index:</p>

<p>The following <em>can</em> work at times, but it is not guaranteed to, and therefore should be avoided:</p>

<p>Last, the subsequent example will <strong>not</strong> work at all, and so should be avoided:</p>

<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>The chained assignment warnings / exceptions are aiming to inform the user of a possibly invalid
assignment. There may be false positives; situations where a chained assignment is inadvertently
reported.</p>
</div>
</section>
</section>
</section>
</article>","Indexing and selecting data # The axis labeling information in pandas objects serves many purposes: Identifies data (i.e. provides metadata ) using known indicators, important for analysis, visualization, and interactive console display. Enables automatic and explicit data alignment. Allows intuitive getting and setting of subsets of the data set. In this section, we will focus on the final point: namely, how to slice, dice, and generally get and set subsets of pandas objects. The primary focus will be on Series and DataFrame as they have received more development attention in this area. Note The Python and NumPy indexing operators [] and attribute operator . provide quick and easy access to pandas data structures across a wide range of use cases. This makes interactive work intuitive, as there’s little new to learn if you already know how to deal with Python dictionaries and NumPy arrays. However, since the type of the data to be accessed isn’t known in advance, directly using standard operators has some optimization limits. For production code, we recommended that you take advantage of the optimized pandas data access methods exposed in this chapter. Warning Whether a copy or a reference is returned for a setting operation, may depend on the context. This is sometimes called chained assignment and should be avoided. See Returning a View versus Copy . See the MultiIndex / Advanced Indexing for MultiIndex and more advanced indexing documentation. See the cookbook for some advanced strategies. Different choices for indexing # Object selection has had a number of user-requested additions in order to support more explicit location based indexing. pandas now supports three types of multi-axis indexing. .loc is primarily label based, but may also be used with a boolean array. .loc will raise KeyError when the items are not found. Allowed inputs are: A single label, e.g. 5 or 'a' (Note that 5 is interpreted as a label of the index. This use is not an integer position along the index.). A list or array of labels ['a', 'b', 'c'] . A slice object with labels 'a':'f' (Note that contrary to usual Python slices, both the start and the stop are included, when present in the index! See Slicing with labels and Endpoints are inclusive .) A boolean array (any NA values will be treated as False ). A callable function with one argument (the calling Series or DataFrame) and that returns valid output for indexing (one of the above). A tuple of row (and column) indices whose elements are one of the above inputs. See more at Selection by Label . .iloc is primarily integer position based (from 0 to length-1 of the axis), but may also be used with a boolean array. .iloc will raise IndexError if a requested indexer is out-of-bounds, except slice indexers which allow out-of-bounds indexing. (this conforms with Python/NumPy slice semantics). Allowed inputs are: An integer e.g. 5 . A list or array of integers [4, 3, 0] . A slice object with ints 1:7 . A boolean array (any NA values will be treated as False ). A callable function with one argument (the calling Series or DataFrame) and that returns valid output for indexing (one of the above). A tuple of row (and column) indices whose elements are one of the above inputs. See more at Selection by Position , Advanced Indexing and Advanced Hierarchical . .loc , .iloc , and also [] indexing can accept a callable as indexer. See more at Selection By Callable . Note Destructuring tuple keys into row (and column) indexes occurs before callables are applied, so you cannot return a tuple from a callable to index both rows and columns. Getting values from an object with multi-axes selection uses the following notation (using .loc as an example, but the following applies to .iloc as well). Any of the axes accessors may be the null slice : . Axes left out of the specification are assumed to be : , e.g. p.loc['a'] is equivalent to p.loc['a', :] . Basics # As mentioned when introducing the data structures in the last section , the primary function of indexing with [] (a.k.a. __getitem__ for those familiar with implementing class behavior in Python) is selecting out lower-dimensional slices. The following table shows return type values when indexing pandas objects with [] : Here we construct a simple time series data set to use for illustrating the indexing functionality: Note None of the indexing functionality is time series specific unless specifically stated. Thus, as per above, we have the most basic indexing using [] : You can pass a list of columns to [] to select columns in that order. If a column is not contained in the DataFrame, an exception will be raised. Multiple columns can also be set in this manner: You may find this useful for applying a transform (in-place) to a subset of the columns. Warning pandas aligns all AXES when setting Series and DataFrame from .loc . This will not modify df because the column alignment is before value assignment. The correct way to swap column values is by using raw values: However, pandas does not align AXES when setting Series and DataFrame from .iloc because .iloc operates by position. This will modify df because the column alignment is not done before value assignment. Attribute access # You may access an index on a Series or column on a DataFrame directly as an attribute: Warning You can use this access only if the index element is a valid Python identifier, e.g. s.1 is not allowed. See here for an explanation of valid identifiers . The attribute will not be available if it conflicts with an existing method name, e.g. s.min is not allowed, but s['min'] is possible. Similarly, the attribute will not be available if it conflicts with any of the following list: index , major_axis , minor_axis , items . In any of these cases, standard indexing will still work, e.g. s['1'] , s['min'] , and s['index'] will access the corresponding element or column. If you are using the IPython environment, you may also use tab-completion to see these accessible attributes. You can also assign a dict to a row of a DataFrame : You can use attribute access to modify an existing element of a Series or column of a DataFrame, but be careful; if you try to use attribute access to create a new column, it creates a new attribute rather than a new column and will this raise a UserWarning : Slicing ranges # The most robust and consistent way of slicing ranges along arbitrary axes is described in the Selection by Position section detailing the .iloc method. For now, we explain the semantics of slicing using the [] operator. With Series, the syntax works exactly as with an ndarray, returning a slice of the values and the corresponding labels: Note that setting works as well: With DataFrame, slicing inside of [] slices the rows . This is provided largely as a convenience since it is such a common operation. Selection by label # Warning Whether a copy or a reference is returned for a setting operation, may depend on the context. This is sometimes called chained assignment and should be avoided. See Returning a View versus Copy . Warning .loc is strict when you present slicers that are not compatible (or convertible) with the index type. For example using integers in a DatetimeIndex . These will raise a TypeError . String likes in slicing can be convertible to the type of the index and lead to natural slicing. pandas provides a suite of methods in order to have purely label based indexing . This is a strict inclusion based protocol. Every label asked for must be in the index, or a KeyError will be raised. When slicing, both the start bound AND the stop bound are included , if present in the index. Integers are valid labels, but they refer to the label and not the position . The .loc attribute is the primary access method. The following are valid inputs: A single label, e.g. 5 or 'a' (Note that 5 is interpreted as a label of the index. This use is not an integer position along the index.). A list or array of labels ['a', 'b', 'c'] . A slice object with labels 'a':'f' (Note that contrary to usual Python slices, both the start and the stop are included, when present in the index! See Slicing with labels . A boolean array. A callable , see Selection By Callable . Note that setting works as well: With a DataFrame: Accessing via label slices: For getting a cross section using a label (equivalent to df.xs('a') ): For getting values with a boolean array: NA values in a boolean array propagate as False : For getting a value explicitly: Slicing with labels # When using .loc with slices, if both the start and the stop labels are present in the index, then elements located between the two (including them) are returned: If at least one of the two is absent, but the index is sorted, and can be compared against start and stop labels, then slicing will still work as expected, by selecting labels which rank between the two: However, if at least one of the two is absent and the index is not sorted, an error will be raised (since doing otherwise would be computationally expensive, as well as potentially ambiguous for mixed type indexes). For instance, in the above example, s.loc[1:6] would raise KeyError . For the rationale behind this behavior, see Endpoints are inclusive . Also, if the index has duplicate labels and either the start or the stop label is duplicated, an error will be raised. For instance, in the above example, s.loc[2:5] would raise a KeyError . For more information about duplicate labels, see Duplicate Labels . Selection by position # Warning Whether a copy or a reference is returned for a setting operation, may depend on the context. This is sometimes called chained assignment and should be avoided. See Returning a View versus Copy . pandas provides a suite of methods in order to get purely integer based indexing . The semantics follow closely Python and NumPy slicing. These are 0-based indexing. When slicing, the start bound is included , while the upper bound is excluded . Trying to use a non-integer, even a valid label will raise an IndexError . The .iloc attribute is the primary access method. The following are valid inputs: An integer e.g. 5 . A list or array of integers [4, 3, 0] . A slice object with ints 1:7 . A boolean array. A callable , see Selection By Callable . A tuple of row (and column) indexes, whose elements are one of the above types. Note that setting works as well: With a DataFrame: Select via integer slicing: Select via integer list: For getting a cross section using an integer position (equiv to df.xs(1) ): Out of range slice indexes are handled gracefully just as in Python/NumPy. Note that using slices that go out of bounds can result in an empty axis (e.g. an empty DataFrame being returned). A single indexer that is out of bounds will raise an IndexError . A list of indexers where any element is out of bounds will raise an IndexError . Selection by callable # .loc , .iloc , and also [] indexing can accept a callable as indexer. The callable must be a function with one argument (the calling Series or DataFrame) that returns valid output for indexing. Note For .iloc indexing, returning a tuple from the callable is not supported, since tuple destructuring for row and column indexes occurs before applying callables. You can use callable indexing in Series . Using these methods / indexers, you can chain data selection operations without using a temporary variable. Combining positional and label-based indexing # If you wish to get the 0th and the 2nd elements from the index in the ‘A’ column, you can do: This can also be expressed using .iloc , by explicitly getting locations on the indexers, and using positional indexing to select things. For getting multiple indexers, using .get_indexer : Reindexing # The idiomatic way to achieve selecting potentially not-found elements is via .reindex() . See also the section on reindexing . Alternatively, if you want to select only valid keys, the following is idiomatic and efficient; it is guaranteed to preserve the dtype of the selection. Having a duplicated index will raise for a .reindex() : Generally, you can intersect the desired labels with the current axis, and then reindex. However, this would still raise if your resulting index is duplicated. Selecting random samples # A random selection of rows or columns from a Series or DataFrame with the sample() method. The method will sample rows by default, and accepts a specific number of rows/columns to return, or a fraction of rows. By default, sample will return each row at most once, but one can also sample with replacement using the replace option: By default, each row has an equal probability of being selected, but if you want rows to have different probabilities, you can pass the sample function sampling weights as weights . These weights can be a list, a NumPy array, or a Series, but they must be of the same length as the object you are sampling. Missing values will be treated as a weight of zero, and inf values are not allowed. If weights do not sum to 1, they will be re-normalized by dividing all weights by the sum of the weights. For example: When applied to a DataFrame, you can use a column of the DataFrame as sampling weights (provided you are sampling rows and not columns) by simply passing the name of the column as a string. sample also allows users to sample columns instead of rows using the axis argument. Finally, one can also set a seed for sample ’s random number generator using the random_state argument, which will accept either an integer (as a seed) or a NumPy RandomState object. Setting with enlargement # The .loc/[] operations can perform enlargement when setting a non-existent key for that axis. In the Series case this is effectively an appending operation. A DataFrame can be enlarged on either axis via .loc . This is like an append operation on the DataFrame . Fast scalar value getting and setting # Since indexing with [] must handle a lot of cases (single-label access, slicing, boolean indexing, etc.), it has a bit of overhead in order to figure out what you’re asking for. If you only want to access a scalar value, the fastest way is to use the at and iat methods, which are implemented on all of the data structures. Similarly to loc , at provides label based scalar lookups, while, iat provides integer based lookups analogously to iloc You can also set using these same indexers. at may enlarge the object in-place as above if the indexer is missing. Boolean indexing # Another common operation is the use of boolean vectors to filter the data. The operators are: | for or , & for and , and ~ for not . These must be grouped by using parentheses, since by default Python will evaluate an expression such as df['A'] > 2 & df['B'] < 3 as df['A'] > (2 & df['B']) < 3 , while the desired evaluation order is (df['A'] > 2) & (df['B'] < 3) . Using a boolean vector to index a Series works exactly as in a NumPy ndarray: You may select rows from a DataFrame using a boolean vector the same length as the DataFrame’s index (for example, something derived from one of the columns of the DataFrame): List comprehensions and the map method of Series can also be used to produce more complex criteria: With the choice methods Selection by Label , Selection by Position , and Advanced Indexing you may select along more than one axis using boolean vectors combined with other indexing expressions. Warning iloc supports two kinds of boolean indexing. If the indexer is a boolean Series , an error will be raised. For instance, in the following example, df.iloc[s.values, 1] is ok. The boolean indexer is an array. But df.iloc[s, 1] would raise ValueError . Indexing with isin # Consider the isin() method of Series , which returns a boolean vector that is true wherever the Series elements exist in the passed list. This allows you to select rows where one or more columns have values you want: The same method is available for Index objects and is useful for the cases when you don’t know which of the sought labels are in fact present: In addition to that, MultiIndex allows selecting a separate level to use in the membership check: DataFrame also has an isin() method. When calling isin , pass a set of values as either an array or dict. If values is an array, isin returns a DataFrame of booleans that is the same shape as the original DataFrame, with True wherever the element is in the sequence of values. Oftentimes you’ll want to match certain values with certain columns. Just make values a dict where the key is the column, and the value is a list of items you want to check for. To return the DataFrame of booleans where the values are not in the original DataFrame, use the ~ operator: Combine DataFrame’s isin with the any() and all() methods to quickly select subsets of your data that meet a given criteria. To select a row where each column meets its own criterion: The where() Method and Masking # Selecting values from a Series with a boolean vector generally returns a subset of the data. To guarantee that selection output has the same shape as the original data, you can use the where method in Series and DataFrame . To return only the selected rows: To return a Series of the same shape as the original: Selecting values from a DataFrame with a boolean criterion now also preserves input data shape. where is used under the hood as the implementation. The code below is equivalent to df.where(df < 0) . In addition, where takes an optional other argument for replacement of values where the condition is False, in the returned copy. You may wish to set values based on some boolean criteria. This can be done intuitively like so: where returns a modified copy of the data. Note The signature for DataFrame.where() differs from numpy.where() . Roughly df1.where(m, df2) is equivalent to np.where(m, df1, df2) . Alignment Furthermore, where aligns the input boolean condition (ndarray or DataFrame), such that partial selection with setting is possible. This is analogous to partial setting via .loc (but on the contents rather than the axis labels). Where can also accept axis and level parameters to align the input when performing the where . This is equivalent to (but faster than) the following. where can accept a callable as condition and other arguments. The function must be with one argument (the calling Series or DataFrame) and that returns valid output as condition and other argument. Mask # mask() is the inverse boolean operation of where . Setting with enlargement conditionally using numpy() # An alternative to where() is to use numpy.where() . Combined with setting a new column, you can use it to enlarge a DataFrame where the values are determined conditionally. Consider you have two choices to choose from in the following DataFrame. And you want to set a new column color to ‘green’ when the second column has ‘Z’. You can do the following: If you have multiple conditions, you can use numpy.select() to achieve that. Say corresponding to three conditions there are three choice of colors, with a fourth color as a fallback, you can do the following. The query() Method # DataFrame objects have a query() method that allows selection using an expression. You can get the value of the frame where column b has values between the values of columns a and c . For example: Do the same thing but fall back on a named index if there is no column with the name a . If instead you don’t want to or cannot name your index, you can use the name index in your query expression: Note If the name of your index overlaps with a column name, the column name is given precedence. For example, You can still use the index in a query expression by using the special identifier ‘index’: If for some reason you have a column named index , then you can refer to the index as ilevel_0 as well, but at this point you should consider renaming your columns to something less ambiguous. MultiIndex query() Syntax # You can also use the levels of a DataFrame with a MultiIndex as if they were columns in the frame: If the levels of the MultiIndex are unnamed, you can refer to them using special names: The convention is ilevel_0 , which means “index level 0” for the 0th level of the index . query() Use Cases # A use case for query() is when you have a collection of DataFrame objects that have a subset of column names (or index levels/names) in common. You can pass the same query to both frames without having to specify which frame you’re interested in querying query() Python versus pandas Syntax Comparison # Full numpy-like syntax: Slightly nicer by removing the parentheses (comparison operators bind tighter than & and | ): Use English instead of symbols: Pretty close to how you might write it on paper: The in and not in operators # query() also supports special use of Python’s in and not in comparison operators, providing a succinct syntax for calling the isin method of a Series or DataFrame . You can combine this with other expressions for very succinct queries: Note Note that in and not in are evaluated in Python, since numexpr has no equivalent of this operation. However, only the in / not in expression itself is evaluated in vanilla Python. For example, in the expression df . query ( 'a in b + c + d' ) (b + c + d) is evaluated by numexpr and then the in operation is evaluated in plain Python. In general, any operations that can be evaluated using numexpr will be. Special use of the == operator with list objects # Comparing a list of values to a column using == / != works similarly to in / not in . Boolean operators # You can negate boolean expressions with the word not or the ~ operator. Of course, expressions can be arbitrarily complex too: Performance of query() # DataFrame.query() using numexpr is slightly faster than Python for large frames. You will only see the performance benefits of using the numexpr engine with DataFrame.query() if your frame has more than approximately 100,000 rows. This plot was created using a DataFrame with 3 columns each containing floating point values generated using numpy.random.randn() . Duplicate data # If you want to identify and remove duplicate rows in a DataFrame, there are two methods that will help: duplicated and drop_duplicates . Each takes as an argument the columns to use to identify duplicated rows. duplicated returns a boolean vector whose length is the number of rows, and which indicates whether a row is duplicated. drop_duplicates removes duplicate rows. By default, the first observed row of a duplicate set is considered unique, but each method has a keep parameter to specify targets to be kept. keep='first' (default): mark / drop duplicates except for the first occurrence. keep='last' : mark / drop duplicates except for the last occurrence. keep=False : mark / drop all duplicates. Also, you can pass a list of columns to identify duplications. To drop duplicates by index value, use Index.duplicated then perform slicing. The same set of options are available for the keep parameter. Dictionary-like get() method # Each of Series or DataFrame have a get method which can return a default value. Looking up values by index/column labels # Sometimes you want to extract a set of values given a sequence of row labels and column labels, this can be achieved by pandas.factorize and NumPy indexing. For instance: Formerly this could be achieved with the dedicated DataFrame.lookup method which was deprecated in version 1.2.0 and removed in version 2.0.0. Index objects # The pandas Index class and its subclasses can be viewed as implementing an ordered multiset . Duplicates are allowed. Index also provides the infrastructure necessary for lookups, data alignment, and reindexing. The easiest way to create an Index directly is to pass a list or other sequence to Index : or using numbers: If no dtype is given, Index tries to infer the dtype from the data. It is also possible to give an explicit dtype when instantiating an Index : You can also pass a name to be stored in the index: The name, if set, will be shown in the console display: Setting metadata # Indexes are “mostly immutable”, but it is possible to set and change their name attribute. You can use the rename , set_names to set these attributes directly, and they default to returning a copy. See Advanced Indexing for usage of MultiIndexes. set_names , set_levels , and set_codes also take an optional level argument Set operations on Index objects # The two main operations are union and intersection . Difference is provided via the .difference() method. Also available is the symmetric_difference operation, which returns elements that appear in either idx1 or idx2 , but not in both. This is equivalent to the Index created by idx1.difference(idx2).union(idx2.difference(idx1)) , with duplicates dropped. Note The resulting index from a set operation will be sorted in ascending order. When performing Index.union() between indexes with different dtypes, the indexes must be cast to a common dtype. Typically, though not always, this is object dtype. The exception is when performing a union between integer and float data. In this case, the integer values are converted to float Missing values # Important Even though Index can hold missing values ( NaN ), it should be avoided if you do not want any unexpected results. For example, some operations exclude missing values implicitly. Index.fillna fills missing values with specified scalar value. Set / reset index # Occasionally you will load or create a data set into a DataFrame and want to add an index after you’ve already done so. There are a couple of different ways. Set an index # DataFrame has a set_index() method which takes a column name (for a regular Index ) or a list of column names (for a MultiIndex ). To create a new, re-indexed DataFrame: The append keyword option allow you to keep the existing index and append the given columns to a MultiIndex: Other options in set_index allow you not drop the index columns. Reset the index # As a convenience, there is a new function on DataFrame called reset_index() which transfers the index values into the DataFrame’s columns and sets a simple integer index. This is the inverse operation of set_index() . The output is more similar to a SQL table or a record array. The names for the columns derived from the index are the ones stored in the names attribute. You can use the level keyword to remove only a portion of the index: reset_index takes an optional parameter drop which if true simply discards the index, instead of putting index values in the DataFrame’s columns. Adding an ad hoc index # You can assign a custom index to the index attribute: Returning a view versus a copy # Warning Copy-on-Write will become the new default in pandas 3.0. This means than chained indexing will never work. As a consequence, the SettingWithCopyWarning won’t be necessary anymore. See this section for more context. We recommend turning Copy-on-Write on to leverage the improvements with ` pd.options.mode.copy_on_write = True ` even before pandas 3.0 is available. When setting values in a pandas object, care must be taken to avoid what is called chained indexing . Here is an example. Compare these two access methods: These both yield the same results, so which should you use? It is instructive to understand the order of operations on these and why method 2 ( .loc ) is much preferred over method 1 (chained [] ). dfmi['one'] selects the first level of the columns and returns a DataFrame that is singly-indexed. Then another Python operation dfmi_with_one['second'] selects the series indexed by 'second' . This is indicated by the variable dfmi_with_one because pandas sees these operations as separate events. e.g. separate calls to __getitem__ , so it has to treat them as linear operations, they happen one after another. Contrast this to df.loc[:,('one','second')] which passes a nested tuple of (slice(None),('one','second')) to a single call to __getitem__ . This allows pandas to deal with this as a single entity. Furthermore this order of operations can be significantly faster, and allows one to index both axes if so desired. Why does assignment fail when using chained indexing? # Warning Copy-on-Write will become the new default in pandas 3.0. This means than chained indexing will never work. As a consequence, the SettingWithCopyWarning won’t be necessary anymore. See this section for more context. We recommend turning Copy-on-Write on to leverage the improvements with ` pd.options.mode.copy_on_write = True ` even before pandas 3.0 is available. The problem in the previous section is just a performance issue. What’s up with the SettingWithCopy warning? We don’t usually throw warnings around when you do something that might cost a few extra milliseconds! But it turns out that assigning to the product of chained indexing has inherently unpredictable results. To see this, think about how the Python interpreter executes this code: dfmi . loc [:, ( 'one' , 'second' )] = value # becomes dfmi . loc . __setitem__ (( slice ( None ), ( 'one' , 'second' )), value ) But this code is handled differently: dfmi [ 'one' ][ 'second' ] = value # becomes dfmi . __getitem__ ( 'one' ) . __setitem__ ( 'second' , value ) See that __getitem__ in there? Outside of simple cases, it’s very hard to predict whether it will return a view or a copy (it depends on the memory layout of the array, about which pandas makes no guarantees), and therefore whether the __setitem__ will modify dfmi or a temporary object that gets thrown out immediately afterward. That’s what SettingWithCopy is warning you about! Note You may be wondering whether we should be concerned about the loc property in the first example. But dfmi.loc is guaranteed to be dfmi itself with modified indexing behavior, so dfmi.loc.__getitem__ / dfmi.loc.__setitem__ operate on dfmi directly. Of course, dfmi.loc.__getitem__(idx) may be a view or a copy of dfmi . Sometimes a SettingWithCopy warning will arise at times when there’s no obvious chained indexing going on. These are the bugs that SettingWithCopy is designed to catch! pandas is probably trying to warn you that you’ve done this: def do_something ( df ): foo = df [[ 'bar' , 'baz' ]] # Is foo a view? A copy? Nobody knows! # ... many lines here ... # We don't know whether this will modify df or not! foo [ 'quux' ] = value return foo Yikes! Evaluation order matters # Warning Copy-on-Write will become the new default in pandas 3.0. This means than chained indexing will never work. As a consequence, the SettingWithCopyWarning won’t be necessary anymore. See this section for more context. We recommend turning Copy-on-Write on to leverage the improvements with ` pd.options.mode.copy_on_write = True ` even before pandas 3.0 is available. When you use chained indexing, the order and type of the indexing operation partially determine whether the result is a slice into the original object, or a copy of the slice. pandas has the SettingWithCopyWarning because assigning to a copy of a slice is frequently not intentional, but a mistake caused by chained indexing returning a copy where a slice was expected. If you would like pandas to be more or less trusting about assignment to a chained indexing expression, you can set the option mode.chained_assignment to one of these values: 'warn' , the default, means a SettingWithCopyWarning is printed. 'raise' means pandas will raise a SettingWithCopyError you have to deal with. None will suppress the warnings entirely. This however is operating on a copy and will not work. A chained assignment can also crop up in setting in a mixed dtype frame. Note These setting rules apply to all of .loc/.iloc . The following is the recommended access method using .loc for multiple items (using mask ) and a single item using a fixed index: The following can work at times, but it is not guaranteed to, and therefore should be avoided: Last, the subsequent example will not work at all, and so should be avoided: Warning The chained assignment warnings / exceptions are aiming to inform the user of a possibly invalid assignment. There may be false positives; situations where a chained assignment is inadvertently reported."
https://pandas.pydata.org/docs/user_guide/advanced.html,MultiIndex / advanced indexing,"<article class=""bd-article"" role=""main"">
<section id=""multiindex-advanced-indexing"">
<span id=""advanced""></span><h1>MultiIndex / advanced indexing<a class=""headerlink"" href=""#multiindex-advanced-indexing"" title=""Link to this heading"">#</a></h1>
<p>This section covers <a class=""reference internal"" href=""#advanced-hierarchical""><span class=""std std-ref"">indexing with a MultiIndex</span></a>
and <a class=""reference internal"" href=""#advanced-index-types""><span class=""std std-ref"">other advanced indexing features</span></a>.</p>
<p>See the <a class=""reference internal"" href=""indexing.html#indexing""><span class=""std std-ref"">Indexing and Selecting Data</span></a> for general indexing documentation.</p>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Whether a copy or a reference is returned for a setting operation may
depend on the context. This is sometimes called <code class=""docutils literal notranslate""><span class=""pre"">chained</span> <span class=""pre"">assignment</span></code> and
should be avoided. See <a class=""reference internal"" href=""indexing.html#indexing-view-versus-copy""><span class=""std std-ref"">Returning a View versus Copy</span></a>.</p>
</div>
<p>See the <a class=""reference internal"" href=""cookbook.html#cookbook-selection""><span class=""std std-ref"">cookbook</span></a> for some advanced strategies.</p>
<section id=""hierarchical-indexing-multiindex"">
<span id=""advanced-hierarchical""></span><h2>Hierarchical indexing (MultiIndex)<a class=""headerlink"" href=""#hierarchical-indexing-multiindex"" title=""Link to this heading"">#</a></h2>
<p>Hierarchical / Multi-level indexing is very exciting as it opens the door to some
quite sophisticated data analysis and manipulation, especially for working with
higher dimensional data. In essence, it enables you to store and manipulate
data with an arbitrary number of dimensions in lower dimensional data
structures like <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> (1d) and <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> (2d).</p>
<p>In this section, we will show what exactly we mean by “hierarchical” indexing
and how it integrates with all of the pandas indexing functionality
described above and in prior sections. Later, when discussing <a class=""reference internal"" href=""groupby.html#groupby""><span class=""std std-ref"">group by</span></a> and <a class=""reference internal"" href=""reshaping.html#reshaping""><span class=""std std-ref"">pivoting and reshaping data</span></a>, we’ll show
non-trivial applications to illustrate how it aids in structuring data for
analysis.</p>
<p>See the <a class=""reference internal"" href=""cookbook.html#cookbook-multi-index""><span class=""std std-ref"">cookbook</span></a> for some advanced strategies.</p>
<section id=""creating-a-multiindex-hierarchical-index-object"">
<h3>Creating a MultiIndex (hierarchical index) object<a class=""headerlink"" href=""#creating-a-multiindex-hierarchical-index-object"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a> object is the hierarchical analogue of the standard
<a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a> object which typically stores the axis labels in pandas objects. You
can think of <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> as an array of tuples where each tuple is unique. A
<code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> can be created from a list of arrays (using
<a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.from_arrays.html#pandas.MultiIndex.from_arrays"" title=""pandas.MultiIndex.from_arrays""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">MultiIndex.from_arrays()</span></code></a>), an array of tuples (using
<a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.from_tuples.html#pandas.MultiIndex.from_tuples"" title=""pandas.MultiIndex.from_tuples""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">MultiIndex.from_tuples()</span></code></a>), a crossed set of iterables (using
<a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.from_product.html#pandas.MultiIndex.from_product"" title=""pandas.MultiIndex.from_product""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">MultiIndex.from_product()</span></code></a>), or a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> (using
<a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.from_frame.html#pandas.MultiIndex.from_frame"" title=""pandas.MultiIndex.from_frame""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">MultiIndex.from_frame()</span></code></a>). The <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> constructor will attempt to return
a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> when it is passed a list of tuples. The following examples
demonstrate different ways to initialize MultiIndexes.</p>

<p>When you want every pairing of the elements in two iterables, it can be easier
to use the <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.from_product.html#pandas.MultiIndex.from_product"" title=""pandas.MultiIndex.from_product""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">MultiIndex.from_product()</span></code></a> method:</p>

<p>You can also construct a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> from a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> directly, using
the method <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.from_frame.html#pandas.MultiIndex.from_frame"" title=""pandas.MultiIndex.from_frame""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">MultiIndex.from_frame()</span></code></a>. This is a complementary method to
<a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.to_frame.html#pandas.MultiIndex.to_frame"" title=""pandas.MultiIndex.to_frame""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">MultiIndex.to_frame()</span></code></a>.</p>

<p>As a convenience, you can pass a list of arrays directly into <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> or
<code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> to construct a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> automatically:</p>

<p>All of the <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> constructors accept a <code class=""docutils literal notranslate""><span class=""pre"">names</span></code> argument which stores
string names for the levels themselves. If no names are provided, <code class=""docutils literal notranslate""><span class=""pre"">None</span></code> will
be assigned:</p>

<p>This index can back any axis of a pandas object, and the number of <strong>levels</strong>
of the index is up to you:</p>

<p>We’ve “sparsified” the higher levels of the indexes to make the console output a
bit easier on the eyes. Note that how the index is displayed can be controlled using the
<code class=""docutils literal notranslate""><span class=""pre"">multi_sparse</span></code> option in <code class=""docutils literal notranslate""><span class=""pre"">pandas.set_options()</span></code>:</p>

<p>It’s worth keeping in mind that there’s nothing preventing you from using
tuples as atomic labels on an axis:</p>

<p>The reason that the <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> matters is that it can allow you to do
grouping, selection, and reshaping operations as we will describe below and in
subsequent areas of the documentation. As you will see in later sections, you
can find yourself working with hierarchically-indexed data without creating a
<code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> explicitly yourself. However, when loading data from a file, you
may wish to generate your own <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> when preparing the data set.</p>
</section>
<section id=""reconstructing-the-level-labels"">
<span id=""advanced-get-level-values""></span><h3>Reconstructing the level labels<a class=""headerlink"" href=""#reconstructing-the-level-labels"" title=""Link to this heading"">#</a></h3>
<p>The method <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.get_level_values.html#pandas.MultiIndex.get_level_values"" title=""pandas.MultiIndex.get_level_values""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">get_level_values()</span></code></a> will return a vector of the labels for each
location at a particular level:</p>

</section>
<section id=""basic-indexing-on-axis-with-multiindex"">
<h3>Basic indexing on axis with MultiIndex<a class=""headerlink"" href=""#basic-indexing-on-axis-with-multiindex"" title=""Link to this heading"">#</a></h3>
<p>One of the important features of hierarchical indexing is that you can select
data by a “partial” label identifying a subgroup in the data. <strong>Partial</strong>
selection “drops” levels of the hierarchical index in the result in a
completely analogous way to selecting a column in a regular DataFrame:</p>

<p>See <a class=""reference internal"" href=""#advanced-xs""><span class=""std std-ref"">Cross-section with hierarchical index</span></a> for how to select
on a deeper level.</p>
</section>
<section id=""defined-levels"">
<span id=""advanced-shown-levels""></span><h3>Defined levels<a class=""headerlink"" href=""#defined-levels"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a> keeps all the defined levels of an index, even
if they are not actually used. When slicing an index, you may notice this.
For example:</p>

<p>This is done to avoid a recomputation of the levels in order to make slicing
highly performant. If you want to see only the used levels, you can use the
<a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.get_level_values.html#pandas.MultiIndex.get_level_values"" title=""pandas.MultiIndex.get_level_values""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">get_level_values()</span></code></a> method.</p>

<p>To reconstruct the <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> with only the used levels, the
<a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.remove_unused_levels.html#pandas.MultiIndex.remove_unused_levels"" title=""pandas.MultiIndex.remove_unused_levels""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">remove_unused_levels()</span></code></a> method may be used.</p>

</section>
<section id=""data-alignment-and-using-reindex"">
<h3>Data alignment and using <code class=""docutils literal notranslate""><span class=""pre"">reindex</span></code><a class=""headerlink"" href=""#data-alignment-and-using-reindex"" title=""Link to this heading"">#</a></h3>
<p>Operations between differently-indexed objects having <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> on the
axes will work as you expect; data alignment will work the same as an Index of
tuples:</p>

<p>The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.reindex.html#pandas.DataFrame.reindex"" title=""pandas.DataFrame.reindex""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">reindex()</span></code></a> method of <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>/<code class=""docutils literal notranslate""><span class=""pre"">DataFrames</span></code> can be
called with another <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code>, or even a list or array of tuples:</p>

</section>
</section>
<section id=""advanced-indexing-with-hierarchical-index"">
<span id=""advanced-advanced-hierarchical""></span><h2>Advanced indexing with hierarchical index<a class=""headerlink"" href=""#advanced-indexing-with-hierarchical-index"" title=""Link to this heading"">#</a></h2>
<p>Syntactically integrating <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> in advanced indexing with <code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code> is a
bit challenging, but we’ve made every effort to do so. In general, MultiIndex
keys take the form of tuples. For example, the following works as you would expect:</p>

<p>Note that <code class=""docutils literal notranslate""><span class=""pre"">df.loc['bar',</span> <span class=""pre"">'two']</span></code> would also work in this example, but this shorthand
notation can lead to ambiguity in general.</p>
<p>If you also want to index a specific column with <code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code>, you must use a tuple
like this:</p>

<p>You don’t have to specify all levels of the <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> by passing only the
first elements of the tuple. For example, you can use “partial” indexing to
get all elements with <code class=""docutils literal notranslate""><span class=""pre"">bar</span></code> in the first level as follows:</p>

<p>This is a shortcut for the slightly more verbose notation <code class=""docutils literal notranslate""><span class=""pre"">df.loc[('bar',),]</span></code> (equivalent
to <code class=""docutils literal notranslate""><span class=""pre"">df.loc['bar',]</span></code> in this example).</p>
<p>“Partial” slicing also works quite nicely.</p>

<p>You can slice with a ‘range’ of values, by providing a slice of tuples.</p>

<p>Passing a list of labels or tuples works similar to reindexing:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>It is important to note that tuples and lists are not treated identically
in pandas when it comes to indexing. Whereas a tuple is interpreted as one
multi-level key, a list is used to specify several keys. Or in other words,
tuples go horizontally (traversing levels), lists go vertically (scanning levels).</p>
</div>
<p>Importantly, a list of tuples indexes several complete <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> keys,
whereas a tuple of lists refer to several values within a level:</p>

<section id=""using-slicers"">
<span id=""advanced-mi-slicers""></span><h3>Using slicers<a class=""headerlink"" href=""#using-slicers"" title=""Link to this heading"">#</a></h3>
<p>You can slice a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> by providing multiple indexers.</p>
<p>You can provide any of the selectors as if you are indexing by label, see <a class=""reference internal"" href=""indexing.html#indexing-label""><span class=""std std-ref"">Selection by Label</span></a>,
including slices, lists of labels, labels, and boolean indexers.</p>
<p>You can use <code class=""docutils literal notranslate""><span class=""pre"">slice(None)</span></code> to select all the contents of <em>that</em> level. You do not need to specify all the
<em>deeper</em> levels, they will be implied as <code class=""docutils literal notranslate""><span class=""pre"">slice(None)</span></code>.</p>
<p>As usual, <strong>both sides</strong> of the slicers are included as this is label indexing.</p>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>You should specify all axes in the <code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code> specifier, meaning the indexer for the <strong>index</strong> and
for the <strong>columns</strong>. There are some ambiguous cases where the passed indexer could be misinterpreted
as indexing <em>both</em> axes, rather than into say the <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> for the rows.</p>
<p>You should do this:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df</span><span class=""o"">.</span><span class=""n"">loc</span><span class=""p"">[(</span><span class=""nb"">slice</span><span class=""p"">(</span><span class=""s2"">""A1""</span><span class=""p"">,</span> <span class=""s2"">""A3""</span><span class=""p"">),</span> <span class=""o"">...</span><span class=""p"">),</span> <span class=""p"">:]</span>  <span class=""c1""># noqa: E999</span>
</pre></div>
</div>
<p>You should <strong>not</strong> do this:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df</span><span class=""o"">.</span><span class=""n"">loc</span><span class=""p"">[(</span><span class=""nb"">slice</span><span class=""p"">(</span><span class=""s2"">""A1""</span><span class=""p"">,</span> <span class=""s2"">""A3""</span><span class=""p"">),</span> <span class=""o"">...</span><span class=""p"">)]</span>  <span class=""c1""># noqa: E999</span>
</pre></div>
</div>
</div>

<p>Basic MultiIndex slicing using slices, lists, and labels.</p>

<p>You can use <a class=""reference internal"" href=""../reference/api/pandas.IndexSlice.html#pandas.IndexSlice"" title=""pandas.IndexSlice""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">pandas.IndexSlice</span></code></a> to facilitate a more natural syntax
using <code class=""docutils literal notranslate""><span class=""pre"">:</span></code>, rather than using <code class=""docutils literal notranslate""><span class=""pre"">slice(None)</span></code>.</p>

<p>It is possible to perform quite complicated selections using this method on multiple
axes at the same time.</p>

<p>Using a boolean indexer you can provide selection related to the <em>values</em>.</p>

<p>You can also specify the <code class=""docutils literal notranslate""><span class=""pre"">axis</span></code> argument to <code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code> to interpret the passed
slicers on a single axis.</p>

<p>Furthermore, you can <em>set</em> the values using the following methods.</p>

<p>You can use a right-hand-side of an alignable object as well.</p>

</section>
<section id=""cross-section"">
<span id=""advanced-xs""></span><h3>Cross-section<a class=""headerlink"" href=""#cross-section"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.xs.html#pandas.DataFrame.xs"" title=""pandas.DataFrame.xs""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">xs()</span></code></a> method of <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> additionally takes a level argument to make
selecting data at a particular level of a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> easier.</p>


<p>You can also select on the columns with <code class=""docutils literal notranslate""><span class=""pre"">xs</span></code>, by
providing the axis argument.</p>


<p><code class=""docutils literal notranslate""><span class=""pre"">xs</span></code> also allows selection with multiple keys.</p>


<p>You can pass <code class=""docutils literal notranslate""><span class=""pre"">drop_level=False</span></code> to <code class=""docutils literal notranslate""><span class=""pre"">xs</span></code> to retain
the level that was selected.</p>

<p>Compare the above with the result using <code class=""docutils literal notranslate""><span class=""pre"">drop_level=True</span></code> (the default value).</p>

</section>
<section id=""advanced-reindexing-and-alignment"">
<span id=""advanced-advanced-reindex""></span><h3>Advanced reindexing and alignment<a class=""headerlink"" href=""#advanced-reindexing-and-alignment"" title=""Link to this heading"">#</a></h3>
<p>Using the parameter <code class=""docutils literal notranslate""><span class=""pre"">level</span></code> in the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.reindex.html#pandas.DataFrame.reindex"" title=""pandas.DataFrame.reindex""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">reindex()</span></code></a> and
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.align.html#pandas.DataFrame.align"" title=""pandas.DataFrame.align""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">align()</span></code></a> methods of pandas objects is useful to broadcast
values across a level. For instance:</p>

</section>
<section id=""swapping-levels-with-swaplevel"">
<h3>Swapping levels with <code class=""docutils literal notranslate""><span class=""pre"">swaplevel</span></code><a class=""headerlink"" href=""#swapping-levels-with-swaplevel"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.swaplevel.html#pandas.MultiIndex.swaplevel"" title=""pandas.MultiIndex.swaplevel""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">swaplevel()</span></code></a> method can switch the order of two levels:</p>

</section>
<section id=""reordering-levels-with-reorder-levels"">
<span id=""advanced-reorderlevels""></span><h3>Reordering levels with <code class=""docutils literal notranslate""><span class=""pre"">reorder_levels</span></code><a class=""headerlink"" href=""#reordering-levels-with-reorder-levels"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.reorder_levels.html#pandas.MultiIndex.reorder_levels"" title=""pandas.MultiIndex.reorder_levels""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">reorder_levels()</span></code></a> method generalizes the <code class=""docutils literal notranslate""><span class=""pre"">swaplevel</span></code>
method, allowing you to permute the hierarchical index levels in one step:</p>

</section>
<section id=""renaming-names-of-an-index-or-multiindex"">
<span id=""advanced-index-names""></span><h3>Renaming names of an <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code><a class=""headerlink"" href=""#renaming-names-of-an-index-or-multiindex"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.rename.html#pandas.DataFrame.rename"" title=""pandas.DataFrame.rename""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">rename()</span></code></a> method is used to rename the labels of a
<code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code>, and is typically used to rename the columns of a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>.
The <code class=""docutils literal notranslate""><span class=""pre"">columns</span></code> argument of <code class=""docutils literal notranslate""><span class=""pre"">rename</span></code> allows a dictionary to be specified
that includes only the columns you wish to rename.</p>

<p>This method can also be used to rename specific labels of the main index
of the <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>.</p>

<p>The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.rename_axis.html#pandas.DataFrame.rename_axis"" title=""pandas.DataFrame.rename_axis""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">rename_axis()</span></code></a> method is used to rename the name of a
<code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code>. In particular, the names of the levels of a
<code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> can be specified, which is useful if <code class=""docutils literal notranslate""><span class=""pre"">reset_index()</span></code> is later
used to move the values from the <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> to a column.</p>

<p>Note that the columns of a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> are an index, so that using
<code class=""docutils literal notranslate""><span class=""pre"">rename_axis</span></code> with the <code class=""docutils literal notranslate""><span class=""pre"">columns</span></code> argument will change the name of that
index.</p>

<p>Both <code class=""docutils literal notranslate""><span class=""pre"">rename</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">rename_axis</span></code> support specifying a dictionary,
<code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> or a mapping function to map labels/names to new values.</p>
<p>When working with an <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> object directly, rather than via a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>,
<a class=""reference internal"" href=""../reference/api/pandas.Index.set_names.html#pandas.Index.set_names"" title=""pandas.Index.set_names""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Index.set_names()</span></code></a> can be used to change the names.</p>

<p>You cannot set the names of the MultiIndex via a level.</p>

<p>Use <a class=""reference internal"" href=""../reference/api/pandas.Index.set_names.html#pandas.Index.set_names"" title=""pandas.Index.set_names""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Index.set_names()</span></code></a> instead.</p>
</section>
</section>
<section id=""sorting-a-multiindex"">
<h2>Sorting a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code><a class=""headerlink"" href=""#sorting-a-multiindex"" title=""Link to this heading"">#</a></h2>
<p>For <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a>-ed objects to be indexed and sliced effectively,
they need to be sorted. As with any index, you can use <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.sort_index.html#pandas.DataFrame.sort_index"" title=""pandas.DataFrame.sort_index""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">sort_index()</span></code></a>.</p>

<p id=""advanced-sortlevel-byname"">You may also pass a level name to <code class=""docutils literal notranslate""><span class=""pre"">sort_index</span></code> if the <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> levels
are named.</p>

<p>On higher dimensional objects, you can sort any of the other axes by level if
they have a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code>:</p>

<p>Indexing will work even if the data are not sorted, but will be rather
inefficient (and show a <code class=""docutils literal notranslate""><span class=""pre"">PerformanceWarning</span></code>). It will also
return a copy of the data rather than a view:</p>

<p id=""advanced-unsorted"">Furthermore, if you try to index something that is not fully lexsorted, this can raise:</p>

<p>The <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">is_monotonic_increasing()</span></code> method on a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> shows if the
index is sorted:</p>


<p>And now selection works as expected.</p>

</section>
<section id=""take-methods"">
<h2>Take methods<a class=""headerlink"" href=""#take-methods"" title=""Link to this heading"">#</a></h2>
<p id=""advanced-take"">Similar to NumPy ndarrays, pandas <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> also provides
the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.take.html#pandas.DataFrame.take"" title=""pandas.DataFrame.take""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">take()</span></code></a> method that retrieves elements along a given axis at the given
indices. The given indices must be either a list or an ndarray of integer
index positions. <code class=""docutils literal notranslate""><span class=""pre"">take</span></code> will also accept negative integers as relative positions to the end of the object.</p>

<p>For DataFrames, the given indices should be a 1d list or ndarray that specifies
row or column positions.</p>

<p>It is important to note that the <code class=""docutils literal notranslate""><span class=""pre"">take</span></code> method on pandas objects are not
intended to work on boolean indices and may return unexpected results.</p>

<p>Finally, as a small note on performance, because the <code class=""docutils literal notranslate""><span class=""pre"">take</span></code> method handles
a narrower range of inputs, it can offer performance that is a good deal
faster than fancy indexing.</p>


</section>
<section id=""index-types"">
<span id=""advanced-index-types""></span><h2>Index types<a class=""headerlink"" href=""#index-types"" title=""Link to this heading"">#</a></h2>
<p>We have discussed <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> in the previous sections pretty extensively.
Documentation about <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code> are shown <a class=""reference internal"" href=""timeseries.html#timeseries-overview""><span class=""std std-ref"">here</span></a>,
and documentation about <code class=""docutils literal notranslate""><span class=""pre"">TimedeltaIndex</span></code> is found <a class=""reference internal"" href=""timedeltas.html#timedeltas-index""><span class=""std std-ref"">here</span></a>.</p>
<p>In the following sub-sections we will highlight some other index types.</p>
<section id=""categoricalindex"">
<span id=""advanced-categoricalindex""></span><h3>CategoricalIndex<a class=""headerlink"" href=""#categoricalindex"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.CategoricalIndex.html#pandas.CategoricalIndex"" title=""pandas.CategoricalIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">CategoricalIndex</span></code></a> is a type of index that is useful for supporting
indexing with duplicates. This is a container around a <a class=""reference internal"" href=""../reference/api/pandas.Categorical.html#pandas.Categorical"" title=""pandas.Categorical""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Categorical</span></code></a>
and allows efficient indexing and storage of an index with a large number of duplicated elements.</p>

<p>Setting the index will create a <code class=""docutils literal notranslate""><span class=""pre"">CategoricalIndex</span></code>.</p>

<p>Indexing with <code class=""docutils literal notranslate""><span class=""pre"">__getitem__/.iloc/.loc</span></code> works similarly to an <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> with duplicates.
The indexers <strong>must</strong> be in the category or the operation will raise a <code class=""docutils literal notranslate""><span class=""pre"">KeyError</span></code>.</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">CategoricalIndex</span></code> is <strong>preserved</strong> after indexing:</p>

<p>Sorting the index will sort by the order of the categories (recall that we
created the index with <code class=""docutils literal notranslate""><span class=""pre"">CategoricalDtype(list('cab'))</span></code>, so the sorted
order is <code class=""docutils literal notranslate""><span class=""pre"">cab</span></code>).</p>

<p>Groupby operations on the index will preserve the index nature as well.</p>

<p>Reindexing operations will return a resulting index based on the type of the passed
indexer. Passing a list will return a plain-old <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code>; indexing with
a <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> will return a <code class=""docutils literal notranslate""><span class=""pre"">CategoricalIndex</span></code>, indexed according to the categories
of the <strong>passed</strong> <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> dtype. This allows one to arbitrarily index these even with
values <strong>not</strong> in the categories, similarly to how you can reindex <strong>any</strong> pandas index.</p>


<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Reshaping and Comparison operations on a <code class=""docutils literal notranslate""><span class=""pre"">CategoricalIndex</span></code> must have the same categories
or a <code class=""docutils literal notranslate""><span class=""pre"">TypeError</span></code> will be raised.</p>


</div>
</section>
<section id=""rangeindex"">
<span id=""advanced-rangeindex""></span><h3>RangeIndex<a class=""headerlink"" href=""#rangeindex"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.RangeIndex.html#pandas.RangeIndex"" title=""pandas.RangeIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">RangeIndex</span></code></a> is a sub-class of <a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a> that provides the default index for all <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> objects.
<code class=""docutils literal notranslate""><span class=""pre"">RangeIndex</span></code> is an optimized version of <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> that can represent a monotonic ordered set. These are analogous to Python <a class=""reference external"" href=""https://docs.python.org/3/library/stdtypes.html#typesseq-range"">range types</a>.
A <code class=""docutils literal notranslate""><span class=""pre"">RangeIndex</span></code> will always have an <code class=""docutils literal notranslate""><span class=""pre"">int64</span></code> dtype.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">RangeIndex</span></code> is the default index for all <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> objects:</p>

<p>A <code class=""docutils literal notranslate""><span class=""pre"">RangeIndex</span></code> will behave similarly to a <a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a> with an <code class=""docutils literal notranslate""><span class=""pre"">int64</span></code> dtype and operations on a <code class=""docutils literal notranslate""><span class=""pre"">RangeIndex</span></code>,
whose result cannot be represented by a <code class=""docutils literal notranslate""><span class=""pre"">RangeIndex</span></code>, but should have an integer dtype, will be converted to an <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> with <code class=""docutils literal notranslate""><span class=""pre"">int64</span></code>.
For example:</p>

</section>
<section id=""intervalindex"">
<span id=""advanced-intervalindex""></span><h3>IntervalIndex<a class=""headerlink"" href=""#intervalindex"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.IntervalIndex.html#pandas.IntervalIndex"" title=""pandas.IntervalIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">IntervalIndex</span></code></a> together with its own dtype, <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">IntervalDtype</span></code>
as well as the <a class=""reference internal"" href=""../reference/api/pandas.Interval.html#pandas.Interval"" title=""pandas.Interval""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Interval</span></code></a> scalar type, allow first-class support in pandas
for interval notation.</p>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">IntervalIndex</span></code> allows some unique indexing and is also used as a
return type for the categories in <a class=""reference internal"" href=""../reference/api/pandas.cut.html#pandas.cut"" title=""pandas.cut""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">cut()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.qcut.html#pandas.qcut"" title=""pandas.qcut""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">qcut()</span></code></a>.</p>
<section id=""indexing-with-an-intervalindex"">
<h4>Indexing with an <code class=""docutils literal notranslate""><span class=""pre"">IntervalIndex</span></code><a class=""headerlink"" href=""#indexing-with-an-intervalindex"" title=""Link to this heading"">#</a></h4>
<p>An <code class=""docutils literal notranslate""><span class=""pre"">IntervalIndex</span></code> can be used in <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> and in <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> as the index.</p>

<p>Label based indexing via <code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code> along the edges of an interval works as you would expect,
selecting that particular interval.</p>

<p>If you select a label <em>contained</em> within an interval, this will also select the interval.</p>

<p>Selecting using an <code class=""docutils literal notranslate""><span class=""pre"">Interval</span></code> will only return exact matches.</p>

<p>Trying to select an <code class=""docutils literal notranslate""><span class=""pre"">Interval</span></code> that is not exactly contained in the <code class=""docutils literal notranslate""><span class=""pre"">IntervalIndex</span></code> will raise a <code class=""docutils literal notranslate""><span class=""pre"">KeyError</span></code>.</p>

<p>Selecting all <code class=""docutils literal notranslate""><span class=""pre"">Intervals</span></code> that overlap a given <code class=""docutils literal notranslate""><span class=""pre"">Interval</span></code> can be performed using the
<a class=""reference internal"" href=""../reference/api/pandas.IntervalIndex.overlaps.html#pandas.IntervalIndex.overlaps"" title=""pandas.IntervalIndex.overlaps""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">overlaps()</span></code></a> method to create a boolean indexer.</p>

</section>
<section id=""binning-data-with-cut-and-qcut"">
<h4>Binning data with <code class=""docutils literal notranslate""><span class=""pre"">cut</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">qcut</span></code><a class=""headerlink"" href=""#binning-data-with-cut-and-qcut"" title=""Link to this heading"">#</a></h4>
<p><a class=""reference internal"" href=""../reference/api/pandas.cut.html#pandas.cut"" title=""pandas.cut""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">cut()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.qcut.html#pandas.qcut"" title=""pandas.qcut""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">qcut()</span></code></a> both return a <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> object, and the bins they
create are stored as an <code class=""docutils literal notranslate""><span class=""pre"">IntervalIndex</span></code> in its <code class=""docutils literal notranslate""><span class=""pre"">.categories</span></code> attribute.</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.cut.html#pandas.cut"" title=""pandas.cut""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">cut()</span></code></a> also accepts an <code class=""docutils literal notranslate""><span class=""pre"">IntervalIndex</span></code> for its <code class=""docutils literal notranslate""><span class=""pre"">bins</span></code> argument, which enables
a useful pandas idiom. First, We call <a class=""reference internal"" href=""../reference/api/pandas.cut.html#pandas.cut"" title=""pandas.cut""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">cut()</span></code></a> with some data and <code class=""docutils literal notranslate""><span class=""pre"">bins</span></code> set to a
fixed number, to generate the bins. Then, we pass the values of <code class=""docutils literal notranslate""><span class=""pre"">.categories</span></code> as the
<code class=""docutils literal notranslate""><span class=""pre"">bins</span></code> argument in subsequent calls to <a class=""reference internal"" href=""../reference/api/pandas.cut.html#pandas.cut"" title=""pandas.cut""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">cut()</span></code></a>, supplying new data which will be
binned into the same bins.</p>

<p>Any value which falls outside all bins will be assigned a <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code> value.</p>
</section>
<section id=""generating-ranges-of-intervals"">
<h4>Generating ranges of intervals<a class=""headerlink"" href=""#generating-ranges-of-intervals"" title=""Link to this heading"">#</a></h4>
<p>If we need intervals on a regular frequency, we can use the <a class=""reference internal"" href=""../reference/api/pandas.interval_range.html#pandas.interval_range"" title=""pandas.interval_range""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">interval_range()</span></code></a> function
to create an <code class=""docutils literal notranslate""><span class=""pre"">IntervalIndex</span></code> using various combinations of <code class=""docutils literal notranslate""><span class=""pre"">start</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">end</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">periods</span></code>.
The default frequency for <code class=""docutils literal notranslate""><span class=""pre"">interval_range</span></code> is a 1 for numeric intervals, and calendar day for
datetime-like intervals:</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">freq</span></code> parameter can used to specify non-default frequencies, and can utilize a variety
of <a class=""reference internal"" href=""timeseries.html#timeseries-offset-aliases""><span class=""std std-ref"">frequency aliases</span></a> with datetime-like intervals:</p>

<p>Additionally, the <code class=""docutils literal notranslate""><span class=""pre"">closed</span></code> parameter can be used to specify which side(s) the intervals
are closed on. Intervals are closed on the right side by default.</p>

<p>Specifying <code class=""docutils literal notranslate""><span class=""pre"">start</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">end</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">periods</span></code> will generate a range of evenly spaced
intervals from <code class=""docutils literal notranslate""><span class=""pre"">start</span></code> to <code class=""docutils literal notranslate""><span class=""pre"">end</span></code> inclusively, with <code class=""docutils literal notranslate""><span class=""pre"">periods</span></code> number of elements
in the resulting <code class=""docutils literal notranslate""><span class=""pre"">IntervalIndex</span></code>:</p>

</section>
</section>
</section>
<section id=""miscellaneous-indexing-faq"">
<h2>Miscellaneous indexing FAQ<a class=""headerlink"" href=""#miscellaneous-indexing-faq"" title=""Link to this heading"">#</a></h2>
<section id=""integer-indexing"">
<h3>Integer indexing<a class=""headerlink"" href=""#integer-indexing"" title=""Link to this heading"">#</a></h3>
<p>Label-based indexing with integer axis labels is a thorny topic. It has been
discussed heavily on mailing lists and among various members of the scientific
Python community. In pandas, our general viewpoint is that labels matter more
than integer locations. Therefore, with an integer axis index <em>only</em>
label-based indexing is possible with the standard tools like <code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code>. The
following code will generate exceptions:</p>

<p>This deliberate decision was made to prevent ambiguities and subtle bugs (many
users reported finding bugs when the API change was made to stop “falling back”
on position-based indexing).</p>
</section>
<section id=""non-monotonic-indexes-require-exact-matches"">
<h3>Non-monotonic indexes require exact matches<a class=""headerlink"" href=""#non-monotonic-indexes-require-exact-matches"" title=""Link to this heading"">#</a></h3>
<p>If the index of a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> is monotonically increasing or decreasing, then the bounds
of a label-based slice can be outside the range of the index, much like slice indexing a
normal Python <code class=""docutils literal notranslate""><span class=""pre"">list</span></code>. Monotonicity of an index can be tested with the <a class=""reference internal"" href=""../reference/api/pandas.Index.is_monotonic_increasing.html#pandas.Index.is_monotonic_increasing"" title=""pandas.Index.is_monotonic_increasing""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">is_monotonic_increasing()</span></code></a> and
<a class=""reference internal"" href=""../reference/api/pandas.Index.is_monotonic_decreasing.html#pandas.Index.is_monotonic_decreasing"" title=""pandas.Index.is_monotonic_decreasing""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">is_monotonic_decreasing()</span></code></a> attributes.</p>

<p>On the other hand, if the index is not monotonic, then both slice bounds must be
<em>unique</em> members of the index.</p>


<p><code class=""docutils literal notranslate""><span class=""pre"">Index.is_monotonic_increasing</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">Index.is_monotonic_decreasing</span></code> only check that
an index is weakly monotonic. To check for strict monotonicity, you can combine one of those with
the <a class=""reference internal"" href=""../reference/api/pandas.Index.is_unique.html#pandas.Index.is_unique"" title=""pandas.Index.is_unique""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">is_unique()</span></code></a> attribute.</p>

</section>
<section id=""endpoints-are-inclusive"">
<span id=""advanced-endpoints-are-inclusive""></span><h3>Endpoints are inclusive<a class=""headerlink"" href=""#endpoints-are-inclusive"" title=""Link to this heading"">#</a></h3>
<p>Compared with standard Python sequence slicing in which the slice endpoint is
not inclusive, label-based slicing in pandas <strong>is inclusive</strong>. The primary
reason for this is that it is often not possible to easily determine the
“successor” or next element after a particular label in an index. For example,
consider the following <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>:</p>

<p>Suppose we wished to slice from <code class=""docutils literal notranslate""><span class=""pre"">c</span></code> to <code class=""docutils literal notranslate""><span class=""pre"">e</span></code>, using integers this would be
accomplished as such:</p>

<p>However, if you only had <code class=""docutils literal notranslate""><span class=""pre"">c</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">e</span></code>, determining the next element in the
index can be somewhat complicated. For example, the following does not work:</p>

<p>A very common use case is to limit a time series to start and end at two
specific dates. To enable this, we made the design choice to make label-based
slicing include both endpoints:</p>

<p>This is most definitely a “practicality beats purity” sort of thing, but it is
something to watch out for if you expect label-based slicing to behave exactly
in the way that standard Python integer slicing works.</p>
</section>
<section id=""indexing-potentially-changes-underlying-series-dtype"">
<h3>Indexing potentially changes underlying Series dtype<a class=""headerlink"" href=""#indexing-potentially-changes-underlying-series-dtype"" title=""Link to this heading"">#</a></h3>
<p>The different indexing operation can potentially change the dtype of a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>.</p>


<p>This is because the (re)indexing operations above silently inserts <code class=""docutils literal notranslate""><span class=""pre"">NaNs</span></code> and the <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code>
changes accordingly. This can cause some issues when using <code class=""docutils literal notranslate""><span class=""pre"">numpy</span></code> <code class=""docutils literal notranslate""><span class=""pre"">ufuncs</span></code>
such as <code class=""docutils literal notranslate""><span class=""pre"">numpy.logical_and</span></code>.</p>
<p>See the <a class=""reference external"" href=""https://github.com/pandas-dev/pandas/issues/2388"">GH 2388</a> for a more
detailed discussion.</p>
</section>
</section>
</section>
</article>","MultiIndex / advanced indexing # This section covers indexing with a MultiIndex and other advanced indexing features . See the Indexing and Selecting Data for general indexing documentation. Warning Whether a copy or a reference is returned for a setting operation may depend on the context. This is sometimes called chained assignment and should be avoided. See Returning a View versus Copy . See the cookbook for some advanced strategies. Hierarchical indexing (MultiIndex) # Hierarchical / Multi-level indexing is very exciting as it opens the door to some quite sophisticated data analysis and manipulation, especially for working with higher dimensional data. In essence, it enables you to store and manipulate data with an arbitrary number of dimensions in lower dimensional data structures like Series (1d) and DataFrame (2d). In this section, we will show what exactly we mean by “hierarchical” indexing and how it integrates with all of the pandas indexing functionality described above and in prior sections. Later, when discussing group by and pivoting and reshaping data , we’ll show non-trivial applications to illustrate how it aids in structuring data for analysis. See the cookbook for some advanced strategies. Creating a MultiIndex (hierarchical index) object # The MultiIndex object is the hierarchical analogue of the standard Index object which typically stores the axis labels in pandas objects. You can think of MultiIndex as an array of tuples where each tuple is unique. A MultiIndex can be created from a list of arrays (using MultiIndex.from_arrays() ), an array of tuples (using MultiIndex.from_tuples() ), a crossed set of iterables (using MultiIndex.from_product() ), or a DataFrame (using MultiIndex.from_frame() ). The Index constructor will attempt to return a MultiIndex when it is passed a list of tuples. The following examples demonstrate different ways to initialize MultiIndexes. When you want every pairing of the elements in two iterables, it can be easier to use the MultiIndex.from_product() method: You can also construct a MultiIndex from a DataFrame directly, using the method MultiIndex.from_frame() . This is a complementary method to MultiIndex.to_frame() . As a convenience, you can pass a list of arrays directly into Series or DataFrame to construct a MultiIndex automatically: All of the MultiIndex constructors accept a names argument which stores string names for the levels themselves. If no names are provided, None will be assigned: This index can back any axis of a pandas object, and the number of levels of the index is up to you: We’ve “sparsified” the higher levels of the indexes to make the console output a bit easier on the eyes. Note that how the index is displayed can be controlled using the multi_sparse option in pandas.set_options() : It’s worth keeping in mind that there’s nothing preventing you from using tuples as atomic labels on an axis: The reason that the MultiIndex matters is that it can allow you to do grouping, selection, and reshaping operations as we will describe below and in subsequent areas of the documentation. As you will see in later sections, you can find yourself working with hierarchically-indexed data without creating a MultiIndex explicitly yourself. However, when loading data from a file, you may wish to generate your own MultiIndex when preparing the data set. Reconstructing the level labels # The method get_level_values() will return a vector of the labels for each location at a particular level: Basic indexing on axis with MultiIndex # One of the important features of hierarchical indexing is that you can select data by a “partial” label identifying a subgroup in the data. Partial selection “drops” levels of the hierarchical index in the result in a completely analogous way to selecting a column in a regular DataFrame: See Cross-section with hierarchical index for how to select on a deeper level. Defined levels # The MultiIndex keeps all the defined levels of an index, even if they are not actually used. When slicing an index, you may notice this. For example: This is done to avoid a recomputation of the levels in order to make slicing highly performant. If you want to see only the used levels, you can use the get_level_values() method. To reconstruct the MultiIndex with only the used levels, the remove_unused_levels() method may be used. Data alignment and using reindex # Operations between differently-indexed objects having MultiIndex on the axes will work as you expect; data alignment will work the same as an Index of tuples: The reindex() method of Series / DataFrames can be called with another MultiIndex , or even a list or array of tuples: Advanced indexing with hierarchical index # Syntactically integrating MultiIndex in advanced indexing with .loc is a bit challenging, but we’ve made every effort to do so. In general, MultiIndex keys take the form of tuples. For example, the following works as you would expect: Note that df.loc['bar', 'two'] would also work in this example, but this shorthand notation can lead to ambiguity in general. If you also want to index a specific column with .loc , you must use a tuple like this: You don’t have to specify all levels of the MultiIndex by passing only the first elements of the tuple. For example, you can use “partial” indexing to get all elements with bar in the first level as follows: This is a shortcut for the slightly more verbose notation df.loc[('bar',),] (equivalent to df.loc['bar',] in this example). “Partial” slicing also works quite nicely. You can slice with a ‘range’ of values, by providing a slice of tuples. Passing a list of labels or tuples works similar to reindexing: Note It is important to note that tuples and lists are not treated identically in pandas when it comes to indexing. Whereas a tuple is interpreted as one multi-level key, a list is used to specify several keys. Or in other words, tuples go horizontally (traversing levels), lists go vertically (scanning levels). Importantly, a list of tuples indexes several complete MultiIndex keys, whereas a tuple of lists refer to several values within a level: Using slicers # You can slice a MultiIndex by providing multiple indexers. You can provide any of the selectors as if you are indexing by label, see Selection by Label , including slices, lists of labels, labels, and boolean indexers. You can use slice(None) to select all the contents of that level. You do not need to specify all the deeper levels, they will be implied as slice(None) . As usual, both sides of the slicers are included as this is label indexing. Warning You should specify all axes in the .loc specifier, meaning the indexer for the index and for the columns . There are some ambiguous cases where the passed indexer could be misinterpreted as indexing both axes, rather than into say the MultiIndex for the rows. You should do this: df . loc [( slice ( ""A1"" , ""A3"" ), ... ), :] # noqa: E999 You should not do this: df . loc [( slice ( ""A1"" , ""A3"" ), ... )] # noqa: E999 Basic MultiIndex slicing using slices, lists, and labels. You can use pandas.IndexSlice to facilitate a more natural syntax using : , rather than using slice(None) . It is possible to perform quite complicated selections using this method on multiple axes at the same time. Using a boolean indexer you can provide selection related to the values . You can also specify the axis argument to .loc to interpret the passed slicers on a single axis. Furthermore, you can set the values using the following methods. You can use a right-hand-side of an alignable object as well. Cross-section # The xs() method of DataFrame additionally takes a level argument to make selecting data at a particular level of a MultiIndex easier. You can also select on the columns with xs , by providing the axis argument. xs also allows selection with multiple keys. You can pass drop_level=False to xs to retain the level that was selected. Compare the above with the result using drop_level=True (the default value). Advanced reindexing and alignment # Using the parameter level in the reindex() and align() methods of pandas objects is useful to broadcast values across a level. For instance: Swapping levels with swaplevel # The swaplevel() method can switch the order of two levels: Reordering levels with reorder_levels # The reorder_levels() method generalizes the swaplevel method, allowing you to permute the hierarchical index levels in one step: Renaming names of an Index or MultiIndex # The rename() method is used to rename the labels of a MultiIndex , and is typically used to rename the columns of a DataFrame . The columns argument of rename allows a dictionary to be specified that includes only the columns you wish to rename. This method can also be used to rename specific labels of the main index of the DataFrame . The rename_axis() method is used to rename the name of a Index or MultiIndex . In particular, the names of the levels of a MultiIndex can be specified, which is useful if reset_index() is later used to move the values from the MultiIndex to a column. Note that the columns of a DataFrame are an index, so that using rename_axis with the columns argument will change the name of that index. Both rename and rename_axis support specifying a dictionary, Series or a mapping function to map labels/names to new values. When working with an Index object directly, rather than via a DataFrame , Index.set_names() can be used to change the names. You cannot set the names of the MultiIndex via a level. Use Index.set_names() instead. Sorting a MultiIndex # For MultiIndex -ed objects to be indexed and sliced effectively, they need to be sorted. As with any index, you can use sort_index() . You may also pass a level name to sort_index if the MultiIndex levels are named. On higher dimensional objects, you can sort any of the other axes by level if they have a MultiIndex : Indexing will work even if the data are not sorted, but will be rather inefficient (and show a PerformanceWarning ). It will also return a copy of the data rather than a view: Furthermore, if you try to index something that is not fully lexsorted, this can raise: The is_monotonic_increasing() method on a MultiIndex shows if the index is sorted: And now selection works as expected. Take methods # Similar to NumPy ndarrays, pandas Index , Series , and DataFrame also provides the take() method that retrieves elements along a given axis at the given indices. The given indices must be either a list or an ndarray of integer index positions. take will also accept negative integers as relative positions to the end of the object. For DataFrames, the given indices should be a 1d list or ndarray that specifies row or column positions. It is important to note that the take method on pandas objects are not intended to work on boolean indices and may return unexpected results. Finally, as a small note on performance, because the take method handles a narrower range of inputs, it can offer performance that is a good deal faster than fancy indexing. Index types # We have discussed MultiIndex in the previous sections pretty extensively. Documentation about DatetimeIndex and PeriodIndex are shown here , and documentation about TimedeltaIndex is found here . In the following sub-sections we will highlight some other index types. CategoricalIndex # CategoricalIndex is a type of index that is useful for supporting indexing with duplicates. This is a container around a Categorical and allows efficient indexing and storage of an index with a large number of duplicated elements. Setting the index will create a CategoricalIndex . Indexing with __getitem__/.iloc/.loc works similarly to an Index with duplicates. The indexers must be in the category or the operation will raise a KeyError . The CategoricalIndex is preserved after indexing: Sorting the index will sort by the order of the categories (recall that we created the index with CategoricalDtype(list('cab')) , so the sorted order is cab ). Groupby operations on the index will preserve the index nature as well. Reindexing operations will return a resulting index based on the type of the passed indexer. Passing a list will return a plain-old Index ; indexing with a Categorical will return a CategoricalIndex , indexed according to the categories of the passed Categorical dtype. This allows one to arbitrarily index these even with values not in the categories, similarly to how you can reindex any pandas index. Warning Reshaping and Comparison operations on a CategoricalIndex must have the same categories or a TypeError will be raised. RangeIndex # RangeIndex is a sub-class of Index that provides the default index for all DataFrame and Series objects. RangeIndex is an optimized version of Index that can represent a monotonic ordered set. These are analogous to Python range types . A RangeIndex will always have an int64 dtype. RangeIndex is the default index for all DataFrame and Series objects: A RangeIndex will behave similarly to a Index with an int64 dtype and operations on a RangeIndex , whose result cannot be represented by a RangeIndex , but should have an integer dtype, will be converted to an Index with int64 . For example: IntervalIndex # IntervalIndex together with its own dtype, IntervalDtype as well as the Interval scalar type, allow first-class support in pandas for interval notation. The IntervalIndex allows some unique indexing and is also used as a return type for the categories in cut() and qcut() . Indexing with an IntervalIndex # An IntervalIndex can be used in Series and in DataFrame as the index. Label based indexing via .loc along the edges of an interval works as you would expect, selecting that particular interval. If you select a label contained within an interval, this will also select the interval. Selecting using an Interval will only return exact matches. Trying to select an Interval that is not exactly contained in the IntervalIndex will raise a KeyError . Selecting all Intervals that overlap a given Interval can be performed using the overlaps() method to create a boolean indexer. Binning data with cut and qcut # cut() and qcut() both return a Categorical object, and the bins they create are stored as an IntervalIndex in its .categories attribute. cut() also accepts an IntervalIndex for its bins argument, which enables a useful pandas idiom. First, We call cut() with some data and bins set to a fixed number, to generate the bins. Then, we pass the values of .categories as the bins argument in subsequent calls to cut() , supplying new data which will be binned into the same bins. Any value which falls outside all bins will be assigned a NaN value. Generating ranges of intervals # If we need intervals on a regular frequency, we can use the interval_range() function to create an IntervalIndex using various combinations of start , end , and periods . The default frequency for interval_range is a 1 for numeric intervals, and calendar day for datetime-like intervals: The freq parameter can used to specify non-default frequencies, and can utilize a variety of frequency aliases with datetime-like intervals: Additionally, the closed parameter can be used to specify which side(s) the intervals are closed on. Intervals are closed on the right side by default. Specifying start , end , and periods will generate a range of evenly spaced intervals from start to end inclusively, with periods number of elements in the resulting IntervalIndex : Miscellaneous indexing FAQ # Integer indexing # Label-based indexing with integer axis labels is a thorny topic. It has been discussed heavily on mailing lists and among various members of the scientific Python community. In pandas, our general viewpoint is that labels matter more than integer locations. Therefore, with an integer axis index only label-based indexing is possible with the standard tools like .loc . The following code will generate exceptions: This deliberate decision was made to prevent ambiguities and subtle bugs (many users reported finding bugs when the API change was made to stop “falling back” on position-based indexing). Non-monotonic indexes require exact matches # If the index of a Series or DataFrame is monotonically increasing or decreasing, then the bounds of a label-based slice can be outside the range of the index, much like slice indexing a normal Python list . Monotonicity of an index can be tested with the is_monotonic_increasing() and is_monotonic_decreasing() attributes. On the other hand, if the index is not monotonic, then both slice bounds must be unique members of the index. Index.is_monotonic_increasing and Index.is_monotonic_decreasing only check that an index is weakly monotonic. To check for strict monotonicity, you can combine one of those with the is_unique() attribute. Endpoints are inclusive # Compared with standard Python sequence slicing in which the slice endpoint is not inclusive, label-based slicing in pandas is inclusive . The primary reason for this is that it is often not possible to easily determine the “successor” or next element after a particular label in an index. For example, consider the following Series : Suppose we wished to slice from c to e , using integers this would be accomplished as such: However, if you only had c and e , determining the next element in the index can be somewhat complicated. For example, the following does not work: A very common use case is to limit a time series to start and end at two specific dates. To enable this, we made the design choice to make label-based slicing include both endpoints: This is most definitely a “practicality beats purity” sort of thing, but it is something to watch out for if you expect label-based slicing to behave exactly in the way that standard Python integer slicing works. Indexing potentially changes underlying Series dtype # The different indexing operation can potentially change the dtype of a Series . This is because the (re)indexing operations above silently inserts NaNs and the dtype changes accordingly. This can cause some issues when using numpy ufuncs such as numpy.logical_and . See the GH 2388 for a more detailed discussion."
https://pandas.pydata.org/docs/user_guide/copy_on_write.html,Copy-on-Write (CoW),"<article class=""bd-article"" role=""main"">
<section id=""copy-on-write-cow"">
<span id=""copy-on-write""></span><h1>Copy-on-Write (CoW)<a class=""headerlink"" href=""#copy-on-write-cow"" title=""Link to this heading"">#</a></h1>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Copy-on-Write will become the default in pandas 3.0. We recommend
<a class=""reference internal"" href=""#copy-on-write-enabling""><span class=""std std-ref"">turning it on now</span></a>
to benefit from all improvements.</p>
</div>
<p>Copy-on-Write was first introduced in version 1.5.0. Starting from version 2.0 most of the
optimizations that become possible through CoW are implemented and supported. All possible
optimizations are supported starting from pandas 2.1.</p>
<p>CoW will be enabled by default in version 3.0.</p>
<p>CoW will lead to more predictable behavior since it is not possible to update more than
one object with one statement, e.g. indexing operations or methods won’t have side-effects. Additionally, through
delaying copies as long as possible, the average performance and memory usage will improve.</p>
<section id=""previous-behavior"">
<h2>Previous behavior<a class=""headerlink"" href=""#previous-behavior"" title=""Link to this heading"">#</a></h2>
<p>pandas indexing behavior is tricky to understand. Some operations return views while
other return copies. Depending on the result of the operation, mutating one object
might accidentally mutate another:</p>

<p>Mutating <code class=""docutils literal notranslate""><span class=""pre"">subset</span></code>, e.g. updating its values, also updates <code class=""docutils literal notranslate""><span class=""pre"">df</span></code>. The exact behavior is
hard to predict. Copy-on-Write solves accidentally modifying more than one object,
it explicitly disallows this. With CoW enabled, <code class=""docutils literal notranslate""><span class=""pre"">df</span></code> is unchanged:</p>

<p>The following sections will explain what this means and how it impacts existing
applications.</p>
</section>
<section id=""migrating-to-copy-on-write"">
<span id=""copy-on-write-migration-guide""></span><h2>Migrating to Copy-on-Write<a class=""headerlink"" href=""#migrating-to-copy-on-write"" title=""Link to this heading"">#</a></h2>
<p>Copy-on-Write will be the default and only mode in pandas 3.0. This means that users
need to migrate their code to be compliant with CoW rules.</p>
<p>The default mode in pandas will raise warnings for certain cases that will actively
change behavior and thus change user intended behavior.</p>
<p>We added another mode, e.g.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">options</span><span class=""o"">.</span><span class=""n"">mode</span><span class=""o"">.</span><span class=""n"">copy_on_write</span> <span class=""o"">=</span> <span class=""s2"">""warn""</span>
</pre></div>
</div>
<p>that will warn for every operation that will change behavior with CoW. We expect this mode
to be very noisy, since many cases that we don’t expect that they will influence users will
also emit a warning. We recommend checking this mode and analyzing the warnings, but it is
not necessary to address all of these warning. The first two items of the following lists
are the only cases that need to be addressed to make existing code work with CoW.</p>
<p>The following few items describe the user visible changes:</p>
<p><strong>Chained assignment will never work</strong></p>
<p><code class=""docutils literal notranslate""><span class=""pre"">loc</span></code> should be used as an alternative. Check the
<a class=""reference internal"" href=""#copy-on-write-chained-assignment""><span class=""std std-ref"">chained assignment section</span></a> for more details.</p>
<p><strong>Accessing the underlying array of a pandas object will return a read-only view</strong></p>

<p>This example returns a NumPy array that is a view of the Series object. This view can
be modified and thus also modify the pandas object. This is not compliant with CoW
rules. The returned array is set to non-writeable to protect against this behavior.
Creating a copy of this array allows modification. You can also make the array
writeable again if you don’t care about the pandas object anymore.</p>
<p>See the section about <a class=""reference internal"" href=""#copy-on-write-read-only-na""><span class=""std std-ref"">read-only NumPy arrays</span></a>
for more details.</p>
<p><strong>Only one pandas object is updated at once</strong></p>
<p>The following code snippet updates both <code class=""docutils literal notranslate""><span class=""pre"">df</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">subset</span></code> without CoW:</p>

<p>This won’t be possible anymore with CoW, since the CoW rules explicitly forbid this.
This includes updating a single column as a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> and relying on the change
propagating back to the parent <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>.
This statement can be rewritten into a single statement with <code class=""docutils literal notranslate""><span class=""pre"">loc</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">iloc</span></code> if
this behavior is necessary. <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.where.html#pandas.DataFrame.where"" title=""pandas.DataFrame.where""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.where()</span></code></a> is another suitable alternative
for this case.</p>
<p>Updating a column selected from a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> with an inplace method will
also not work anymore.</p>

<p>This is another form of chained assignment. This can generally be rewritten in 2
different forms:</p>

<p>A different alternative would be to not use <code class=""docutils literal notranslate""><span class=""pre"">inplace</span></code>:</p>

<p><strong>Constructors now copy NumPy arrays by default</strong></p>
<p>The Series and DataFrame constructors will now copy NumPy array by default when not
otherwise specified. This was changed to avoid mutating a pandas object when the
NumPy array is changed inplace outside of pandas. You can set <code class=""docutils literal notranslate""><span class=""pre"">copy=False</span></code> to
avoid this copy.</p>
</section>
<section id=""description"">
<h2>Description<a class=""headerlink"" href=""#description"" title=""Link to this heading"">#</a></h2>
<p>CoW means that any DataFrame or Series derived from another in any way always
behaves as a copy. As a consequence, we can only change the values of an object
through modifying the object itself. CoW disallows updating a DataFrame or a Series
that shares data with another DataFrame or Series object inplace.</p>
<p>This avoids side-effects when modifying values and hence, most methods can avoid
actually copying the data and only trigger a copy when necessary.</p>
<p>The following example will operate inplace with CoW:</p>

<p>The object <code class=""docutils literal notranslate""><span class=""pre"">df</span></code> does not share any data with any other object and hence no
copy is triggered when updating the values. In contrast, the following operation
triggers a copy of the data under CoW:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">reset_index</span></code> returns a lazy copy with CoW while it copies the data without CoW.
Since both objects, <code class=""docutils literal notranslate""><span class=""pre"">df</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">df2</span></code> share the same data, a copy is triggered
when modifying <code class=""docutils literal notranslate""><span class=""pre"">df2</span></code>. The object <code class=""docutils literal notranslate""><span class=""pre"">df</span></code> still has the same values as initially
while <code class=""docutils literal notranslate""><span class=""pre"">df2</span></code> was modified.</p>
<p>If the object <code class=""docutils literal notranslate""><span class=""pre"">df</span></code> isn’t needed anymore after performing the <code class=""docutils literal notranslate""><span class=""pre"">reset_index</span></code> operation,
you can emulate an inplace-like operation through assigning the output of <code class=""docutils literal notranslate""><span class=""pre"">reset_index</span></code>
to the same variable:</p>

<p>The initial object gets out of scope as soon as the result of <code class=""docutils literal notranslate""><span class=""pre"">reset_index</span></code> is
reassigned and hence <code class=""docutils literal notranslate""><span class=""pre"">df</span></code> does not share data with any other object. No copy
is necessary when modifying the object. This is generally true for all methods
listed in <a class=""reference internal"" href=""#copy-on-write-optimizations""><span class=""std std-ref"">Copy-on-Write optimizations</span></a>.</p>
<p>Previously, when operating on views, the view and the parent object was modified:</p>

<p>CoW triggers a copy when <code class=""docutils literal notranslate""><span class=""pre"">df</span></code> is changed to avoid mutating <code class=""docutils literal notranslate""><span class=""pre"">view</span></code> as well:</p>

</section>
<section id=""chained-assignment"">
<span id=""copy-on-write-chained-assignment""></span><h2>Chained Assignment<a class=""headerlink"" href=""#chained-assignment"" title=""Link to this heading"">#</a></h2>
<p>Chained assignment references a technique where an object is updated through
two subsequent indexing operations, e.g.</p>

<p>The column <code class=""docutils literal notranslate""><span class=""pre"">foo</span></code> is updated where the column <code class=""docutils literal notranslate""><span class=""pre"">bar</span></code> is greater than 5.
This violates the CoW principles though, because it would have to modify the
view <code class=""docutils literal notranslate""><span class=""pre"">df[""foo""]</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">df</span></code> in one step. Hence, chained assignment will
consistently never work and raise a <code class=""docutils literal notranslate""><span class=""pre"">ChainedAssignmentError</span></code> warning
with CoW enabled:</p>

<p>With copy on write this can be done by using <code class=""docutils literal notranslate""><span class=""pre"">loc</span></code>.</p>

</section>
<section id=""read-only-numpy-arrays"">
<span id=""copy-on-write-read-only-na""></span><h2>Read-only NumPy arrays<a class=""headerlink"" href=""#read-only-numpy-arrays"" title=""Link to this heading"">#</a></h2>
<p>Accessing the underlying NumPy array of a DataFrame will return a read-only array if the array
shares data with the initial DataFrame:</p>
<p>The array is a copy if the initial DataFrame consists of more than one array:</p>

<p>The array shares data with the DataFrame if the DataFrame consists of only one NumPy array:</p>

<p>This array is read-only, which means that it can’t be modified inplace:</p>

<p>The same holds true for a Series, since a Series always consists of a single array.</p>
<p>There are two potential solution to this:</p>
<ul class=""simple"">
<li><p>Trigger a copy manually if you want to avoid updating DataFrames that share memory with your array.</p></li>
<li><p>Make the array writeable. This is a more performant solution but circumvents Copy-on-Write rules, so
it should be used with caution.</p></li>
</ul>

</section>
<section id=""patterns-to-avoid"">
<h2>Patterns to avoid<a class=""headerlink"" href=""#patterns-to-avoid"" title=""Link to this heading"">#</a></h2>
<p>No defensive copy will be performed if two objects share the same data while
you are modifying one object inplace.</p>

<p>This creates two objects that share data and thus the setitem operation will trigger a
copy. This is not necessary if the initial object <code class=""docutils literal notranslate""><span class=""pre"">df</span></code> isn’t needed anymore.
Simply reassigning to the same variable will invalidate the reference that is
held by the object.</p>

<p>No copy is necessary in this example.
Creating multiple references keeps unnecessary references alive
and thus will hurt performance with Copy-on-Write.</p>
</section>
<section id=""copy-on-write-optimizations"">
<span id=""id1""></span><h2>Copy-on-Write optimizations<a class=""headerlink"" href=""#copy-on-write-optimizations"" title=""Link to this heading"">#</a></h2>
<p>A new lazy copy mechanism that defers the copy until the object in question is modified
and only if this object shares data with another object. This mechanism was added to
methods that don’t require a copy of the underlying data. Popular examples are <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.drop.html#pandas.DataFrame.drop"" title=""pandas.DataFrame.drop""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.drop()</span></code></a> for <code class=""docutils literal notranslate""><span class=""pre"">axis=1</span></code>
and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.rename.html#pandas.DataFrame.rename"" title=""pandas.DataFrame.rename""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.rename()</span></code></a>.</p>
<p>These methods return views when Copy-on-Write is enabled, which provides a significant
performance improvement compared to the regular execution.</p>
</section>
<section id=""how-to-enable-cow"">
<span id=""copy-on-write-enabling""></span><h2>How to enable CoW<a class=""headerlink"" href=""#how-to-enable-cow"" title=""Link to this heading"">#</a></h2>
<p>Copy-on-Write can be enabled through the configuration option <code class=""docutils literal notranslate""><span class=""pre"">copy_on_write</span></code>. The option can
be turned on __globally__ through either of the following:</p>

</section>
</section>
</article>","Copy-on-Write (CoW) # Note Copy-on-Write will become the default in pandas 3.0. We recommend turning it on now to benefit from all improvements. Copy-on-Write was first introduced in version 1.5.0. Starting from version 2.0 most of the optimizations that become possible through CoW are implemented and supported. All possible optimizations are supported starting from pandas 2.1. CoW will be enabled by default in version 3.0. CoW will lead to more predictable behavior since it is not possible to update more than one object with one statement, e.g. indexing operations or methods won’t have side-effects. Additionally, through delaying copies as long as possible, the average performance and memory usage will improve. Previous behavior # pandas indexing behavior is tricky to understand. Some operations return views while other return copies. Depending on the result of the operation, mutating one object might accidentally mutate another: Mutating subset , e.g. updating its values, also updates df . The exact behavior is hard to predict. Copy-on-Write solves accidentally modifying more than one object, it explicitly disallows this. With CoW enabled, df is unchanged: The following sections will explain what this means and how it impacts existing applications. Migrating to Copy-on-Write # Copy-on-Write will be the default and only mode in pandas 3.0. This means that users need to migrate their code to be compliant with CoW rules. The default mode in pandas will raise warnings for certain cases that will actively change behavior and thus change user intended behavior. We added another mode, e.g. pd . options . mode . copy_on_write = ""warn"" that will warn for every operation that will change behavior with CoW. We expect this mode to be very noisy, since many cases that we don’t expect that they will influence users will also emit a warning. We recommend checking this mode and analyzing the warnings, but it is not necessary to address all of these warning. The first two items of the following lists are the only cases that need to be addressed to make existing code work with CoW. The following few items describe the user visible changes: Chained assignment will never work loc should be used as an alternative. Check the chained assignment section for more details. Accessing the underlying array of a pandas object will return a read-only view This example returns a NumPy array that is a view of the Series object. This view can be modified and thus also modify the pandas object. This is not compliant with CoW rules. The returned array is set to non-writeable to protect against this behavior. Creating a copy of this array allows modification. You can also make the array writeable again if you don’t care about the pandas object anymore. See the section about read-only NumPy arrays for more details. Only one pandas object is updated at once The following code snippet updates both df and subset without CoW: This won’t be possible anymore with CoW, since the CoW rules explicitly forbid this. This includes updating a single column as a Series and relying on the change propagating back to the parent DataFrame . This statement can be rewritten into a single statement with loc or iloc if this behavior is necessary. DataFrame.where() is another suitable alternative for this case. Updating a column selected from a DataFrame with an inplace method will also not work anymore. This is another form of chained assignment. This can generally be rewritten in 2 different forms: A different alternative would be to not use inplace : Constructors now copy NumPy arrays by default The Series and DataFrame constructors will now copy NumPy array by default when not otherwise specified. This was changed to avoid mutating a pandas object when the NumPy array is changed inplace outside of pandas. You can set copy=False to avoid this copy. Description # CoW means that any DataFrame or Series derived from another in any way always behaves as a copy. As a consequence, we can only change the values of an object through modifying the object itself. CoW disallows updating a DataFrame or a Series that shares data with another DataFrame or Series object inplace. This avoids side-effects when modifying values and hence, most methods can avoid actually copying the data and only trigger a copy when necessary. The following example will operate inplace with CoW: The object df does not share any data with any other object and hence no copy is triggered when updating the values. In contrast, the following operation triggers a copy of the data under CoW: reset_index returns a lazy copy with CoW while it copies the data without CoW. Since both objects, df and df2 share the same data, a copy is triggered when modifying df2 . The object df still has the same values as initially while df2 was modified. If the object df isn’t needed anymore after performing the reset_index operation, you can emulate an inplace-like operation through assigning the output of reset_index to the same variable: The initial object gets out of scope as soon as the result of reset_index is reassigned and hence df does not share data with any other object. No copy is necessary when modifying the object. This is generally true for all methods listed in Copy-on-Write optimizations . Previously, when operating on views, the view and the parent object was modified: CoW triggers a copy when df is changed to avoid mutating view as well: Chained Assignment # Chained assignment references a technique where an object is updated through two subsequent indexing operations, e.g. The column foo is updated where the column bar is greater than 5. This violates the CoW principles though, because it would have to modify the view df[""foo""] and df in one step. Hence, chained assignment will consistently never work and raise a ChainedAssignmentError warning with CoW enabled: With copy on write this can be done by using loc . Read-only NumPy arrays # Accessing the underlying NumPy array of a DataFrame will return a read-only array if the array shares data with the initial DataFrame: The array is a copy if the initial DataFrame consists of more than one array: The array shares data with the DataFrame if the DataFrame consists of only one NumPy array: This array is read-only, which means that it can’t be modified inplace: The same holds true for a Series, since a Series always consists of a single array. There are two potential solution to this: Trigger a copy manually if you want to avoid updating DataFrames that share memory with your array. Make the array writeable. This is a more performant solution but circumvents Copy-on-Write rules, so it should be used with caution. Patterns to avoid # No defensive copy will be performed if two objects share the same data while you are modifying one object inplace. This creates two objects that share data and thus the setitem operation will trigger a copy. This is not necessary if the initial object df isn’t needed anymore. Simply reassigning to the same variable will invalidate the reference that is held by the object. No copy is necessary in this example. Creating multiple references keeps unnecessary references alive and thus will hurt performance with Copy-on-Write. Copy-on-Write optimizations # A new lazy copy mechanism that defers the copy until the object in question is modified and only if this object shares data with another object. This mechanism was added to methods that don’t require a copy of the underlying data. Popular examples are DataFrame.drop() for axis=1 and DataFrame.rename() . These methods return views when Copy-on-Write is enabled, which provides a significant performance improvement compared to the regular execution. How to enable CoW # Copy-on-Write can be enabled through the configuration option copy_on_write . The option can be turned on __globally__ through either of the following:"
https://pandas.pydata.org/docs/user_guide/merging.html,"Merge, join, concatenate and compare","<article class=""bd-article"" role=""main"">
<section id=""merge-join-concatenate-and-compare"">
<span id=""merging""></span><h1>Merge, join, concatenate and compare<a class=""headerlink"" href=""#merge-join-concatenate-and-compare"" title=""Link to this heading"">#</a></h1>
<p>pandas provides various methods for combining and comparing <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>.</p>
<ul class=""simple"">
<li><p><a class=""reference internal"" href=""../reference/api/pandas.concat.html#pandas.concat"" title=""pandas.concat""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">concat()</span></code></a>: Merge multiple <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> objects along a shared index or column</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.join.html#pandas.DataFrame.join"" title=""pandas.DataFrame.join""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.join()</span></code></a>: Merge multiple <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> objects along the columns</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.combine_first.html#pandas.DataFrame.combine_first"" title=""pandas.DataFrame.combine_first""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.combine_first()</span></code></a>: Update missing values with non-missing values in the same location</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.merge.html#pandas.merge"" title=""pandas.merge""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">merge()</span></code></a>: Combine two <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> objects with SQL-style joining</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.merge_ordered.html#pandas.merge_ordered"" title=""pandas.merge_ordered""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">merge_ordered()</span></code></a>: Combine two <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> objects along an ordered axis</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.merge_asof.html#pandas.merge_asof"" title=""pandas.merge_asof""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">merge_asof()</span></code></a>: Combine two <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> objects by near instead of exact matching keys</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.Series.compare.html#pandas.Series.compare"" title=""pandas.Series.compare""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.compare()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.compare.html#pandas.DataFrame.compare"" title=""pandas.DataFrame.compare""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.compare()</span></code></a>: Show differences in values between two <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> objects</p></li>
</ul>
<section id=""concat"">
<span id=""merging-concat""></span><h2><a class=""reference internal"" href=""../reference/api/pandas.concat.html#pandas.concat"" title=""pandas.concat""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">concat()</span></code></a><a class=""headerlink"" href=""#concat"" title=""Link to this heading"">#</a></h2>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.concat.html#pandas.concat"" title=""pandas.concat""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">concat()</span></code></a> function concatenates an arbitrary amount of
<a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> objects along an axis while
performing optional set logic (union or intersection) of the indexes on
the other axes. Like <code class=""docutils literal notranslate""><span class=""pre"">numpy.concatenate</span></code>, <a class=""reference internal"" href=""../reference/api/pandas.concat.html#pandas.concat"" title=""pandas.concat""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">concat()</span></code></a>
takes a list or dict of homogeneously-typed objects and concatenates them.</p>


<img alt=""../_images/merging_concat_basic.png"" src=""../_images/merging_concat_basic.png""/>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p><a class=""reference internal"" href=""../reference/api/pandas.concat.html#pandas.concat"" title=""pandas.concat""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">concat()</span></code></a> makes a full copy of the data, and iteratively
reusing <a class=""reference internal"" href=""../reference/api/pandas.concat.html#pandas.concat"" title=""pandas.concat""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">concat()</span></code></a> can create unnecessary copies. Collect all
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> objects in a list before using
<a class=""reference internal"" href=""../reference/api/pandas.concat.html#pandas.concat"" title=""pandas.concat""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">concat()</span></code></a>.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">frames</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""n"">process_your_file</span><span class=""p"">(</span><span class=""n"">f</span><span class=""p"">)</span> <span class=""k"">for</span> <span class=""n"">f</span> <span class=""ow"">in</span> <span class=""n"">files</span><span class=""p"">]</span>
<span class=""n"">result</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">concat</span><span class=""p"">(</span><span class=""n"">frames</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>When concatenating <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> with named axes, pandas will attempt to preserve
these index/column names whenever possible. In the case where all inputs share a
common name, this name will be assigned to the result. When the input names do
not all agree, the result will be unnamed. The same is true for <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a>,
but the logic is applied separately on a level-by-level basis.</p>
</div>
<section id=""joining-logic-of-the-resulting-axis"">
<h3>Joining logic of the resulting axis<a class=""headerlink"" href=""#joining-logic-of-the-resulting-axis"" title=""Link to this heading"">#</a></h3>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">join</span></code> keyword specifies how to handle axis values that don’t exist in the first
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>.</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">join='outer'</span></code> takes the union of all axis values</p>


<img alt=""../_images/merging_concat_axis1.png"" src=""../_images/merging_concat_axis1.png""/>
<p><code class=""docutils literal notranslate""><span class=""pre"">join='inner'</span></code> takes the intersection of the axis values</p>


<img alt=""../_images/merging_concat_axis1_inner.png"" src=""../_images/merging_concat_axis1_inner.png""/>
<p>To perform an effective “left” join using the <em>exact index</em> from the original
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>, result can be reindexed.</p>


<img alt=""../_images/merging_concat_axis1_join_axes.png"" src=""../_images/merging_concat_axis1_join_axes.png""/>
</section>
<section id=""ignoring-indexes-on-the-concatenation-axis"">
<span id=""merging-ignore-index""></span><h3>Ignoring indexes on the concatenation axis<a class=""headerlink"" href=""#ignoring-indexes-on-the-concatenation-axis"" title=""Link to this heading"">#</a></h3>
<p>For <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> objects which don’t have a meaningful index, the <code class=""docutils literal notranslate""><span class=""pre"">ignore_index</span></code>
ignores overlapping indexes.</p>


<img alt=""../_images/merging_concat_ignore_index.png"" src=""../_images/merging_concat_ignore_index.png""/>
</section>
<section id=""concatenating-series-and-dataframe-together"">
<span id=""merging-mixed-ndims""></span><h3>Concatenating <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> together<a class=""headerlink"" href=""#concatenating-series-and-dataframe-together"" title=""Link to this heading"">#</a></h3>
<p>You can concatenate a mix of <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> objects. The
<a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> will be transformed to <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> with the column name as
the name of the <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>.</p>


<img alt=""../_images/merging_concat_mixed_ndim.png"" src=""../_images/merging_concat_mixed_ndim.png""/>
<p>Unnamed <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> will be numbered consecutively.</p>


<img alt=""../_images/merging_concat_unnamed_series.png"" src=""../_images/merging_concat_unnamed_series.png""/>
<p><code class=""docutils literal notranslate""><span class=""pre"">ignore_index=True</span></code> will drop all name references.</p>


<img alt=""../_images/merging_concat_series_ignore_index.png"" src=""../_images/merging_concat_series_ignore_index.png""/>
</section>
<section id=""resulting-keys"">
<h3>Resulting <code class=""docutils literal notranslate""><span class=""pre"">keys</span></code><a class=""headerlink"" href=""#resulting-keys"" title=""Link to this heading"">#</a></h3>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">keys</span></code> argument adds another axis level to the resulting index or column (creating
a <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a>) associate specific keys with each original <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>.</p>


<img alt=""../_images/merging_concat_keys.png"" src=""../_images/merging_concat_keys.png""/>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">keys</span></code> argument cane override the column names
when creating a new <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> based on existing <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>.</p>

<p>You can also pass a dict to <a class=""reference internal"" href=""../reference/api/pandas.concat.html#pandas.concat"" title=""pandas.concat""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">concat()</span></code></a> in which case the dict keys will be used
for the <code class=""docutils literal notranslate""><span class=""pre"">keys</span></code> argument unless other <code class=""docutils literal notranslate""><span class=""pre"">keys</span></code> argument is specified:</p>


<img alt=""../_images/merging_concat_dict.png"" src=""../_images/merging_concat_dict.png""/>


<img alt=""../_images/merging_concat_dict_keys.png"" src=""../_images/merging_concat_dict_keys.png""/>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a> created has levels that are constructed from the passed keys and
the index of the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> pieces:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">levels</span></code> argument allows specifying resulting levels associated with the <code class=""docutils literal notranslate""><span class=""pre"">keys</span></code></p>


<img alt=""../_images/merging_concat_dict_keys_names.png"" src=""../_images/merging_concat_dict_keys_names.png""/>

</section>
<section id=""appending-rows-to-a-dataframe"">
<span id=""merging-append-row""></span><h3>Appending rows to a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a><a class=""headerlink"" href=""#appending-rows-to-a-dataframe"" title=""Link to this heading"">#</a></h3>
<p>If you have a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> that you want to append as a single row to a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>, you can convert the row into a
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> and use <a class=""reference internal"" href=""../reference/api/pandas.concat.html#pandas.concat"" title=""pandas.concat""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">concat()</span></code></a></p>


<img alt=""../_images/merging_append_series_as_row.png"" src=""../_images/merging_append_series_as_row.png""/>
</section>
</section>
<section id=""merge"">
<span id=""merging-join""></span><h2><a class=""reference internal"" href=""../reference/api/pandas.merge.html#pandas.merge"" title=""pandas.merge""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">merge()</span></code></a><a class=""headerlink"" href=""#merge"" title=""Link to this heading"">#</a></h2>
<p><a class=""reference internal"" href=""../reference/api/pandas.merge.html#pandas.merge"" title=""pandas.merge""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">merge()</span></code></a> performs join operations similar to relational databases like SQL.
Users who are familiar with SQL but new to pandas can reference a
<a class=""reference internal"" href=""../getting_started/comparison/comparison_with_sql.html#compare-with-sql-join""><span class=""std std-ref"">comparison with SQL</span></a>.</p>
<section id=""merge-types"">
<h3>Merge types<a class=""headerlink"" href=""#merge-types"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.merge.html#pandas.merge"" title=""pandas.merge""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">merge()</span></code></a> implements common SQL style joining operations.</p>
<ul class=""simple"">
<li><p><strong>one-to-one</strong>: joining two <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> objects on
their indexes which must contain unique values.</p></li>
<li><p><strong>many-to-one</strong>: joining a unique index to one or
more columns in a different <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>.</p></li>
<li><p><strong>many-to-many</strong> : joining columns on columns.</p></li>
</ul>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>When joining columns on columns, potentially a many-to-many join, any
indexes on the passed <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> objects <strong>will be discarded</strong>.</p>
</div>
<p>For a <strong>many-to-many</strong> join, if a key combination appears
more than once in both tables, the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> will have the <strong>Cartesian
product</strong> of the associated data.</p>


<img alt=""../_images/merging_merge_on_key.png"" src=""../_images/merging_merge_on_key.png""/>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">how</span></code> argument to <a class=""reference internal"" href=""../reference/api/pandas.merge.html#pandas.merge"" title=""pandas.merge""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">merge()</span></code></a> specifies which keys are
included in the resulting table. If a key combination <strong>does not appear</strong> in
either the left or right tables, the values in the joined table will be
<code class=""docutils literal notranslate""><span class=""pre"">NA</span></code>. Here is a summary of the <code class=""docutils literal notranslate""><span class=""pre"">how</span></code> options and their SQL equivalent names:</p>



<img alt=""../_images/merging_merge_on_key_left.png"" src=""../_images/merging_merge_on_key_left.png""/>


<img alt=""../_images/merging_merge_on_key_right.png"" src=""../_images/merging_merge_on_key_right.png""/>


<img alt=""../_images/merging_merge_on_key_outer.png"" src=""../_images/merging_merge_on_key_outer.png""/>


<img alt=""../_images/merging_merge_on_key_inner.png"" src=""../_images/merging_merge_on_key_inner.png""/>


<img alt=""../_images/merging_merge_cross.png"" src=""../_images/merging_merge_cross.png""/>
<p>You can <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> and a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> with a <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a> if the names of
the <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a> correspond to the columns from the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>. Transform
the <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> to a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> using <a class=""reference internal"" href=""../reference/api/pandas.Series.reset_index.html#pandas.Series.reset_index"" title=""pandas.Series.reset_index""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.reset_index()</span></code></a> before merging</p>

<p>Performing an outer join with duplicate join keys in <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a></p>


<img alt=""../_images/merging_merge_on_key_dup.png"" src=""../_images/merging_merge_on_key_dup.png""/>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Merging on duplicate keys significantly increase the dimensions of the result
and can cause a memory overflow.</p>
</div>
</section>
<section id=""merge-key-uniqueness"">
<span id=""merging-validation""></span><h3>Merge key uniqueness<a class=""headerlink"" href=""#merge-key-uniqueness"" title=""Link to this heading"">#</a></h3>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">validate</span></code> argument checks whether the uniqueness of merge keys.
Key uniqueness is checked before merge operations and can protect against memory overflows
and unexpected key duplication.</p>

<p>If the user is aware of the duplicates in the right <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> but wants to
ensure there are no duplicates in the left <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>, one can use the
<code class=""docutils literal notranslate""><span class=""pre"">validate='one_to_many'</span></code> argument instead, which will not raise an exception.</p>

</section>
<section id=""merge-result-indicator"">
<span id=""merging-indicator""></span><h3>Merge result indicator<a class=""headerlink"" href=""#merge-result-indicator"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.merge.html#pandas.merge"" title=""pandas.merge""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">merge()</span></code></a> accepts the argument <code class=""docutils literal notranslate""><span class=""pre"">indicator</span></code>. If <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>, a
Categorical-type column called <code class=""docutils literal notranslate""><span class=""pre"">_merge</span></code> will be added to the output object
that takes on values:</p>
<blockquote>
<div>
</div></blockquote>

<p>A string argument to <code class=""docutils literal notranslate""><span class=""pre"">indicator</span></code> will use the value as the name for the indicator column.</p>

</section>
<section id=""overlapping-value-columns"">
<h3>Overlapping value columns<a class=""headerlink"" href=""#overlapping-value-columns"" title=""Link to this heading"">#</a></h3>
<p>The merge <code class=""docutils literal notranslate""><span class=""pre"">suffixes</span></code> argument takes a tuple of list of strings to append to
overlapping column names in the input <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> to disambiguate the result
columns:</p>


<img alt=""../_images/merging_merge_overlapped.png"" src=""../_images/merging_merge_overlapped.png""/>


<img alt=""../_images/merging_merge_overlapped_suffix.png"" src=""../_images/merging_merge_overlapped_suffix.png""/>
</section>
</section>
<section id=""dataframe-join"">
<h2><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.join.html#pandas.DataFrame.join"" title=""pandas.DataFrame.join""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.join()</span></code></a><a class=""headerlink"" href=""#dataframe-join"" title=""Link to this heading"">#</a></h2>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.join.html#pandas.DataFrame.join"" title=""pandas.DataFrame.join""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.join()</span></code></a> combines the columns of multiple,
potentially differently-indexed <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> into a single result
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>.</p>


<img alt=""../_images/merging_join.png"" src=""../_images/merging_join.png""/>


<img alt=""../_images/merging_join_outer.png"" src=""../_images/merging_join_outer.png""/>


<img alt=""../_images/merging_join_inner.png"" src=""../_images/merging_join_inner.png""/>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.join.html#pandas.DataFrame.join"" title=""pandas.DataFrame.join""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.join()</span></code></a> takes an optional <code class=""docutils literal notranslate""><span class=""pre"">on</span></code> argument which may be a column
or multiple column names that the passed <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> is to be
aligned.</p>


<img alt=""../_images/merging_join_key_columns.png"" src=""../_images/merging_join_key_columns.png""/>


<img alt=""../_images/merging_merge_key_columns.png"" src=""../_images/merging_merge_key_columns.png""/>
<p id=""merging-multikey-join"">To join on multiple keys, the passed <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> must have a <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a>:</p>


<img alt=""../_images/merging_join_multikeys.png"" src=""../_images/merging_join_multikeys.png""/>
<p id=""merging-df-inner-join"">The default for <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.join.html#pandas.DataFrame.join"" title=""pandas.DataFrame.join""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame.join</span></code></a> is to perform a left join
which uses only the keys found in the
calling <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>. Other join types can be specified with <code class=""docutils literal notranslate""><span class=""pre"">how</span></code>.</p>


<img alt=""../_images/merging_join_multikeys_inner.png"" src=""../_images/merging_join_multikeys_inner.png""/>
<section id=""joining-a-single-index-to-a-multiindex"">
<span id=""merging-join-on-mi""></span><h3>Joining a single Index to a MultiIndex<a class=""headerlink"" href=""#joining-a-single-index-to-a-multiindex"" title=""Link to this heading"">#</a></h3>
<p>You can join a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> with a <a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a> to a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> with a <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a> on a level.
The <code class=""docutils literal notranslate""><span class=""pre"">name</span></code> of the <a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a> with match the level name of the <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a>.</p>


<img alt=""../_images/merging_join_multiindex_inner.png"" src=""../_images/merging_join_multiindex_inner.png""/>
</section>
<section id=""joining-with-two-multiindex"">
<span id=""merging-join-with-two-multi-indexes""></span><h3>Joining with two <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a><a class=""headerlink"" href=""#joining-with-two-multiindex"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a> of the input argument must be completely used
in the join and is a subset of the indices in the left argument.</p>



<img alt=""../_images/merging_merge_two_multiindex.png"" src=""../_images/merging_merge_two_multiindex.png""/>
</section>
<section id=""merging-on-a-combination-of-columns-and-index-levels"">
<span id=""merging-merge-on-columns-and-levels""></span><h3>Merging on a combination of columns and index levels<a class=""headerlink"" href=""#merging-on-a-combination-of-columns-and-index-levels"" title=""Link to this heading"">#</a></h3>
<p>Strings passed as the <code class=""docutils literal notranslate""><span class=""pre"">on</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">left_on</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">right_on</span></code> parameters
may refer to either column names or index level names. This enables merging
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> instances on a combination of index levels and columns without
resetting indexes.</p>


<img alt=""../_images/merge_on_index_and_column.png"" src=""../_images/merge_on_index_and_column.png""/>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>When <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> are joined on a string that matches an index level in both
arguments, the index level is preserved as an index level in the resulting
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>.</p>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>When <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> are joined using only some of the levels of a <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a>,
the extra levels will be dropped from the resulting join. To
preserve those levels, use <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.reset_index.html#pandas.DataFrame.reset_index"" title=""pandas.DataFrame.reset_index""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.reset_index()</span></code></a> on those level
names to move those levels to columns prior to the join.</p>
</div>
</section>
<section id=""joining-multiple-dataframe"">
<span id=""merging-multiple-join""></span><h3>Joining multiple <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a><a class=""headerlink"" href=""#joining-multiple-dataframe"" title=""Link to this heading"">#</a></h3>
<p>A list or tuple of <code class=""docutils literal notranslate""><span class=""pre"">:class:`DataFrame`</span></code> can also be passed to <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.join.html#pandas.DataFrame.join"" title=""pandas.DataFrame.join""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">join()</span></code></a>
to join them together on their indexes.</p>


<img alt=""../_images/merging_join_multi_df.png"" src=""../_images/merging_join_multi_df.png""/>
</section>
<section id=""dataframe-combine-first"">
<span id=""merging-combine-first-update""></span><h3><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.combine_first.html#pandas.DataFrame.combine_first"" title=""pandas.DataFrame.combine_first""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.combine_first()</span></code></a><a class=""headerlink"" href=""#dataframe-combine-first"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.combine_first.html#pandas.DataFrame.combine_first"" title=""pandas.DataFrame.combine_first""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.combine_first()</span></code></a> update missing values from one <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>
with the non-missing values in another <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> in the corresponding
location.</p>


<img alt=""../_images/merging_combine_first.png"" src=""../_images/merging_combine_first.png""/>
</section>
</section>
<section id=""merge-ordered"">
<span id=""merging-merge-ordered""></span><h2><a class=""reference internal"" href=""../reference/api/pandas.merge_ordered.html#pandas.merge_ordered"" title=""pandas.merge_ordered""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">merge_ordered()</span></code></a><a class=""headerlink"" href=""#merge-ordered"" title=""Link to this heading"">#</a></h2>
<p><a class=""reference internal"" href=""../reference/api/pandas.merge_ordered.html#pandas.merge_ordered"" title=""pandas.merge_ordered""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">merge_ordered()</span></code></a> combines order data such as numeric or time series data
with optional filling of missing data with <code class=""docutils literal notranslate""><span class=""pre"">fill_method</span></code>.</p>

</section>
<section id=""merge-asof"">
<span id=""merging-merge-asof""></span><h2><a class=""reference internal"" href=""../reference/api/pandas.merge_asof.html#pandas.merge_asof"" title=""pandas.merge_asof""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">merge_asof()</span></code></a><a class=""headerlink"" href=""#merge-asof"" title=""Link to this heading"">#</a></h2>
<p><a class=""reference internal"" href=""../reference/api/pandas.merge_asof.html#pandas.merge_asof"" title=""pandas.merge_asof""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">merge_asof()</span></code></a> is similar to an ordered left-join except that mactches are on the
nearest key rather than equal keys. For each row in the <code class=""docutils literal notranslate""><span class=""pre"">left</span></code> <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>,
the last row in the <code class=""docutils literal notranslate""><span class=""pre"">right</span></code> <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> are selected where the <code class=""docutils literal notranslate""><span class=""pre"">on</span></code> key is less
than the left’s key. Both <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> must be sorted by the key.</p>
<p>Optionally an <a class=""reference internal"" href=""../reference/api/pandas.merge_asof.html#pandas.merge_asof"" title=""pandas.merge_asof""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">merge_asof()</span></code></a> can perform a group-wise merge by matching the
<code class=""docutils literal notranslate""><span class=""pre"">by</span></code> key in addition to the nearest match on the <code class=""docutils literal notranslate""><span class=""pre"">on</span></code> key.</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.merge_asof.html#pandas.merge_asof"" title=""pandas.merge_asof""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">merge_asof()</span></code></a> within <code class=""docutils literal notranslate""><span class=""pre"">2ms</span></code> between the quote time and the trade time.</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.merge_asof.html#pandas.merge_asof"" title=""pandas.merge_asof""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">merge_asof()</span></code></a> within <code class=""docutils literal notranslate""><span class=""pre"">10ms</span></code> between the quote time and the trade time and
exclude exact matches on time. Note that though we exclude the exact matches
(of the quotes), prior quotes <strong>do</strong> propagate to that point in time.</p>

</section>
<section id=""compare"">
<span id=""merging-compare""></span><h2><a class=""reference internal"" href=""../reference/api/pandas.Series.compare.html#pandas.Series.compare"" title=""pandas.Series.compare""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">compare()</span></code></a><a class=""headerlink"" href=""#compare"" title=""Link to this heading"">#</a></h2>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.Series.compare.html#pandas.Series.compare"" title=""pandas.Series.compare""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.compare()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.compare.html#pandas.DataFrame.compare"" title=""pandas.DataFrame.compare""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.compare()</span></code></a> methods allow you to
compare two <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>, respectively, and summarize their differences.</p>

<p>By default, if two corresponding values are equal, they will be shown as <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>.
Furthermore, if all values in an entire row / column, the row / column will be
omitted from the result. The remaining differences will be aligned on columns.</p>
<p>Stack the differences on rows.</p>

<p>Keep all original rows and columns with <code class=""docutils literal notranslate""><span class=""pre"">keep_shape=True</span></code></p>

<p>Keep all the original values even if they are equal.</p>

</section>
</section>
</article>","Merge, join, concatenate and compare # pandas provides various methods for combining and comparing Series or DataFrame . concat() : Merge multiple Series or DataFrame objects along a shared index or column DataFrame.join() : Merge multiple DataFrame objects along the columns DataFrame.combine_first() : Update missing values with non-missing values in the same location merge() : Combine two Series or DataFrame objects with SQL-style joining merge_ordered() : Combine two Series or DataFrame objects along an ordered axis merge_asof() : Combine two Series or DataFrame objects by near instead of exact matching keys Series.compare() and DataFrame.compare() : Show differences in values between two Series or DataFrame objects concat() # The concat() function concatenates an arbitrary amount of Series or DataFrame objects along an axis while performing optional set logic (union or intersection) of the indexes on the other axes. Like numpy.concatenate , concat() takes a list or dict of homogeneously-typed objects and concatenates them. Note concat() makes a full copy of the data, and iteratively reusing concat() can create unnecessary copies. Collect all DataFrame or Series objects in a list before using concat() . frames = [ process_your_file ( f ) for f in files ] result = pd . concat ( frames ) Note When concatenating DataFrame with named axes, pandas will attempt to preserve these index/column names whenever possible. In the case where all inputs share a common name, this name will be assigned to the result. When the input names do not all agree, the result will be unnamed. The same is true for MultiIndex , but the logic is applied separately on a level-by-level basis. Joining logic of the resulting axis # The join keyword specifies how to handle axis values that don’t exist in the first DataFrame . join='outer' takes the union of all axis values join='inner' takes the intersection of the axis values To perform an effective “left” join using the exact index from the original DataFrame , result can be reindexed. Ignoring indexes on the concatenation axis # For DataFrame objects which don’t have a meaningful index, the ignore_index ignores overlapping indexes. Concatenating Series and DataFrame together # You can concatenate a mix of Series and DataFrame objects. The Series will be transformed to DataFrame with the column name as the name of the Series . Unnamed Series will be numbered consecutively. ignore_index=True will drop all name references. Resulting keys # The keys argument adds another axis level to the resulting index or column (creating a MultiIndex ) associate specific keys with each original DataFrame . The keys argument cane override the column names when creating a new DataFrame based on existing Series . You can also pass a dict to concat() in which case the dict keys will be used for the keys argument unless other keys argument is specified: The MultiIndex created has levels that are constructed from the passed keys and the index of the DataFrame pieces: levels argument allows specifying resulting levels associated with the keys Appending rows to a DataFrame # If you have a Series that you want to append as a single row to a DataFrame , you can convert the row into a DataFrame and use concat() merge() # merge() performs join operations similar to relational databases like SQL. Users who are familiar with SQL but new to pandas can reference a comparison with SQL . Merge types # merge() implements common SQL style joining operations. one-to-one : joining two DataFrame objects on their indexes which must contain unique values. many-to-one : joining a unique index to one or more columns in a different DataFrame . many-to-many : joining columns on columns. Note When joining columns on columns, potentially a many-to-many join, any indexes on the passed DataFrame objects will be discarded . For a many-to-many join, if a key combination appears more than once in both tables, the DataFrame will have the Cartesian product of the associated data. The how argument to merge() specifies which keys are included in the resulting table. If a key combination does not appear in either the left or right tables, the values in the joined table will be NA . Here is a summary of the how options and their SQL equivalent names: You can Series and a DataFrame with a MultiIndex if the names of the MultiIndex correspond to the columns from the DataFrame . Transform the Series to a DataFrame using Series.reset_index() before merging Performing an outer join with duplicate join keys in DataFrame Warning Merging on duplicate keys significantly increase the dimensions of the result and can cause a memory overflow. Merge key uniqueness # The validate argument checks whether the uniqueness of merge keys. Key uniqueness is checked before merge operations and can protect against memory overflows and unexpected key duplication. If the user is aware of the duplicates in the right DataFrame but wants to ensure there are no duplicates in the left DataFrame , one can use the validate='one_to_many' argument instead, which will not raise an exception. Merge result indicator # merge() accepts the argument indicator . If True , a Categorical-type column called _merge will be added to the output object that takes on values: A string argument to indicator will use the value as the name for the indicator column. Overlapping value columns # The merge suffixes argument takes a tuple of list of strings to append to overlapping column names in the input DataFrame to disambiguate the result columns: DataFrame.join() # DataFrame.join() combines the columns of multiple, potentially differently-indexed DataFrame into a single result DataFrame . DataFrame.join() takes an optional on argument which may be a column or multiple column names that the passed DataFrame is to be aligned. To join on multiple keys, the passed DataFrame must have a MultiIndex : The default for DataFrame.join is to perform a left join which uses only the keys found in the calling DataFrame . Other join types can be specified with how . Joining a single Index to a MultiIndex # You can join a DataFrame with a Index to a DataFrame with a MultiIndex on a level. The name of the Index with match the level name of the MultiIndex . Joining with two MultiIndex # The MultiIndex of the input argument must be completely used in the join and is a subset of the indices in the left argument. Merging on a combination of columns and index levels # Strings passed as the on , left_on , and right_on parameters may refer to either column names or index level names. This enables merging DataFrame instances on a combination of index levels and columns without resetting indexes. Note When DataFrame are joined on a string that matches an index level in both arguments, the index level is preserved as an index level in the resulting DataFrame . Note When DataFrame are joined using only some of the levels of a MultiIndex , the extra levels will be dropped from the resulting join. To preserve those levels, use DataFrame.reset_index() on those level names to move those levels to columns prior to the join. Joining multiple DataFrame # A list or tuple of :class:`DataFrame` can also be passed to join() to join them together on their indexes. DataFrame.combine_first() # DataFrame.combine_first() update missing values from one DataFrame with the non-missing values in another DataFrame in the corresponding location. merge_ordered() # merge_ordered() combines order data such as numeric or time series data with optional filling of missing data with fill_method . merge_asof() # merge_asof() is similar to an ordered left-join except that mactches are on the nearest key rather than equal keys. For each row in the left DataFrame , the last row in the right DataFrame are selected where the on key is less than the left’s key. Both DataFrame must be sorted by the key. Optionally an merge_asof() can perform a group-wise merge by matching the by key in addition to the nearest match on the on key. merge_asof() within 2ms between the quote time and the trade time. merge_asof() within 10ms between the quote time and the trade time and exclude exact matches on time. Note that though we exclude the exact matches (of the quotes), prior quotes do propagate to that point in time. compare() # The Series.compare() and DataFrame.compare() methods allow you to compare two DataFrame or Series , respectively, and summarize their differences. By default, if two corresponding values are equal, they will be shown as NaN . Furthermore, if all values in an entire row / column, the row / column will be omitted from the result. The remaining differences will be aligned on columns. Stack the differences on rows. Keep all original rows and columns with keep_shape=True Keep all the original values even if they are equal."
https://pandas.pydata.org/docs/user_guide/reshaping.html,Reshaping and pivot tables,"<article class=""bd-article"" role=""main"">
<section id=""reshaping-and-pivot-tables"">
<span id=""reshaping""></span><h1>Reshaping and pivot tables<a class=""headerlink"" href=""#reshaping-and-pivot-tables"" title=""Link to this heading"">#</a></h1>
<p id=""reshaping-reshaping"">pandas provides methods for manipulating a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> to alter the
representation of the data for further data processing or data summarization.</p>
<ul class=""simple"">
<li><p><a class=""reference internal"" href=""../reference/api/pandas.pivot.html#pandas.pivot"" title=""pandas.pivot""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pivot()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.pivot_table.html#pandas.pivot_table"" title=""pandas.pivot_table""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pivot_table()</span></code></a>: Group unique values within one or more discrete categories.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack"" title=""pandas.DataFrame.stack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">stack()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack"" title=""pandas.DataFrame.unstack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">unstack()</span></code></a>: Pivot a column or row level to the opposite axis respectively.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.melt.html#pandas.melt"" title=""pandas.melt""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">melt()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.wide_to_long.html#pandas.wide_to_long"" title=""pandas.wide_to_long""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">wide_to_long()</span></code></a>: Unpivot a wide <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> to a long format.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.get_dummies.html#pandas.get_dummies"" title=""pandas.get_dummies""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">get_dummies()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.from_dummies.html#pandas.from_dummies"" title=""pandas.from_dummies""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">from_dummies()</span></code></a>: Conversions with indicator variables.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.Series.explode.html#pandas.Series.explode"" title=""pandas.Series.explode""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">explode()</span></code></a>: Convert a column of list-like values to individual rows.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.crosstab.html#pandas.crosstab"" title=""pandas.crosstab""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">crosstab()</span></code></a>: Calculate a cross-tabulation of multiple 1 dimensional factor arrays.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.cut.html#pandas.cut"" title=""pandas.cut""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">cut()</span></code></a>: Transform continuous variables to discrete, categorical values</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.factorize.html#pandas.factorize"" title=""pandas.factorize""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">factorize()</span></code></a>: Encode 1 dimensional variables into integer labels.</p></li>
</ul>
<section id=""pivot-and-pivot-table"">
<h2><a class=""reference internal"" href=""../reference/api/pandas.pivot.html#pandas.pivot"" title=""pandas.pivot""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pivot()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.pivot_table.html#pandas.pivot_table"" title=""pandas.pivot_table""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pivot_table()</span></code></a><a class=""headerlink"" href=""#pivot-and-pivot-table"" title=""Link to this heading"">#</a></h2>
<img alt=""../_images/reshaping_pivot.png"" src=""../_images/reshaping_pivot.png""/>
<section id=""pivot"">
<h3><a class=""reference internal"" href=""../reference/api/pandas.pivot.html#pandas.pivot"" title=""pandas.pivot""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pivot()</span></code></a><a class=""headerlink"" href=""#pivot"" title=""Link to this heading"">#</a></h3>
<p>Data is often stored in so-called “stacked” or “record” format. In a “record” or “wide” format,
typically there is one row for each subject. In the “stacked” or “long” format there are
multiple rows for each subject where applicable.</p>

<p>To perform time series operations with each unique variable, a better
representation would be where the <code class=""docutils literal notranslate""><span class=""pre"">columns</span></code> are the unique variables and an
<code class=""docutils literal notranslate""><span class=""pre"">index</span></code> of dates identifies individual observations. To reshape the data into
this form, we use the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.pivot.html#pandas.DataFrame.pivot"" title=""pandas.DataFrame.pivot""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.pivot()</span></code></a> method (also implemented as a
top level function <a class=""reference internal"" href=""../reference/api/pandas.pivot.html#pandas.pivot"" title=""pandas.pivot""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pivot()</span></code></a>):</p>

<p>If the <code class=""docutils literal notranslate""><span class=""pre"">values</span></code> argument is omitted, and the input <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> has more than
one column of values which are not used as column or index inputs to <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.pivot.html#pandas.DataFrame.pivot"" title=""pandas.DataFrame.pivot""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">pivot()</span></code></a>,
then the resulting “pivoted” <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> will have <a class=""reference internal"" href=""advanced.html#advanced-hierarchical""><span class=""std std-ref"">hierarchical columns</span></a> whose topmost level indicates the respective value
column:</p>

<p>You can then select subsets from the pivoted <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>:</p>

<p>Note that this returns a view on the underlying data in the case where the data
are homogeneously-typed.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p><a class=""reference internal"" href=""../reference/api/pandas.pivot.html#pandas.pivot"" title=""pandas.pivot""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pivot()</span></code></a> can only handle unique rows specified by <code class=""docutils literal notranslate""><span class=""pre"">index</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">columns</span></code>.
If you data contains duplicates, use <a class=""reference internal"" href=""../reference/api/pandas.pivot_table.html#pandas.pivot_table"" title=""pandas.pivot_table""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pivot_table()</span></code></a>.</p>
</div>
</section>
<section id=""pivot-table"">
<span id=""reshaping-pivot""></span><h3><a class=""reference internal"" href=""../reference/api/pandas.pivot_table.html#pandas.pivot_table"" title=""pandas.pivot_table""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pivot_table()</span></code></a><a class=""headerlink"" href=""#pivot-table"" title=""Link to this heading"">#</a></h3>
<p>While <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.pivot.html#pandas.DataFrame.pivot"" title=""pandas.DataFrame.pivot""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">pivot()</span></code></a> provides general purpose pivoting with various
data types, pandas also provides <a class=""reference internal"" href=""../reference/api/pandas.pivot_table.html#pandas.pivot_table"" title=""pandas.pivot_table""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pivot_table()</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.pivot_table.html#pandas.DataFrame.pivot_table"" title=""pandas.DataFrame.pivot_table""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">pivot_table()</span></code></a>
for pivoting with aggregation of numeric data.</p>
<p>The function <a class=""reference internal"" href=""../reference/api/pandas.pivot_table.html#pandas.pivot_table"" title=""pandas.pivot_table""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pivot_table()</span></code></a> can be used to create spreadsheet-style
pivot tables. See the <a class=""reference internal"" href=""cookbook.html#cookbook-pivot""><span class=""std std-ref"">cookbook</span></a> for some advanced
strategies.</p>

<p>The result is a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> potentially having a <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a> on the
index or column. If the <code class=""docutils literal notranslate""><span class=""pre"">values</span></code> column name is not given, the pivot table
will include all of the data in an additional level of hierarchy in the columns:</p>

<p>Also, you can use <a class=""reference internal"" href=""../reference/api/pandas.Grouper.html#pandas.Grouper"" title=""pandas.Grouper""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Grouper</span></code></a> for <code class=""docutils literal notranslate""><span class=""pre"">index</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">columns</span></code> keywords. For detail of <a class=""reference internal"" href=""../reference/api/pandas.Grouper.html#pandas.Grouper"" title=""pandas.Grouper""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Grouper</span></code></a>, see <a class=""reference internal"" href=""groupby.html#groupby-specify""><span class=""std std-ref"">Grouping with a Grouper specification</span></a>.</p>

<section id=""adding-margins"">
<span id=""reshaping-pivot-margins""></span><h4>Adding margins<a class=""headerlink"" href=""#adding-margins"" title=""Link to this heading"">#</a></h4>
<p>Passing <code class=""docutils literal notranslate""><span class=""pre"">margins=True</span></code> to <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.pivot_table.html#pandas.DataFrame.pivot_table"" title=""pandas.DataFrame.pivot_table""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">pivot_table()</span></code></a> will add a row and column with an
<code class=""docutils literal notranslate""><span class=""pre"">All</span></code> label with partial group aggregates across the categories on the
rows and columns:</p>

<p>Additionally, you can call <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack"" title=""pandas.DataFrame.stack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.stack()</span></code></a> to display a pivoted DataFrame
as having a multi-level index:</p>

</section>
</section>
</section>
<section id=""stack-and-unstack"">
<span id=""reshaping-stacking""></span><h2><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack"" title=""pandas.DataFrame.stack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">stack()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack"" title=""pandas.DataFrame.unstack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">unstack()</span></code></a><a class=""headerlink"" href=""#stack-and-unstack"" title=""Link to this heading"">#</a></h2>
<img alt=""../_images/reshaping_stack.png"" src=""../_images/reshaping_stack.png""/>
<p>Closely related to the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.pivot.html#pandas.DataFrame.pivot"" title=""pandas.DataFrame.pivot""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">pivot()</span></code></a> method are the related
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack"" title=""pandas.DataFrame.stack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">stack()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack"" title=""pandas.DataFrame.unstack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">unstack()</span></code></a> methods available on
<a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>. These methods are designed to work together with
<a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a> objects (see the section on <a class=""reference internal"" href=""advanced.html#advanced-hierarchical""><span class=""std std-ref"">hierarchical indexing</span></a>).</p>
<ul class=""simple"">
<li><p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack"" title=""pandas.DataFrame.stack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">stack()</span></code></a>: “pivot” a level of the (possibly hierarchical) column labels,
returning a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> with an index with a new inner-most level of row
labels.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack"" title=""pandas.DataFrame.unstack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">unstack()</span></code></a>: (inverse operation of <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack"" title=""pandas.DataFrame.stack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">stack()</span></code></a>) “pivot” a level of the
(possibly hierarchical) row index to the column axis, producing a reshaped
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> with a new inner-most level of column labels.</p></li>
</ul>
<img alt=""../_images/reshaping_unstack.png"" src=""../_images/reshaping_unstack.png""/>

<p>The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack"" title=""pandas.DataFrame.stack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">stack()</span></code></a> function “compresses” a level in the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> columns to
produce either:</p>
<ul class=""simple"">
<li><p>A <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>, in the case of a <a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a> in the columns.</p></li>
<li><p>A <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>, in the case of a <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a> in the columns.</p></li>
</ul>
<p>If the columns have a <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a>, you can choose which level to stack. The
stacked level becomes the new lowest level in a <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a> on the columns:</p>

<p>With a “stacked” <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> (having a <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a> as the
<code class=""docutils literal notranslate""><span class=""pre"">index</span></code>), the inverse operation of <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack"" title=""pandas.DataFrame.stack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">stack()</span></code></a> is <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack"" title=""pandas.DataFrame.unstack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">unstack()</span></code></a>, which by default
unstacks the <strong>last level</strong>:</p>

<img alt=""../_images/reshaping_unstack_1.png"" id=""reshaping-unstack-by-name"" src=""../_images/reshaping_unstack_1.png""/>
<p>If the indexes have names, you can use the level names instead of specifying
the level numbers:</p>

<img alt=""../_images/reshaping_unstack_0.png"" src=""../_images/reshaping_unstack_0.png""/>
<p>Notice that the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack"" title=""pandas.DataFrame.stack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">stack()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack"" title=""pandas.DataFrame.unstack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">unstack()</span></code></a> methods implicitly sort the index
levels involved. Hence a call to <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack"" title=""pandas.DataFrame.stack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">stack()</span></code></a> and then <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack"" title=""pandas.DataFrame.unstack""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">unstack()</span></code></a>, or vice versa,
will result in a <strong>sorted</strong> copy of the original <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>:</p>

<section id=""multiple-levels"">
<span id=""reshaping-stack-multiple""></span><h3>Multiple levels<a class=""headerlink"" href=""#multiple-levels"" title=""Link to this heading"">#</a></h3>
<p>You may also stack or unstack more than one level at a time by passing a list
of levels, in which case the end result is as if each level in the list were
processed individually.</p>

<p>The list of levels can contain either level names or level numbers but
not a mixture of the two.</p>

</section>
<section id=""missing-data"">
<h3>Missing data<a class=""headerlink"" href=""#missing-data"" title=""Link to this heading"">#</a></h3>
<p>Unstacking can result in missing values if subgroups do not have the same
set of labels. By default, missing values will be replaced with the default
fill value for that data type.</p>

<p>The missing value can be filled with a specific value with the <code class=""docutils literal notranslate""><span class=""pre"">fill_value</span></code> argument.</p>

</section>
</section>
<section id=""melt-and-wide-to-long"">
<span id=""reshaping-melt""></span><h2><a class=""reference internal"" href=""../reference/api/pandas.melt.html#pandas.melt"" title=""pandas.melt""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">melt()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.wide_to_long.html#pandas.wide_to_long"" title=""pandas.wide_to_long""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">wide_to_long()</span></code></a><a class=""headerlink"" href=""#melt-and-wide-to-long"" title=""Link to this heading"">#</a></h2>
<img alt=""../_images/reshaping_melt.png"" src=""../_images/reshaping_melt.png""/>
<p>The top-level <a class=""reference internal"" href=""../reference/api/pandas.melt.html#pandas.melt"" title=""pandas.melt""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">melt()</span></code></a> function and the corresponding <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.melt.html#pandas.DataFrame.melt"" title=""pandas.DataFrame.melt""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.melt()</span></code></a>
are useful to massage a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> into a format where one or more columns
are <em>identifier variables</em>, while all other columns, considered <em>measured
variables</em>, are “unpivoted” to the row axis, leaving just two non-identifier
columns, “variable” and “value”. The names of those columns can be customized
by supplying the <code class=""docutils literal notranslate""><span class=""pre"">var_name</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">value_name</span></code> parameters.</p>

<p>When transforming a DataFrame using <a class=""reference internal"" href=""../reference/api/pandas.melt.html#pandas.melt"" title=""pandas.melt""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">melt()</span></code></a>, the index will be ignored.
The original index values can be kept by setting the <code class=""docutils literal notranslate""><span class=""pre"">ignore_index=False</span></code> parameter to <code class=""docutils literal notranslate""><span class=""pre"">False</span></code> (default is <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>).
<code class=""docutils literal notranslate""><span class=""pre"">ignore_index=False</span></code> will however duplicate index values.</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.wide_to_long.html#pandas.wide_to_long"" title=""pandas.wide_to_long""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">wide_to_long()</span></code></a> is similar to <a class=""reference internal"" href=""../reference/api/pandas.melt.html#pandas.melt"" title=""pandas.melt""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">melt()</span></code></a> with more customization for
column matching.</p>

</section>
<section id=""get-dummies-and-from-dummies"">
<span id=""reshaping-dummies""></span><h2><a class=""reference internal"" href=""../reference/api/pandas.get_dummies.html#pandas.get_dummies"" title=""pandas.get_dummies""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">get_dummies()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.from_dummies.html#pandas.from_dummies"" title=""pandas.from_dummies""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">from_dummies()</span></code></a><a class=""headerlink"" href=""#get-dummies-and-from-dummies"" title=""Link to this heading"">#</a></h2>
<p>To convert categorical variables of a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> into a “dummy” or “indicator”,
<a class=""reference internal"" href=""../reference/api/pandas.get_dummies.html#pandas.get_dummies"" title=""pandas.get_dummies""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">get_dummies()</span></code></a> creates a new <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> with columns of the unique
variables and the values representing the presence of those variables per row.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">prefix</span></code> adds a prefix to the the column names which is useful for merging the result
with the original <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>:</p>

<p>This function is often used along with discretization functions like <a class=""reference internal"" href=""../reference/api/pandas.cut.html#pandas.cut"" title=""pandas.cut""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">cut()</span></code></a>:</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.get_dummies.html#pandas.get_dummies"" title=""pandas.get_dummies""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">get_dummies()</span></code></a> also accepts a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>. By default, <code class=""docutils literal notranslate""><span class=""pre"">object</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">string</span></code>,
or <code class=""docutils literal notranslate""><span class=""pre"">categorical</span></code> type columns are encoded as dummy variables with other columns unaltered.</p>

<p>Specifying the <code class=""docutils literal notranslate""><span class=""pre"">columns</span></code> keyword will encode a column of any type.</p>

<p>As with the <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> version, you can pass values for the <code class=""docutils literal notranslate""><span class=""pre"">prefix</span></code> and
<code class=""docutils literal notranslate""><span class=""pre"">prefix_sep</span></code>. By default the column name is used as the prefix and <code class=""docutils literal notranslate""><span class=""pre"">_</span></code> as
the prefix separator. You can specify <code class=""docutils literal notranslate""><span class=""pre"">prefix</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">prefix_sep</span></code> in 3 ways:</p>
<ul class=""simple"">
<li><p>string: Use the same value for <code class=""docutils literal notranslate""><span class=""pre"">prefix</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">prefix_sep</span></code> for each column
to be encoded.</p></li>
<li><p>list: Must be the same length as the number of columns being encoded.</p></li>
<li><p>dict: Mapping column name to prefix.</p></li>
</ul>

<p>To avoid collinearity when feeding the result to statistical models,
specify <code class=""docutils literal notranslate""><span class=""pre"">drop_first=True</span></code>.</p>

<p>When a column contains only one level, it will be omitted in the result.</p>

<p>The values can be cast to a different type using the <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code> argument.</p>

<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.5.0.</span></p>
</div>
<p><a class=""reference internal"" href=""../reference/api/pandas.from_dummies.html#pandas.from_dummies"" title=""pandas.from_dummies""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">from_dummies()</span></code></a> converts the output of <a class=""reference internal"" href=""../reference/api/pandas.get_dummies.html#pandas.get_dummies"" title=""pandas.get_dummies""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">get_dummies()</span></code></a> back into
a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> of categorical values from indicator values.</p>

<p>Dummy coded data only requires <code class=""docutils literal notranslate""><span class=""pre"">k</span> <span class=""pre"">-</span> <span class=""pre"">1</span></code> categories to be included, in this case
the last category is the default category. The default category can be modified with
<code class=""docutils literal notranslate""><span class=""pre"">default_category</span></code>.</p>

</section>
<section id=""explode"">
<span id=""reshaping-explode""></span><h2><a class=""reference internal"" href=""../reference/api/pandas.Series.explode.html#pandas.Series.explode"" title=""pandas.Series.explode""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">explode()</span></code></a><a class=""headerlink"" href=""#explode"" title=""Link to this heading"">#</a></h2>
<p>For a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> column with nested, list-like values, <a class=""reference internal"" href=""../reference/api/pandas.Series.explode.html#pandas.Series.explode"" title=""pandas.Series.explode""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">explode()</span></code></a> will transform
each list-like value to a separate row. The resulting <a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a> will be duplicated corresponding
to the index label from the original row:</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.explode.html#pandas.DataFrame.explode"" title=""pandas.DataFrame.explode""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame.explode</span></code></a> can also explode the column in the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>.</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.Series.explode.html#pandas.Series.explode"" title=""pandas.Series.explode""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.explode()</span></code></a> will replace empty lists with a missing value indicator and preserve scalar entries.</p>

<p>A comma-separated string value can be split into individual values in a list and then exploded to a new row.</p>

</section>
<section id=""crosstab"">
<span id=""reshaping-crosstabulations""></span><h2><a class=""reference internal"" href=""../reference/api/pandas.crosstab.html#pandas.crosstab"" title=""pandas.crosstab""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">crosstab()</span></code></a><a class=""headerlink"" href=""#crosstab"" title=""Link to this heading"">#</a></h2>
<p>Use <a class=""reference internal"" href=""../reference/api/pandas.crosstab.html#pandas.crosstab"" title=""pandas.crosstab""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">crosstab()</span></code></a> to compute a cross-tabulation of two (or more)
factors. By default <a class=""reference internal"" href=""../reference/api/pandas.crosstab.html#pandas.crosstab"" title=""pandas.crosstab""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">crosstab()</span></code></a> computes a frequency table of the factors
unless an array of values and an aggregation function are passed.</p>
<p>Any <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> passed will have their name attributes used unless row or column
names for the cross-tabulation are specified</p>

<p>If <a class=""reference internal"" href=""../reference/api/pandas.crosstab.html#pandas.crosstab"" title=""pandas.crosstab""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">crosstab()</span></code></a> receives only two <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>, it will provide a frequency table.</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.crosstab.html#pandas.crosstab"" title=""pandas.crosstab""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">crosstab()</span></code></a> can also summarize to <a class=""reference internal"" href=""../reference/api/pandas.Categorical.html#pandas.Categorical"" title=""pandas.Categorical""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Categorical</span></code></a> data.</p>

<p>For <a class=""reference internal"" href=""../reference/api/pandas.Categorical.html#pandas.Categorical"" title=""pandas.Categorical""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Categorical</span></code></a> data, to include <strong>all</strong> of data categories even if the actual data does
not contain any instances of a particular category, use <code class=""docutils literal notranslate""><span class=""pre"">dropna=False</span></code>.</p>

<section id=""normalization"">
<h3>Normalization<a class=""headerlink"" href=""#normalization"" title=""Link to this heading"">#</a></h3>
<p>Frequency tables can also be normalized to show percentages rather than counts
using the <code class=""docutils literal notranslate""><span class=""pre"">normalize</span></code> argument:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">normalize</span></code> can also normalize values within each row or within each column:</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.crosstab.html#pandas.crosstab"" title=""pandas.crosstab""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">crosstab()</span></code></a> can also accept a third <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> and an aggregation function
(<code class=""docutils literal notranslate""><span class=""pre"">aggfunc</span></code>) that will be applied to the values of the third <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> within
each group defined by the first two <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>:</p>

</section>
<section id=""id1"">
<h3>Adding margins<a class=""headerlink"" href=""#id1"" title=""Link to this heading"">#</a></h3>
<p><code class=""docutils literal notranslate""><span class=""pre"">margins=True</span></code> will add a row and column with an <code class=""docutils literal notranslate""><span class=""pre"">All</span></code> label with partial group aggregates
across the categories on the rows and columns:</p>

</section>
</section>
<section id=""cut"">
<span id=""reshaping-tile-cut""></span><span id=""reshaping-tile""></span><h2><a class=""reference internal"" href=""../reference/api/pandas.cut.html#pandas.cut"" title=""pandas.cut""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">cut()</span></code></a><a class=""headerlink"" href=""#cut"" title=""Link to this heading"">#</a></h2>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.cut.html#pandas.cut"" title=""pandas.cut""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">cut()</span></code></a> function computes groupings for the values of the input
array and is often used to transform continuous variables to discrete or
categorical variables:</p>
<p>An integer <code class=""docutils literal notranslate""><span class=""pre"">bins</span></code> will form equal-width bins.</p>

<p>A list of ordered bin edges will assign an interval for each variable.</p>

<p>If the <code class=""docutils literal notranslate""><span class=""pre"">bins</span></code> keyword is an <a class=""reference internal"" href=""../reference/api/pandas.IntervalIndex.html#pandas.IntervalIndex"" title=""pandas.IntervalIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">IntervalIndex</span></code></a>, then these will be
used to bin the passed data.</p>

</section>
<section id=""factorize"">
<span id=""reshaping-factorize""></span><h2><a class=""reference internal"" href=""../reference/api/pandas.factorize.html#pandas.factorize"" title=""pandas.factorize""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">factorize()</span></code></a><a class=""headerlink"" href=""#factorize"" title=""Link to this heading"">#</a></h2>
<p><a class=""reference internal"" href=""../reference/api/pandas.factorize.html#pandas.factorize"" title=""pandas.factorize""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">factorize()</span></code></a> encodes 1 dimensional values into integer labels. Missing values
are encoded as <code class=""docutils literal notranslate""><span class=""pre"">-1</span></code>.</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.Categorical.html#pandas.Categorical"" title=""pandas.Categorical""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Categorical</span></code></a> will similarly encode 1 dimensional values for further
categorical operations</p>

</section>
</section>
</article>","Reshaping and pivot tables # pandas provides methods for manipulating a Series and DataFrame to alter the representation of the data for further data processing or data summarization. pivot() and pivot_table() : Group unique values within one or more discrete categories. stack() and unstack() : Pivot a column or row level to the opposite axis respectively. melt() and wide_to_long() : Unpivot a wide DataFrame to a long format. get_dummies() and from_dummies() : Conversions with indicator variables. explode() : Convert a column of list-like values to individual rows. crosstab() : Calculate a cross-tabulation of multiple 1 dimensional factor arrays. cut() : Transform continuous variables to discrete, categorical values factorize() : Encode 1 dimensional variables into integer labels. pivot() and pivot_table() # pivot() # Data is often stored in so-called “stacked” or “record” format. In a “record” or “wide” format, typically there is one row for each subject. In the “stacked” or “long” format there are multiple rows for each subject where applicable. To perform time series operations with each unique variable, a better representation would be where the columns are the unique variables and an index of dates identifies individual observations. To reshape the data into this form, we use the DataFrame.pivot() method (also implemented as a top level function pivot() ): If the values argument is omitted, and the input DataFrame has more than one column of values which are not used as column or index inputs to pivot() , then the resulting “pivoted” DataFrame will have hierarchical columns whose topmost level indicates the respective value column: You can then select subsets from the pivoted DataFrame : Note that this returns a view on the underlying data in the case where the data are homogeneously-typed. Note pivot() can only handle unique rows specified by index and columns . If you data contains duplicates, use pivot_table() . pivot_table() # While pivot() provides general purpose pivoting with various data types, pandas also provides pivot_table() or pivot_table() for pivoting with aggregation of numeric data. The function pivot_table() can be used to create spreadsheet-style pivot tables. See the cookbook for some advanced strategies. The result is a DataFrame potentially having a MultiIndex on the index or column. If the values column name is not given, the pivot table will include all of the data in an additional level of hierarchy in the columns: Also, you can use Grouper for index and columns keywords. For detail of Grouper , see Grouping with a Grouper specification . Adding margins # Passing margins=True to pivot_table() will add a row and column with an All label with partial group aggregates across the categories on the rows and columns: Additionally, you can call DataFrame.stack() to display a pivoted DataFrame as having a multi-level index: stack() and unstack() # Closely related to the pivot() method are the related stack() and unstack() methods available on Series and DataFrame . These methods are designed to work together with MultiIndex objects (see the section on hierarchical indexing ). stack() : “pivot” a level of the (possibly hierarchical) column labels, returning a DataFrame with an index with a new inner-most level of row labels. unstack() : (inverse operation of stack() ) “pivot” a level of the (possibly hierarchical) row index to the column axis, producing a reshaped DataFrame with a new inner-most level of column labels. The stack() function “compresses” a level in the DataFrame columns to produce either: A Series , in the case of a Index in the columns. A DataFrame , in the case of a MultiIndex in the columns. If the columns have a MultiIndex , you can choose which level to stack. The stacked level becomes the new lowest level in a MultiIndex on the columns: With a “stacked” DataFrame or Series (having a MultiIndex as the index ), the inverse operation of stack() is unstack() , which by default unstacks the last level : If the indexes have names, you can use the level names instead of specifying the level numbers: Notice that the stack() and unstack() methods implicitly sort the index levels involved. Hence a call to stack() and then unstack() , or vice versa, will result in a sorted copy of the original DataFrame or Series : Multiple levels # You may also stack or unstack more than one level at a time by passing a list of levels, in which case the end result is as if each level in the list were processed individually. The list of levels can contain either level names or level numbers but not a mixture of the two. Missing data # Unstacking can result in missing values if subgroups do not have the same set of labels. By default, missing values will be replaced with the default fill value for that data type. The missing value can be filled with a specific value with the fill_value argument. melt() and wide_to_long() # The top-level melt() function and the corresponding DataFrame.melt() are useful to massage a DataFrame into a format where one or more columns are identifier variables , while all other columns, considered measured variables , are “unpivoted” to the row axis, leaving just two non-identifier columns, “variable” and “value”. The names of those columns can be customized by supplying the var_name and value_name parameters. When transforming a DataFrame using melt() , the index will be ignored. The original index values can be kept by setting the ignore_index=False parameter to False (default is True ). ignore_index=False will however duplicate index values. wide_to_long() is similar to melt() with more customization for column matching. get_dummies() and from_dummies() # To convert categorical variables of a Series into a “dummy” or “indicator”, get_dummies() creates a new DataFrame with columns of the unique variables and the values representing the presence of those variables per row. prefix adds a prefix to the the column names which is useful for merging the result with the original DataFrame : This function is often used along with discretization functions like cut() : get_dummies() also accepts a DataFrame . By default, object , string , or categorical type columns are encoded as dummy variables with other columns unaltered. Specifying the columns keyword will encode a column of any type. As with the Series version, you can pass values for the prefix and prefix_sep . By default the column name is used as the prefix and _ as the prefix separator. You can specify prefix and prefix_sep in 3 ways: string: Use the same value for prefix or prefix_sep for each column to be encoded. list: Must be the same length as the number of columns being encoded. dict: Mapping column name to prefix. To avoid collinearity when feeding the result to statistical models, specify drop_first=True . When a column contains only one level, it will be omitted in the result. The values can be cast to a different type using the dtype argument. New in version 1.5.0. from_dummies() converts the output of get_dummies() back into a Series of categorical values from indicator values. Dummy coded data only requires k - 1 categories to be included, in this case the last category is the default category. The default category can be modified with default_category . explode() # For a DataFrame column with nested, list-like values, explode() will transform each list-like value to a separate row. The resulting Index will be duplicated corresponding to the index label from the original row: DataFrame.explode can also explode the column in the DataFrame . Series.explode() will replace empty lists with a missing value indicator and preserve scalar entries. A comma-separated string value can be split into individual values in a list and then exploded to a new row. crosstab() # Use crosstab() to compute a cross-tabulation of two (or more) factors. By default crosstab() computes a frequency table of the factors unless an array of values and an aggregation function are passed. Any Series passed will have their name attributes used unless row or column names for the cross-tabulation are specified If crosstab() receives only two Series , it will provide a frequency table. crosstab() can also summarize to Categorical data. For Categorical data, to include all of data categories even if the actual data does not contain any instances of a particular category, use dropna=False . Normalization # Frequency tables can also be normalized to show percentages rather than counts using the normalize argument: normalize can also normalize values within each row or within each column: crosstab() can also accept a third Series and an aggregation function ( aggfunc ) that will be applied to the values of the third Series within each group defined by the first two Series : Adding margins # margins=True will add a row and column with an All label with partial group aggregates across the categories on the rows and columns: cut() # The cut() function computes groupings for the values of the input array and is often used to transform continuous variables to discrete or categorical variables: An integer bins will form equal-width bins. A list of ordered bin edges will assign an interval for each variable. If the bins keyword is an IntervalIndex , then these will be used to bin the passed data. factorize() # factorize() encodes 1 dimensional values into integer labels. Missing values are encoded as -1 . Categorical will similarly encode 1 dimensional values for further categorical operations"
https://pandas.pydata.org/docs/user_guide/text.html,Working with text data,"<article class=""bd-article"" role=""main"">
<section id=""working-with-text-data"">
<span id=""text""></span><h1>Working with text data<a class=""headerlink"" href=""#working-with-text-data"" title=""Link to this heading"">#</a></h1>
<section id=""text-data-types"">
<span id=""text-types""></span><h2>Text data types<a class=""headerlink"" href=""#text-data-types"" title=""Link to this heading"">#</a></h2>
<p>There are two ways to store text data in pandas:</p>
<ol class=""arabic simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">object</span></code> -dtype NumPy array.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.StringDtype.html#pandas.StringDtype"" title=""pandas.StringDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">StringDtype</span></code></a> extension type.</p></li>
</ol>
<p>We recommend using <a class=""reference internal"" href=""../reference/api/pandas.StringDtype.html#pandas.StringDtype"" title=""pandas.StringDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">StringDtype</span></code></a> to store text data.</p>
<p>Prior to pandas 1.0, <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> dtype was the only option. This was unfortunate
for many reasons:</p>
<ol class=""arabic simple"">
<li><p>You can accidentally store a <em>mixture</em> of strings and non-strings in an
<code class=""docutils literal notranslate""><span class=""pre"">object</span></code> dtype array. It’s better to have a dedicated dtype.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">object</span></code> dtype breaks dtype-specific operations like <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.select_dtypes.html#pandas.DataFrame.select_dtypes"" title=""pandas.DataFrame.select_dtypes""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.select_dtypes()</span></code></a>.
There isn’t a clear way to select <em>just</em> text while excluding non-text
but still object-dtype columns.</p></li>
<li><p>When reading code, the contents of an <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> dtype array is less clear
than <code class=""docutils literal notranslate""><span class=""pre"">'string'</span></code>.</p></li>
</ol>
<p>Currently, the performance of <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> dtype arrays of strings and
<a class=""reference internal"" href=""../reference/api/pandas.arrays.StringArray.html#pandas.arrays.StringArray"" title=""pandas.arrays.StringArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">arrays.StringArray</span></code></a> are about the same. We expect future enhancements
to significantly increase the performance and lower the memory overhead of
<a class=""reference internal"" href=""../reference/api/pandas.arrays.StringArray.html#pandas.arrays.StringArray"" title=""pandas.arrays.StringArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">StringArray</span></code></a>.</p>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">StringArray</span></code> is currently considered experimental. The implementation
and parts of the API may change without warning.</p>
</div>
<p>For backwards-compatibility, <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> dtype remains the default type we
infer a list of strings to</p>

<p>To explicitly request <code class=""docutils literal notranslate""><span class=""pre"">string</span></code> dtype, specify the <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code></p>

<p>Or <code class=""docutils literal notranslate""><span class=""pre"">astype</span></code> after the <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> is created</p>

<p>You can also use <a class=""reference internal"" href=""../reference/api/pandas.StringDtype.html#pandas.StringDtype"" title=""pandas.StringDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">StringDtype</span></code></a>/<code class=""docutils literal notranslate""><span class=""pre"">""string""</span></code> as the dtype on non-string data and
it will be converted to <code class=""docutils literal notranslate""><span class=""pre"">string</span></code> dtype:</p>

<p>or convert from existing pandas data:</p>

<section id=""behavior-differences"">
<span id=""text-differences""></span><h3>Behavior differences<a class=""headerlink"" href=""#behavior-differences"" title=""Link to this heading"">#</a></h3>
<p>These are places where the behavior of <code class=""docutils literal notranslate""><span class=""pre"">StringDtype</span></code> objects differ from
<code class=""docutils literal notranslate""><span class=""pre"">object</span></code> dtype</p>
<ol class=""loweralpha"" start=""12"">
<li><p>For <code class=""docutils literal notranslate""><span class=""pre"">StringDtype</span></code>, <a class=""reference internal"" href=""../reference/series.html#api-series-str""><span class=""std std-ref"">string accessor methods</span></a>
that return <strong>numeric</strong> output will always return a nullable integer dtype,
rather than either int or float dtype, depending on the presence of NA values.
Methods returning <strong>boolean</strong> output will return a nullable boolean dtype.</p>

<p>Both outputs are <code class=""docutils literal notranslate""><span class=""pre"">Int64</span></code> dtype. Compare that with object-dtype</p>

<p>When NA values are present, the output dtype is float64. Similarly for
methods returning boolean values.</p>

</li>
</ol>
<ol class=""arabic simple"" start=""2"">
<li><p>Some string methods, like <a class=""reference internal"" href=""../reference/api/pandas.Series.str.decode.html#pandas.Series.str.decode"" title=""pandas.Series.str.decode""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.str.decode()</span></code></a> are not available
on <code class=""docutils literal notranslate""><span class=""pre"">StringArray</span></code> because <code class=""docutils literal notranslate""><span class=""pre"">StringArray</span></code> only holds strings, not
bytes.</p></li>
<li><p>In comparison operations, <a class=""reference internal"" href=""../reference/api/pandas.arrays.StringArray.html#pandas.arrays.StringArray"" title=""pandas.arrays.StringArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">arrays.StringArray</span></code></a> and <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> backed
by a <code class=""docutils literal notranslate""><span class=""pre"">StringArray</span></code> will return an object with <a class=""reference internal"" href=""../reference/api/pandas.BooleanDtype.html#pandas.BooleanDtype"" title=""pandas.BooleanDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">BooleanDtype</span></code></a>,
rather than a <code class=""docutils literal notranslate""><span class=""pre"">bool</span></code> dtype object. Missing values in a <code class=""docutils literal notranslate""><span class=""pre"">StringArray</span></code>
will propagate in comparison operations, rather than always comparing
unequal like <code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">numpy.nan</span></code>.</p></li>
</ol>
<p>Everything else that follows in the rest of this document applies equally to
<code class=""docutils literal notranslate""><span class=""pre"">string</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> dtype.</p>
</section>
</section>
<section id=""string-methods"">
<span id=""text-string-methods""></span><h2>String methods<a class=""headerlink"" href=""#string-methods"" title=""Link to this heading"">#</a></h2>
<p>Series and Index are equipped with a set of string processing methods
that make it easy to operate on each element of the array. Perhaps most
importantly, these methods exclude missing/NA values automatically. These are
accessed via the <code class=""docutils literal notranslate""><span class=""pre"">str</span></code> attribute and generally have names matching
the equivalent (scalar) built-in string methods:</p>


<p>The string methods on Index are especially useful for cleaning up or
transforming DataFrame columns. For instance, you may have columns with
leading or trailing whitespace:</p>

<p>Since <code class=""docutils literal notranslate""><span class=""pre"">df.columns</span></code> is an Index object, we can use the <code class=""docutils literal notranslate""><span class=""pre"">.str</span></code> accessor</p>

<p>These string methods can then be used to clean up the columns as needed.
Here we are removing leading and trailing whitespaces, lower casing all names,
and replacing any remaining whitespaces with underscores:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>If you have a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> where lots of elements are repeated
(i.e. the number of unique elements in the <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> is a lot smaller than the length of the
<code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>), it can be faster to convert the original <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> to one of type
<code class=""docutils literal notranslate""><span class=""pre"">category</span></code> and then use <code class=""docutils literal notranslate""><span class=""pre"">.str.&lt;method&gt;</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">.dt.&lt;property&gt;</span></code> on that.
The performance difference comes from the fact that, for <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> of type <code class=""docutils literal notranslate""><span class=""pre"">category</span></code>, the
string operations are done on the <code class=""docutils literal notranslate""><span class=""pre"">.categories</span></code> and not on each element of the
<code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>.</p>
<p>Please note that a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> of type <code class=""docutils literal notranslate""><span class=""pre"">category</span></code> with string <code class=""docutils literal notranslate""><span class=""pre"">.categories</span></code> has
some limitations in comparison to <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> of type string (e.g. you can’t add strings to
each other: <code class=""docutils literal notranslate""><span class=""pre"">s</span> <span class=""pre"">+</span> <span class=""pre"">""</span> <span class=""pre"">""</span> <span class=""pre"">+</span> <span class=""pre"">s</span></code> won’t work if <code class=""docutils literal notranslate""><span class=""pre"">s</span></code> is a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> of type <code class=""docutils literal notranslate""><span class=""pre"">category</span></code>). Also,
<code class=""docutils literal notranslate""><span class=""pre"">.str</span></code> methods which operate on elements of type <code class=""docutils literal notranslate""><span class=""pre"">list</span></code> are not available on such a
<code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>.</p>
</div>
<div class=""admonition warning"" id=""text-warn-types"">
<p class=""admonition-title"">Warning</p>
<p>The type of the Series is inferred and the allowed types (i.e. strings).</p>
<p>Generally speaking, the <code class=""docutils literal notranslate""><span class=""pre"">.str</span></code> accessor is intended to work only on strings. With very few
exceptions, other uses are not supported, and may be disabled at a later point.</p>
</div>
</section>
<section id=""splitting-and-replacing-strings"">
<span id=""text-split""></span><h2>Splitting and replacing strings<a class=""headerlink"" href=""#splitting-and-replacing-strings"" title=""Link to this heading"">#</a></h2>
<p>Methods like <code class=""docutils literal notranslate""><span class=""pre"">split</span></code> return a Series of lists:</p>

<p>Elements in the split lists can be accessed using <code class=""docutils literal notranslate""><span class=""pre"">get</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">[]</span></code> notation:</p>

<p>It is easy to expand this to return a DataFrame using <code class=""docutils literal notranslate""><span class=""pre"">expand</span></code>.</p>

<p>When original <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> has <a class=""reference internal"" href=""../reference/api/pandas.StringDtype.html#pandas.StringDtype"" title=""pandas.StringDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">StringDtype</span></code></a>, the output columns will all
be <a class=""reference internal"" href=""../reference/api/pandas.StringDtype.html#pandas.StringDtype"" title=""pandas.StringDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">StringDtype</span></code></a> as well.</p>
<p>It is also possible to limit the number of splits:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">rsplit</span></code> is similar to <code class=""docutils literal notranslate""><span class=""pre"">split</span></code> except it works in the reverse direction,
i.e., from the end of the string to the beginning of the string:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">replace</span></code> optionally uses <a class=""reference external"" href=""https://docs.python.org/3/library/re.html"">regular expressions</a>:</p>

<div class=""versionchanged"">
<p><span class=""versionmodified changed"">Changed in version 2.0.</span></p>
</div>
<p>Single character pattern with <code class=""docutils literal notranslate""><span class=""pre"">regex=True</span></code> will also be treated as regular expressions:</p>

<p>If you want literal replacement of a string (equivalent to <a class=""reference external"" href=""https://docs.python.org/3/library/stdtypes.html#str.replace"" title=""(in Python v3.12)""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">str.replace()</span></code></a>), you
can set the optional <code class=""docutils literal notranslate""><span class=""pre"">regex</span></code> parameter to <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>, rather than escaping each
character. In this case both <code class=""docutils literal notranslate""><span class=""pre"">pat</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">repl</span></code> must be strings:</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">replace</span></code> method can also take a callable as replacement. It is called
on every <code class=""docutils literal notranslate""><span class=""pre"">pat</span></code> using <a class=""reference external"" href=""https://docs.python.org/3/library/re.html#re.sub"" title=""(in Python v3.12)""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">re.sub()</span></code></a>. The callable should expect one
positional argument (a regex object) and return a string.</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">replace</span></code> method also accepts a compiled regular expression object
from <a class=""reference external"" href=""https://docs.python.org/3/library/re.html#re.compile"" title=""(in Python v3.12)""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">re.compile()</span></code></a> as a pattern. All flags should be included in the
compiled regular expression object.</p>

<p>Including a <code class=""docutils literal notranslate""><span class=""pre"">flags</span></code> argument when calling <code class=""docutils literal notranslate""><span class=""pre"">replace</span></code> with a compiled
regular expression object will raise a <code class=""docutils literal notranslate""><span class=""pre"">ValueError</span></code>.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">removeprefix</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">removesuffix</span></code> have the same effect as <code class=""docutils literal notranslate""><span class=""pre"">str.removeprefix</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">str.removesuffix</span></code> added in Python 3.9
&lt;<a class=""reference external"" href=""https://docs.python.org/3/library/stdtypes.html#str.removeprefix"">https://docs.python.org/3/library/stdtypes.html#str.removeprefix</a>&gt;`__:</p>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.4.0.</span></p>
</div>

</section>
<section id=""concatenation"">
<span id=""text-concatenate""></span><h2>Concatenation<a class=""headerlink"" href=""#concatenation"" title=""Link to this heading"">#</a></h2>
<p>There are several ways to concatenate a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code>, either with itself or others, all based on <a class=""reference internal"" href=""../reference/api/pandas.Series.str.cat.html#pandas.Series.str.cat"" title=""pandas.Series.str.cat""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">cat()</span></code></a>,
resp. <code class=""docutils literal notranslate""><span class=""pre"">Index.str.cat</span></code>.</p>
<section id=""concatenating-a-single-series-into-a-string"">
<h3>Concatenating a single Series into a string<a class=""headerlink"" href=""#concatenating-a-single-series-into-a-string"" title=""Link to this heading"">#</a></h3>
<p>The content of a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> (or <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code>) can be concatenated:</p>

<p>If not specified, the keyword <code class=""docutils literal notranslate""><span class=""pre"">sep</span></code> for the separator defaults to the empty string, <code class=""docutils literal notranslate""><span class=""pre"">sep=''</span></code>:</p>

<p>By default, missing values are ignored. Using <code class=""docutils literal notranslate""><span class=""pre"">na_rep</span></code>, they can be given a representation:</p>

</section>
<section id=""concatenating-a-series-and-something-list-like-into-a-series"">
<h3>Concatenating a Series and something list-like into a Series<a class=""headerlink"" href=""#concatenating-a-series-and-something-list-like-into-a-series"" title=""Link to this heading"">#</a></h3>
<p>The first argument to <a class=""reference internal"" href=""../reference/api/pandas.Series.str.cat.html#pandas.Series.str.cat"" title=""pandas.Series.str.cat""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">cat()</span></code></a> can be a list-like object, provided that it matches the length of the calling <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> (or <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code>).</p>

<p>Missing values on either side will result in missing values in the result as well, <em>unless</em> <code class=""docutils literal notranslate""><span class=""pre"">na_rep</span></code> is specified:</p>

</section>
<section id=""concatenating-a-series-and-something-array-like-into-a-series"">
<h3>Concatenating a Series and something array-like into a Series<a class=""headerlink"" href=""#concatenating-a-series-and-something-array-like-into-a-series"" title=""Link to this heading"">#</a></h3>
<p>The parameter <code class=""docutils literal notranslate""><span class=""pre"">others</span></code> can also be two-dimensional. In this case, the number or rows must match the lengths of the calling <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> (or <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code>).</p>

</section>
<section id=""concatenating-a-series-and-an-indexed-object-into-a-series-with-alignment"">
<h3>Concatenating a Series and an indexed object into a Series, with alignment<a class=""headerlink"" href=""#concatenating-a-series-and-an-indexed-object-into-a-series-with-alignment"" title=""Link to this heading"">#</a></h3>
<p>For concatenation with a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>, it is possible to align the indexes before concatenation by setting
the <code class=""docutils literal notranslate""><span class=""pre"">join</span></code>-keyword.</p>

<p>The usual options are available for <code class=""docutils literal notranslate""><span class=""pre"">join</span></code> (one of <code class=""docutils literal notranslate""><span class=""pre"">'left',</span> <span class=""pre"">'outer',</span> <span class=""pre"">'inner',</span> <span class=""pre"">'right'</span></code>).
In particular, alignment also means that the different lengths do not need to coincide anymore.</p>

<p>The same alignment can be used when <code class=""docutils literal notranslate""><span class=""pre"">others</span></code> is a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>:</p>

</section>
<section id=""concatenating-a-series-and-many-objects-into-a-series"">
<h3>Concatenating a Series and many objects into a Series<a class=""headerlink"" href=""#concatenating-a-series-and-many-objects-into-a-series"" title=""Link to this heading"">#</a></h3>
<p>Several array-like items (specifically: <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code>, and 1-dimensional variants of <code class=""docutils literal notranslate""><span class=""pre"">np.ndarray</span></code>)
can be combined in a list-like container (including iterators, <code class=""docutils literal notranslate""><span class=""pre"">dict</span></code>-views, etc.).</p>

<p>All elements without an index (e.g. <code class=""docutils literal notranslate""><span class=""pre"">np.ndarray</span></code>) within the passed list-like must match in length to the calling <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> (or <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code>),
but <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> may have arbitrary length (as long as alignment is not disabled with <code class=""docutils literal notranslate""><span class=""pre"">join=None</span></code>):</p>

<p>If using <code class=""docutils literal notranslate""><span class=""pre"">join='right'</span></code> on a list-like of <code class=""docutils literal notranslate""><span class=""pre"">others</span></code> that contains different indexes,
the union of these indexes will be used as the basis for the final concatenation:</p>

</section>
</section>
<section id=""indexing-with-str"">
<h2>Indexing with <code class=""docutils literal notranslate""><span class=""pre"">.str</span></code><a class=""headerlink"" href=""#indexing-with-str"" title=""Link to this heading"">#</a></h2>
<p id=""text-indexing"">You can use <code class=""docutils literal notranslate""><span class=""pre"">[]</span></code> notation to directly index by position locations. If you index past the end
of the string, the result will be a <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>.</p>

</section>
<section id=""extracting-substrings"">
<h2>Extracting substrings<a class=""headerlink"" href=""#extracting-substrings"" title=""Link to this heading"">#</a></h2>
<section id=""extract-first-match-in-each-subject-extract"">
<span id=""text-extract""></span><h3>Extract first match in each subject (extract)<a class=""headerlink"" href=""#extract-first-match-in-each-subject-extract"" title=""Link to this heading"">#</a></h3>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">extract</span></code> method accepts a <a class=""reference external"" href=""https://docs.python.org/3/library/re.html"">regular expression</a> with at least one
capture group.</p>
<p>Extracting a regular expression with more than one group returns a
DataFrame with one column per group.</p>

<p>Elements that do not match return a row filled with <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>. Thus, a
Series of messy strings can be “converted” into a like-indexed Series
or DataFrame of cleaned-up or more useful strings, without
necessitating <code class=""docutils literal notranslate""><span class=""pre"">get()</span></code> to access tuples or <code class=""docutils literal notranslate""><span class=""pre"">re.match</span></code> objects. The
dtype of the result is always object, even if no match is found and
the result only contains <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>.</p>
<p>Named groups like</p>

<p>and optional groups like</p>

<p>can also be used. Note that any capture group names in the regular
expression will be used for column names; otherwise capture group
numbers will be used.</p>
<p>Extracting a regular expression with one group returns a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>
with one column if <code class=""docutils literal notranslate""><span class=""pre"">expand=True</span></code>.</p>

<p>It returns a Series if <code class=""docutils literal notranslate""><span class=""pre"">expand=False</span></code>.</p>

<p>Calling on an <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> with a regex with exactly one capture group
returns a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> with one column if <code class=""docutils literal notranslate""><span class=""pre"">expand=True</span></code>.</p>

<p>It returns an <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> if <code class=""docutils literal notranslate""><span class=""pre"">expand=False</span></code>.</p>

<p>Calling on an <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> with a regex with more than one capture group
returns a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> if <code class=""docutils literal notranslate""><span class=""pre"">expand=True</span></code>.</p>

<p>It raises <code class=""docutils literal notranslate""><span class=""pre"">ValueError</span></code> if <code class=""docutils literal notranslate""><span class=""pre"">expand=False</span></code>.</p>

<p>The table below summarizes the behavior of <code class=""docutils literal notranslate""><span class=""pre"">extract(expand=False)</span></code>
(input subject in first column, number of groups in regex in
first row)</p>

</section>
<section id=""extract-all-matches-in-each-subject-extractall"">
<h3>Extract all matches in each subject (extractall)<a class=""headerlink"" href=""#extract-all-matches-in-each-subject-extractall"" title=""Link to this heading"">#</a></h3>
<p id=""text-extractall"">Unlike <code class=""docutils literal notranslate""><span class=""pre"">extract</span></code> (which returns only the first match),</p>

<p>the <code class=""docutils literal notranslate""><span class=""pre"">extractall</span></code> method returns every match. The result of
<code class=""docutils literal notranslate""><span class=""pre"">extractall</span></code> is always a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> with a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> on its
rows. The last level of the <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> is named <code class=""docutils literal notranslate""><span class=""pre"">match</span></code> and
indicates the order in the subject.</p>

<p>When each subject string in the Series has exactly one match,</p>

<p>then <code class=""docutils literal notranslate""><span class=""pre"">extractall(pat).xs(0,</span> <span class=""pre"">level='match')</span></code> gives the same result as
<code class=""docutils literal notranslate""><span class=""pre"">extract(pat)</span></code>.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> also supports <code class=""docutils literal notranslate""><span class=""pre"">.str.extractall</span></code>. It returns a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> which has the
same result as a <code class=""docutils literal notranslate""><span class=""pre"">Series.str.extractall</span></code> with a default index (starts from 0).</p>

</section>
</section>
<section id=""testing-for-strings-that-match-or-contain-a-pattern"">
<h2>Testing for strings that match or contain a pattern<a class=""headerlink"" href=""#testing-for-strings-that-match-or-contain-a-pattern"" title=""Link to this heading"">#</a></h2>
<p>You can check whether elements contain a pattern:</p>

<p>Or whether elements match a pattern:</p>


<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The distinction between <code class=""docutils literal notranslate""><span class=""pre"">match</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">fullmatch</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">contains</span></code> is strictness:
<code class=""docutils literal notranslate""><span class=""pre"">fullmatch</span></code> tests whether the entire string matches the regular expression;
<code class=""docutils literal notranslate""><span class=""pre"">match</span></code> tests whether there is a match of the regular expression that begins
at the first character of the string; and <code class=""docutils literal notranslate""><span class=""pre"">contains</span></code> tests whether there is
a match of the regular expression at any position within the string.</p>
<p>The corresponding functions in the <code class=""docutils literal notranslate""><span class=""pre"">re</span></code> package for these three match modes are
<a class=""reference external"" href=""https://docs.python.org/3/library/re.html#re.fullmatch"">re.fullmatch</a>,
<a class=""reference external"" href=""https://docs.python.org/3/library/re.html#re.match"">re.match</a>, and
<a class=""reference external"" href=""https://docs.python.org/3/library/re.html#re.search"">re.search</a>,
respectively.</p>
</div>
<p>Methods like <code class=""docutils literal notranslate""><span class=""pre"">match</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">fullmatch</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">contains</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">startswith</span></code>, and
<code class=""docutils literal notranslate""><span class=""pre"">endswith</span></code> take an extra <code class=""docutils literal notranslate""><span class=""pre"">na</span></code> argument so missing values can be considered
True or False:</p>

</section>
<section id=""creating-indicator-variables"">
<span id=""text-indicator""></span><h2>Creating indicator variables<a class=""headerlink"" href=""#creating-indicator-variables"" title=""Link to this heading"">#</a></h2>
<p>You can extract dummy variables from string columns.
For example if they are separated by a <code class=""docutils literal notranslate""><span class=""pre"">'|'</span></code>:</p>

<p>String <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> also supports <code class=""docutils literal notranslate""><span class=""pre"">get_dummies</span></code> which returns a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code>.</p>

<p>See also <a class=""reference internal"" href=""../reference/api/pandas.get_dummies.html#pandas.get_dummies"" title=""pandas.get_dummies""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">get_dummies()</span></code></a>.</p>
</section>
<section id=""method-summary"">
<h2>Method summary<a class=""headerlink"" href=""#method-summary"" title=""Link to this heading"">#</a></h2>

</section>
</section>
</article>","Working with text data # Text data types # There are two ways to store text data in pandas: object -dtype NumPy array. StringDtype extension type. We recommend using StringDtype to store text data. Prior to pandas 1.0, object dtype was the only option. This was unfortunate for many reasons: You can accidentally store a mixture of strings and non-strings in an object dtype array. It’s better to have a dedicated dtype. object dtype breaks dtype-specific operations like DataFrame.select_dtypes() . There isn’t a clear way to select just text while excluding non-text but still object-dtype columns. When reading code, the contents of an object dtype array is less clear than 'string' . Currently, the performance of object dtype arrays of strings and arrays.StringArray are about the same. We expect future enhancements to significantly increase the performance and lower the memory overhead of StringArray . Warning StringArray is currently considered experimental. The implementation and parts of the API may change without warning. For backwards-compatibility, object dtype remains the default type we infer a list of strings to To explicitly request string dtype, specify the dtype Or astype after the Series or DataFrame is created You can also use StringDtype / ""string"" as the dtype on non-string data and it will be converted to string dtype: or convert from existing pandas data: Behavior differences # These are places where the behavior of StringDtype objects differ from object dtype For StringDtype , string accessor methods that return numeric output will always return a nullable integer dtype, rather than either int or float dtype, depending on the presence of NA values. Methods returning boolean output will return a nullable boolean dtype. Both outputs are Int64 dtype. Compare that with object-dtype When NA values are present, the output dtype is float64. Similarly for methods returning boolean values. Some string methods, like Series.str.decode() are not available on StringArray because StringArray only holds strings, not bytes. In comparison operations, arrays.StringArray and Series backed by a StringArray will return an object with BooleanDtype , rather than a bool dtype object. Missing values in a StringArray will propagate in comparison operations, rather than always comparing unequal like numpy.nan . Everything else that follows in the rest of this document applies equally to string and object dtype. String methods # Series and Index are equipped with a set of string processing methods that make it easy to operate on each element of the array. Perhaps most importantly, these methods exclude missing/NA values automatically. These are accessed via the str attribute and generally have names matching the equivalent (scalar) built-in string methods: The string methods on Index are especially useful for cleaning up or transforming DataFrame columns. For instance, you may have columns with leading or trailing whitespace: Since df.columns is an Index object, we can use the .str accessor These string methods can then be used to clean up the columns as needed. Here we are removing leading and trailing whitespaces, lower casing all names, and replacing any remaining whitespaces with underscores: Note If you have a Series where lots of elements are repeated (i.e. the number of unique elements in the Series is a lot smaller than the length of the Series ), it can be faster to convert the original Series to one of type category and then use .str.<method> or .dt.<property> on that. The performance difference comes from the fact that, for Series of type category , the string operations are done on the .categories and not on each element of the Series . Please note that a Series of type category with string .categories has some limitations in comparison to Series of type string (e.g. you can’t add strings to each other: s + "" "" + s won’t work if s is a Series of type category ). Also, .str methods which operate on elements of type list are not available on such a Series . Warning The type of the Series is inferred and the allowed types (i.e. strings). Generally speaking, the .str accessor is intended to work only on strings. With very few exceptions, other uses are not supported, and may be disabled at a later point. Splitting and replacing strings # Methods like split return a Series of lists: Elements in the split lists can be accessed using get or [] notation: It is easy to expand this to return a DataFrame using expand . When original Series has StringDtype , the output columns will all be StringDtype as well. It is also possible to limit the number of splits: rsplit is similar to split except it works in the reverse direction, i.e., from the end of the string to the beginning of the string: replace optionally uses regular expressions : Changed in version 2.0. Single character pattern with regex=True will also be treated as regular expressions: If you want literal replacement of a string (equivalent to str.replace() ), you can set the optional regex parameter to False , rather than escaping each character. In this case both pat and repl must be strings: The replace method can also take a callable as replacement. It is called on every pat using re.sub() . The callable should expect one positional argument (a regex object) and return a string. The replace method also accepts a compiled regular expression object from re.compile() as a pattern. All flags should be included in the compiled regular expression object. Including a flags argument when calling replace with a compiled regular expression object will raise a ValueError . removeprefix and removesuffix have the same effect as str.removeprefix and str.removesuffix added in Python 3.9 < https://docs.python.org/3/library/stdtypes.html#str.removeprefix >`__: New in version 1.4.0. Concatenation # There are several ways to concatenate a Series or Index , either with itself or others, all based on cat() , resp. Index.str.cat . Concatenating a single Series into a string # The content of a Series (or Index ) can be concatenated: If not specified, the keyword sep for the separator defaults to the empty string, sep='' : By default, missing values are ignored. Using na_rep , they can be given a representation: Concatenating a Series and something list-like into a Series # The first argument to cat() can be a list-like object, provided that it matches the length of the calling Series (or Index ). Missing values on either side will result in missing values in the result as well, unless na_rep is specified: Concatenating a Series and something array-like into a Series # The parameter others can also be two-dimensional. In this case, the number or rows must match the lengths of the calling Series (or Index ). Concatenating a Series and an indexed object into a Series, with alignment # For concatenation with a Series or DataFrame , it is possible to align the indexes before concatenation by setting the join -keyword. The usual options are available for join (one of 'left', 'outer', 'inner', 'right' ). In particular, alignment also means that the different lengths do not need to coincide anymore. The same alignment can be used when others is a DataFrame : Concatenating a Series and many objects into a Series # Several array-like items (specifically: Series , Index , and 1-dimensional variants of np.ndarray ) can be combined in a list-like container (including iterators, dict -views, etc.). All elements without an index (e.g. np.ndarray ) within the passed list-like must match in length to the calling Series (or Index ), but Series and Index may have arbitrary length (as long as alignment is not disabled with join=None ): If using join='right' on a list-like of others that contains different indexes, the union of these indexes will be used as the basis for the final concatenation: Indexing with .str # You can use [] notation to directly index by position locations. If you index past the end of the string, the result will be a NaN . Extracting substrings # Extract first match in each subject (extract) # The extract method accepts a regular expression with at least one capture group. Extracting a regular expression with more than one group returns a DataFrame with one column per group. Elements that do not match return a row filled with NaN . Thus, a Series of messy strings can be “converted” into a like-indexed Series or DataFrame of cleaned-up or more useful strings, without necessitating get() to access tuples or re.match objects. The dtype of the result is always object, even if no match is found and the result only contains NaN . Named groups like and optional groups like can also be used. Note that any capture group names in the regular expression will be used for column names; otherwise capture group numbers will be used. Extracting a regular expression with one group returns a DataFrame with one column if expand=True . It returns a Series if expand=False . Calling on an Index with a regex with exactly one capture group returns a DataFrame with one column if expand=True . It returns an Index if expand=False . Calling on an Index with a regex with more than one capture group returns a DataFrame if expand=True . It raises ValueError if expand=False . The table below summarizes the behavior of extract(expand=False) (input subject in first column, number of groups in regex in first row) Extract all matches in each subject (extractall) # Unlike extract (which returns only the first match), the extractall method returns every match. The result of extractall is always a DataFrame with a MultiIndex on its rows. The last level of the MultiIndex is named match and indicates the order in the subject. When each subject string in the Series has exactly one match, then extractall(pat).xs(0, level='match') gives the same result as extract(pat) . Index also supports .str.extractall . It returns a DataFrame which has the same result as a Series.str.extractall with a default index (starts from 0). Testing for strings that match or contain a pattern # You can check whether elements contain a pattern: Or whether elements match a pattern: Note The distinction between match , fullmatch , and contains is strictness: fullmatch tests whether the entire string matches the regular expression; match tests whether there is a match of the regular expression that begins at the first character of the string; and contains tests whether there is a match of the regular expression at any position within the string. The corresponding functions in the re package for these three match modes are re.fullmatch , re.match , and re.search , respectively. Methods like match , fullmatch , contains , startswith , and endswith take an extra na argument so missing values can be considered True or False: Creating indicator variables # You can extract dummy variables from string columns. For example if they are separated by a '|' : String Index also supports get_dummies which returns a MultiIndex . See also get_dummies() . Method summary #"
https://pandas.pydata.org/docs/user_guide/missing_data.html,Working with missing data,"<article class=""bd-article"" role=""main"">
<section id=""working-with-missing-data"">
<span id=""missing-data""></span><h1>Working with missing data<a class=""headerlink"" href=""#working-with-missing-data"" title=""Link to this heading"">#</a></h1>
<section id=""values-considered-missing"">
<h2>Values considered “missing”<a class=""headerlink"" href=""#values-considered-missing"" title=""Link to this heading"">#</a></h2>
<p>pandas uses different sentinel values to represent a missing (also referred to as NA)
depending on the data type.</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">numpy.nan</span></code> for NumPy data types. The disadvantage of using NumPy data types
is that the original data type will be coerced to <code class=""docutils literal notranslate""><span class=""pre"">np.float64</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">object</span></code>.</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.NaT.html#pandas.NaT"" title=""pandas.NaT""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NaT</span></code></a> for NumPy <code class=""docutils literal notranslate""><span class=""pre"">np.datetime64</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">np.timedelta64</span></code>, and <a class=""reference internal"" href=""../reference/api/pandas.PeriodDtype.html#pandas.PeriodDtype"" title=""pandas.PeriodDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">PeriodDtype</span></code></a>. For typing applications,
use <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">api.types.NaTType</span></code>.</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a> for <a class=""reference internal"" href=""../reference/api/pandas.StringDtype.html#pandas.StringDtype"" title=""pandas.StringDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">StringDtype</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.Int64Dtype.html#pandas.Int64Dtype"" title=""pandas.Int64Dtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Int64Dtype</span></code></a> (and other bit widths),
<code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Float64Dtype`(and</span> <span class=""pre"">other</span> <span class=""pre"">bit</span> <span class=""pre"">widths),</span> <span class=""pre"">:class:`BooleanDtype</span></code> and <a class=""reference internal"" href=""../reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"" title=""pandas.ArrowDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">ArrowDtype</span></code></a>.
These types will maintain the original data type of the data.
For typing applications, use <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">api.types.NAType</span></code>.</p>

<p>To detect these missing value, use the <a class=""reference internal"" href=""../reference/api/pandas.isna.html#pandas.isna"" title=""pandas.isna""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">isna()</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.notna.html#pandas.notna"" title=""pandas.notna""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">notna()</span></code></a> methods.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p><a class=""reference internal"" href=""../reference/api/pandas.isna.html#pandas.isna"" title=""pandas.isna""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">isna()</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.notna.html#pandas.notna"" title=""pandas.notna""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">notna()</span></code></a> will also consider <code class=""docutils literal notranslate""><span class=""pre"">None</span></code> a missing value.</p>

</div>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Equality compaisons between <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code>, <a class=""reference internal"" href=""../reference/api/pandas.NaT.html#pandas.NaT"" title=""pandas.NaT""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NaT</span></code></a>, and <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a>
do not act like <code class=""docutils literal notranslate""><span class=""pre"">None</span></code></p>

<p>Therefore, an equality comparison between a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>
with one of these missing values does not provide the same information as
<a class=""reference internal"" href=""../reference/api/pandas.isna.html#pandas.isna"" title=""pandas.isna""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">isna()</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.notna.html#pandas.notna"" title=""pandas.notna""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">notna()</span></code></a>.</p>

</div>
</section>
<section id=""na-semantics"">
<span id=""missing-data-na""></span><h2><a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a> semantics<a class=""headerlink"" href=""#na-semantics"" title=""Link to this heading"">#</a></h2>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Experimental: the behaviour of <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA`</span></code> can still change without warning.</p>
</div>
<p>Starting from pandas 1.0, an experimental <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a> value (singleton) is
available to represent scalar missing values. The goal of <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a> is provide a
“missing” indicator that can be used consistently across data types
(instead of <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">None</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">pd.NaT</span></code> depending on the data type).</p>
<p>For example, when having missing values in a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> with the nullable integer
dtype, it will use <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a>:</p>

<p>Currently, pandas does not yet use those data types using <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a> by default
a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>, so you need to specify
the dtype explicitly. An easy way to convert to those dtypes is explained in the
<a class=""reference internal"" href=""#missing-data-na-conversion""><span class=""std std-ref"">conversion section</span></a>.</p>
<section id=""propagation-in-arithmetic-and-comparison-operations"">
<h3>Propagation in arithmetic and comparison operations<a class=""headerlink"" href=""#propagation-in-arithmetic-and-comparison-operations"" title=""Link to this heading"">#</a></h3>
<p>In general, missing values <em>propagate</em> in operations involving <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a>. When
one of the operands is unknown, the outcome of the operation is also unknown.</p>
<p>For example, <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a> propagates in arithmetic operations, similarly to
<code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code>:</p>

<p>There are a few special cases when the result is known, even when one of the
operands is <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code>.</p>

<p>In equality and comparison operations, <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a> also propagates. This deviates
from the behaviour of <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code>, where comparisons with <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code> always
return <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>.</p>

<p>To check if a value is equal to <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a>, use <a class=""reference internal"" href=""../reference/api/pandas.isna.html#pandas.isna"" title=""pandas.isna""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">isna()</span></code></a></p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>An exception on this basic propagation rule are <em>reductions</em> (such as the
mean or the minimum), where pandas defaults to skipping missing values. See the
<a class=""reference internal"" href=""#missing-data-calculations""><span class=""std std-ref"">calculation section</span></a> for more.</p>
</div>
</section>
<section id=""logical-operations"">
<h3>Logical operations<a class=""headerlink"" href=""#logical-operations"" title=""Link to this heading"">#</a></h3>
<p>For logical operations, <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a> follows the rules of the
<a class=""reference external"" href=""https://en.wikipedia.org/wiki/Three-valued_logic"">three-valued logic</a> (or
<em>Kleene logic</em>, similarly to R, SQL and Julia). This logic means to only
propagate missing values when it is logically required.</p>
<p>For example, for the logical “or” operation (<code class=""docutils literal notranslate""><span class=""pre"">|</span></code>), if one of the operands
is <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>, we already know the result will be <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>, regardless of the
other value (so regardless the missing value would be <code class=""docutils literal notranslate""><span class=""pre"">True</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>).
In this case, <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a> does not propagate:</p>

<p>On the other hand, if one of the operands is <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>, the result depends
on the value of the other operand. Therefore, in this case <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a>
propagates:</p>

<p>The behaviour of the logical “and” operation (<code class=""docutils literal notranslate""><span class=""pre"">&amp;</span></code>) can be derived using
similar logic (where now <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a> will not propagate if one of the operands
is already <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>):</p>


</section>
<section id=""na-in-a-boolean-context"">
<h3><code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> in a boolean context<a class=""headerlink"" href=""#na-in-a-boolean-context"" title=""Link to this heading"">#</a></h3>
<p>Since the actual value of an NA is unknown, it is ambiguous to convert NA
to a boolean value.</p>

<p>This also means that <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a> cannot be used in a context where it is
evaluated to a boolean, such as <code class=""docutils literal notranslate""><span class=""pre"">if</span> <span class=""pre"">condition:</span> <span class=""pre"">...</span></code> where <code class=""docutils literal notranslate""><span class=""pre"">condition</span></code> can
potentially be <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a>. In such cases, <a class=""reference internal"" href=""../reference/api/pandas.isna.html#pandas.isna"" title=""pandas.isna""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">isna()</span></code></a> can be used to check
for <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a> or <code class=""docutils literal notranslate""><span class=""pre"">condition</span></code> being <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a> can be avoided, for example by
filling missing values beforehand.</p>
<p>A similar situation occurs when using <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> objects in <code class=""docutils literal notranslate""><span class=""pre"">if</span></code>
statements, see <a class=""reference internal"" href=""gotchas.html#gotchas-truth""><span class=""std std-ref"">Using if/truth statements with pandas</span></a>.</p>
</section>
<section id=""numpy-ufuncs"">
<h3>NumPy ufuncs<a class=""headerlink"" href=""#numpy-ufuncs"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">pandas.NA</span></code></a> implements NumPy’s <code class=""docutils literal notranslate""><span class=""pre"">__array_ufunc__</span></code> protocol. Most ufuncs
work with <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code>, and generally return <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code>:</p>

<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Currently, ufuncs involving an ndarray and <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> will return an
object-dtype filled with NA values.</p>

<p>The return type here may change to return a different array type
in the future.</p>
</div>
<p>See <a class=""reference internal"" href=""dsintro.html#dsintro-numpy-interop""><span class=""std std-ref"">DataFrame interoperability with NumPy functions</span></a> for more on ufuncs.</p>
<section id=""conversion"">
<span id=""missing-data-na-conversion""></span><h4>Conversion<a class=""headerlink"" href=""#conversion"" title=""Link to this heading"">#</a></h4>
<p>If you have a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> using <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code>,
<a class=""reference internal"" href=""../reference/api/pandas.Series.convert_dtypes.html#pandas.Series.convert_dtypes"" title=""pandas.Series.convert_dtypes""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.convert_dtypes()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.convert_dtypes.html#pandas.DataFrame.convert_dtypes"" title=""pandas.DataFrame.convert_dtypes""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.convert_dtypes()</span></code></a>
in <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> that can convert data to use the data types that use <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a>
such as <a class=""reference internal"" href=""../reference/api/pandas.Int64Dtype.html#pandas.Int64Dtype"" title=""pandas.Int64Dtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Int64Dtype</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"" title=""pandas.ArrowDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">ArrowDtype</span></code></a>. This is especially helpful after reading
in data sets from IO methods where data types were inferred.</p>
<p>In this example, while the dtypes of all columns are changed, we show the results for
the first 10 columns.</p>

</section>
</section>
</section>
<section id=""inserting-missing-data"">
<span id=""missing-inserting""></span><h2>Inserting missing data<a class=""headerlink"" href=""#inserting-missing-data"" title=""Link to this heading"">#</a></h2>
<p>You can insert missing values by simply assigning to a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>.
The missing value sentinel used will be chosen based on the dtype.</p>

<p>For <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> types, pandas will use the value given:</p>

</section>
<section id=""calculations-with-missing-data"">
<span id=""missing-data-calculations""></span><h2>Calculations with missing data<a class=""headerlink"" href=""#calculations-with-missing-data"" title=""Link to this heading"">#</a></h2>
<p>Missing values propagate through arithmetic operations between pandas objects.</p>

<p>The descriptive statistics and computational methods discussed in the
<a class=""reference internal"" href=""basics.html#basics-stats""><span class=""std std-ref"">data structure overview</span></a> (and listed <a class=""reference internal"" href=""../reference/series.html#api-series-stats""><span class=""std std-ref"">here</span></a> and <a class=""reference internal"" href=""../reference/frame.html#api-dataframe-stats""><span class=""std std-ref"">here</span></a>) are all
account for missing data.</p>
<p>When summing data, NA values or empty data will be treated as zero.</p>

<p>When taking the product, NA values or empty data will be treated as 1.</p>

<p>Cumulative methods like <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.cumsum.html#pandas.DataFrame.cumsum"" title=""pandas.DataFrame.cumsum""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">cumsum()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.cumprod.html#pandas.DataFrame.cumprod"" title=""pandas.DataFrame.cumprod""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">cumprod()</span></code></a>
ignore NA values by default preserve them in the result. This behavior can be changed
with <code class=""docutils literal notranslate""><span class=""pre"">skipna</span></code></p>
<ul class=""simple"">
<li><p>Cumulative methods like <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.cumsum.html#pandas.DataFrame.cumsum"" title=""pandas.DataFrame.cumsum""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">cumsum()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.cumprod.html#pandas.DataFrame.cumprod"" title=""pandas.DataFrame.cumprod""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">cumprod()</span></code></a> ignore NA values by default, but preserve them in the resulting arrays. To override this behaviour and include NA values, use <code class=""docutils literal notranslate""><span class=""pre"">skipna=False</span></code>.</p></li>
</ul>

</section>
<section id=""dropping-missing-data"">
<span id=""missing-data-dropna""></span><h2>Dropping missing data<a class=""headerlink"" href=""#dropping-missing-data"" title=""Link to this heading"">#</a></h2>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.dropna.html#pandas.DataFrame.dropna"" title=""pandas.DataFrame.dropna""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">dropna()</span></code></a> dropa rows or columns with missing data.</p>

</section>
<section id=""filling-missing-data"">
<h2>Filling missing data<a class=""headerlink"" href=""#filling-missing-data"" title=""Link to this heading"">#</a></h2>
<section id=""filling-by-value"">
<span id=""missing-data-fillna""></span><h3>Filling by value<a class=""headerlink"" href=""#filling-by-value"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna"" title=""pandas.DataFrame.fillna""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">fillna()</span></code></a> replaces NA values with non-NA data.</p>
<p>Replace NA with a scalar value</p>

<p>Fill gaps forward or backward</p>

<p id=""missing-data-fillna-limit"">Limit the number of NA values filled</p>

<p>NA values can be replaced with corresponding value from a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>
where the index and column aligns between the original object and the filled object.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.where.html#pandas.DataFrame.where"" title=""pandas.DataFrame.where""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.where()</span></code></a> can also be used to fill NA values.Same result as above.</p>

</div>
</section>
<section id=""interpolation"">
<span id=""missing-data-interpolate""></span><h3>Interpolation<a class=""headerlink"" href=""#interpolation"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.interpolate.html#pandas.DataFrame.interpolate"" title=""pandas.DataFrame.interpolate""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.interpolate()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.Series.interpolate.html#pandas.Series.interpolate"" title=""pandas.Series.interpolate""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.interpolate()</span></code></a> fills NA values
using various interpolation methods.</p>

<img alt=""../_images/series_before_interpolate.png"" src=""../_images/series_before_interpolate.png""/>

<img alt=""../_images/series_interpolate.png"" src=""../_images/series_interpolate.png""/>
<p>Interpolation relative to a <a class=""reference internal"" href=""../reference/api/pandas.Timestamp.html#pandas.Timestamp"" title=""pandas.Timestamp""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Timestamp</span></code></a> in the <a class=""reference internal"" href=""../reference/api/pandas.DatetimeIndex.html#pandas.DatetimeIndex"" title=""pandas.DatetimeIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code></a>
is available by setting <code class=""docutils literal notranslate""><span class=""pre"">method=""time""</span></code></p>

<p>For a floating-point index, use <code class=""docutils literal notranslate""><span class=""pre"">method='values'</span></code>:</p>

<p>If you have <a class=""reference external"" href=""https://scipy.org/"">scipy</a> installed, you can pass the name of a 1-d interpolation routine to <code class=""docutils literal notranslate""><span class=""pre"">method</span></code>.
as specified in the scipy interpolation <a class=""reference external"" href=""https://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation"">documentation</a> and reference <a class=""reference external"" href=""https://docs.scipy.org/doc/scipy/tutorial/interpolate.html"">guide</a>.
The appropriate interpolation method will depend on the data type.</p>
<div class=""admonition tip"">
<p class=""admonition-title"">Tip</p>
<p>If you are dealing with a time series that is growing at an increasing rate,
use <code class=""docutils literal notranslate""><span class=""pre"">method='barycentric'</span></code>.</p>
<p>If you have values approximating a cumulative distribution function,
use <code class=""docutils literal notranslate""><span class=""pre"">method='pchip'</span></code>.</p>
<p>To fill missing values with goal of smooth plotting use <code class=""docutils literal notranslate""><span class=""pre"">method='akima'</span></code>.</p>

</div>
<p>When interpolating via a polynomial or spline approximation, you must also specify
the degree or order of the approximation:</p>

<p>Comparing several methods.</p>

<img alt=""../_images/compare_interpolations.png"" src=""../_images/compare_interpolations.png""/>
<p>Interpolating new observations from expanding data with <a class=""reference internal"" href=""../reference/api/pandas.Series.reindex.html#pandas.Series.reindex"" title=""pandas.Series.reindex""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.reindex()</span></code></a>.</p>

<section id=""interpolation-limits"">
<span id=""missing-data-interp-limits""></span><h4>Interpolation limits<a class=""headerlink"" href=""#interpolation-limits"" title=""Link to this heading"">#</a></h4>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.interpolate.html#pandas.DataFrame.interpolate"" title=""pandas.DataFrame.interpolate""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">interpolate()</span></code></a> accepts a <code class=""docutils literal notranslate""><span class=""pre"">limit</span></code> keyword
argument to limit the number of consecutive <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code> values
filled since the last valid observation</p>

<p>By default, <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code> values are filled in a <code class=""docutils literal notranslate""><span class=""pre"">forward</span></code> direction. Use
<code class=""docutils literal notranslate""><span class=""pre"">limit_direction</span></code> parameter to fill <code class=""docutils literal notranslate""><span class=""pre"">backward</span></code> or from <code class=""docutils literal notranslate""><span class=""pre"">both</span></code> directions.</p>

<p>By default, <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code> values are filled whether they are surrounded by
existing valid values or outside existing valid values. The <code class=""docutils literal notranslate""><span class=""pre"">limit_area</span></code>
parameter restricts filling to either inside or outside values.</p>

</section>
</section>
<section id=""replacing-values"">
<span id=""missing-data-replace""></span><h3>Replacing values<a class=""headerlink"" href=""#replacing-values"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.Series.replace.html#pandas.Series.replace"" title=""pandas.Series.replace""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.replace()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.replace.html#pandas.DataFrame.replace"" title=""pandas.DataFrame.replace""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.replace()</span></code></a> can be used similar to
<a class=""reference internal"" href=""../reference/api/pandas.Series.fillna.html#pandas.Series.fillna"" title=""pandas.Series.fillna""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.fillna()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna"" title=""pandas.DataFrame.fillna""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.fillna()</span></code></a> to replace or insert missing values.</p>

<p>Replacing more than one value is possible by passing a list.</p>

<p>Replacing using a mapping dict.</p>

<section id=""regular-expression-replacement"">
<span id=""missing-data-replace-expression""></span><h4>Regular expression replacement<a class=""headerlink"" href=""#regular-expression-replacement"" title=""Link to this heading"">#</a></h4>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Python strings prefixed with the <code class=""docutils literal notranslate""><span class=""pre"">r</span></code> character such as <code class=""docutils literal notranslate""><span class=""pre"">r'hello</span> <span class=""pre"">world'</span></code>
are <a class=""reference external"" href=""https://docs.python.org/3/reference/lexical_analysis.html#string-and-bytes-literals"">“raw” strings</a>.
They have different semantics regarding backslashes than strings without this prefix.
Backslashes in raw strings will be interpreted as an escaped backslash, e.g., <code class=""docutils literal notranslate""><span class=""pre"">r'\'</span> <span class=""pre"">==</span> <span class=""pre"">'\\'</span></code>.</p>
</div>
<p>Replace the ‘.’ with <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code></p>

<p>Replace the ‘.’ with <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code> with regular expression that removes surrounding whitespace</p>

<p>Replace with a list of regexes.</p>

<p>Replace with a regex in a mapping dict.</p>

<p>Pass nested dictionaries of regular expressions that use the <code class=""docutils literal notranslate""><span class=""pre"">regex</span></code> keyword.</p>

<p>Pass a list of regular expressions that will replace matches with a scalar.</p>

<p>All of the regular expression examples can also be passed with the
<code class=""docutils literal notranslate""><span class=""pre"">to_replace</span></code> argument as the <code class=""docutils literal notranslate""><span class=""pre"">regex</span></code> argument. In this case the <code class=""docutils literal notranslate""><span class=""pre"">value</span></code>
argument must be passed explicitly by name or <code class=""docutils literal notranslate""><span class=""pre"">regex</span></code> must be a nested
dictionary.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>A regular expression object from <code class=""docutils literal notranslate""><span class=""pre"">re.compile</span></code> is a valid input as well.</p>
</div>
</section>
</section>
</section>
</section>
</article>","Working with missing data # Values considered “missing” # pandas uses different sentinel values to represent a missing (also referred to as NA) depending on the data type. numpy.nan for NumPy data types. The disadvantage of using NumPy data types is that the original data type will be coerced to np.float64 or object . NaT for NumPy np.datetime64 , np.timedelta64 , and PeriodDtype . For typing applications, use api.types.NaTType . NA for StringDtype , Int64Dtype (and other bit widths), Float64Dtype`(and other bit widths), :class:`BooleanDtype and ArrowDtype . These types will maintain the original data type of the data. For typing applications, use api.types.NAType . To detect these missing value, use the isna() or notna() methods. Note isna() or notna() will also consider None a missing value. Warning Equality compaisons between np.nan , NaT , and NA do not act like None Therefore, an equality comparison between a DataFrame or Series with one of these missing values does not provide the same information as isna() or notna() . NA semantics # Warning Experimental: the behaviour of NA` can still change without warning. Starting from pandas 1.0, an experimental NA value (singleton) is available to represent scalar missing values. The goal of NA is provide a “missing” indicator that can be used consistently across data types (instead of np.nan , None or pd.NaT depending on the data type). For example, when having missing values in a Series with the nullable integer dtype, it will use NA : Currently, pandas does not yet use those data types using NA by default a DataFrame or Series , so you need to specify the dtype explicitly. An easy way to convert to those dtypes is explained in the conversion section . Propagation in arithmetic and comparison operations # In general, missing values propagate in operations involving NA . When one of the operands is unknown, the outcome of the operation is also unknown. For example, NA propagates in arithmetic operations, similarly to np.nan : There are a few special cases when the result is known, even when one of the operands is NA . In equality and comparison operations, NA also propagates. This deviates from the behaviour of np.nan , where comparisons with np.nan always return False . To check if a value is equal to NA , use isna() Note An exception on this basic propagation rule are reductions (such as the mean or the minimum), where pandas defaults to skipping missing values. See the calculation section for more. Logical operations # For logical operations, NA follows the rules of the three-valued logic (or Kleene logic , similarly to R, SQL and Julia). This logic means to only propagate missing values when it is logically required. For example, for the logical “or” operation ( | ), if one of the operands is True , we already know the result will be True , regardless of the other value (so regardless the missing value would be True or False ). In this case, NA does not propagate: On the other hand, if one of the operands is False , the result depends on the value of the other operand. Therefore, in this case NA propagates: The behaviour of the logical “and” operation ( & ) can be derived using similar logic (where now NA will not propagate if one of the operands is already False ): NA in a boolean context # Since the actual value of an NA is unknown, it is ambiguous to convert NA to a boolean value. This also means that NA cannot be used in a context where it is evaluated to a boolean, such as if condition: ... where condition can potentially be NA . In such cases, isna() can be used to check for NA or condition being NA can be avoided, for example by filling missing values beforehand. A similar situation occurs when using Series or DataFrame objects in if statements, see Using if/truth statements with pandas . NumPy ufuncs # pandas.NA implements NumPy’s __array_ufunc__ protocol. Most ufuncs work with NA , and generally return NA : Warning Currently, ufuncs involving an ndarray and NA will return an object-dtype filled with NA values. The return type here may change to return a different array type in the future. See DataFrame interoperability with NumPy functions for more on ufuncs. Conversion # If you have a DataFrame or Series using np.nan , Series.convert_dtypes() and DataFrame.convert_dtypes() in DataFrame that can convert data to use the data types that use NA such as Int64Dtype or ArrowDtype . This is especially helpful after reading in data sets from IO methods where data types were inferred. In this example, while the dtypes of all columns are changed, we show the results for the first 10 columns. Inserting missing data # You can insert missing values by simply assigning to a Series or DataFrame . The missing value sentinel used will be chosen based on the dtype. For object types, pandas will use the value given: Calculations with missing data # Missing values propagate through arithmetic operations between pandas objects. The descriptive statistics and computational methods discussed in the data structure overview (and listed here and here ) are all account for missing data. When summing data, NA values or empty data will be treated as zero. When taking the product, NA values or empty data will be treated as 1. Cumulative methods like cumsum() and cumprod() ignore NA values by default preserve them in the result. This behavior can be changed with skipna Cumulative methods like cumsum() and cumprod() ignore NA values by default, but preserve them in the resulting arrays. To override this behaviour and include NA values, use skipna=False . Dropping missing data # dropna() dropa rows or columns with missing data. Filling missing data # Filling by value # fillna() replaces NA values with non-NA data. Replace NA with a scalar value Fill gaps forward or backward Limit the number of NA values filled NA values can be replaced with corresponding value from a Series or DataFrame where the index and column aligns between the original object and the filled object. Note DataFrame.where() can also be used to fill NA values.Same result as above. Interpolation # DataFrame.interpolate() and Series.interpolate() fills NA values using various interpolation methods. Interpolation relative to a Timestamp in the DatetimeIndex is available by setting method=""time"" For a floating-point index, use method='values' : If you have scipy installed, you can pass the name of a 1-d interpolation routine to method . as specified in the scipy interpolation documentation and reference guide . The appropriate interpolation method will depend on the data type. Tip If you are dealing with a time series that is growing at an increasing rate, use method='barycentric' . If you have values approximating a cumulative distribution function, use method='pchip' . To fill missing values with goal of smooth plotting use method='akima' . When interpolating via a polynomial or spline approximation, you must also specify the degree or order of the approximation: Comparing several methods. Interpolating new observations from expanding data with Series.reindex() . Interpolation limits # interpolate() accepts a limit keyword argument to limit the number of consecutive NaN values filled since the last valid observation By default, NaN values are filled in a forward direction. Use limit_direction parameter to fill backward or from both directions. By default, NaN values are filled whether they are surrounded by existing valid values or outside existing valid values. The limit_area parameter restricts filling to either inside or outside values. Replacing values # Series.replace() and DataFrame.replace() can be used similar to Series.fillna() and DataFrame.fillna() to replace or insert missing values. Replacing more than one value is possible by passing a list. Replacing using a mapping dict. Regular expression replacement # Note Python strings prefixed with the r character such as r'hello world' are “raw” strings . They have different semantics regarding backslashes than strings without this prefix. Backslashes in raw strings will be interpreted as an escaped backslash, e.g., r'\' == '\\' . Replace the ‘.’ with NaN Replace the ‘.’ with NaN with regular expression that removes surrounding whitespace Replace with a list of regexes. Replace with a regex in a mapping dict. Pass nested dictionaries of regular expressions that use the regex keyword. Pass a list of regular expressions that will replace matches with a scalar. All of the regular expression examples can also be passed with the to_replace argument as the regex argument. In this case the value argument must be passed explicitly by name or regex must be a nested dictionary. Note A regular expression object from re.compile is a valid input as well."
https://pandas.pydata.org/docs/user_guide/duplicates.html,Duplicate Labels,"<article class=""bd-article"" role=""main"">
<section id=""duplicate-labels"">
<span id=""duplicates""></span><h1>Duplicate Labels<a class=""headerlink"" href=""#duplicate-labels"" title=""Link to this heading"">#</a></h1>
<p><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code> objects are not required to be unique; you can have duplicate row
or column labels. This may be a bit confusing at first. If you’re familiar with
SQL, you know that row labels are similar to a primary key on a table, and you
would never want duplicates in a SQL table. But one of pandas’ roles is to clean
messy, real-world data before it goes to some downstream system. And real-world
data has duplicates, even in fields that are supposed to be unique.</p>
<p>This section describes how duplicate labels change the behavior of certain
operations, and how prevent duplicates from arising during operations, or to
detect them if they do.</p>

<section id=""consequences-of-duplicate-labels"">
<h2>Consequences of Duplicate Labels<a class=""headerlink"" href=""#consequences-of-duplicate-labels"" title=""Link to this heading"">#</a></h2>
<p>Some pandas methods (<code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.reindex()</span></code> for example) just don’t work with
duplicates present. The output can’t be determined, and so pandas raises.</p>

<p>Other methods, like indexing, can give very surprising results. Typically
indexing with a scalar will <em>reduce dimensionality</em>. Slicing a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>
with a scalar will return a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>. Slicing a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> with a scalar will
return a scalar. But with duplicates, this isn’t the case.</p>

<p>We have duplicates in the columns. If we slice <code class=""docutils literal notranslate""><span class=""pre"">'B'</span></code>, we get back a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code></p>

<p>But slicing <code class=""docutils literal notranslate""><span class=""pre"">'A'</span></code> returns a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code></p>

<p>This applies to row labels as well</p>

</section>
<section id=""duplicate-label-detection"">
<h2>Duplicate Label Detection<a class=""headerlink"" href=""#duplicate-label-detection"" title=""Link to this heading"">#</a></h2>
<p>You can check whether an <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code> (storing the row or column labels) is
unique with <code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">Index.is_unique</span></code>:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Checking whether an index is unique is somewhat expensive for large datasets.
pandas does cache this result, so re-checking on the same index is very fast.</p>
</div>
<p><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Index.duplicated()</span></code> will return a boolean ndarray indicating whether a
label is repeated.</p>

<p>Which can be used as a boolean filter to drop duplicate rows.</p>

<p>If you need additional logic to handle duplicate labels, rather than just
dropping the repeats, using <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">groupby()</span></code> on the index is a common
trick. For example, we’ll resolve duplicates by taking the average of all rows
with the same label.</p>

</section>
<section id=""disallowing-duplicate-labels"">
<span id=""duplicates-disallow""></span><h2>Disallowing Duplicate Labels<a class=""headerlink"" href=""#disallowing-duplicate-labels"" title=""Link to this heading"">#</a></h2>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.2.0.</span></p>
</div>
<p>As noted above, handling duplicates is an important feature when reading in raw
data. That said, you may want to avoid introducing duplicates as part of a data
processing pipeline (from methods like <a class=""reference internal"" href=""../reference/api/pandas.concat.html#pandas.concat"" title=""pandas.concat""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">pandas.concat()</span></code></a>,
<code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">rename()</span></code>, etc.). Both <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code> and <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code>
<em>disallow</em> duplicate labels by calling <code class=""docutils literal notranslate""><span class=""pre"">.set_flags(allows_duplicate_labels=False)</span></code>.
(the default is to allow them). If there are duplicate labels, an exception
will be raised.</p>

<p>This applies to both row and column labels for a <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></p>

<p>This attribute can be checked or set with <code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">allows_duplicate_labels</span></code>,
which indicates whether that object can have duplicate labels.</p>

<p><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.set_flags()</span></code> can be used to return a new <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> with attributes
like <code class=""docutils literal notranslate""><span class=""pre"">allows_duplicate_labels</span></code> set to some value</p>

<p>The new <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> returned is a view on the same data as the old <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>.
Or the property can just be set directly on the same object</p>

<p>When processing raw, messy data you might initially read in the messy data
(which potentially has duplicate labels), deduplicate, and then disallow duplicates
going forward, to ensure that your data pipeline doesn’t introduce duplicates.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">raw</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">read_csv</span><span class=""p"">(</span><span class=""s2"">""...""</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">deduplicated</span> <span class=""o"">=</span> <span class=""n"">raw</span><span class=""o"">.</span><span class=""n"">groupby</span><span class=""p"">(</span><span class=""n"">level</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">first</span><span class=""p"">()</span>  <span class=""c1""># remove duplicates</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">deduplicated</span><span class=""o"">.</span><span class=""n"">flags</span><span class=""o"">.</span><span class=""n"">allows_duplicate_labels</span> <span class=""o"">=</span> <span class=""kc"">False</span>  <span class=""c1""># disallow going forward</span>
</pre></div>
</div>
<p>Setting <code class=""docutils literal notranslate""><span class=""pre"">allows_duplicate_labels=False</span></code> on a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> with duplicate
labels or performing an operation that introduces duplicate labels on a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> or
<code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> that disallows duplicates will raise an
<code class=""xref py py-class docutils literal notranslate""><span class=""pre"">errors.DuplicateLabelError</span></code>.</p>

<p>This error message contains the labels that are duplicated, and the numeric positions
of all the duplicates (including the “original”) in the <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code></p>
<section id=""duplicate-label-propagation"">
<h3>Duplicate Label Propagation<a class=""headerlink"" href=""#duplicate-label-propagation"" title=""Link to this heading"">#</a></h3>
<p>In general, disallowing duplicates is “sticky”. It’s preserved through
operations.</p>

<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>This is an experimental feature. Currently, many methods fail to
propagate the <code class=""docutils literal notranslate""><span class=""pre"">allows_duplicate_labels</span></code> value. In future versions
it is expected that every method taking or returning one or more
DataFrame or Series objects will propagate <code class=""docutils literal notranslate""><span class=""pre"">allows_duplicate_labels</span></code>.</p>
</div>
</section>
</section>
</section>
</article>","Duplicate Labels # Index objects are not required to be unique; you can have duplicate row or column labels. This may be a bit confusing at first. If you’re familiar with SQL, you know that row labels are similar to a primary key on a table, and you would never want duplicates in a SQL table. But one of pandas’ roles is to clean messy, real-world data before it goes to some downstream system. And real-world data has duplicates, even in fields that are supposed to be unique. This section describes how duplicate labels change the behavior of certain operations, and how prevent duplicates from arising during operations, or to detect them if they do. Consequences of Duplicate Labels # Some pandas methods ( Series.reindex() for example) just don’t work with duplicates present. The output can’t be determined, and so pandas raises. Other methods, like indexing, can give very surprising results. Typically indexing with a scalar will reduce dimensionality . Slicing a DataFrame with a scalar will return a Series . Slicing a Series with a scalar will return a scalar. But with duplicates, this isn’t the case. We have duplicates in the columns. If we slice 'B' , we get back a Series But slicing 'A' returns a DataFrame This applies to row labels as well Duplicate Label Detection # You can check whether an Index (storing the row or column labels) is unique with Index.is_unique : Note Checking whether an index is unique is somewhat expensive for large datasets. pandas does cache this result, so re-checking on the same index is very fast. Index.duplicated() will return a boolean ndarray indicating whether a label is repeated. Which can be used as a boolean filter to drop duplicate rows. If you need additional logic to handle duplicate labels, rather than just dropping the repeats, using groupby() on the index is a common trick. For example, we’ll resolve duplicates by taking the average of all rows with the same label. Disallowing Duplicate Labels # New in version 1.2.0. As noted above, handling duplicates is an important feature when reading in raw data. That said, you may want to avoid introducing duplicates as part of a data processing pipeline (from methods like pandas.concat() , rename() , etc.). Both Series and DataFrame disallow duplicate labels by calling .set_flags(allows_duplicate_labels=False) . (the default is to allow them). If there are duplicate labels, an exception will be raised. This applies to both row and column labels for a DataFrame This attribute can be checked or set with allows_duplicate_labels , which indicates whether that object can have duplicate labels. DataFrame.set_flags() can be used to return a new DataFrame with attributes like allows_duplicate_labels set to some value The new DataFrame returned is a view on the same data as the old DataFrame . Or the property can just be set directly on the same object When processing raw, messy data you might initially read in the messy data (which potentially has duplicate labels), deduplicate, and then disallow duplicates going forward, to ensure that your data pipeline doesn’t introduce duplicates. >>> raw = pd . read_csv ( ""..."" ) >>> deduplicated = raw . groupby ( level = 0 ) . first () # remove duplicates >>> deduplicated . flags . allows_duplicate_labels = False # disallow going forward Setting allows_duplicate_labels=False on a Series or DataFrame with duplicate labels or performing an operation that introduces duplicate labels on a Series or DataFrame that disallows duplicates will raise an errors.DuplicateLabelError . This error message contains the labels that are duplicated, and the numeric positions of all the duplicates (including the “original”) in the Series or DataFrame Duplicate Label Propagation # In general, disallowing duplicates is “sticky”. It’s preserved through operations. Warning This is an experimental feature. Currently, many methods fail to propagate the allows_duplicate_labels value. In future versions it is expected that every method taking or returning one or more DataFrame or Series objects will propagate allows_duplicate_labels ."
https://pandas.pydata.org/docs/user_guide/categorical.html,Categorical data,"<article class=""bd-article"" role=""main"">
<section id=""categorical-data"">
<span id=""categorical""></span><h1>Categorical data<a class=""headerlink"" href=""#categorical-data"" title=""Link to this heading"">#</a></h1>
<p>This is an introduction to pandas categorical data type, including a short comparison
with R’s <code class=""docutils literal notranslate""><span class=""pre"">factor</span></code>.</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">Categoricals</span></code> are a pandas data type corresponding to categorical variables in
statistics. A categorical variable takes on a limited, and usually fixed,
number of possible values (<code class=""docutils literal notranslate""><span class=""pre"">categories</span></code>; <code class=""docutils literal notranslate""><span class=""pre"">levels</span></code> in R). Examples are gender,
social class, blood type, country affiliation, observation time or rating via
Likert scales.</p>
<p>In contrast to statistical categorical variables, categorical data might have an order (e.g.
‘strongly agree’ vs ‘agree’ or ‘first observation’ vs. ‘second observation’), but numerical
operations (additions, divisions, …) are not possible.</p>
<p>All values of categorical data are either in <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code>. Order is defined by
the order of <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code>, not lexical order of the values. Internally, the data structure
consists of a <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code> array and an integer array of <code class=""docutils literal notranslate""><span class=""pre"">codes</span></code> which point to the real value in
the <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code> array.</p>
<p>The categorical data type is useful in the following cases:</p>
<ul class=""simple"">
<li><p>A string variable consisting of only a few different values. Converting such a string
variable to a categorical variable will save some memory, see <a class=""reference internal"" href=""#categorical-memory""><span class=""std std-ref"">here</span></a>.</p></li>
<li><p>The lexical order of a variable is not the same as the logical order (“one”, “two”, “three”).
By converting to a categorical and specifying an order on the categories, sorting and
min/max will use the logical order instead of the lexical order, see <a class=""reference internal"" href=""#categorical-sort""><span class=""std std-ref"">here</span></a>.</p></li>
<li><p>As a signal to other Python libraries that this column should be treated as a categorical
variable (e.g. to use suitable statistical methods or plot types).</p></li>
</ul>
<p>See also the <a class=""reference internal"" href=""../reference/arrays.html#api-arrays-categorical""><span class=""std std-ref"">API docs on categoricals</span></a>.</p>
<section id=""object-creation"">
<span id=""categorical-objectcreation""></span><h2>Object creation<a class=""headerlink"" href=""#object-creation"" title=""Link to this heading"">#</a></h2>
<section id=""series-creation"">
<h3>Series creation<a class=""headerlink"" href=""#series-creation"" title=""Link to this heading"">#</a></h3>
<p>Categorical <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> or columns in a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> can be created in several ways:</p>
<p>By specifying <code class=""docutils literal notranslate""><span class=""pre"">dtype=""category""</span></code> when constructing a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>:</p>

<p>By converting an existing <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> or column to a <code class=""docutils literal notranslate""><span class=""pre"">category</span></code> dtype:</p>

<p>By using special functions, such as <a class=""reference internal"" href=""../reference/api/pandas.cut.html#pandas.cut"" title=""pandas.cut""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">cut()</span></code></a>, which groups data into
discrete bins. See the <a class=""reference internal"" href=""reshaping.html#reshaping-tile-cut""><span class=""std std-ref"">example on tiling</span></a> in the docs.</p>

<p>By passing a <a class=""reference internal"" href=""../reference/api/pandas.Categorical.html#pandas.Categorical"" title=""pandas.Categorical""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">pandas.Categorical</span></code></a> object to a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> or assigning it to a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>.</p>

<p>Categorical data has a specific <code class=""docutils literal notranslate""><span class=""pre"">category</span></code> <a class=""reference internal"" href=""basics.html#basics-dtypes""><span class=""std std-ref"">dtype</span></a>:</p>

</section>
<section id=""dataframe-creation"">
<h3>DataFrame creation<a class=""headerlink"" href=""#dataframe-creation"" title=""Link to this heading"">#</a></h3>
<p>Similar to the previous section where a single column was converted to categorical, all columns in a
<code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> can be batch converted to categorical either during or after construction.</p>
<p>This can be done during construction by specifying <code class=""docutils literal notranslate""><span class=""pre"">dtype=""category""</span></code> in the <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> constructor:</p>

<p>Note that the categories present in each column differ; the conversion is done column by column, so
only labels present in a given column are categories:</p>

<p>Analogously, all columns in an existing <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> can be batch converted using <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.astype.html#pandas.DataFrame.astype"" title=""pandas.DataFrame.astype""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.astype()</span></code></a>:</p>

<p>This conversion is likewise done column by column:</p>

</section>
<section id=""controlling-behavior"">
<h3>Controlling behavior<a class=""headerlink"" href=""#controlling-behavior"" title=""Link to this heading"">#</a></h3>
<p>In the examples above where we passed <code class=""docutils literal notranslate""><span class=""pre"">dtype='category'</span></code>, we used the default
behavior:</p>
<ol class=""arabic simple"">
<li><p>Categories are inferred from the data.</p></li>
<li><p>Categories are unordered.</p></li>
</ol>
<p>To control those behaviors, instead of passing <code class=""docutils literal notranslate""><span class=""pre"">'category'</span></code>, use an instance
of <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">CategoricalDtype</span></code>.</p>

<p>Similarly, a <code class=""docutils literal notranslate""><span class=""pre"">CategoricalDtype</span></code> can be used with a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> to ensure that categories
are consistent among all columns.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>To perform table-wise conversion, where all labels in the entire <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> are used as
categories for each column, the <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code> parameter can be determined programmatically by
<code class=""docutils literal notranslate""><span class=""pre"">categories</span> <span class=""pre"">=</span> <span class=""pre"">pd.unique(df.to_numpy().ravel())</span></code>.</p>
</div>
<p>If you already have <code class=""docutils literal notranslate""><span class=""pre"">codes</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code>, you can use the
<a class=""reference internal"" href=""../reference/api/pandas.Categorical.from_codes.html#pandas.Categorical.from_codes"" title=""pandas.Categorical.from_codes""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">from_codes()</span></code></a> constructor to save the factorize step
during normal constructor mode:</p>

</section>
<section id=""regaining-original-data"">
<h3>Regaining original data<a class=""headerlink"" href=""#regaining-original-data"" title=""Link to this heading"">#</a></h3>
<p>To get back to the original <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> or NumPy array, use
<code class=""docutils literal notranslate""><span class=""pre"">Series.astype(original_dtype)</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">np.asarray(categorical)</span></code>:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>In contrast to R’s <code class=""docutils literal notranslate""><span class=""pre"">factor</span></code> function, categorical data is not converting input values to
strings; categories will end up the same data type as the original values.</p>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>In contrast to R’s <code class=""docutils literal notranslate""><span class=""pre"">factor</span></code> function, there is currently no way to assign/change labels at
creation time. Use <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code> to change the categories after creation time.</p>
</div>
</section>
</section>
<section id=""categoricaldtype"">
<span id=""categorical-categoricaldtype""></span><h2>CategoricalDtype<a class=""headerlink"" href=""#categoricaldtype"" title=""Link to this heading"">#</a></h2>
<p>A categorical’s type is fully described by</p>
<ol class=""arabic simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">categories</span></code>: a sequence of unique values and no missing values</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">ordered</span></code>: a boolean</p></li>
</ol>
<p>This information can be stored in a <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">CategoricalDtype</span></code>.
The <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code> argument is optional, which implies that the actual categories
should be inferred from whatever is present in the data when the
<a class=""reference internal"" href=""../reference/api/pandas.Categorical.html#pandas.Categorical"" title=""pandas.Categorical""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">pandas.Categorical</span></code></a> is created. The categories are assumed to be unordered
by default.</p>

<p>A <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">CategoricalDtype</span></code> can be used in any place pandas
expects a <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code>. For example <a class=""reference internal"" href=""../reference/api/pandas.read_csv.html#pandas.read_csv"" title=""pandas.read_csv""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.read_csv()</span></code></a>,
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.astype.html#pandas.DataFrame.astype"" title=""pandas.DataFrame.astype""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.DataFrame.astype()</span></code></a>, or in the <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> constructor.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>As a convenience, you can use the string <code class=""docutils literal notranslate""><span class=""pre"">'category'</span></code> in place of a
<code class=""xref py py-class docutils literal notranslate""><span class=""pre"">CategoricalDtype</span></code> when you want the default behavior of
the categories being unordered, and equal to the set values present in the
array. In other words, <code class=""docutils literal notranslate""><span class=""pre"">dtype='category'</span></code> is equivalent to
<code class=""docutils literal notranslate""><span class=""pre"">dtype=CategoricalDtype()</span></code>.</p>
</div>
<section id=""equality-semantics"">
<h3>Equality semantics<a class=""headerlink"" href=""#equality-semantics"" title=""Link to this heading"">#</a></h3>
<p>Two instances of <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">CategoricalDtype</span></code> compare equal
whenever they have the same categories and order. When comparing two
unordered categoricals, the order of the <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code> is not considered.</p>

<p>All instances of <code class=""docutils literal notranslate""><span class=""pre"">CategoricalDtype</span></code> compare equal to the string <code class=""docutils literal notranslate""><span class=""pre"">'category'</span></code>.</p>

</section>
</section>
<section id=""description"">
<h2>Description<a class=""headerlink"" href=""#description"" title=""Link to this heading"">#</a></h2>
<p>Using <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.describe.html#pandas.DataFrame.describe"" title=""pandas.DataFrame.describe""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">describe()</span></code></a> on categorical data will produce similar
output to a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> of type <code class=""docutils literal notranslate""><span class=""pre"">string</span></code>.</p>

</section>
<section id=""working-with-categories"">
<span id=""categorical-cat""></span><h2>Working with categories<a class=""headerlink"" href=""#working-with-categories"" title=""Link to this heading"">#</a></h2>
<p>Categorical data has a <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code> and a <code class=""docutils literal notranslate""><span class=""pre"">ordered</span></code> property, which list their
possible values and whether the ordering matters or not. These properties are
exposed as <code class=""docutils literal notranslate""><span class=""pre"">s.cat.categories</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">s.cat.ordered</span></code>. If you don’t manually
specify categories and ordering, they are inferred from the passed arguments.</p>

<p>It’s also possible to pass in the categories in a specific order:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>New categorical data are <strong>not</strong> automatically ordered. You must explicitly
pass <code class=""docutils literal notranslate""><span class=""pre"">ordered=True</span></code> to indicate an ordered <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code>.</p>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The result of <a class=""reference internal"" href=""../reference/api/pandas.Series.unique.html#pandas.Series.unique"" title=""pandas.Series.unique""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">unique()</span></code></a> is not always the same as <code class=""docutils literal notranslate""><span class=""pre"">Series.cat.categories</span></code>,
because <code class=""docutils literal notranslate""><span class=""pre"">Series.unique()</span></code> has a couple of guarantees, namely that it returns categories
in the order of appearance, and it only includes values that are actually present.</p>

</div>
<section id=""renaming-categories"">
<h3>Renaming categories<a class=""headerlink"" href=""#renaming-categories"" title=""Link to this heading"">#</a></h3>
<p>Renaming categories is done by using the
<code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">rename_categories()</span></code> method:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>In contrast to R’s <code class=""docutils literal notranslate""><span class=""pre"">factor</span></code>, categorical data can have categories of other types than string.</p>
</div>
<p>Categories must be unique or a <code class=""docutils literal notranslate""><span class=""pre"">ValueError</span></code> is raised:</p>

<p>Categories must also not be <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code> or a <code class=""docutils literal notranslate""><span class=""pre"">ValueError</span></code> is raised:</p>

</section>
<section id=""appending-new-categories"">
<h3>Appending new categories<a class=""headerlink"" href=""#appending-new-categories"" title=""Link to this heading"">#</a></h3>
<p>Appending categories can be done by using the
<code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">add_categories()</span></code> method:</p>

</section>
<section id=""removing-categories"">
<h3>Removing categories<a class=""headerlink"" href=""#removing-categories"" title=""Link to this heading"">#</a></h3>
<p>Removing categories can be done by using the
<code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">remove_categories()</span></code> method. Values which are removed
are replaced by <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code>.:</p>

</section>
<section id=""removing-unused-categories"">
<h3>Removing unused categories<a class=""headerlink"" href=""#removing-unused-categories"" title=""Link to this heading"">#</a></h3>
<p>Removing unused categories can also be done:</p>

</section>
<section id=""setting-categories"">
<h3>Setting categories<a class=""headerlink"" href=""#setting-categories"" title=""Link to this heading"">#</a></h3>
<p>If you want to do remove and add new categories in one step (which has some
speed advantage), or simply set the categories to a predefined scale,
use <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">set_categories()</span></code>.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Be aware that <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">Categorical.set_categories()</span></code> cannot know whether some category is omitted
intentionally or because it is misspelled or (under Python3) due to a type difference (e.g.,
NumPy S1 dtype and Python strings). This can result in surprising behaviour!</p>
</div>
</section>
</section>
<section id=""sorting-and-order"">
<h2>Sorting and order<a class=""headerlink"" href=""#sorting-and-order"" title=""Link to this heading"">#</a></h2>
<p id=""categorical-sort"">If categorical data is ordered (<code class=""docutils literal notranslate""><span class=""pre"">s.cat.ordered</span> <span class=""pre"">==</span> <span class=""pre"">True</span></code>), then the order of the categories has a
meaning and certain operations are possible. If the categorical is unordered, <code class=""docutils literal notranslate""><span class=""pre"">.min()/.max()</span></code> will raise a <code class=""docutils literal notranslate""><span class=""pre"">TypeError</span></code>.</p>

<p>You can set categorical data to be ordered by using <code class=""docutils literal notranslate""><span class=""pre"">as_ordered()</span></code> or unordered by using <code class=""docutils literal notranslate""><span class=""pre"">as_unordered()</span></code>. These will by
default return a <em>new</em> object.</p>

<p>Sorting will use the order defined by categories, not any lexical order present on the data type.
This is even true for strings and numeric data:</p>

<section id=""reordering"">
<h3>Reordering<a class=""headerlink"" href=""#reordering"" title=""Link to this heading"">#</a></h3>
<p>Reordering the categories is possible via the <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Categorical.reorder_categories()</span></code> and
the <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Categorical.set_categories()</span></code> methods. For <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Categorical.reorder_categories()</span></code>, all
old categories must be included in the new categories and no new categories are allowed. This will
necessarily make the sort order the same as the categories order.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Note the difference between assigning new categories and reordering the categories: the first
renames categories and therefore the individual values in the <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>, but if the first
position was sorted last, the renamed value will still be sorted last. Reordering means that the
way values are sorted is different afterwards, but not that individual values in the
<code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> are changed.</p>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>If the <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> is not ordered, <a class=""reference internal"" href=""../reference/api/pandas.Series.min.html#pandas.Series.min"" title=""pandas.Series.min""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.min()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.Series.max.html#pandas.Series.max"" title=""pandas.Series.max""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.max()</span></code></a> will raise
<code class=""docutils literal notranslate""><span class=""pre"">TypeError</span></code>. Numeric operations like <code class=""docutils literal notranslate""><span class=""pre"">+</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">-</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">*</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">/</span></code> and operations based on them
(e.g. <a class=""reference internal"" href=""../reference/api/pandas.Series.median.html#pandas.Series.median"" title=""pandas.Series.median""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.median()</span></code></a>, which would need to compute the mean between two values if the length
of an array is even) do not work and raise a <code class=""docutils literal notranslate""><span class=""pre"">TypeError</span></code>.</p>
</div>
</section>
<section id=""multi-column-sorting"">
<h3>Multi column sorting<a class=""headerlink"" href=""#multi-column-sorting"" title=""Link to this heading"">#</a></h3>
<p>A categorical dtyped column will participate in a multi-column sort in a similar manner to other columns.
The ordering of the categorical is determined by the <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code> of that column.</p>

<p>Reordering the <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code> changes a future sort.</p>

</section>
</section>
<section id=""comparisons"">
<h2>Comparisons<a class=""headerlink"" href=""#comparisons"" title=""Link to this heading"">#</a></h2>
<p>Comparing categorical data with other objects is possible in three cases:</p>
<ul class=""simple"">
<li><p>Comparing equality (<code class=""docutils literal notranslate""><span class=""pre"">==</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">!=</span></code>) to a list-like object (list, Series, array,
…) of the same length as the categorical data.</p></li>
<li><p>All comparisons (<code class=""docutils literal notranslate""><span class=""pre"">==</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">!=</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">&gt;</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">&gt;=</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">&lt;</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">&lt;=</span></code>) of categorical data to
another categorical Series, when <code class=""docutils literal notranslate""><span class=""pre"">ordered==True</span></code> and the <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code> are the same.</p></li>
<li><p>All comparisons of a categorical data to a scalar.</p></li>
</ul>
<p>All other comparisons, especially “non-equality” comparisons of two categoricals with different
categories or a categorical with any list-like object, will raise a <code class=""docutils literal notranslate""><span class=""pre"">TypeError</span></code>.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Any “non-equality” comparisons of categorical data with a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">np.array</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">list</span></code> or
categorical data with different categories or ordering will raise a <code class=""docutils literal notranslate""><span class=""pre"">TypeError</span></code> because custom
categories ordering could be interpreted in two ways: one with taking into account the
ordering and one without.</p>
</div>

<p>Comparing to a categorical with the same categories and ordering or to a scalar works:</p>

<p>Equality comparisons work with any list-like object of same length and scalars:</p>

<p>This doesn’t work because the categories are not the same:</p>

<p>If you want to do a “non-equality” comparison of a categorical series with a list-like object
which is not categorical data, you need to be explicit and convert the categorical data back to
the original values:</p>

<p>When you compare two unordered categoricals with the same categories, the order is not considered:</p>

</section>
<section id=""operations"">
<h2>Operations<a class=""headerlink"" href=""#operations"" title=""Link to this heading"">#</a></h2>
<p>Apart from <a class=""reference internal"" href=""../reference/api/pandas.Series.min.html#pandas.Series.min"" title=""pandas.Series.min""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.min()</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.Series.max.html#pandas.Series.max"" title=""pandas.Series.max""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.max()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.Series.mode.html#pandas.Series.mode"" title=""pandas.Series.mode""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.mode()</span></code></a>, the
following operations are possible with categorical data:</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> methods like <a class=""reference internal"" href=""../reference/api/pandas.Series.value_counts.html#pandas.Series.value_counts"" title=""pandas.Series.value_counts""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.value_counts()</span></code></a> will use all categories,
even if some categories are not present in the data:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> methods like <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.sum.html#pandas.DataFrame.sum"" title=""pandas.DataFrame.sum""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.sum()</span></code></a> also show “unused” categories when <code class=""docutils literal notranslate""><span class=""pre"">observed=False</span></code>.</p>

<p>Groupby will also show “unused” categories when <code class=""docutils literal notranslate""><span class=""pre"">observed=False</span></code>:</p>

<p>Pivot tables:</p>

</section>
<section id=""data-munging"">
<h2>Data munging<a class=""headerlink"" href=""#data-munging"" title=""Link to this heading"">#</a></h2>
<p>The optimized pandas data access methods <code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">.iloc</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">.at</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">.iat</span></code>,
work as normal. The only difference is the return type (for getting) and
that only values already in <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code> can be assigned.</p>
<section id=""getting"">
<h3>Getting<a class=""headerlink"" href=""#getting"" title=""Link to this heading"">#</a></h3>
<p>If the slicing operation returns either a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> or a column of type
<code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>, the <code class=""docutils literal notranslate""><span class=""pre"">category</span></code> dtype is preserved.</p>

<p>An example where the category type is not preserved is if you take one single
row: the resulting <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> is of dtype <code class=""docutils literal notranslate""><span class=""pre"">object</span></code>:</p>

<p>Returning a single item from categorical data will also return the value, not a categorical
of length “1”.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The is in contrast to R’s <code class=""docutils literal notranslate""><span class=""pre"">factor</span></code> function, where <code class=""docutils literal notranslate""><span class=""pre"">factor(c(1,2,3))[1]</span></code>
returns a single value <code class=""docutils literal notranslate""><span class=""pre"">factor</span></code>.</p>
</div>
<p>To get a single value <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> of type <code class=""docutils literal notranslate""><span class=""pre"">category</span></code>, you pass in a list with
a single value:</p>

</section>
<section id=""string-and-datetime-accessors"">
<h3>String and datetime accessors<a class=""headerlink"" href=""#string-and-datetime-accessors"" title=""Link to this heading"">#</a></h3>
<p>The accessors <code class=""docutils literal notranslate""><span class=""pre"">.dt</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">.str</span></code> will work if the <code class=""docutils literal notranslate""><span class=""pre"">s.cat.categories</span></code> are of
an appropriate type:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The returned <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> (or <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>) is of the same type as if you used the
<code class=""docutils literal notranslate""><span class=""pre"">.str.&lt;method&gt;</span></code> / <code class=""docutils literal notranslate""><span class=""pre"">.dt.&lt;method&gt;</span></code> on a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> of that type (and not of
type <code class=""docutils literal notranslate""><span class=""pre"">category</span></code>!).</p>
</div>
<p>That means, that the returned values from methods and properties on the accessors of a
<code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> and the returned values from methods and properties on the accessors of this
<code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> transformed to one of type <code class=""docutils literal notranslate""><span class=""pre"">category</span></code> will be equal:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The work is done on the <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code> and then a new <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> is constructed. This has
some performance implication if you have a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> of type string, where lots of elements
are repeated (i.e. the number of unique elements in the <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> is a lot smaller than the
length of the <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>). In this case it can be faster to convert the original <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>
to one of type <code class=""docutils literal notranslate""><span class=""pre"">category</span></code> and use <code class=""docutils literal notranslate""><span class=""pre"">.str.&lt;method&gt;</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">.dt.&lt;property&gt;</span></code> on that.</p>
</div>
</section>
<section id=""setting"">
<h3>Setting<a class=""headerlink"" href=""#setting"" title=""Link to this heading"">#</a></h3>
<p>Setting values in a categorical column (or <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>) works as long as the
value is included in the <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code>:</p>

<p>Setting values by assigning categorical data will also check that the <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code> match:</p>

<p>Assigning a <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> to parts of a column of other types will use the values:</p>

</section>
<section id=""merging-concatenation"">
<span id=""categorical-concat""></span><span id=""categorical-merge""></span><h3>Merging / concatenation<a class=""headerlink"" href=""#merging-concatenation"" title=""Link to this heading"">#</a></h3>
<p>By default, combining <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">DataFrames</span></code> which contain the same
categories results in <code class=""docutils literal notranslate""><span class=""pre"">category</span></code> dtype, otherwise results will depend on the
dtype of the underlying categories. Merges that result in non-categorical
dtypes will likely have higher memory usage. Use <code class=""docutils literal notranslate""><span class=""pre"">.astype</span></code> or
<code class=""docutils literal notranslate""><span class=""pre"">union_categoricals</span></code> to ensure <code class=""docutils literal notranslate""><span class=""pre"">category</span></code> results.</p>

<p>The following table summarizes the results of merging <code class=""docutils literal notranslate""><span class=""pre"">Categoricals</span></code>:</p>

</section>
<section id=""unioning"">
<span id=""categorical-union""></span><h3>Unioning<a class=""headerlink"" href=""#unioning"" title=""Link to this heading"">#</a></h3>
<p>If you want to combine categoricals that do not necessarily have the same
categories, the <a class=""reference internal"" href=""../reference/api/pandas.api.types.union_categoricals.html#pandas.api.types.union_categoricals"" title=""pandas.api.types.union_categoricals""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">union_categoricals()</span></code></a> function will
combine a list-like of categoricals. The new categories will be the union of
the categories being combined.</p>

<p>By default, the resulting categories will be ordered as
they appear in the data. If you want the categories to
be lexsorted, use <code class=""docutils literal notranslate""><span class=""pre"">sort_categories=True</span></code> argument.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">union_categoricals</span></code> also works with the “easy” case of combining two
categoricals of the same categories and order information
(e.g. what you could also <code class=""docutils literal notranslate""><span class=""pre"">append</span></code> for).</p>

<p>The below raises <code class=""docutils literal notranslate""><span class=""pre"">TypeError</span></code> because the categories are ordered and not identical.</p>

<p>Ordered categoricals with different categories or orderings can be combined by
using the <code class=""docutils literal notranslate""><span class=""pre"">ignore_ordered=True</span></code> argument.</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.api.types.union_categoricals.html#pandas.api.types.union_categoricals"" title=""pandas.api.types.union_categoricals""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">union_categoricals()</span></code></a> also works with a
<code class=""docutils literal notranslate""><span class=""pre"">CategoricalIndex</span></code>, or <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> containing categorical data, but note that
the resulting array will always be a plain <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code>:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">union_categoricals</span></code> may recode the integer codes for categories
when combining categoricals. This is likely what you want,
but if you are relying on the exact numbering of the categories, be
aware.</p>

</div>
</section>
</section>
<section id=""getting-data-in-out"">
<h2>Getting data in/out<a class=""headerlink"" href=""#getting-data-in-out"" title=""Link to this heading"">#</a></h2>
<p>You can write data that contains <code class=""docutils literal notranslate""><span class=""pre"">category</span></code> dtypes to a <code class=""docutils literal notranslate""><span class=""pre"">HDFStore</span></code>.
See <a class=""reference internal"" href=""io.html#io-hdf5-categorical""><span class=""std std-ref"">here</span></a> for an example and caveats.</p>
<p>It is also possible to write data to and reading data from <em>Stata</em> format files.
See <a class=""reference internal"" href=""io.html#io-stata-categorical""><span class=""std std-ref"">here</span></a> for an example and caveats.</p>
<p>Writing to a CSV file will convert the data, effectively removing any information about the
categorical (categories and ordering). So if you read back the CSV file you have to convert the
relevant columns back to <code class=""docutils literal notranslate""><span class=""pre"">category</span></code> and assign the right categories and categories ordering.</p>

<p>The same holds for writing to a SQL database with <code class=""docutils literal notranslate""><span class=""pre"">to_sql</span></code>.</p>
</section>
<section id=""missing-data"">
<h2>Missing data<a class=""headerlink"" href=""#missing-data"" title=""Link to this heading"">#</a></h2>
<p>pandas primarily uses the value <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code> to represent missing data. It is by
default not included in computations. See the <a class=""reference internal"" href=""missing_data.html#missing-data""><span class=""std std-ref"">Missing Data section</span></a>.</p>
<p>Missing values should <strong>not</strong> be included in the Categorical’s <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code>,
only in the <code class=""docutils literal notranslate""><span class=""pre"">values</span></code>.
Instead, it is understood that NaN is different, and is always a possibility.
When working with the Categorical’s <code class=""docutils literal notranslate""><span class=""pre"">codes</span></code>, missing values will always have
a code of <code class=""docutils literal notranslate""><span class=""pre"">-1</span></code>.</p>

<p>Methods for working with missing data, e.g. <a class=""reference internal"" href=""../reference/api/pandas.Series.isna.html#pandas.Series.isna"" title=""pandas.Series.isna""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">isna()</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.Series.fillna.html#pandas.Series.fillna"" title=""pandas.Series.fillna""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">fillna()</span></code></a>,
<a class=""reference internal"" href=""../reference/api/pandas.Series.dropna.html#pandas.Series.dropna"" title=""pandas.Series.dropna""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">dropna()</span></code></a>, all work normally:</p>

</section>
<section id=""differences-to-r-s-factor"">
<h2>Differences to R’s <code class=""docutils literal notranslate""><span class=""pre"">factor</span></code><a class=""headerlink"" href=""#differences-to-r-s-factor"" title=""Link to this heading"">#</a></h2>
<p>The following differences to R’s factor functions can be observed:</p>
<ul class=""simple"">
<li><p>R’s <code class=""docutils literal notranslate""><span class=""pre"">levels</span></code> are named <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code>.</p></li>
<li><p>R’s <code class=""docutils literal notranslate""><span class=""pre"">levels</span></code> are always of type string, while <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code> in pandas can be of any dtype.</p></li>
<li><p>It’s not possible to specify labels at creation time. Use <code class=""docutils literal notranslate""><span class=""pre"">s.cat.rename_categories(new_labels)</span></code>
afterwards.</p></li>
<li><p>In contrast to R’s <code class=""docutils literal notranslate""><span class=""pre"">factor</span></code> function, using categorical data as the sole input to create a
new categorical series will <em>not</em> remove unused categories but create a new categorical series
which is equal to the passed in one!</p></li>
<li><p>R allows for missing values to be included in its <code class=""docutils literal notranslate""><span class=""pre"">levels</span></code> (pandas’ <code class=""docutils literal notranslate""><span class=""pre"">categories</span></code>). pandas
does not allow <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code> categories, but missing values can still be in the <code class=""docutils literal notranslate""><span class=""pre"">values</span></code>.</p></li>
</ul>
</section>
<section id=""gotchas"">
<h2>Gotchas<a class=""headerlink"" href=""#gotchas"" title=""Link to this heading"">#</a></h2>
<section id=""memory-usage"">
<span id=""categorical-rfactor""></span><h3>Memory usage<a class=""headerlink"" href=""#memory-usage"" title=""Link to this heading"">#</a></h3>
<p id=""categorical-memory"">The memory usage of a <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> is proportional to the number of categories plus the length of the data. In contrast,
an <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> dtype is a constant times the length of the data.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>If the number of categories approaches the length of the data, the <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> will use nearly the same or
more memory than an equivalent <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> dtype representation.</p>

</div>
</section>
<section id=""categorical-is-not-a-numpy-array"">
<h3><code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> is not a <code class=""docutils literal notranslate""><span class=""pre"">numpy</span></code> array<a class=""headerlink"" href=""#categorical-is-not-a-numpy-array"" title=""Link to this heading"">#</a></h3>
<p>Currently, categorical data and the underlying <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> is implemented as a Python
object and not as a low-level NumPy array dtype. This leads to some problems.</p>
<p>NumPy itself doesn’t know about the new <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code>:</p>

<p>Dtype comparisons work:</p>

<p>To check if a Series contains Categorical data, use <code class=""docutils literal notranslate""><span class=""pre"">hasattr(s,</span> <span class=""pre"">'cat')</span></code>:</p>

<p>Using NumPy functions on a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> of type <code class=""docutils literal notranslate""><span class=""pre"">category</span></code> should not work as <code class=""docutils literal notranslate""><span class=""pre"">Categoricals</span></code>
are not numeric data (even in the case that <code class=""docutils literal notranslate""><span class=""pre"">.categories</span></code> is numeric).</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>If such a function works, please file a bug at <a class=""github reference external"" href=""https://github.com/pandas-dev/pandas"">pandas-dev/pandas</a>!</p>
</div>
</section>
<section id=""dtype-in-apply"">
<h3>dtype in apply<a class=""headerlink"" href=""#dtype-in-apply"" title=""Link to this heading"">#</a></h3>
<p>pandas currently does not preserve the dtype in apply functions: If you apply along rows you get
a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> of <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> <code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code> (same as getting a row -&gt; getting one element will return a
basic type) and applying along columns will also convert to object. <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code> values are unaffected.
You can use <code class=""docutils literal notranslate""><span class=""pre"">fillna</span></code> to handle missing values before applying a function.</p>

</section>
<section id=""categorical-index"">
<h3>Categorical index<a class=""headerlink"" href=""#categorical-index"" title=""Link to this heading"">#</a></h3>
<p><code class=""docutils literal notranslate""><span class=""pre"">CategoricalIndex</span></code> is a type of index that is useful for supporting
indexing with duplicates. This is a container around a <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code>
and allows efficient indexing and storage of an index with a large number of duplicated elements.
See the <a class=""reference internal"" href=""advanced.html#advanced-categoricalindex""><span class=""std std-ref"">advanced indexing docs</span></a> for a more detailed
explanation.</p>
<p>Setting the index will create a <code class=""docutils literal notranslate""><span class=""pre"">CategoricalIndex</span></code>:</p>

</section>
<section id=""side-effects"">
<h3>Side effects<a class=""headerlink"" href=""#side-effects"" title=""Link to this heading"">#</a></h3>
<p>Constructing a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> from a <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> will not copy the input
<code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code>. This means that changes to the <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> will in most cases
change the original <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code>:</p>

<p>Use <code class=""docutils literal notranslate""><span class=""pre"">copy=True</span></code> to prevent such a behaviour or simply don’t reuse <code class=""docutils literal notranslate""><span class=""pre"">Categoricals</span></code>:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>This also happens in some cases when you supply a NumPy array instead of a <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code>:
using an int array (e.g. <code class=""docutils literal notranslate""><span class=""pre"">np.array([1,2,3,4])</span></code>) will exhibit the same behavior, while using
a string array (e.g. <code class=""docutils literal notranslate""><span class=""pre"">np.array([""a"",""b"",""c"",""a""])</span></code>) will not.</p>
</div>
</section>
</section>
</section>
</article>","Categorical data # This is an introduction to pandas categorical data type, including a short comparison with R’s factor . Categoricals are a pandas data type corresponding to categorical variables in statistics. A categorical variable takes on a limited, and usually fixed, number of possible values ( categories ; levels in R). Examples are gender, social class, blood type, country affiliation, observation time or rating via Likert scales. In contrast to statistical categorical variables, categorical data might have an order (e.g. ‘strongly agree’ vs ‘agree’ or ‘first observation’ vs. ‘second observation’), but numerical operations (additions, divisions, …) are not possible. All values of categorical data are either in categories or np.nan . Order is defined by the order of categories , not lexical order of the values. Internally, the data structure consists of a categories array and an integer array of codes which point to the real value in the categories array. The categorical data type is useful in the following cases: A string variable consisting of only a few different values. Converting such a string variable to a categorical variable will save some memory, see here . The lexical order of a variable is not the same as the logical order (“one”, “two”, “three”). By converting to a categorical and specifying an order on the categories, sorting and min/max will use the logical order instead of the lexical order, see here . As a signal to other Python libraries that this column should be treated as a categorical variable (e.g. to use suitable statistical methods or plot types). See also the API docs on categoricals . Object creation # Series creation # Categorical Series or columns in a DataFrame can be created in several ways: By specifying dtype=""category"" when constructing a Series : By converting an existing Series or column to a category dtype: By using special functions, such as cut() , which groups data into discrete bins. See the example on tiling in the docs. By passing a pandas.Categorical object to a Series or assigning it to a DataFrame . Categorical data has a specific category dtype : DataFrame creation # Similar to the previous section where a single column was converted to categorical, all columns in a DataFrame can be batch converted to categorical either during or after construction. This can be done during construction by specifying dtype=""category"" in the DataFrame constructor: Note that the categories present in each column differ; the conversion is done column by column, so only labels present in a given column are categories: Analogously, all columns in an existing DataFrame can be batch converted using DataFrame.astype() : This conversion is likewise done column by column: Controlling behavior # In the examples above where we passed dtype='category' , we used the default behavior: Categories are inferred from the data. Categories are unordered. To control those behaviors, instead of passing 'category' , use an instance of CategoricalDtype . Similarly, a CategoricalDtype can be used with a DataFrame to ensure that categories are consistent among all columns. Note To perform table-wise conversion, where all labels in the entire DataFrame are used as categories for each column, the categories parameter can be determined programmatically by categories = pd.unique(df.to_numpy().ravel()) . If you already have codes and categories , you can use the from_codes() constructor to save the factorize step during normal constructor mode: Regaining original data # To get back to the original Series or NumPy array, use Series.astype(original_dtype) or np.asarray(categorical) : Note In contrast to R’s factor function, categorical data is not converting input values to strings; categories will end up the same data type as the original values. Note In contrast to R’s factor function, there is currently no way to assign/change labels at creation time. Use categories to change the categories after creation time. CategoricalDtype # A categorical’s type is fully described by categories : a sequence of unique values and no missing values ordered : a boolean This information can be stored in a CategoricalDtype . The categories argument is optional, which implies that the actual categories should be inferred from whatever is present in the data when the pandas.Categorical is created. The categories are assumed to be unordered by default. A CategoricalDtype can be used in any place pandas expects a dtype . For example pandas.read_csv() , pandas.DataFrame.astype() , or in the Series constructor. Note As a convenience, you can use the string 'category' in place of a CategoricalDtype when you want the default behavior of the categories being unordered, and equal to the set values present in the array. In other words, dtype='category' is equivalent to dtype=CategoricalDtype() . Equality semantics # Two instances of CategoricalDtype compare equal whenever they have the same categories and order. When comparing two unordered categoricals, the order of the categories is not considered. All instances of CategoricalDtype compare equal to the string 'category' . Description # Using describe() on categorical data will produce similar output to a Series or DataFrame of type string . Working with categories # Categorical data has a categories and a ordered property, which list their possible values and whether the ordering matters or not. These properties are exposed as s.cat.categories and s.cat.ordered . If you don’t manually specify categories and ordering, they are inferred from the passed arguments. It’s also possible to pass in the categories in a specific order: Note New categorical data are not automatically ordered. You must explicitly pass ordered=True to indicate an ordered Categorical . Note The result of unique() is not always the same as Series.cat.categories , because Series.unique() has a couple of guarantees, namely that it returns categories in the order of appearance, and it only includes values that are actually present. Renaming categories # Renaming categories is done by using the rename_categories() method: Note In contrast to R’s factor , categorical data can have categories of other types than string. Categories must be unique or a ValueError is raised: Categories must also not be NaN or a ValueError is raised: Appending new categories # Appending categories can be done by using the add_categories() method: Removing categories # Removing categories can be done by using the remove_categories() method. Values which are removed are replaced by np.nan .: Removing unused categories # Removing unused categories can also be done: Setting categories # If you want to do remove and add new categories in one step (which has some speed advantage), or simply set the categories to a predefined scale, use set_categories() . Note Be aware that Categorical.set_categories() cannot know whether some category is omitted intentionally or because it is misspelled or (under Python3) due to a type difference (e.g., NumPy S1 dtype and Python strings). This can result in surprising behaviour! Sorting and order # If categorical data is ordered ( s.cat.ordered == True ), then the order of the categories has a meaning and certain operations are possible. If the categorical is unordered, .min()/.max() will raise a TypeError . You can set categorical data to be ordered by using as_ordered() or unordered by using as_unordered() . These will by default return a new object. Sorting will use the order defined by categories, not any lexical order present on the data type. This is even true for strings and numeric data: Reordering # Reordering the categories is possible via the Categorical.reorder_categories() and the Categorical.set_categories() methods. For Categorical.reorder_categories() , all old categories must be included in the new categories and no new categories are allowed. This will necessarily make the sort order the same as the categories order. Note Note the difference between assigning new categories and reordering the categories: the first renames categories and therefore the individual values in the Series , but if the first position was sorted last, the renamed value will still be sorted last. Reordering means that the way values are sorted is different afterwards, but not that individual values in the Series are changed. Note If the Categorical is not ordered, Series.min() and Series.max() will raise TypeError . Numeric operations like + , - , * , / and operations based on them (e.g. Series.median() , which would need to compute the mean between two values if the length of an array is even) do not work and raise a TypeError . Multi column sorting # A categorical dtyped column will participate in a multi-column sort in a similar manner to other columns. The ordering of the categorical is determined by the categories of that column. Reordering the categories changes a future sort. Comparisons # Comparing categorical data with other objects is possible in three cases: Comparing equality ( == and != ) to a list-like object (list, Series, array, …) of the same length as the categorical data. All comparisons ( == , != , > , >= , < , and <= ) of categorical data to another categorical Series, when ordered==True and the categories are the same. All comparisons of a categorical data to a scalar. All other comparisons, especially “non-equality” comparisons of two categoricals with different categories or a categorical with any list-like object, will raise a TypeError . Note Any “non-equality” comparisons of categorical data with a Series , np.array , list or categorical data with different categories or ordering will raise a TypeError because custom categories ordering could be interpreted in two ways: one with taking into account the ordering and one without. Comparing to a categorical with the same categories and ordering or to a scalar works: Equality comparisons work with any list-like object of same length and scalars: This doesn’t work because the categories are not the same: If you want to do a “non-equality” comparison of a categorical series with a list-like object which is not categorical data, you need to be explicit and convert the categorical data back to the original values: When you compare two unordered categoricals with the same categories, the order is not considered: Operations # Apart from Series.min() , Series.max() and Series.mode() , the following operations are possible with categorical data: Series methods like Series.value_counts() will use all categories, even if some categories are not present in the data: DataFrame methods like DataFrame.sum() also show “unused” categories when observed=False . Groupby will also show “unused” categories when observed=False : Pivot tables: Data munging # The optimized pandas data access methods .loc , .iloc , .at , and .iat , work as normal. The only difference is the return type (for getting) and that only values already in categories can be assigned. Getting # If the slicing operation returns either a DataFrame or a column of type Series , the category dtype is preserved. An example where the category type is not preserved is if you take one single row: the resulting Series is of dtype object : Returning a single item from categorical data will also return the value, not a categorical of length “1”. Note The is in contrast to R’s factor function, where factor(c(1,2,3))[1] returns a single value factor . To get a single value Series of type category , you pass in a list with a single value: String and datetime accessors # The accessors .dt and .str will work if the s.cat.categories are of an appropriate type: Note The returned Series (or DataFrame ) is of the same type as if you used the .str.<method> / .dt.<method> on a Series of that type (and not of type category !). That means, that the returned values from methods and properties on the accessors of a Series and the returned values from methods and properties on the accessors of this Series transformed to one of type category will be equal: Note The work is done on the categories and then a new Series is constructed. This has some performance implication if you have a Series of type string, where lots of elements are repeated (i.e. the number of unique elements in the Series is a lot smaller than the length of the Series ). In this case it can be faster to convert the original Series to one of type category and use .str.<method> or .dt.<property> on that. Setting # Setting values in a categorical column (or Series ) works as long as the value is included in the categories : Setting values by assigning categorical data will also check that the categories match: Assigning a Categorical to parts of a column of other types will use the values: Merging / concatenation # By default, combining Series or DataFrames which contain the same categories results in category dtype, otherwise results will depend on the dtype of the underlying categories. Merges that result in non-categorical dtypes will likely have higher memory usage. Use .astype or union_categoricals to ensure category results. The following table summarizes the results of merging Categoricals : Unioning # If you want to combine categoricals that do not necessarily have the same categories, the union_categoricals() function will combine a list-like of categoricals. The new categories will be the union of the categories being combined. By default, the resulting categories will be ordered as they appear in the data. If you want the categories to be lexsorted, use sort_categories=True argument. union_categoricals also works with the “easy” case of combining two categoricals of the same categories and order information (e.g. what you could also append for). The below raises TypeError because the categories are ordered and not identical. Ordered categoricals with different categories or orderings can be combined by using the ignore_ordered=True argument. union_categoricals() also works with a CategoricalIndex , or Series containing categorical data, but note that the resulting array will always be a plain Categorical : Note union_categoricals may recode the integer codes for categories when combining categoricals. This is likely what you want, but if you are relying on the exact numbering of the categories, be aware. Getting data in/out # You can write data that contains category dtypes to a HDFStore . See here for an example and caveats. It is also possible to write data to and reading data from Stata format files. See here for an example and caveats. Writing to a CSV file will convert the data, effectively removing any information about the categorical (categories and ordering). So if you read back the CSV file you have to convert the relevant columns back to category and assign the right categories and categories ordering. The same holds for writing to a SQL database with to_sql . Missing data # pandas primarily uses the value np.nan to represent missing data. It is by default not included in computations. See the Missing Data section . Missing values should not be included in the Categorical’s categories , only in the values . Instead, it is understood that NaN is different, and is always a possibility. When working with the Categorical’s codes , missing values will always have a code of -1 . Methods for working with missing data, e.g. isna() , fillna() , dropna() , all work normally: Differences to R’s factor # The following differences to R’s factor functions can be observed: R’s levels are named categories . R’s levels are always of type string, while categories in pandas can be of any dtype. It’s not possible to specify labels at creation time. Use s.cat.rename_categories(new_labels) afterwards. In contrast to R’s factor function, using categorical data as the sole input to create a new categorical series will not remove unused categories but create a new categorical series which is equal to the passed in one! R allows for missing values to be included in its levels (pandas’ categories ). pandas does not allow NaN categories, but missing values can still be in the values . Gotchas # Memory usage # The memory usage of a Categorical is proportional to the number of categories plus the length of the data. In contrast, an object dtype is a constant times the length of the data. Note If the number of categories approaches the length of the data, the Categorical will use nearly the same or more memory than an equivalent object dtype representation. Categorical is not a numpy array # Currently, categorical data and the underlying Categorical is implemented as a Python object and not as a low-level NumPy array dtype. This leads to some problems. NumPy itself doesn’t know about the new dtype : Dtype comparisons work: To check if a Series contains Categorical data, use hasattr(s, 'cat') : Using NumPy functions on a Series of type category should not work as Categoricals are not numeric data (even in the case that .categories is numeric). Note If such a function works, please file a bug at pandas-dev/pandas ! dtype in apply # pandas currently does not preserve the dtype in apply functions: If you apply along rows you get a Series of object dtype (same as getting a row -> getting one element will return a basic type) and applying along columns will also convert to object. NaN values are unaffected. You can use fillna to handle missing values before applying a function. Categorical index # CategoricalIndex is a type of index that is useful for supporting indexing with duplicates. This is a container around a Categorical and allows efficient indexing and storage of an index with a large number of duplicated elements. See the advanced indexing docs for a more detailed explanation. Setting the index will create a CategoricalIndex : Side effects # Constructing a Series from a Categorical will not copy the input Categorical . This means that changes to the Series will in most cases change the original Categorical : Use copy=True to prevent such a behaviour or simply don’t reuse Categoricals : Note This also happens in some cases when you supply a NumPy array instead of a Categorical : using an int array (e.g. np.array([1,2,3,4]) ) will exhibit the same behavior, while using a string array (e.g. np.array([""a"",""b"",""c"",""a""]) ) will not."
https://pandas.pydata.org/docs/user_guide/integer_na.html,Nullable integer data type,"<article class=""bd-article"" role=""main"">
<section id=""nullable-integer-data-type"">
<span id=""integer-na""></span><h1>Nullable integer data type<a class=""headerlink"" href=""#nullable-integer-data-type"" title=""Link to this heading"">#</a></h1>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>IntegerArray is currently experimental. Its API or implementation may
change without warning. Uses <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">pandas.NA</span></code></a> as the missing value.</p>
</div>
<p>In <a class=""reference internal"" href=""missing_data.html#missing-data""><span class=""std std-ref"">Working with missing data</span></a>, we saw that pandas primarily uses <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code> to represent
missing data. Because <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code> is a float, this forces an array of integers with
any missing values to become floating point. In some cases, this may not matter
much. But if your integer column is, say, an identifier, casting to float can
be problematic. Some integers cannot even be represented as floating point
numbers.</p>
<section id=""construction"">
<h2>Construction<a class=""headerlink"" href=""#construction"" title=""Link to this heading"">#</a></h2>
<p>pandas can represent integer data with possibly missing values using
<a class=""reference internal"" href=""../reference/api/pandas.arrays.IntegerArray.html#pandas.arrays.IntegerArray"" title=""pandas.arrays.IntegerArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">arrays.IntegerArray</span></code></a>. This is an <a class=""reference internal"" href=""../development/extending.html#extending-extension-types""><span class=""std std-ref"">extension type</span></a>
implemented within pandas.</p>

<p>Or the string alias <code class=""docutils literal notranslate""><span class=""pre"">""Int64""</span></code> (note the capital <code class=""docutils literal notranslate""><span class=""pre"">""I""</span></code>) to differentiate from
NumPy’s <code class=""docutils literal notranslate""><span class=""pre"">'int64'</span></code> dtype:</p>

<p>All NA-like values are replaced with <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">pandas.NA</span></code></a>.</p>

<p>This array can be stored in a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> like any
NumPy array.</p>

<p>You can also pass the list-like object to the <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> constructor
with the dtype.</p>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Currently <a class=""reference internal"" href=""../reference/api/pandas.array.html#pandas.array"" title=""pandas.array""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">pandas.array()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">pandas.Series()</span></code></a> use different
rules for dtype inference. <a class=""reference internal"" href=""../reference/api/pandas.array.html#pandas.array"" title=""pandas.array""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">pandas.array()</span></code></a> will infer a
nullable-integer dtype</p>

<p>For backwards-compatibility, <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> infers these as either
integer or float dtype.</p>

<p>We recommend explicitly providing the dtype to avoid confusion.</p>

<p>In the future, we may provide an option for <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> to infer a
nullable-integer dtype.</p>
</div>
</section>
<section id=""operations"">
<h2>Operations<a class=""headerlink"" href=""#operations"" title=""Link to this heading"">#</a></h2>
<p>Operations involving an integer array will behave similar to NumPy arrays.
Missing values will be propagated, and the data will be coerced to another
dtype if needed.</p>

<p>These dtypes can operate as part of a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>.</p>

<p>These dtypes can be merged, reshaped &amp; casted.</p>

<p>Reduction and groupby operations such as <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.sum.html#pandas.DataFrame.sum"" title=""pandas.DataFrame.sum""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">sum()</span></code></a> work as well.</p>

</section>
<section id=""scalar-na-value"">
<h2>Scalar NA Value<a class=""headerlink"" href=""#scalar-na-value"" title=""Link to this heading"">#</a></h2>
<p><a class=""reference internal"" href=""../reference/api/pandas.arrays.IntegerArray.html#pandas.arrays.IntegerArray"" title=""pandas.arrays.IntegerArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">arrays.IntegerArray</span></code></a> uses <a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">pandas.NA</span></code></a> as its scalar
missing value. Slicing a single element that’s missing will return
<a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">pandas.NA</span></code></a></p>

</section>
</section>
</article>","Nullable integer data type # Note IntegerArray is currently experimental. Its API or implementation may change without warning. Uses pandas.NA as the missing value. In Working with missing data , we saw that pandas primarily uses NaN to represent missing data. Because NaN is a float, this forces an array of integers with any missing values to become floating point. In some cases, this may not matter much. But if your integer column is, say, an identifier, casting to float can be problematic. Some integers cannot even be represented as floating point numbers. Construction # pandas can represent integer data with possibly missing values using arrays.IntegerArray . This is an extension type implemented within pandas. Or the string alias ""Int64"" (note the capital ""I"" ) to differentiate from NumPy’s 'int64' dtype: All NA-like values are replaced with pandas.NA . This array can be stored in a DataFrame or Series like any NumPy array. You can also pass the list-like object to the Series constructor with the dtype. Warning Currently pandas.array() and pandas.Series() use different rules for dtype inference. pandas.array() will infer a nullable-integer dtype For backwards-compatibility, Series infers these as either integer or float dtype. We recommend explicitly providing the dtype to avoid confusion. In the future, we may provide an option for Series to infer a nullable-integer dtype. Operations # Operations involving an integer array will behave similar to NumPy arrays. Missing values will be propagated, and the data will be coerced to another dtype if needed. These dtypes can operate as part of a DataFrame . These dtypes can be merged, reshaped & casted. Reduction and groupby operations such as sum() work as well. Scalar NA Value # arrays.IntegerArray uses pandas.NA as its scalar missing value. Slicing a single element that’s missing will return pandas.NA"
https://pandas.pydata.org/docs/user_guide/boolean.html,Nullable Boolean data type,"<article class=""bd-article"" role=""main"">
<section id=""nullable-boolean-data-type"">
<span id=""boolean""></span><h1>Nullable Boolean data type<a class=""headerlink"" href=""#nullable-boolean-data-type"" title=""Link to this heading"">#</a></h1>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>BooleanArray is currently experimental. Its API or implementation may
change without warning.</p>
</div>
<section id=""indexing-with-na-values"">
<span id=""boolean-indexing""></span><h2>Indexing with NA values<a class=""headerlink"" href=""#indexing-with-na-values"" title=""Link to this heading"">#</a></h2>
<p>pandas allows indexing with <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> values in a boolean array, which are treated as <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>.</p>

<p>If you would prefer to keep the <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> values you can manually fill them with <code class=""docutils literal notranslate""><span class=""pre"">fillna(True)</span></code>.</p>

</section>
<section id=""kleene-logical-operations"">
<span id=""boolean-kleene""></span><h2>Kleene logical operations<a class=""headerlink"" href=""#kleene-logical-operations"" title=""Link to this heading"">#</a></h2>
<p><a class=""reference internal"" href=""../reference/api/pandas.arrays.BooleanArray.html#pandas.arrays.BooleanArray"" title=""pandas.arrays.BooleanArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">arrays.BooleanArray</span></code></a> implements <a class=""reference external"" href=""https://en.wikipedia.org/wiki/Three-valued_logic#Kleene_and_Priest_logics"">Kleene Logic</a> (sometimes called three-value logic) for
logical operations like <code class=""docutils literal notranslate""><span class=""pre"">&amp;</span></code> (and), <code class=""docutils literal notranslate""><span class=""pre"">|</span></code> (or) and <code class=""docutils literal notranslate""><span class=""pre"">^</span></code> (exclusive-or).</p>
<p>This table demonstrates the results for every combination. These operations are symmetrical,
so flipping the left- and right-hand side makes no difference in the result.</p>

<p>When an <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> is present in an operation, the output value is <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> only if
the result cannot be determined solely based on the other input. For example,
<code class=""docutils literal notranslate""><span class=""pre"">True</span> <span class=""pre"">|</span> <span class=""pre"">NA</span></code> is <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>, because both <code class=""docutils literal notranslate""><span class=""pre"">True</span> <span class=""pre"">|</span> <span class=""pre"">True</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">True</span> <span class=""pre"">|</span> <span class=""pre"">False</span></code>
are <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>. In that case, we don’t actually need to consider the value
of the <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code>.</p>
<p>On the other hand, <code class=""docutils literal notranslate""><span class=""pre"">True</span> <span class=""pre"">&amp;</span> <span class=""pre"">NA</span></code> is <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code>. The result depends on whether
the <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> really is <code class=""docutils literal notranslate""><span class=""pre"">True</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>, since <code class=""docutils literal notranslate""><span class=""pre"">True</span> <span class=""pre"">&amp;</span> <span class=""pre"">True</span></code> is <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>,
but <code class=""docutils literal notranslate""><span class=""pre"">True</span> <span class=""pre"">&amp;</span> <span class=""pre"">False</span></code> is <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>, so we can’t determine the output.</p>
<p>This differs from how <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code> behaves in logical operations. pandas treated
<code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code> is <em>always false in the output</em>.</p>
<p>In <code class=""docutils literal notranslate""><span class=""pre"">or</span></code></p>

<p>In <code class=""docutils literal notranslate""><span class=""pre"">and</span></code></p>

</section>
</section>
</article>","Nullable Boolean data type # Note BooleanArray is currently experimental. Its API or implementation may change without warning. Indexing with NA values # pandas allows indexing with NA values in a boolean array, which are treated as False . If you would prefer to keep the NA values you can manually fill them with fillna(True) . Kleene logical operations # arrays.BooleanArray implements Kleene Logic (sometimes called three-value logic) for logical operations like & (and), | (or) and ^ (exclusive-or). This table demonstrates the results for every combination. These operations are symmetrical, so flipping the left- and right-hand side makes no difference in the result. When an NA is present in an operation, the output value is NA only if the result cannot be determined solely based on the other input. For example, True | NA is True , because both True | True and True | False are True . In that case, we don’t actually need to consider the value of the NA . On the other hand, True & NA is NA . The result depends on whether the NA really is True or False , since True & True is True , but True & False is False , so we can’t determine the output. This differs from how np.nan behaves in logical operations. pandas treated np.nan is always false in the output . In or In and"
https://pandas.pydata.org/docs/user_guide/visualization.html,Chart visualization,"<article class=""bd-article"" role=""main"">
<section id=""chart-visualization"">
<span id=""visualization""></span><h1>Chart visualization<a class=""headerlink"" href=""#chart-visualization"" title=""Link to this heading"">#</a></h1>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The examples below assume that you’re using <a class=""reference external"" href=""https://jupyter.org/"">Jupyter</a>.</p>
</div>
<p>This section demonstrates visualization through charting. For information on
visualization of tabular data please see the section on <a class=""reference internal"" href=""style.html""><span class=""doc"">Table Visualization</span></a>.</p>
<p>We use the standard convention for referencing the matplotlib API:</p>

<p>We provide the basics in pandas to easily create decent looking plots.
See <a class=""reference external"" href=""https://pandas.pydata.org/community/ecosystem.html"">the ecosystem page</a> for visualization
libraries that go beyond the basics documented here.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>All calls to <code class=""docutils literal notranslate""><span class=""pre"">np.random</span></code> are seeded with 123456.</p>
</div>
<section id=""basic-plotting-plot"">
<span id=""visualization-basic""></span><h2>Basic plotting: <code class=""docutils literal notranslate""><span class=""pre"">plot</span></code><a class=""headerlink"" href=""#basic-plotting-plot"" title=""Link to this heading"">#</a></h2>
<p>We will demonstrate the basics, see the <a class=""reference internal"" href=""cookbook.html#cookbook-plotting""><span class=""std std-ref"">cookbook</span></a> for
some advanced strategies.</p>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">plot</span></code> method on Series and DataFrame is just a simple wrapper around
<a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.plot.html#matplotlib.axes.Axes.plot"" title=""(in Matplotlib v3.8.4)""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">plt.plot()</span></code></a>:</p>

<img alt=""../_images/series_plot_basic.png"" src=""../_images/series_plot_basic.png""/>
<p>If the index consists of dates, it calls <a class=""reference external"" href=""https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure.autofmt_xdate"" title=""(in Matplotlib v3.8.4)""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">gcf().autofmt_xdate()</span></code></a>
to try to format the x-axis nicely as per above.</p>
<p>On DataFrame, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.plot.html#pandas.DataFrame.plot"" title=""pandas.DataFrame.plot""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">plot()</span></code></a> is a convenience to plot all of the columns with labels:</p>

<img alt=""../_images/frame_plot_basic.png"" src=""../_images/frame_plot_basic.png""/>
<p>You can plot one column versus another using the <code class=""docutils literal notranslate""><span class=""pre"">x</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">y</span></code> keywords in
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.plot.html#pandas.DataFrame.plot"" title=""pandas.DataFrame.plot""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">plot()</span></code></a>:</p>

<img alt=""../_images/df_plot_xy.png"" src=""../_images/df_plot_xy.png""/>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>For more formatting and styling options, see
<a class=""reference internal"" href=""#visualization-formatting""><span class=""std std-ref"">formatting</span></a> below.</p>
</div>
</section>
<section id=""other-plots"">
<span id=""visualization-other""></span><h2>Other plots<a class=""headerlink"" href=""#other-plots"" title=""Link to this heading"">#</a></h2>
<p>Plotting methods allow for a handful of plot styles other than the
default line plot. These methods can be provided as the <code class=""docutils literal notranslate""><span class=""pre"">kind</span></code>
keyword argument to <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.plot.html#pandas.DataFrame.plot"" title=""pandas.DataFrame.plot""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">plot()</span></code></a>, and include:</p>
<ul class=""simple"">
<li><p><a class=""reference internal"" href=""#visualization-barplot""><span class=""std std-ref"">‘bar’</span></a> or <a class=""reference internal"" href=""#visualization-barplot""><span class=""std std-ref"">‘barh’</span></a> for bar plots</p></li>
<li><p><a class=""reference internal"" href=""#visualization-hist""><span class=""std std-ref"">‘hist’</span></a> for histogram</p></li>
<li><p><a class=""reference internal"" href=""#visualization-box""><span class=""std std-ref"">‘box’</span></a> for boxplot</p></li>
<li><p><a class=""reference internal"" href=""#visualization-kde""><span class=""std std-ref"">‘kde’</span></a> or <a class=""reference internal"" href=""#visualization-kde""><span class=""std std-ref"">‘density’</span></a> for density plots</p></li>
<li><p><a class=""reference internal"" href=""#visualization-area-plot""><span class=""std std-ref"">‘area’</span></a> for area plots</p></li>
<li><p><a class=""reference internal"" href=""#visualization-scatter""><span class=""std std-ref"">‘scatter’</span></a> for scatter plots</p></li>
<li><p><a class=""reference internal"" href=""#visualization-hexbin""><span class=""std std-ref"">‘hexbin’</span></a> for hexagonal bin plots</p></li>
<li><p><a class=""reference internal"" href=""#visualization-pie""><span class=""std std-ref"">‘pie’</span></a> for pie plots</p></li>
</ul>
<p>For example, a bar plot can be created the following way:</p>

<img alt=""../_images/bar_plot_ex.png"" src=""../_images/bar_plot_ex.png""/>
<p>You can also create these other plots using the methods <code class=""docutils literal notranslate""><span class=""pre"">DataFrame.plot.&lt;kind&gt;</span></code> instead of providing the <code class=""docutils literal notranslate""><span class=""pre"">kind</span></code> keyword argument. This makes it easier to discover plot methods and the specific arguments they use:</p>

<p>In addition to these <code class=""docutils literal notranslate""><span class=""pre"">kind</span></code> s, there are the <a class=""reference internal"" href=""#visualization-hist""><span class=""std std-ref"">DataFrame.hist()</span></a>,
and <a class=""reference internal"" href=""#visualization-box""><span class=""std std-ref"">DataFrame.boxplot()</span></a> methods, which use a separate interface.</p>
<p>Finally, there are several <a class=""reference internal"" href=""#visualization-tools""><span class=""std std-ref"">plotting functions</span></a> in <code class=""docutils literal notranslate""><span class=""pre"">pandas.plotting</span></code>
that take a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> as an argument. These
include:</p>
<ul class=""simple"">
<li><p><a class=""reference internal"" href=""#visualization-scatter-matrix""><span class=""std std-ref"">Scatter Matrix</span></a></p></li>
<li><p><a class=""reference internal"" href=""#visualization-andrews-curves""><span class=""std std-ref"">Andrews Curves</span></a></p></li>
<li><p><a class=""reference internal"" href=""#visualization-parallel-coordinates""><span class=""std std-ref"">Parallel Coordinates</span></a></p></li>
<li><p><a class=""reference internal"" href=""#visualization-lag""><span class=""std std-ref"">Lag Plot</span></a></p></li>
<li><p><a class=""reference internal"" href=""#visualization-autocorrelation""><span class=""std std-ref"">Autocorrelation Plot</span></a></p></li>
<li><p><a class=""reference internal"" href=""#visualization-bootstrap""><span class=""std std-ref"">Bootstrap Plot</span></a></p></li>
<li><p><a class=""reference internal"" href=""#visualization-radviz""><span class=""std std-ref"">RadViz</span></a></p></li>
</ul>
<p>Plots may also be adorned with <a class=""reference internal"" href=""#visualization-errorbars""><span class=""std std-ref"">errorbars</span></a>
or <a class=""reference internal"" href=""#visualization-table""><span class=""std std-ref"">tables</span></a>.</p>
<section id=""bar-plots"">
<span id=""visualization-barplot""></span><h3>Bar plots<a class=""headerlink"" href=""#bar-plots"" title=""Link to this heading"">#</a></h3>
<p>For labeled, non-time series data, you may wish to produce a bar plot:</p>

<img alt=""../_images/bar_plot_ex.png"" src=""../_images/bar_plot_ex.png""/>
<p>Calling a DataFrame’s <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.plot.bar.html#pandas.DataFrame.plot.bar"" title=""pandas.DataFrame.plot.bar""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">plot.bar()</span></code></a> method produces a multiple
bar plot:</p>

<img alt=""../_images/bar_plot_multi_ex.png"" src=""../_images/bar_plot_multi_ex.png""/>
<p>To produce a stacked bar plot, pass <code class=""docutils literal notranslate""><span class=""pre"">stacked=True</span></code>:</p>

<img alt=""../_images/bar_plot_stacked_ex.png"" src=""../_images/bar_plot_stacked_ex.png""/>
<p>To get horizontal bar plots, use the <code class=""docutils literal notranslate""><span class=""pre"">barh</span></code> method:</p>

<img alt=""../_images/barh_plot_stacked_ex.png"" src=""../_images/barh_plot_stacked_ex.png""/>
</section>
<section id=""histograms"">
<span id=""visualization-hist""></span><h3>Histograms<a class=""headerlink"" href=""#histograms"" title=""Link to this heading"">#</a></h3>
<p>Histograms can be drawn by using the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.plot.hist.html#pandas.DataFrame.plot.hist"" title=""pandas.DataFrame.plot.hist""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.plot.hist()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.Series.plot.hist.html#pandas.Series.plot.hist"" title=""pandas.Series.plot.hist""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.plot.hist()</span></code></a> methods.</p>

<img alt=""../_images/hist_new.png"" src=""../_images/hist_new.png""/>
<p>A histogram can be stacked using <code class=""docutils literal notranslate""><span class=""pre"">stacked=True</span></code>. Bin size can be changed
using the <code class=""docutils literal notranslate""><span class=""pre"">bins</span></code> keyword.</p>

<img alt=""../_images/hist_new_stacked.png"" src=""../_images/hist_new_stacked.png""/>
<p>You can pass other keywords supported by matplotlib <code class=""docutils literal notranslate""><span class=""pre"">hist</span></code>. For example,
horizontal and cumulative histograms can be drawn by
<code class=""docutils literal notranslate""><span class=""pre"">orientation='horizontal'</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">cumulative=True</span></code>.</p>

<img alt=""../_images/hist_new_kwargs.png"" src=""../_images/hist_new_kwargs.png""/>
<p>See the <a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.hist.html#matplotlib.axes.Axes.hist"" title=""(in Matplotlib v3.8.4)""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">hist</span></code></a> method and the
<a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html"">matplotlib hist documentation</a> for more.</p>
<p>The existing interface <code class=""docutils literal notranslate""><span class=""pre"">DataFrame.hist</span></code> to plot histogram still can be used.</p>

<img alt=""../_images/hist_plot_ex.png"" src=""../_images/hist_plot_ex.png""/>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.hist.html#pandas.DataFrame.hist"" title=""pandas.DataFrame.hist""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.hist()</span></code></a> plots the histograms of the columns on multiple
subplots:</p>

<img alt=""../_images/frame_hist_ex.png"" src=""../_images/frame_hist_ex.png""/>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">by</span></code> keyword can be specified to plot grouped histograms:</p>

<img alt=""../_images/grouped_hist.png"" src=""../_images/grouped_hist.png""/>
<p>In addition, the <code class=""docutils literal notranslate""><span class=""pre"">by</span></code> keyword can also be specified in <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.plot.hist.html#pandas.DataFrame.plot.hist"" title=""pandas.DataFrame.plot.hist""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.plot.hist()</span></code></a>.</p>
<div class=""versionchanged"">
<p><span class=""versionmodified changed"">Changed in version 1.4.0.</span></p>
</div>

<img alt=""../_images/grouped_hist_by.png"" src=""../_images/grouped_hist_by.png""/>
</section>
<section id=""box-plots"">
<span id=""visualization-box""></span><h3>Box plots<a class=""headerlink"" href=""#box-plots"" title=""Link to this heading"">#</a></h3>
<p>Boxplot can be drawn calling <a class=""reference internal"" href=""../reference/api/pandas.Series.plot.box.html#pandas.Series.plot.box"" title=""pandas.Series.plot.box""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.plot.box()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.plot.box.html#pandas.DataFrame.plot.box"" title=""pandas.DataFrame.plot.box""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.plot.box()</span></code></a>,
or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.boxplot.html#pandas.DataFrame.boxplot"" title=""pandas.DataFrame.boxplot""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.boxplot()</span></code></a> to visualize the distribution of values within each column.</p>
<p>For instance, here is a boxplot representing five trials of 10 observations of
a uniform random variable on [0,1).</p>

<img alt=""../_images/box_plot_new.png"" src=""../_images/box_plot_new.png""/>
<p>Boxplot can be colorized by passing <code class=""docutils literal notranslate""><span class=""pre"">color</span></code> keyword. You can pass a <code class=""docutils literal notranslate""><span class=""pre"">dict</span></code>
whose keys are <code class=""docutils literal notranslate""><span class=""pre"">boxes</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">whiskers</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">medians</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">caps</span></code>.
If some keys are missing in the <code class=""docutils literal notranslate""><span class=""pre"">dict</span></code>, default colors are used
for the corresponding artists. Also, boxplot has <code class=""docutils literal notranslate""><span class=""pre"">sym</span></code> keyword to specify fliers style.</p>
<p>When you pass other type of arguments via <code class=""docutils literal notranslate""><span class=""pre"">color</span></code> keyword, it will be directly
passed to matplotlib for all the <code class=""docutils literal notranslate""><span class=""pre"">boxes</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">whiskers</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">medians</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">caps</span></code>
colorization.</p>
<p>The colors are applied to every boxes to be drawn. If you want
more complicated colorization, you can get each drawn artists by passing
<a class=""reference internal"" href=""#visualization-box-return""><span class=""std std-ref"">return_type</span></a>.</p>

<img alt=""../_images/box_new_colorize.png"" src=""../_images/box_new_colorize.png""/>
<p>Also, you can pass other keywords supported by matplotlib <code class=""docutils literal notranslate""><span class=""pre"">boxplot</span></code>.
For example, horizontal and custom-positioned boxplot can be drawn by
<code class=""docutils literal notranslate""><span class=""pre"">vert=False</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">positions</span></code> keywords.</p>

<img alt=""../_images/box_new_kwargs.png"" src=""../_images/box_new_kwargs.png""/>
<p>See the <a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.boxplot.html#matplotlib.axes.Axes.boxplot"" title=""(in Matplotlib v3.8.4)""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">boxplot</span></code></a> method and the
<a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.boxplot.html"">matplotlib boxplot documentation</a> for more.</p>
<p>The existing interface <code class=""docutils literal notranslate""><span class=""pre"">DataFrame.boxplot</span></code> to plot boxplot still can be used.</p>

<img alt=""../_images/box_plot_ex.png"" src=""../_images/box_plot_ex.png""/>
<p>You can create a stratified boxplot using the <code class=""docutils literal notranslate""><span class=""pre"">by</span></code> keyword argument to create
groupings. For instance,</p>

<img alt=""../_images/box_plot_ex2.png"" src=""../_images/box_plot_ex2.png""/>
<p>You can also pass a subset of columns to plot, as well as group by multiple
columns:</p>

<img alt=""../_images/box_plot_ex3.png"" src=""../_images/box_plot_ex3.png""/>
<p>You could also create groupings with <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.plot.box.html#pandas.DataFrame.plot.box"" title=""pandas.DataFrame.plot.box""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.plot.box()</span></code></a>, for instance:</p>
<div class=""versionchanged"">
<p><span class=""versionmodified changed"">Changed in version 1.4.0.</span></p>
</div>

<img alt=""../_images/box_plot_ex4.png"" src=""../_images/box_plot_ex4.png""/>
<p id=""visualization-box-return"">In <code class=""docutils literal notranslate""><span class=""pre"">boxplot</span></code>, the return type can be controlled by the <code class=""docutils literal notranslate""><span class=""pre"">return_type</span></code>, keyword. The valid choices are <code class=""docutils literal notranslate""><span class=""pre"">{""axes"",</span> <span class=""pre"">""dict"",</span> <span class=""pre"">""both"",</span> <span class=""pre"">None}</span></code>.
Faceting, created by <code class=""docutils literal notranslate""><span class=""pre"">DataFrame.boxplot</span></code> with the <code class=""docutils literal notranslate""><span class=""pre"">by</span></code>
keyword, will affect the output type as well:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">Groupby.boxplot</span></code> always returns a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> of <code class=""docutils literal notranslate""><span class=""pre"">return_type</span></code>.</p>

<img alt=""../_images/boxplot_groupby.png"" src=""../_images/boxplot_groupby.png""/>
<p>The subplots above are split by the numeric columns first, then the value of
the <code class=""docutils literal notranslate""><span class=""pre"">g</span></code> column. Below the subplots are first split by the value of <code class=""docutils literal notranslate""><span class=""pre"">g</span></code>,
then by the numeric columns.</p>

<img alt=""../_images/groupby_boxplot_vis.png"" src=""../_images/groupby_boxplot_vis.png""/>
</section>
<section id=""area-plot"">
<span id=""visualization-area-plot""></span><h3>Area plot<a class=""headerlink"" href=""#area-plot"" title=""Link to this heading"">#</a></h3>
<p>You can create area plots with <a class=""reference internal"" href=""../reference/api/pandas.Series.plot.area.html#pandas.Series.plot.area"" title=""pandas.Series.plot.area""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.plot.area()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.plot.area.html#pandas.DataFrame.plot.area"" title=""pandas.DataFrame.plot.area""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.plot.area()</span></code></a>.
Area plots are stacked by default. To produce stacked area plot, each column must be either all positive or all negative values.</p>
<p>When input data contains <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>, it will be automatically filled by 0. If you want to drop or fill by different values, use <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">dataframe.dropna()</span></code> or <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">dataframe.fillna()</span></code> before calling <code class=""docutils literal notranslate""><span class=""pre"">plot</span></code>.</p>

<img alt=""../_images/area_plot_stacked.png"" src=""../_images/area_plot_stacked.png""/>
<p>To produce an unstacked plot, pass <code class=""docutils literal notranslate""><span class=""pre"">stacked=False</span></code>. Alpha value is set to 0.5 unless otherwise specified:</p>

<img alt=""../_images/area_plot_unstacked.png"" src=""../_images/area_plot_unstacked.png""/>
</section>
<section id=""scatter-plot"">
<span id=""visualization-scatter""></span><h3>Scatter plot<a class=""headerlink"" href=""#scatter-plot"" title=""Link to this heading"">#</a></h3>
<p>Scatter plot can be drawn by using the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.plot.scatter.html#pandas.DataFrame.plot.scatter"" title=""pandas.DataFrame.plot.scatter""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.plot.scatter()</span></code></a> method.
Scatter plot requires numeric columns for the x and y axes.
These can be specified by the <code class=""docutils literal notranslate""><span class=""pre"">x</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">y</span></code> keywords.</p>

<img alt=""../_images/scatter_plot.png"" src=""../_images/scatter_plot.png""/>
<p>To plot multiple column groups in a single axes, repeat <code class=""docutils literal notranslate""><span class=""pre"">plot</span></code> method specifying target <code class=""docutils literal notranslate""><span class=""pre"">ax</span></code>.
It is recommended to specify <code class=""docutils literal notranslate""><span class=""pre"">color</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">label</span></code> keywords to distinguish each groups.</p>

<img alt=""../_images/scatter_plot_repeated.png"" src=""../_images/scatter_plot_repeated.png""/>
<p>The keyword <code class=""docutils literal notranslate""><span class=""pre"">c</span></code> may be given as the name of a column to provide colors for
each point:</p>

<img alt=""../_images/scatter_plot_colored.png"" src=""../_images/scatter_plot_colored.png""/>
<p>If a categorical column is passed to <code class=""docutils literal notranslate""><span class=""pre"">c</span></code>, then a discrete colorbar will be produced:</p>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.3.0.</span></p>
</div>

<img alt=""../_images/scatter_plot_categorical.png"" src=""../_images/scatter_plot_categorical.png""/>
<p>You can pass other keywords supported by matplotlib
<a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.scatter.html#matplotlib.axes.Axes.scatter"" title=""(in Matplotlib v3.8.4)""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">scatter</span></code></a>. The example below shows a
bubble chart using a column of the <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> as the bubble size.</p>

<img alt=""../_images/scatter_plot_bubble.png"" src=""../_images/scatter_plot_bubble.png""/>
<p>See the <a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.scatter.html#matplotlib.axes.Axes.scatter"" title=""(in Matplotlib v3.8.4)""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">scatter</span></code></a> method and the
<a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html"">matplotlib scatter documentation</a> for more.</p>
</section>
<section id=""hexagonal-bin-plot"">
<span id=""visualization-hexbin""></span><h3>Hexagonal bin plot<a class=""headerlink"" href=""#hexagonal-bin-plot"" title=""Link to this heading"">#</a></h3>
<p>You can create hexagonal bin plots with <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.plot.hexbin.html#pandas.DataFrame.plot.hexbin"" title=""pandas.DataFrame.plot.hexbin""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.plot.hexbin()</span></code></a>.
Hexbin plots can be a useful alternative to scatter plots if your data are
too dense to plot each point individually.</p>

<img alt=""../_images/hexbin_plot.png"" src=""../_images/hexbin_plot.png""/>
<p>A useful keyword argument is <code class=""docutils literal notranslate""><span class=""pre"">gridsize</span></code>; it controls the number of hexagons
in the x-direction, and defaults to 100. A larger <code class=""docutils literal notranslate""><span class=""pre"">gridsize</span></code> means more, smaller
bins.</p>
<p>By default, a histogram of the counts around each <code class=""docutils literal notranslate""><span class=""pre"">(x,</span> <span class=""pre"">y)</span></code> point is computed.
You can specify alternative aggregations by passing values to the <code class=""docutils literal notranslate""><span class=""pre"">C</span></code> and
<code class=""docutils literal notranslate""><span class=""pre"">reduce_C_function</span></code> arguments. <code class=""docutils literal notranslate""><span class=""pre"">C</span></code> specifies the value at each <code class=""docutils literal notranslate""><span class=""pre"">(x,</span> <span class=""pre"">y)</span></code> point
and <code class=""docutils literal notranslate""><span class=""pre"">reduce_C_function</span></code> is a function of one argument that reduces all the
values in a bin to a single number (e.g. <code class=""docutils literal notranslate""><span class=""pre"">mean</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">max</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">sum</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">std</span></code>). In this
example the positions are given by columns <code class=""docutils literal notranslate""><span class=""pre"">a</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">b</span></code>, while the value is
given by column <code class=""docutils literal notranslate""><span class=""pre"">z</span></code>. The bins are aggregated with NumPy’s <code class=""docutils literal notranslate""><span class=""pre"">max</span></code> function.</p>

<img alt=""../_images/hexbin_plot_agg.png"" src=""../_images/hexbin_plot_agg.png""/>
<p>See the <a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.hexbin.html#matplotlib.axes.Axes.hexbin"" title=""(in Matplotlib v3.8.4)""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">hexbin</span></code></a> method and the
<a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hexbin.html"">matplotlib hexbin documentation</a> for more.</p>
</section>
<section id=""pie-plot"">
<span id=""visualization-pie""></span><h3>Pie plot<a class=""headerlink"" href=""#pie-plot"" title=""Link to this heading"">#</a></h3>
<p>You can create a pie plot with <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.plot.pie.html#pandas.DataFrame.plot.pie"" title=""pandas.DataFrame.plot.pie""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.plot.pie()</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.Series.plot.pie.html#pandas.Series.plot.pie"" title=""pandas.Series.plot.pie""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.plot.pie()</span></code></a>.
If your data includes any <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>, they will be automatically filled with 0.
A <code class=""docutils literal notranslate""><span class=""pre"">ValueError</span></code> will be raised if there are any negative values in your data.</p>

<img alt=""../_images/series_pie_plot.png"" src=""../_images/series_pie_plot.png""/>
<p>For pie plots it’s best to use square figures, i.e. a figure aspect ratio 1.
You can create the figure with equal width and height, or force the aspect ratio
to be equal after plotting by calling <code class=""docutils literal notranslate""><span class=""pre"">ax.set_aspect('equal')</span></code> on the returned
<code class=""docutils literal notranslate""><span class=""pre"">axes</span></code> object.</p>
<p>Note that pie plot with <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> requires that you either specify a
target column by the <code class=""docutils literal notranslate""><span class=""pre"">y</span></code> argument or <code class=""docutils literal notranslate""><span class=""pre"">subplots=True</span></code>. When <code class=""docutils literal notranslate""><span class=""pre"">y</span></code> is
specified, pie plot of selected column will be drawn. If <code class=""docutils literal notranslate""><span class=""pre"">subplots=True</span></code> is
specified, pie plots for each column are drawn as subplots. A legend will be
drawn in each pie plots by default; specify <code class=""docutils literal notranslate""><span class=""pre"">legend=False</span></code> to hide it.</p>

<img alt=""../_images/df_pie_plot.png"" src=""../_images/df_pie_plot.png""/>
<p>You can use the <code class=""docutils literal notranslate""><span class=""pre"">labels</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">colors</span></code> keywords to specify the labels and colors of each wedge.</p>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Most pandas plots use the <code class=""docutils literal notranslate""><span class=""pre"">label</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">color</span></code> arguments (note the lack of “s” on those).
To be consistent with <a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.pie.html#matplotlib.pyplot.pie"" title=""(in Matplotlib v3.8.4)""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">matplotlib.pyplot.pie()</span></code></a> you must use <code class=""docutils literal notranslate""><span class=""pre"">labels</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">colors</span></code>.</p>
</div>
<p>If you want to hide wedge labels, specify <code class=""docutils literal notranslate""><span class=""pre"">labels=None</span></code>.
If <code class=""docutils literal notranslate""><span class=""pre"">fontsize</span></code> is specified, the value will be applied to wedge labels.
Also, other keywords supported by <a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.pie.html#matplotlib.pyplot.pie"" title=""(in Matplotlib v3.8.4)""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">matplotlib.pyplot.pie()</span></code></a> can be used.</p>

<img alt=""../_images/series_pie_plot_options.png"" src=""../_images/series_pie_plot_options.png""/>
<p>If you pass values whose sum total is less than 1.0 they will be rescaled so that they sum to 1.</p>

<img alt=""../_images/series_pie_plot_semi.png"" src=""../_images/series_pie_plot_semi.png""/>
<p>See the <a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.pie.html"">matplotlib pie documentation</a> for more.</p>
</section>
</section>
<section id=""plotting-with-missing-data"">
<span id=""visualization-missing-data""></span><h2>Plotting with missing data<a class=""headerlink"" href=""#plotting-with-missing-data"" title=""Link to this heading"">#</a></h2>
<p>pandas tries to be pragmatic about plotting <code class=""docutils literal notranslate""><span class=""pre"">DataFrames</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>
that contain missing data. Missing values are dropped, left out, or filled
depending on the plot type.</p>

<p>If any of these defaults are not what you want, or if you want to be
explicit about how missing values are handled, consider using
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna"" title=""pandas.DataFrame.fillna""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">fillna()</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.dropna.html#pandas.DataFrame.dropna"" title=""pandas.DataFrame.dropna""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">dropna()</span></code></a>
before plotting.</p>
</section>
<section id=""plotting-tools"">
<span id=""visualization-tools""></span><h2>Plotting tools<a class=""headerlink"" href=""#plotting-tools"" title=""Link to this heading"">#</a></h2>
<p>These functions can be imported from <code class=""docutils literal notranslate""><span class=""pre"">pandas.plotting</span></code>
and take a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> as an argument.</p>
<section id=""scatter-matrix-plot"">
<span id=""visualization-scatter-matrix""></span><h3>Scatter matrix plot<a class=""headerlink"" href=""#scatter-matrix-plot"" title=""Link to this heading"">#</a></h3>
<p>You can create a scatter plot matrix using the
<code class=""docutils literal notranslate""><span class=""pre"">scatter_matrix</span></code> method in <code class=""docutils literal notranslate""><span class=""pre"">pandas.plotting</span></code>:</p>

<img alt=""../_images/scatter_matrix_kde.png"" src=""../_images/scatter_matrix_kde.png""/>
</section>
<section id=""density-plot"">
<span id=""visualization-kde""></span><h3>Density plot<a class=""headerlink"" href=""#density-plot"" title=""Link to this heading"">#</a></h3>
<p>You can create density plots using the <a class=""reference internal"" href=""../reference/api/pandas.Series.plot.kde.html#pandas.Series.plot.kde"" title=""pandas.Series.plot.kde""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.plot.kde()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.plot.kde.html#pandas.DataFrame.plot.kde"" title=""pandas.DataFrame.plot.kde""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.plot.kde()</span></code></a> methods.</p>

<img alt=""../_images/kde_plot.png"" src=""../_images/kde_plot.png""/>
</section>
<section id=""andrews-curves"">
<span id=""visualization-andrews-curves""></span><h3>Andrews curves<a class=""headerlink"" href=""#andrews-curves"" title=""Link to this heading"">#</a></h3>
<p>Andrews curves allow one to plot multivariate data as a large number
of curves that are created using the attributes of samples as coefficients
for Fourier series, see the <a class=""reference external"" href=""https://en.wikipedia.org/wiki/Andrews_plot"">Wikipedia entry</a>
for more information. By coloring these curves differently for each class
it is possible to visualize data clustering. Curves belonging to samples
of the same class will usually be closer together and form larger structures.</p>
<p><strong>Note</strong>: The “Iris” dataset is available <a class=""reference external"" href=""https://raw.githubusercontent.com/pandas-dev/pandas/main/pandas/tests/io/data/csv/iris.csv"">here</a>.</p>

<img alt=""../_images/andrews_curves.png"" src=""../_images/andrews_curves.png""/>
</section>
<section id=""parallel-coordinates"">
<span id=""visualization-parallel-coordinates""></span><h3>Parallel coordinates<a class=""headerlink"" href=""#parallel-coordinates"" title=""Link to this heading"">#</a></h3>
<p>Parallel coordinates is a plotting technique for plotting multivariate data,
see the <a class=""reference external"" href=""https://en.wikipedia.org/wiki/Parallel_coordinates"">Wikipedia entry</a>
for an introduction.
Parallel coordinates allows one to see clusters in data and to estimate other statistics visually.
Using parallel coordinates points are represented as connected line segments.
Each vertical line represents one attribute. One set of connected line segments
represents one data point. Points that tend to cluster will appear closer together.</p>

<img alt=""../_images/parallel_coordinates.png"" src=""../_images/parallel_coordinates.png""/>
</section>
<section id=""lag-plot"">
<span id=""visualization-lag""></span><h3>Lag plot<a class=""headerlink"" href=""#lag-plot"" title=""Link to this heading"">#</a></h3>
<p>Lag plots are used to check if a data set or time series is random. Random
data should not exhibit any structure in the lag plot. Non-random structure
implies that the underlying data are not random. The <code class=""docutils literal notranslate""><span class=""pre"">lag</span></code> argument may
be passed, and when <code class=""docutils literal notranslate""><span class=""pre"">lag=1</span></code> the plot is essentially <code class=""docutils literal notranslate""><span class=""pre"">data[:-1]</span></code> vs.
<code class=""docutils literal notranslate""><span class=""pre"">data[1:]</span></code>.</p>

<img alt=""../_images/lag_plot.png"" src=""../_images/lag_plot.png""/>
</section>
<section id=""autocorrelation-plot"">
<span id=""visualization-autocorrelation""></span><h3>Autocorrelation plot<a class=""headerlink"" href=""#autocorrelation-plot"" title=""Link to this heading"">#</a></h3>
<p>Autocorrelation plots are often used for checking randomness in time series.
This is done by computing autocorrelations for data values at varying time lags.
If time series is random, such autocorrelations should be near zero for any and
all time-lag separations. If time series is non-random then one or more of the
autocorrelations will be significantly non-zero. The horizontal lines displayed
in the plot correspond to 95% and 99% confidence bands. The dashed line is 99%
confidence band. See the
<a class=""reference external"" href=""https://en.wikipedia.org/wiki/Correlogram"">Wikipedia entry</a> for more about
autocorrelation plots.</p>

<img alt=""../_images/autocorrelation_plot.png"" src=""../_images/autocorrelation_plot.png""/>
</section>
<section id=""bootstrap-plot"">
<span id=""visualization-bootstrap""></span><h3>Bootstrap plot<a class=""headerlink"" href=""#bootstrap-plot"" title=""Link to this heading"">#</a></h3>
<p>Bootstrap plots are used to visually assess the uncertainty of a statistic, such
as mean, median, midrange, etc. A random subset of a specified size is selected
from a data set, the statistic in question is computed for this subset and the
process is repeated a specified number of times. Resulting plots and histograms
are what constitutes the bootstrap plot.</p>

<img alt=""../_images/bootstrap_plot.png"" src=""../_images/bootstrap_plot.png""/>
</section>
<section id=""radviz"">
<span id=""visualization-radviz""></span><h3>RadViz<a class=""headerlink"" href=""#radviz"" title=""Link to this heading"">#</a></h3>
<p>RadViz is a way of visualizing multi-variate data. It is based on a simple
spring tension minimization algorithm. Basically you set up a bunch of points in
a plane. In our case they are equally spaced on a unit circle. Each point
represents a single attribute. You then pretend that each sample in the data set
is attached to each of these points by a spring, the stiffness of which is
proportional to the numerical value of that attribute (they are normalized to
unit interval). The point in the plane, where our sample settles to (where the
forces acting on our sample are at an equilibrium) is where a dot representing
our sample will be drawn. Depending on which class that sample belongs it will
be colored differently.
See the R package <a class=""reference external"" href=""https://cran.r-project.org/web/packages/Radviz/index.html"">Radviz</a>
for more information.</p>
<p><strong>Note</strong>: The “Iris” dataset is available <a class=""reference external"" href=""https://raw.githubusercontent.com/pandas-dev/pandas/main/pandas/tests/io/data/csv/iris.csv"">here</a>.</p>

<img alt=""../_images/radviz.png"" src=""../_images/radviz.png""/>
</section>
</section>
<section id=""plot-formatting"">
<span id=""visualization-formatting""></span><h2>Plot formatting<a class=""headerlink"" href=""#plot-formatting"" title=""Link to this heading"">#</a></h2>
<section id=""setting-the-plot-style"">
<h3>Setting the plot style<a class=""headerlink"" href=""#setting-the-plot-style"" title=""Link to this heading"">#</a></h3>
<p>From version 1.5 and up, matplotlib offers a range of pre-configured plotting styles. Setting the
style can be used to easily give plots the general look that you want.
Setting the style is as easy as calling <code class=""docutils literal notranslate""><span class=""pre"">matplotlib.style.use(my_plot_style)</span></code> before
creating your plot. For example you could write <code class=""docutils literal notranslate""><span class=""pre"">matplotlib.style.use('ggplot')</span></code> for ggplot-style
plots.</p>
<p>You can see the various available style names at <code class=""docutils literal notranslate""><span class=""pre"">matplotlib.style.available</span></code> and it’s very
easy to try them out.</p>
</section>
<section id=""general-plot-style-arguments"">
<h3>General plot style arguments<a class=""headerlink"" href=""#general-plot-style-arguments"" title=""Link to this heading"">#</a></h3>
<p>Most plotting methods have a set of keyword arguments that control the
layout and formatting of the returned plot:</p>

<img alt=""../_images/series_plot_basic2.png"" src=""../_images/series_plot_basic2.png""/>
<p>For each kind of plot (e.g. <code class=""docutils literal notranslate""><span class=""pre"">line</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">bar</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">scatter</span></code>) any additional arguments
keywords are passed along to the corresponding matplotlib function
(<a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.plot.html#matplotlib.axes.Axes.plot"" title=""(in Matplotlib v3.8.4)""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">ax.plot()</span></code></a>,
<a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.bar.html#matplotlib.axes.Axes.bar"" title=""(in Matplotlib v3.8.4)""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">ax.bar()</span></code></a>,
<a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.scatter.html#matplotlib.axes.Axes.scatter"" title=""(in Matplotlib v3.8.4)""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">ax.scatter()</span></code></a>). These can be used
to control additional styling, beyond what pandas provides.</p>
</section>
<section id=""controlling-the-legend"">
<h3>Controlling the legend<a class=""headerlink"" href=""#controlling-the-legend"" title=""Link to this heading"">#</a></h3>
<p>You may set the <code class=""docutils literal notranslate""><span class=""pre"">legend</span></code> argument to <code class=""docutils literal notranslate""><span class=""pre"">False</span></code> to hide the legend, which is
shown by default.</p>

<img alt=""../_images/frame_plot_basic_noleg.png"" src=""../_images/frame_plot_basic_noleg.png""/>
</section>
<section id=""controlling-the-labels"">
<h3>Controlling the labels<a class=""headerlink"" href=""#controlling-the-labels"" title=""Link to this heading"">#</a></h3>
<p>You may set the <code class=""docutils literal notranslate""><span class=""pre"">xlabel</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">ylabel</span></code> arguments to give the plot custom labels
for x and y axis. By default, pandas will pick up index name as xlabel, while leaving
it empty for ylabel.</p>


<img alt=""../_images/plot_xlabel_ylabel.png"" src=""../_images/plot_xlabel_ylabel.png""/>
</section>
<section id=""scales"">
<h3>Scales<a class=""headerlink"" href=""#scales"" title=""Link to this heading"">#</a></h3>
<p>You may pass <code class=""docutils literal notranslate""><span class=""pre"">logy</span></code> to get a log-scale Y axis.</p>

<img alt=""../_images/series_plot_logy.png"" src=""../_images/series_plot_logy.png""/>
<p>See also the <code class=""docutils literal notranslate""><span class=""pre"">logx</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">loglog</span></code> keyword arguments.</p>
</section>
<section id=""plotting-on-a-secondary-y-axis"">
<h3>Plotting on a secondary y-axis<a class=""headerlink"" href=""#plotting-on-a-secondary-y-axis"" title=""Link to this heading"">#</a></h3>
<p>To plot data on a secondary y-axis, use the <code class=""docutils literal notranslate""><span class=""pre"">secondary_y</span></code> keyword:</p>

<img alt=""../_images/series_plot_secondary_y.png"" src=""../_images/series_plot_secondary_y.png""/>
<p>To plot some columns in a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>, give the column names to the <code class=""docutils literal notranslate""><span class=""pre"">secondary_y</span></code>
keyword:</p>

<img alt=""../_images/frame_plot_secondary_y.png"" src=""../_images/frame_plot_secondary_y.png""/>
<p>Note that the columns plotted on the secondary y-axis is automatically marked
with “(right)” in the legend. To turn off the automatic marking, use the
<code class=""docutils literal notranslate""><span class=""pre"">mark_right=False</span></code> keyword:</p>

<img alt=""../_images/frame_plot_secondary_y_no_right.png"" src=""../_images/frame_plot_secondary_y_no_right.png""/>
</section>
<section id=""custom-formatters-for-timeseries-plots"">
<span id=""plotting-formatters""></span><h3>Custom formatters for timeseries plots<a class=""headerlink"" href=""#custom-formatters-for-timeseries-plots"" title=""Link to this heading"">#</a></h3>
<p>pandas provides custom formatters for timeseries plots. These change the
formatting of the axis labels for dates and times. By default,
the custom formatters are applied only to plots created by pandas with
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.plot.html#pandas.DataFrame.plot"" title=""pandas.DataFrame.plot""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.plot()</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.Series.plot.html#pandas.Series.plot"" title=""pandas.Series.plot""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.plot()</span></code></a>. To have them apply to all
plots, including those made by matplotlib, set the option
<code class=""docutils literal notranslate""><span class=""pre"">pd.options.plotting.matplotlib.register_converters</span> <span class=""pre"">=</span> <span class=""pre"">True</span></code> or use
<a class=""reference internal"" href=""../reference/api/pandas.plotting.register_matplotlib_converters.html#pandas.plotting.register_matplotlib_converters"" title=""pandas.plotting.register_matplotlib_converters""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">pandas.plotting.register_matplotlib_converters()</span></code></a>.</p>
</section>
<section id=""suppressing-tick-resolution-adjustment"">
<h3>Suppressing tick resolution adjustment<a class=""headerlink"" href=""#suppressing-tick-resolution-adjustment"" title=""Link to this heading"">#</a></h3>
<p>pandas includes automatic tick resolution adjustment for regular frequency
time-series data. For limited cases where pandas cannot infer the frequency
information (e.g., in an externally created <code class=""docutils literal notranslate""><span class=""pre"">twinx</span></code>), you can choose to
suppress this behavior for alignment purposes.</p>
<p>Here is the default behavior, notice how the x-axis tick labeling is performed:</p>

<img alt=""../_images/ser_plot_suppress.png"" src=""../_images/ser_plot_suppress.png""/>
<p>Using the <code class=""docutils literal notranslate""><span class=""pre"">x_compat</span></code> parameter, you can suppress this behavior:</p>

<img alt=""../_images/ser_plot_suppress_parm.png"" src=""../_images/ser_plot_suppress_parm.png""/>
<p>If you have more than one plot that needs to be suppressed, the <code class=""docutils literal notranslate""><span class=""pre"">use</span></code> method
in <code class=""docutils literal notranslate""><span class=""pre"">pandas.plotting.plot_params</span></code> can be used in a <code class=""docutils literal notranslate""><span class=""pre"">with</span></code> statement:</p>

<img alt=""../_images/ser_plot_suppress_context.png"" src=""../_images/ser_plot_suppress_context.png""/>
</section>
<section id=""automatic-date-tick-adjustment"">
<h3>Automatic date tick adjustment<a class=""headerlink"" href=""#automatic-date-tick-adjustment"" title=""Link to this heading"">#</a></h3>
<p><code class=""docutils literal notranslate""><span class=""pre"">TimedeltaIndex</span></code> now uses the native matplotlib
tick locator methods, it is useful to call the automatic
date tick adjustment from matplotlib for figures whose ticklabels overlap.</p>
<p>See the <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">autofmt_xdate</span></code> method and the
<a class=""reference external"" href=""https://matplotlib.org/2.0.2/users/recipes.html#fixing-common-date-annoyances"">matplotlib documentation</a> for more.</p>
</section>
<section id=""subplots"">
<h3>Subplots<a class=""headerlink"" href=""#subplots"" title=""Link to this heading"">#</a></h3>
<p>Each <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> in a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> can be plotted on a different axis
with the <code class=""docutils literal notranslate""><span class=""pre"">subplots</span></code> keyword:</p>

<img alt=""../_images/frame_plot_subplots.png"" src=""../_images/frame_plot_subplots.png""/>
</section>
<section id=""using-layout-and-targeting-multiple-axes"">
<h3>Using layout and targeting multiple axes<a class=""headerlink"" href=""#using-layout-and-targeting-multiple-axes"" title=""Link to this heading"">#</a></h3>
<p>The layout of subplots can be specified by the <code class=""docutils literal notranslate""><span class=""pre"">layout</span></code> keyword. It can accept
<code class=""docutils literal notranslate""><span class=""pre"">(rows,</span> <span class=""pre"">columns)</span></code>. The <code class=""docutils literal notranslate""><span class=""pre"">layout</span></code> keyword can be used in
<code class=""docutils literal notranslate""><span class=""pre"">hist</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">boxplot</span></code> also. If the input is invalid, a <code class=""docutils literal notranslate""><span class=""pre"">ValueError</span></code> will be raised.</p>
<p>The number of axes which can be contained by rows x columns specified by <code class=""docutils literal notranslate""><span class=""pre"">layout</span></code> must be
larger than the number of required subplots. If layout can contain more axes than required,
blank axes are not drawn. Similar to a NumPy array’s <code class=""docutils literal notranslate""><span class=""pre"">reshape</span></code> method, you
can use <code class=""docutils literal notranslate""><span class=""pre"">-1</span></code> for one dimension to automatically calculate the number of rows
or columns needed, given the other.</p>

<img alt=""../_images/frame_plot_subplots_layout.png"" src=""../_images/frame_plot_subplots_layout.png""/>
<p>The above example is identical to using:</p>

<p>The required number of columns (3) is inferred from the number of series to plot
and the given number of rows (2).</p>
<p>You can pass multiple axes created beforehand as list-like via <code class=""docutils literal notranslate""><span class=""pre"">ax</span></code> keyword.
This allows more complicated layouts.
The passed axes must be the same number as the subplots being drawn.</p>
<p>When multiple axes are passed via the <code class=""docutils literal notranslate""><span class=""pre"">ax</span></code> keyword, <code class=""docutils literal notranslate""><span class=""pre"">layout</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">sharex</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">sharey</span></code> keywords
don’t affect to the output. You should explicitly pass <code class=""docutils literal notranslate""><span class=""pre"">sharex=False</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">sharey=False</span></code>,
otherwise you will see a warning.</p>

<img alt=""../_images/frame_plot_subplots_multi_ax.png"" src=""../_images/frame_plot_subplots_multi_ax.png""/>
<p>Another option is passing an <code class=""docutils literal notranslate""><span class=""pre"">ax</span></code> argument to <a class=""reference internal"" href=""../reference/api/pandas.Series.plot.html#pandas.Series.plot"" title=""pandas.Series.plot""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.plot()</span></code></a> to plot on a particular axis:</p>


<img alt=""../_images/series_plot_multi.png"" src=""../_images/series_plot_multi.png""/>
</section>
<section id=""plotting-with-error-bars"">
<span id=""visualization-errorbars""></span><h3>Plotting with error bars<a class=""headerlink"" href=""#plotting-with-error-bars"" title=""Link to this heading"">#</a></h3>
<p>Plotting with error bars is supported in <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.plot.html#pandas.DataFrame.plot"" title=""pandas.DataFrame.plot""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.plot()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.Series.plot.html#pandas.Series.plot"" title=""pandas.Series.plot""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.plot()</span></code></a>.</p>
<p>Horizontal and vertical error bars can be supplied to the <code class=""docutils literal notranslate""><span class=""pre"">xerr</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">yerr</span></code> keyword arguments to <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.plot.html#pandas.DataFrame.plot"" title=""pandas.DataFrame.plot""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">plot()</span></code></a>. The error values can be specified using a variety of formats:</p>
<ul class=""simple"">
<li><p>As a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> or <code class=""docutils literal notranslate""><span class=""pre"">dict</span></code> of errors with column names matching the <code class=""docutils literal notranslate""><span class=""pre"">columns</span></code> attribute of the plotting <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> or matching the <code class=""docutils literal notranslate""><span class=""pre"">name</span></code> attribute of the <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>.</p></li>
<li><p>As a <code class=""docutils literal notranslate""><span class=""pre"">str</span></code> indicating which of the columns of plotting <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> contain the error values.</p></li>
<li><p>As raw values (<code class=""docutils literal notranslate""><span class=""pre"">list</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">tuple</span></code>, or <code class=""docutils literal notranslate""><span class=""pre"">np.ndarray</span></code>). Must be the same length as the plotting <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>/<a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>.</p></li>
</ul>
<p>Here is an example of one way to easily plot group means with standard deviations from the raw data.</p>

<img alt=""../_images/errorbar_example.png"" src=""../_images/errorbar_example.png""/>
<p>Asymmetrical error bars are also supported, however raw error values must be provided in this case. For a <code class=""docutils literal notranslate""><span class=""pre"">N</span></code> length <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>, a <code class=""docutils literal notranslate""><span class=""pre"">2xN</span></code> array should be provided indicating lower and upper (or left and right) errors. For a <code class=""docutils literal notranslate""><span class=""pre"">MxN</span></code> <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>, asymmetrical errors should be in a <code class=""docutils literal notranslate""><span class=""pre"">Mx2xN</span></code> array.</p>
<p>Here is an example of one way to plot the min/max range using asymmetrical error bars.</p>

<img alt=""../_images/errorbar_asymmetrical_example.png"" src=""../_images/errorbar_asymmetrical_example.png""/>
</section>
<section id=""plotting-tables"">
<span id=""visualization-table""></span><h3>Plotting tables<a class=""headerlink"" href=""#plotting-tables"" title=""Link to this heading"">#</a></h3>
<p>Plotting with matplotlib table is now supported in <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.plot.html#pandas.DataFrame.plot"" title=""pandas.DataFrame.plot""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.plot()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.Series.plot.html#pandas.Series.plot"" title=""pandas.Series.plot""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.plot()</span></code></a> with a <code class=""docutils literal notranslate""><span class=""pre"">table</span></code> keyword. The <code class=""docutils literal notranslate""><span class=""pre"">table</span></code> keyword can accept <code class=""docutils literal notranslate""><span class=""pre"">bool</span></code>, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>. The simple way to draw a table is to specify <code class=""docutils literal notranslate""><span class=""pre"">table=True</span></code>. Data will be transposed to meet matplotlib’s default layout.</p>

<img alt=""../_images/line_plot_table_true.png"" src=""../_images/line_plot_table_true.png""/>
<p>Also, you can pass a different <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> to the
<code class=""docutils literal notranslate""><span class=""pre"">table</span></code> keyword. The data will be drawn as displayed in print method
(not transposed automatically). If required, it should be transposed manually
as seen in the example below.</p>

<img alt=""../_images/line_plot_table_data.png"" src=""../_images/line_plot_table_data.png""/>
<p>There also exists a helper function <code class=""docutils literal notranslate""><span class=""pre"">pandas.plotting.table</span></code>, which creates a
table from <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>, and adds it to an
<code class=""docutils literal notranslate""><span class=""pre"">matplotlib.Axes</span></code> instance. This function can accept keywords which the
matplotlib <a class=""reference external"" href=""https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.table.html"">table</a> has.</p>

<img alt=""../_images/line_plot_table_describe.png"" src=""../_images/line_plot_table_describe.png""/>
<p><strong>Note</strong>: You can get table instances on the axes using <code class=""docutils literal notranslate""><span class=""pre"">axes.tables</span></code> property for further decorations. See the <a class=""reference external"" href=""https://matplotlib.org/api/axes_api.html#matplotlib.axes.Axes.table"">matplotlib table documentation</a> for more.</p>
</section>
<section id=""colormaps"">
<span id=""visualization-colormaps""></span><h3>Colormaps<a class=""headerlink"" href=""#colormaps"" title=""Link to this heading"">#</a></h3>
<p>A potential issue when plotting a large number of columns is that it can be
difficult to distinguish some series due to repetition in the default colors. To
remedy this, <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> plotting supports the use of the <code class=""docutils literal notranslate""><span class=""pre"">colormap</span></code> argument,
which accepts either a Matplotlib <a class=""reference external"" href=""https://matplotlib.org/api/cm_api.html"">colormap</a>
or a string that is a name of a colormap registered with Matplotlib. A
visualization of the default matplotlib colormaps is available <a class=""reference external"" href=""https://matplotlib.org/stable/gallery/color/colormap_reference.html"">here</a>.</p>
<p>As matplotlib does not directly support colormaps for line-based plots, the
colors are selected based on an even spacing determined by the number of columns
in the <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>. There is no consideration made for background color, so some
colormaps will produce lines that are not easily visible.</p>
<p>To use the cubehelix colormap, we can pass <code class=""docutils literal notranslate""><span class=""pre"">colormap='cubehelix'</span></code>.</p>

<img alt=""../_images/cubehelix.png"" src=""../_images/cubehelix.png""/>
<p>Alternatively, we can pass the colormap itself:</p>

<img alt=""../_images/cubehelix_cm.png"" src=""../_images/cubehelix_cm.png""/>
<p>Colormaps can also be used other plot types, like bar charts:</p>

<img alt=""../_images/greens.png"" src=""../_images/greens.png""/>
<p>Parallel coordinates charts:</p>

<img alt=""../_images/parallel_gist_rainbow.png"" src=""../_images/parallel_gist_rainbow.png""/>
<p>Andrews curves charts:</p>

<img alt=""../_images/andrews_curve_winter.png"" src=""../_images/andrews_curve_winter.png""/>
</section>
</section>
<section id=""plotting-directly-with-matplotlib"">
<h2>Plotting directly with Matplotlib<a class=""headerlink"" href=""#plotting-directly-with-matplotlib"" title=""Link to this heading"">#</a></h2>
<p>In some situations it may still be preferable or necessary to prepare plots
directly with matplotlib, for instance when a certain type of plot or
customization is not (yet) supported by pandas. <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>
objects behave like arrays and can therefore be passed directly to
matplotlib functions without explicit casts.</p>
<p>pandas also automatically registers formatters and locators that recognize date
indices, thereby extending date and time support to practically all plot types
available in matplotlib. Although this formatting does not provide the same
level of refinement you would get when plotting via pandas, it can be faster
when plotting a large number of points.</p>

<img alt=""../_images/bollinger.png"" src=""../_images/bollinger.png""/>
</section>
<section id=""plotting-backends"">
<h2>Plotting backends<a class=""headerlink"" href=""#plotting-backends"" title=""Link to this heading"">#</a></h2>
<p>pandas can be extended with third-party plotting backends. The
main idea is letting users select a plotting backend different than the provided
one based on Matplotlib.</p>
<p>This can be done by passing ‘backend.module’ as the argument <code class=""docutils literal notranslate""><span class=""pre"">backend</span></code> in <code class=""docutils literal notranslate""><span class=""pre"">plot</span></code>
function. For example:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">Series</span><span class=""p"">([</span><span class=""mi"">1</span><span class=""p"">,</span> <span class=""mi"">2</span><span class=""p"">,</span> <span class=""mi"">3</span><span class=""p"">])</span><span class=""o"">.</span><span class=""n"">plot</span><span class=""p"">(</span><span class=""n"">backend</span><span class=""o"">=</span><span class=""s2"">""backend.module""</span><span class=""p"">)</span>
</pre></div>
</div>
<p>Alternatively, you can also set this option globally, do you don’t need to specify
the keyword in each <code class=""docutils literal notranslate""><span class=""pre"">plot</span></code> call. For example:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">set_option</span><span class=""p"">(</span><span class=""s2"">""plotting.backend""</span><span class=""p"">,</span> <span class=""s2"">""backend.module""</span><span class=""p"">)</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">Series</span><span class=""p"">([</span><span class=""mi"">1</span><span class=""p"">,</span> <span class=""mi"">2</span><span class=""p"">,</span> <span class=""mi"">3</span><span class=""p"">])</span><span class=""o"">.</span><span class=""n"">plot</span><span class=""p"">()</span>
</pre></div>
</div>
<p>Or:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">options</span><span class=""o"">.</span><span class=""n"">plotting</span><span class=""o"">.</span><span class=""n"">backend</span> <span class=""o"">=</span> <span class=""s2"">""backend.module""</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">Series</span><span class=""p"">([</span><span class=""mi"">1</span><span class=""p"">,</span> <span class=""mi"">2</span><span class=""p"">,</span> <span class=""mi"">3</span><span class=""p"">])</span><span class=""o"">.</span><span class=""n"">plot</span><span class=""p"">()</span>
</pre></div>
</div>
<p>This would be more or less equivalent to:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""kn"">import</span> <span class=""nn"">backend.module</span>
<span class=""gp"">&gt;&gt;&gt; </span><span class=""n"">backend</span><span class=""o"">.</span><span class=""n"">module</span><span class=""o"">.</span><span class=""n"">plot</span><span class=""p"">(</span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">Series</span><span class=""p"">([</span><span class=""mi"">1</span><span class=""p"">,</span> <span class=""mi"">2</span><span class=""p"">,</span> <span class=""mi"">3</span><span class=""p"">]))</span>
</pre></div>
</div>
<p>The backend module can then use other visualization tools (Bokeh, Altair, hvplot,…)
to generate the plots. Some libraries implementing a backend for pandas are listed
on <a class=""reference external"" href=""https://pandas.pydata.org/community/ecosystem.html"">the ecosystem page</a>.</p>
<p>Developers guide can be found at
<a class=""reference external"" href=""https://pandas.pydata.org/docs/dev/development/extending.html#plotting-backends"">https://pandas.pydata.org/docs/dev/development/extending.html#plotting-backends</a></p>
</section>
</section>
</article>","Chart visualization # Note The examples below assume that you’re using Jupyter . This section demonstrates visualization through charting. For information on visualization of tabular data please see the section on Table Visualization . We use the standard convention for referencing the matplotlib API: We provide the basics in pandas to easily create decent looking plots. See the ecosystem page for visualization libraries that go beyond the basics documented here. Note All calls to np.random are seeded with 123456. Basic plotting: plot # We will demonstrate the basics, see the cookbook for some advanced strategies. The plot method on Series and DataFrame is just a simple wrapper around plt.plot() : If the index consists of dates, it calls gcf().autofmt_xdate() to try to format the x-axis nicely as per above. On DataFrame, plot() is a convenience to plot all of the columns with labels: You can plot one column versus another using the x and y keywords in plot() : Note For more formatting and styling options, see formatting below. Other plots # Plotting methods allow for a handful of plot styles other than the default line plot. These methods can be provided as the kind keyword argument to plot() , and include: ‘bar’ or ‘barh’ for bar plots ‘hist’ for histogram ‘box’ for boxplot ‘kde’ or ‘density’ for density plots ‘area’ for area plots ‘scatter’ for scatter plots ‘hexbin’ for hexagonal bin plots ‘pie’ for pie plots For example, a bar plot can be created the following way: You can also create these other plots using the methods DataFrame.plot.<kind> instead of providing the kind keyword argument. This makes it easier to discover plot methods and the specific arguments they use: In addition to these kind s, there are the DataFrame.hist() , and DataFrame.boxplot() methods, which use a separate interface. Finally, there are several plotting functions in pandas.plotting that take a Series or DataFrame as an argument. These include: Scatter Matrix Andrews Curves Parallel Coordinates Lag Plot Autocorrelation Plot Bootstrap Plot RadViz Plots may also be adorned with errorbars or tables . Bar plots # For labeled, non-time series data, you may wish to produce a bar plot: Calling a DataFrame’s plot.bar() method produces a multiple bar plot: To produce a stacked bar plot, pass stacked=True : To get horizontal bar plots, use the barh method: Histograms # Histograms can be drawn by using the DataFrame.plot.hist() and Series.plot.hist() methods. A histogram can be stacked using stacked=True . Bin size can be changed using the bins keyword. You can pass other keywords supported by matplotlib hist . For example, horizontal and cumulative histograms can be drawn by orientation='horizontal' and cumulative=True . See the hist method and the matplotlib hist documentation for more. The existing interface DataFrame.hist to plot histogram still can be used. DataFrame.hist() plots the histograms of the columns on multiple subplots: The by keyword can be specified to plot grouped histograms: In addition, the by keyword can also be specified in DataFrame.plot.hist() . Changed in version 1.4.0. Box plots # Boxplot can be drawn calling Series.plot.box() and DataFrame.plot.box() , or DataFrame.boxplot() to visualize the distribution of values within each column. For instance, here is a boxplot representing five trials of 10 observations of a uniform random variable on [0,1). Boxplot can be colorized by passing color keyword. You can pass a dict whose keys are boxes , whiskers , medians and caps . If some keys are missing in the dict , default colors are used for the corresponding artists. Also, boxplot has sym keyword to specify fliers style. When you pass other type of arguments via color keyword, it will be directly passed to matplotlib for all the boxes , whiskers , medians and caps colorization. The colors are applied to every boxes to be drawn. If you want more complicated colorization, you can get each drawn artists by passing return_type . Also, you can pass other keywords supported by matplotlib boxplot . For example, horizontal and custom-positioned boxplot can be drawn by vert=False and positions keywords. See the boxplot method and the matplotlib boxplot documentation for more. The existing interface DataFrame.boxplot to plot boxplot still can be used. You can create a stratified boxplot using the by keyword argument to create groupings. For instance, You can also pass a subset of columns to plot, as well as group by multiple columns: You could also create groupings with DataFrame.plot.box() , for instance: Changed in version 1.4.0. In boxplot , the return type can be controlled by the return_type , keyword. The valid choices are {""axes"", ""dict"", ""both"", None} . Faceting, created by DataFrame.boxplot with the by keyword, will affect the output type as well: Groupby.boxplot always returns a Series of return_type . The subplots above are split by the numeric columns first, then the value of the g column. Below the subplots are first split by the value of g , then by the numeric columns. Area plot # You can create area plots with Series.plot.area() and DataFrame.plot.area() . Area plots are stacked by default. To produce stacked area plot, each column must be either all positive or all negative values. When input data contains NaN , it will be automatically filled by 0. If you want to drop or fill by different values, use dataframe.dropna() or dataframe.fillna() before calling plot . To produce an unstacked plot, pass stacked=False . Alpha value is set to 0.5 unless otherwise specified: Scatter plot # Scatter plot can be drawn by using the DataFrame.plot.scatter() method. Scatter plot requires numeric columns for the x and y axes. These can be specified by the x and y keywords. To plot multiple column groups in a single axes, repeat plot method specifying target ax . It is recommended to specify color and label keywords to distinguish each groups. The keyword c may be given as the name of a column to provide colors for each point: If a categorical column is passed to c , then a discrete colorbar will be produced: New in version 1.3.0. You can pass other keywords supported by matplotlib scatter . The example below shows a bubble chart using a column of the DataFrame as the bubble size. See the scatter method and the matplotlib scatter documentation for more. Hexagonal bin plot # You can create hexagonal bin plots with DataFrame.plot.hexbin() . Hexbin plots can be a useful alternative to scatter plots if your data are too dense to plot each point individually. A useful keyword argument is gridsize ; it controls the number of hexagons in the x-direction, and defaults to 100. A larger gridsize means more, smaller bins. By default, a histogram of the counts around each (x, y) point is computed. You can specify alternative aggregations by passing values to the C and reduce_C_function arguments. C specifies the value at each (x, y) point and reduce_C_function is a function of one argument that reduces all the values in a bin to a single number (e.g. mean , max , sum , std ). In this example the positions are given by columns a and b , while the value is given by column z . The bins are aggregated with NumPy’s max function. See the hexbin method and the matplotlib hexbin documentation for more. Pie plot # You can create a pie plot with DataFrame.plot.pie() or Series.plot.pie() . If your data includes any NaN , they will be automatically filled with 0. A ValueError will be raised if there are any negative values in your data. For pie plots it’s best to use square figures, i.e. a figure aspect ratio 1. You can create the figure with equal width and height, or force the aspect ratio to be equal after plotting by calling ax.set_aspect('equal') on the returned axes object. Note that pie plot with DataFrame requires that you either specify a target column by the y argument or subplots=True . When y is specified, pie plot of selected column will be drawn. If subplots=True is specified, pie plots for each column are drawn as subplots. A legend will be drawn in each pie plots by default; specify legend=False to hide it. You can use the labels and colors keywords to specify the labels and colors of each wedge. Warning Most pandas plots use the label and color arguments (note the lack of “s” on those). To be consistent with matplotlib.pyplot.pie() you must use labels and colors . If you want to hide wedge labels, specify labels=None . If fontsize is specified, the value will be applied to wedge labels. Also, other keywords supported by matplotlib.pyplot.pie() can be used. If you pass values whose sum total is less than 1.0 they will be rescaled so that they sum to 1. See the matplotlib pie documentation for more. Plotting with missing data # pandas tries to be pragmatic about plotting DataFrames or Series that contain missing data. Missing values are dropped, left out, or filled depending on the plot type. If any of these defaults are not what you want, or if you want to be explicit about how missing values are handled, consider using fillna() or dropna() before plotting. Plotting tools # These functions can be imported from pandas.plotting and take a Series or DataFrame as an argument. Scatter matrix plot # You can create a scatter plot matrix using the scatter_matrix method in pandas.plotting : Density plot # You can create density plots using the Series.plot.kde() and DataFrame.plot.kde() methods. Andrews curves # Andrews curves allow one to plot multivariate data as a large number of curves that are created using the attributes of samples as coefficients for Fourier series, see the Wikipedia entry for more information. By coloring these curves differently for each class it is possible to visualize data clustering. Curves belonging to samples of the same class will usually be closer together and form larger structures. Note : The “Iris” dataset is available here . Parallel coordinates # Parallel coordinates is a plotting technique for plotting multivariate data, see the Wikipedia entry for an introduction. Parallel coordinates allows one to see clusters in data and to estimate other statistics visually. Using parallel coordinates points are represented as connected line segments. Each vertical line represents one attribute. One set of connected line segments represents one data point. Points that tend to cluster will appear closer together. Lag plot # Lag plots are used to check if a data set or time series is random. Random data should not exhibit any structure in the lag plot. Non-random structure implies that the underlying data are not random. The lag argument may be passed, and when lag=1 the plot is essentially data[:-1] vs. data[1:] . Autocorrelation plot # Autocorrelation plots are often used for checking randomness in time series. This is done by computing autocorrelations for data values at varying time lags. If time series is random, such autocorrelations should be near zero for any and all time-lag separations. If time series is non-random then one or more of the autocorrelations will be significantly non-zero. The horizontal lines displayed in the plot correspond to 95% and 99% confidence bands. The dashed line is 99% confidence band. See the Wikipedia entry for more about autocorrelation plots. Bootstrap plot # Bootstrap plots are used to visually assess the uncertainty of a statistic, such as mean, median, midrange, etc. A random subset of a specified size is selected from a data set, the statistic in question is computed for this subset and the process is repeated a specified number of times. Resulting plots and histograms are what constitutes the bootstrap plot. RadViz # RadViz is a way of visualizing multi-variate data. It is based on a simple spring tension minimization algorithm. Basically you set up a bunch of points in a plane. In our case they are equally spaced on a unit circle. Each point represents a single attribute. You then pretend that each sample in the data set is attached to each of these points by a spring, the stiffness of which is proportional to the numerical value of that attribute (they are normalized to unit interval). The point in the plane, where our sample settles to (where the forces acting on our sample are at an equilibrium) is where a dot representing our sample will be drawn. Depending on which class that sample belongs it will be colored differently. See the R package Radviz for more information. Note : The “Iris” dataset is available here . Plot formatting # Setting the plot style # From version 1.5 and up, matplotlib offers a range of pre-configured plotting styles. Setting the style can be used to easily give plots the general look that you want. Setting the style is as easy as calling matplotlib.style.use(my_plot_style) before creating your plot. For example you could write matplotlib.style.use('ggplot') for ggplot-style plots. You can see the various available style names at matplotlib.style.available and it’s very easy to try them out. General plot style arguments # Most plotting methods have a set of keyword arguments that control the layout and formatting of the returned plot: For each kind of plot (e.g. line , bar , scatter ) any additional arguments keywords are passed along to the corresponding matplotlib function ( ax.plot() , ax.bar() , ax.scatter() ). These can be used to control additional styling, beyond what pandas provides. Controlling the legend # You may set the legend argument to False to hide the legend, which is shown by default. Controlling the labels # You may set the xlabel and ylabel arguments to give the plot custom labels for x and y axis. By default, pandas will pick up index name as xlabel, while leaving it empty for ylabel. Scales # You may pass logy to get a log-scale Y axis. See also the logx and loglog keyword arguments. Plotting on a secondary y-axis # To plot data on a secondary y-axis, use the secondary_y keyword: To plot some columns in a DataFrame , give the column names to the secondary_y keyword: Note that the columns plotted on the secondary y-axis is automatically marked with “(right)” in the legend. To turn off the automatic marking, use the mark_right=False keyword: Custom formatters for timeseries plots # pandas provides custom formatters for timeseries plots. These change the formatting of the axis labels for dates and times. By default, the custom formatters are applied only to plots created by pandas with DataFrame.plot() or Series.plot() . To have them apply to all plots, including those made by matplotlib, set the option pd.options.plotting.matplotlib.register_converters = True or use pandas.plotting.register_matplotlib_converters() . Suppressing tick resolution adjustment # pandas includes automatic tick resolution adjustment for regular frequency time-series data. For limited cases where pandas cannot infer the frequency information (e.g., in an externally created twinx ), you can choose to suppress this behavior for alignment purposes. Here is the default behavior, notice how the x-axis tick labeling is performed: Using the x_compat parameter, you can suppress this behavior: If you have more than one plot that needs to be suppressed, the use method in pandas.plotting.plot_params can be used in a with statement: Automatic date tick adjustment # TimedeltaIndex now uses the native matplotlib tick locator methods, it is useful to call the automatic date tick adjustment from matplotlib for figures whose ticklabels overlap. See the autofmt_xdate method and the matplotlib documentation for more. Subplots # Each Series in a DataFrame can be plotted on a different axis with the subplots keyword: Using layout and targeting multiple axes # The layout of subplots can be specified by the layout keyword. It can accept (rows, columns) . The layout keyword can be used in hist and boxplot also. If the input is invalid, a ValueError will be raised. The number of axes which can be contained by rows x columns specified by layout must be larger than the number of required subplots. If layout can contain more axes than required, blank axes are not drawn. Similar to a NumPy array’s reshape method, you can use -1 for one dimension to automatically calculate the number of rows or columns needed, given the other. The above example is identical to using: The required number of columns (3) is inferred from the number of series to plot and the given number of rows (2). You can pass multiple axes created beforehand as list-like via ax keyword. This allows more complicated layouts. The passed axes must be the same number as the subplots being drawn. When multiple axes are passed via the ax keyword, layout , sharex and sharey keywords don’t affect to the output. You should explicitly pass sharex=False and sharey=False , otherwise you will see a warning. Another option is passing an ax argument to Series.plot() to plot on a particular axis: Plotting with error bars # Plotting with error bars is supported in DataFrame.plot() and Series.plot() . Horizontal and vertical error bars can be supplied to the xerr and yerr keyword arguments to plot() . The error values can be specified using a variety of formats: As a DataFrame or dict of errors with column names matching the columns attribute of the plotting DataFrame or matching the name attribute of the Series . As a str indicating which of the columns of plotting DataFrame contain the error values. As raw values ( list , tuple , or np.ndarray ). Must be the same length as the plotting DataFrame / Series . Here is an example of one way to easily plot group means with standard deviations from the raw data. Asymmetrical error bars are also supported, however raw error values must be provided in this case. For a N length Series , a 2xN array should be provided indicating lower and upper (or left and right) errors. For a MxN DataFrame , asymmetrical errors should be in a Mx2xN array. Here is an example of one way to plot the min/max range using asymmetrical error bars. Plotting tables # Plotting with matplotlib table is now supported in DataFrame.plot() and Series.plot() with a table keyword. The table keyword can accept bool , DataFrame or Series . The simple way to draw a table is to specify table=True . Data will be transposed to meet matplotlib’s default layout. Also, you can pass a different DataFrame or Series to the table keyword. The data will be drawn as displayed in print method (not transposed automatically). If required, it should be transposed manually as seen in the example below. There also exists a helper function pandas.plotting.table , which creates a table from DataFrame or Series , and adds it to an matplotlib.Axes instance. This function can accept keywords which the matplotlib table has. Note : You can get table instances on the axes using axes.tables property for further decorations. See the matplotlib table documentation for more. Colormaps # A potential issue when plotting a large number of columns is that it can be difficult to distinguish some series due to repetition in the default colors. To remedy this, DataFrame plotting supports the use of the colormap argument, which accepts either a Matplotlib colormap or a string that is a name of a colormap registered with Matplotlib. A visualization of the default matplotlib colormaps is available here . As matplotlib does not directly support colormaps for line-based plots, the colors are selected based on an even spacing determined by the number of columns in the DataFrame . There is no consideration made for background color, so some colormaps will produce lines that are not easily visible. To use the cubehelix colormap, we can pass colormap='cubehelix' . Alternatively, we can pass the colormap itself: Colormaps can also be used other plot types, like bar charts: Parallel coordinates charts: Andrews curves charts: Plotting directly with Matplotlib # In some situations it may still be preferable or necessary to prepare plots directly with matplotlib, for instance when a certain type of plot or customization is not (yet) supported by pandas. Series and DataFrame objects behave like arrays and can therefore be passed directly to matplotlib functions without explicit casts. pandas also automatically registers formatters and locators that recognize date indices, thereby extending date and time support to practically all plot types available in matplotlib. Although this formatting does not provide the same level of refinement you would get when plotting via pandas, it can be faster when plotting a large number of points. Plotting backends # pandas can be extended with third-party plotting backends. The main idea is letting users select a plotting backend different than the provided one based on Matplotlib. This can be done by passing ‘backend.module’ as the argument backend in plot function. For example: >>> Series ([ 1 , 2 , 3 ]) . plot ( backend = ""backend.module"" ) Alternatively, you can also set this option globally, do you don’t need to specify the keyword in each plot call. For example: >>> pd . set_option ( ""plotting.backend"" , ""backend.module"" ) >>> pd . Series ([ 1 , 2 , 3 ]) . plot () Or: >>> pd . options . plotting . backend = ""backend.module"" >>> pd . Series ([ 1 , 2 , 3 ]) . plot () This would be more or less equivalent to: >>> import backend.module >>> backend . module . plot ( pd . Series ([ 1 , 2 , 3 ])) The backend module can then use other visualization tools (Bokeh, Altair, hvplot,…) to generate the plots. Some libraries implementing a backend for pandas are listed on the ecosystem page . Developers guide can be found at https://pandas.pydata.org/docs/dev/development/extending.html#plotting-backends"
https://pandas.pydata.org/docs/user_guide/style.html,Table Visualization,"<article class=""bd-article"" role=""main"">
<section id=""Table-Visualization"">
<h1>Table Visualization<a class=""headerlink"" href=""#Table-Visualization"" title=""Link to this heading"">#</a></h1>
<p>This section demonstrates visualization of tabular data using the <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.html""><span class=""doc"">Styler</span></a> class. For information on visualization with charting please see <a class=""reference internal"" href=""visualization.html""><span class=""doc"">Chart Visualization</span></a>. This document is written as a Jupyter Notebook, and can be viewed or downloaded <a class=""reference external"" href=""https://nbviewer.org/github/pandas-dev/pandas/blob/main/doc/source/user_guide/style.ipynb"">here</a>.</p>
<section id=""Styler-Object-and-Customising-the-Display"">
<h2>Styler Object and Customising the Display<a class=""headerlink"" href=""#Styler-Object-and-Customising-the-Display"" title=""Link to this heading"">#</a></h2>
<p>Styling and output display customisation should be performed <strong>after</strong> the data in a DataFrame has been processed. The Styler is <strong>not</strong> dynamically updated if further changes to the DataFrame are made. The <code class=""docutils literal notranslate""><span class=""pre"">DataFrame.style</span></code> attribute is a property that returns a <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.html""><span class=""doc"">Styler</span></a> object. It has a <code class=""docutils literal notranslate""><span class=""pre"">_repr_html_</span></code> method defined on it so it is rendered automatically in Jupyter Notebook.</p>
<p>The Styler, which can be used for large data but is primarily designed for small data, currently has the ability to output to these formats:</p>
<ul class=""simple"">
<li><p>HTML</p></li>
<li><p>LaTeX</p></li>
<li><p>String (and CSV by extension)</p></li>
<li><p>Excel</p></li>
<li><p>(JSON is not currently available)</p></li>
</ul>
<p>The first three of these have display customisation methods designed to format and customise the output. These include:</p>
<ul class=""simple"">
<li><p>Formatting values, the index and columns headers, using <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.format.html""><span class=""doc"">.format()</span></a> and <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.format_index.html""><span class=""doc"">.format_index()</span></a>,</p></li>
<li><p>Renaming the index or column header labels, using <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.relabel_index.html""><span class=""doc"">.relabel_index()</span></a></p></li>
<li><p>Hiding certain columns, the index and/or column headers, or index names, using <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.hide.html""><span class=""doc"">.hide()</span></a></p></li>
<li><p>Concatenating similar DataFrames, using <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.concat.html""><span class=""doc"">.concat()</span></a></p></li>
</ul>
</section>
<section id=""Formatting-the-Display"">
<h2>Formatting the Display<a class=""headerlink"" href=""#Formatting-the-Display"" title=""Link to this heading"">#</a></h2>
<section id=""Formatting-Values"">
<h3>Formatting Values<a class=""headerlink"" href=""#Formatting-Values"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.html""><span class=""doc"">Styler</span></a> distinguishes the <em>display</em> value from the <em>actual</em> value, in both data values and index or columns headers. To control the display value, the text is printed in each cell as a string, and we can use the <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.format.html""><span class=""doc"">.format()</span></a> and <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.format_index.html""><span class=""doc"">.format_index()</span></a> methods to manipulate this according to a <a class=""reference external"" href=""https://docs.python.org/3/library/string.html#format-specification-mini-language"">format spec
string</a> or a callable that takes a single value and returns a string. It is possible to define this for the whole table, or index, or for individual columns, or MultiIndex levels. We can also overwrite index names.</p>
<p>Additionally, the format function has a <strong>precision</strong> argument to specifically help format floats, as well as <strong>decimal</strong> and <strong>thousands</strong> separators to support other locales, an <strong>na_rep</strong> argument to display missing data, and an <strong>escape</strong> and <strong>hyperlinks</strong> arguments to help displaying safe-HTML or safe-LaTeX. The default formatter is configured to adopt pandas’ global options such as <code class=""docutils literal notranslate""><span class=""pre"">styler.format.precision</span></code> option, controllable using <code class=""docutils literal notranslate""><span class=""pre"">with</span> <span class=""pre"">pd.option_context('format.precision',</span> <span class=""pre"">2):</span></code></p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[2]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">pandas</span> <span class=""k"">as</span> <span class=""nn"">pd</span>
<span class=""kn"">import</span> <span class=""nn"">numpy</span> <span class=""k"">as</span> <span class=""nn"">np</span>
<span class=""kn"">import</span> <span class=""nn"">matplotlib</span> <span class=""k"">as</span> <span class=""nn"">mpl</span>

<span class=""n"">df</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">({</span>
    <span class=""s2"">""strings""</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""s2"">""Adam""</span><span class=""p"">,</span> <span class=""s2"">""Mike""</span><span class=""p"">],</span>
    <span class=""s2"">""ints""</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""mi"">1</span><span class=""p"">,</span> <span class=""mi"">3</span><span class=""p"">],</span>
    <span class=""s2"">""floats""</span><span class=""p"">:</span> <span class=""p"">[</span><span class=""mf"">1.123</span><span class=""p"">,</span> <span class=""mf"">1000.23</span><span class=""p"">]</span>
<span class=""p"">})</span>
<span class=""n"">df</span><span class=""o"">.</span><span class=""n"">style</span> \
  <span class=""o"">.</span><span class=""n"">format</span><span class=""p"">(</span><span class=""n"">precision</span><span class=""o"">=</span><span class=""mi"">3</span><span class=""p"">,</span> <span class=""n"">thousands</span><span class=""o"">=</span><span class=""s2"">"".""</span><span class=""p"">,</span> <span class=""n"">decimal</span><span class=""o"">=</span><span class=""s2"">"",""</span><span class=""p"">)</span> \
  <span class=""o"">.</span><span class=""n"">format_index</span><span class=""p"">(</span><span class=""nb"">str</span><span class=""o"">.</span><span class=""n"">upper</span><span class=""p"">,</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">1</span><span class=""p"">)</span> \
  <span class=""o"">.</span><span class=""n"">relabel_index</span><span class=""p"">([</span><span class=""s2"">""row 1""</span><span class=""p"">,</span> <span class=""s2"">""row 2""</span><span class=""p"">],</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[2]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
</style>
<table id=""T_6e647"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_6e647_level0_col0"">STRINGS</th>
<th class=""col_heading level0 col1"" id=""T_6e647_level0_col1"">INTS</th>
<th class=""col_heading level0 col2"" id=""T_6e647_level0_col2"">FLOATS</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_6e647_level0_row0"">row 1</th>
<td class=""data row0 col0"" id=""T_6e647_row0_col0"">Adam</td>
<td class=""data row0 col1"" id=""T_6e647_row0_col1"">1</td>
<td class=""data row0 col2"" id=""T_6e647_row0_col2"">1,123</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_6e647_level0_row1"">row 2</th>
<td class=""data row1 col0"" id=""T_6e647_row1_col0"">Mike</td>
<td class=""data row1 col1"" id=""T_6e647_row1_col1"">3</td>
<td class=""data row1 col2"" id=""T_6e647_row1_col2"">1.000,230</td>
</tr>
</tbody>
</table></div>
</div>
<p>Using Styler to manipulate the display is a useful feature because maintaining the indexing and data values for other purposes gives greater control. You do not have to overwrite your DataFrame to display it how you like. Here is a more comprehensive example of using the formatting functions whilst still relying on the underlying data for indexing and calculations.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[3]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">weather_df</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">(</span><span class=""n"">np</span><span class=""o"">.</span><span class=""n"">random</span><span class=""o"">.</span><span class=""n"">rand</span><span class=""p"">(</span><span class=""mi"">10</span><span class=""p"">,</span><span class=""mi"">2</span><span class=""p"">)</span><span class=""o"">*</span><span class=""mi"">5</span><span class=""p"">,</span>
                          <span class=""n"">index</span><span class=""o"">=</span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">date_range</span><span class=""p"">(</span><span class=""n"">start</span><span class=""o"">=</span><span class=""s2"">""2021-01-01""</span><span class=""p"">,</span> <span class=""n"">periods</span><span class=""o"">=</span><span class=""mi"">10</span><span class=""p"">),</span>
                          <span class=""n"">columns</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""Tokyo""</span><span class=""p"">,</span> <span class=""s2"">""Beijing""</span><span class=""p"">])</span>

<span class=""k"">def</span> <span class=""nf"">rain_condition</span><span class=""p"">(</span><span class=""n"">v</span><span class=""p"">):</span>
    <span class=""k"">if</span> <span class=""n"">v</span> <span class=""o"">&lt;</span> <span class=""mf"">1.75</span><span class=""p"">:</span>
        <span class=""k"">return</span> <span class=""s2"">""Dry""</span>
    <span class=""k"">elif</span> <span class=""n"">v</span> <span class=""o"">&lt;</span> <span class=""mf"">2.75</span><span class=""p"">:</span>
        <span class=""k"">return</span> <span class=""s2"">""Rain""</span>
    <span class=""k"">return</span> <span class=""s2"">""Heavy Rain""</span>

<span class=""k"">def</span> <span class=""nf"">make_pretty</span><span class=""p"">(</span><span class=""n"">styler</span><span class=""p"">):</span>
    <span class=""n"">styler</span><span class=""o"">.</span><span class=""n"">set_caption</span><span class=""p"">(</span><span class=""s2"">""Weather Conditions""</span><span class=""p"">)</span>
    <span class=""n"">styler</span><span class=""o"">.</span><span class=""n"">format</span><span class=""p"">(</span><span class=""n"">rain_condition</span><span class=""p"">)</span>
    <span class=""n"">styler</span><span class=""o"">.</span><span class=""n"">format_index</span><span class=""p"">(</span><span class=""k"">lambda</span> <span class=""n"">v</span><span class=""p"">:</span> <span class=""n"">v</span><span class=""o"">.</span><span class=""n"">strftime</span><span class=""p"">(</span><span class=""s2"">""%A""</span><span class=""p"">))</span>
    <span class=""n"">styler</span><span class=""o"">.</span><span class=""n"">background_gradient</span><span class=""p"">(</span><span class=""n"">axis</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""n"">vmin</span><span class=""o"">=</span><span class=""mi"">1</span><span class=""p"">,</span> <span class=""n"">vmax</span><span class=""o"">=</span><span class=""mi"">5</span><span class=""p"">,</span> <span class=""n"">cmap</span><span class=""o"">=</span><span class=""s2"">""YlGnBu""</span><span class=""p"">)</span>
    <span class=""k"">return</span> <span class=""n"">styler</span>

<span class=""n"">weather_df</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[3]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<div>
<style scoped="""">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border=""1"" class=""dataframe"">
<thead>
<tr style=""text-align: right;"">
<th></th>
<th>Tokyo</th>
<th>Beijing</th>
</tr>
</thead>
<tbody>
<tr>
<th>2021-01-01</th>
<td>2.552517</td>
<td>1.976602</td>
</tr>
<tr>
<th>2021-01-02</th>
<td>1.665753</td>
<td>3.757927</td>
</tr>
<tr>
<th>2021-01-03</th>
<td>4.679882</td>
<td>2.242228</td>
</tr>
<tr>
<th>2021-01-04</th>
<td>1.268592</td>
<td>0.915911</td>
</tr>
<tr>
<th>2021-01-05</th>
<td>0.258386</td>
<td>4.647607</td>
</tr>
<tr>
<th>2021-01-06</th>
<td>1.279295</td>
<td>4.642458</td>
</tr>
<tr>
<th>2021-01-07</th>
<td>0.560487</td>
<td>3.670073</td>
</tr>
<tr>
<th>2021-01-08</th>
<td>0.980423</td>
<td>1.026641</td>
</tr>
<tr>
<th>2021-01-09</th>
<td>1.471664</td>
<td>1.384219</td>
</tr>
<tr>
<th>2021-01-10</th>
<td>4.617766</td>
<td>4.251794</td>
</tr>
</tbody>
</table>
</div></div>
</div>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[4]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">weather_df</span><span class=""o"">.</span><span class=""n"">loc</span><span class=""p"">[</span><span class=""s2"">""2021-01-04""</span><span class=""p"">:</span><span class=""s2"">""2021-01-08""</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">pipe</span><span class=""p"">(</span><span class=""n"">make_pretty</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[4]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_e25c7_row0_col0, #T_e25c7_row2_col0 {
  background-color: #f5fbc4;
  color: #000000;
}
#T_e25c7_row0_col1, #T_e25c7_row1_col0, #T_e25c7_row3_col0, #T_e25c7_row4_col0 {
  background-color: #ffffd9;
  color: #000000;
}
#T_e25c7_row1_col1, #T_e25c7_row2_col1 {
  background-color: #1c2d81;
  color: #f1f1f1;
}
#T_e25c7_row3_col1 {
  background-color: #1f80b8;
  color: #f1f1f1;
}
#T_e25c7_row4_col1 {
  background-color: #feffd8;
  color: #000000;
}
</style>
<table id=""T_e25c7"">
<caption>Weather Conditions</caption>
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_e25c7_level0_col0"">Tokyo</th>
<th class=""col_heading level0 col1"" id=""T_e25c7_level0_col1"">Beijing</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_e25c7_level0_row0"">Monday</th>
<td class=""data row0 col0"" id=""T_e25c7_row0_col0"">Dry</td>
<td class=""data row0 col1"" id=""T_e25c7_row0_col1"">Dry</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_e25c7_level0_row1"">Tuesday</th>
<td class=""data row1 col0"" id=""T_e25c7_row1_col0"">Dry</td>
<td class=""data row1 col1"" id=""T_e25c7_row1_col1"">Heavy Rain</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_e25c7_level0_row2"">Wednesday</th>
<td class=""data row2 col0"" id=""T_e25c7_row2_col0"">Dry</td>
<td class=""data row2 col1"" id=""T_e25c7_row2_col1"">Heavy Rain</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_e25c7_level0_row3"">Thursday</th>
<td class=""data row3 col0"" id=""T_e25c7_row3_col0"">Dry</td>
<td class=""data row3 col1"" id=""T_e25c7_row3_col1"">Heavy Rain</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_e25c7_level0_row4"">Friday</th>
<td class=""data row4 col0"" id=""T_e25c7_row4_col0"">Dry</td>
<td class=""data row4 col1"" id=""T_e25c7_row4_col1"">Dry</td>
</tr>
</tbody>
</table></div>
</div>
</section>
<section id=""Hiding-Data"">
<h3>Hiding Data<a class=""headerlink"" href=""#Hiding-Data"" title=""Link to this heading"">#</a></h3>
<p>The index and column headers can be completely hidden, as well subselecting rows or columns that one wishes to exclude. Both these options are performed using the same methods.</p>
<p>The index can be hidden from rendering by calling <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.hide.html""><span class=""doc"">.hide()</span></a> without any arguments, which might be useful if your index is integer based. Similarly column headers can be hidden by calling <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.hide.html""><span class=""doc"">.hide(axis=”columns”)</span></a> without any further arguments.</p>
<p>Specific rows or columns can be hidden from rendering by calling the same <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.hide.html""><span class=""doc"">.hide()</span></a> method and passing in a row/column label, a list-like or a slice of row/column labels to for the <code class=""docutils literal notranslate""><span class=""pre"">subset</span></code> argument.</p>
<p>Hiding does not change the integer arrangement of CSS classes, e.g. hiding the first two columns of a DataFrame means the column class indexing will still start at <code class=""docutils literal notranslate""><span class=""pre"">col2</span></code>, since <code class=""docutils literal notranslate""><span class=""pre"">col0</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">col1</span></code> are simply ignored.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[5]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">(</span><span class=""n"">np</span><span class=""o"">.</span><span class=""n"">random</span><span class=""o"">.</span><span class=""n"">randn</span><span class=""p"">(</span><span class=""mi"">5</span><span class=""p"">,</span> <span class=""mi"">5</span><span class=""p"">))</span>
<span class=""n"">df</span><span class=""o"">.</span><span class=""n"">style</span> \
  <span class=""o"">.</span><span class=""n"">hide</span><span class=""p"">(</span><span class=""n"">subset</span><span class=""o"">=</span><span class=""p"">[</span><span class=""mi"">0</span><span class=""p"">,</span> <span class=""mi"">2</span><span class=""p"">,</span> <span class=""mi"">4</span><span class=""p"">],</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">)</span> \
  <span class=""o"">.</span><span class=""n"">hide</span><span class=""p"">(</span><span class=""n"">subset</span><span class=""o"">=</span><span class=""p"">[</span><span class=""mi"">0</span><span class=""p"">,</span> <span class=""mi"">2</span><span class=""p"">,</span> <span class=""mi"">4</span><span class=""p"">],</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">1</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[5]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
</style>
<table id=""T_1d3cf"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col1"" id=""T_1d3cf_level0_col1"">1</th>
<th class=""col_heading level0 col3"" id=""T_1d3cf_level0_col3"">3</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row1"" id=""T_1d3cf_level0_row1"">1</th>
<td class=""data row1 col1"" id=""T_1d3cf_row1_col1"">0.561440</td>
<td class=""data row1 col3"" id=""T_1d3cf_row1_col3"">-0.858225</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_1d3cf_level0_row3"">3</th>
<td class=""data row3 col1"" id=""T_1d3cf_row3_col1"">0.176255</td>
<td class=""data row3 col3"" id=""T_1d3cf_row3_col3"">0.876609</td>
</tr>
</tbody>
</table></div>
</div>
<p>To invert the function to a <strong>show</strong> functionality it is best practice to compose a list of hidden items.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[6]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">show</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""mi"">0</span><span class=""p"">,</span> <span class=""mi"">2</span><span class=""p"">,</span> <span class=""mi"">4</span><span class=""p"">]</span>
<span class=""n"">df</span><span class=""o"">.</span><span class=""n"">style</span> \
  <span class=""o"">.</span><span class=""n"">hide</span><span class=""p"">([</span><span class=""n"">row</span> <span class=""k"">for</span> <span class=""n"">row</span> <span class=""ow"">in</span> <span class=""n"">df</span><span class=""o"">.</span><span class=""n"">index</span> <span class=""k"">if</span> <span class=""n"">row</span> <span class=""ow"">not</span> <span class=""ow"">in</span> <span class=""n"">show</span><span class=""p"">],</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">)</span> \
  <span class=""o"">.</span><span class=""n"">hide</span><span class=""p"">([</span><span class=""n"">col</span> <span class=""k"">for</span> <span class=""n"">col</span> <span class=""ow"">in</span> <span class=""n"">df</span><span class=""o"">.</span><span class=""n"">columns</span> <span class=""k"">if</span> <span class=""n"">col</span> <span class=""ow"">not</span> <span class=""ow"">in</span> <span class=""n"">show</span><span class=""p"">],</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">1</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[6]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
</style>
<table id=""T_741f6"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_741f6_level0_col0"">0</th>
<th class=""col_heading level0 col2"" id=""T_741f6_level0_col2"">2</th>
<th class=""col_heading level0 col4"" id=""T_741f6_level0_col4"">4</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_741f6_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_741f6_row0_col0"">-0.056334</td>
<td class=""data row0 col2"" id=""T_741f6_row0_col2"">-1.188982</td>
<td class=""data row0 col4"" id=""T_741f6_row0_col4"">0.482870</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_741f6_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_741f6_row2_col0"">-0.718731</td>
<td class=""data row2 col2"" id=""T_741f6_row2_col2"">-0.499113</td>
<td class=""data row2 col4"" id=""T_741f6_row2_col4"">-1.350023</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_741f6_level0_row4"">4</th>
<td class=""data row4 col0"" id=""T_741f6_row4_col0"">-0.720169</td>
<td class=""data row4 col2"" id=""T_741f6_row4_col2"">1.225336</td>
<td class=""data row4 col4"" id=""T_741f6_row4_col4"">-0.512159</td>
</tr>
</tbody>
</table></div>
</div>
</section>
<section id=""Concatenating-DataFrame-Outputs"">
<h3>Concatenating DataFrame Outputs<a class=""headerlink"" href=""#Concatenating-DataFrame-Outputs"" title=""Link to this heading"">#</a></h3>
<p>Two or more Stylers can be concatenated together provided they share the same columns. This is very useful for showing summary statistics for a DataFrame, and is often used in combination with DataFrame.agg.</p>
<p>Since the objects concatenated are Stylers they can independently be styled as will be shown below and their concatenation preserves those styles.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[7]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">summary_styler</span> <span class=""o"">=</span> <span class=""n"">df</span><span class=""o"">.</span><span class=""n"">agg</span><span class=""p"">([</span><span class=""s2"">""sum""</span><span class=""p"">,</span> <span class=""s2"">""mean""</span><span class=""p"">])</span><span class=""o"">.</span><span class=""n"">style</span> \
                   <span class=""o"">.</span><span class=""n"">format</span><span class=""p"">(</span><span class=""n"">precision</span><span class=""o"">=</span><span class=""mi"">3</span><span class=""p"">)</span> \
                   <span class=""o"">.</span><span class=""n"">relabel_index</span><span class=""p"">([</span><span class=""s2"">""Sum""</span><span class=""p"">,</span> <span class=""s2"">""Average""</span><span class=""p"">])</span>
<span class=""n"">df</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">format</span><span class=""p"">(</span><span class=""n"">precision</span><span class=""o"">=</span><span class=""mi"">1</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">concat</span><span class=""p"">(</span><span class=""n"">summary_styler</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[7]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
</style>
<table id=""T_2dc16"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_2dc16_level0_col0"">0</th>
<th class=""col_heading level0 col1"" id=""T_2dc16_level0_col1"">1</th>
<th class=""col_heading level0 col2"" id=""T_2dc16_level0_col2"">2</th>
<th class=""col_heading level0 col3"" id=""T_2dc16_level0_col3"">3</th>
<th class=""col_heading level0 col4"" id=""T_2dc16_level0_col4"">4</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_2dc16_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_2dc16_row0_col0"">-0.1</td>
<td class=""data row0 col1"" id=""T_2dc16_row0_col1"">0.8</td>
<td class=""data row0 col2"" id=""T_2dc16_row0_col2"">-1.2</td>
<td class=""data row0 col3"" id=""T_2dc16_row0_col3"">0.3</td>
<td class=""data row0 col4"" id=""T_2dc16_row0_col4"">0.5</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_2dc16_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_2dc16_row1_col0"">0.5</td>
<td class=""data row1 col1"" id=""T_2dc16_row1_col1"">0.6</td>
<td class=""data row1 col2"" id=""T_2dc16_row1_col2"">0.1</td>
<td class=""data row1 col3"" id=""T_2dc16_row1_col3"">-0.9</td>
<td class=""data row1 col4"" id=""T_2dc16_row1_col4"">0.9</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_2dc16_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_2dc16_row2_col0"">-0.7</td>
<td class=""data row2 col1"" id=""T_2dc16_row2_col1"">-0.8</td>
<td class=""data row2 col2"" id=""T_2dc16_row2_col2"">-0.5</td>
<td class=""data row2 col3"" id=""T_2dc16_row2_col3"">0.2</td>
<td class=""data row2 col4"" id=""T_2dc16_row2_col4"">-1.4</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_2dc16_level0_row3"">3</th>
<td class=""data row3 col0"" id=""T_2dc16_row3_col0"">2.2</td>
<td class=""data row3 col1"" id=""T_2dc16_row3_col1"">0.2</td>
<td class=""data row3 col2"" id=""T_2dc16_row3_col2"">0.9</td>
<td class=""data row3 col3"" id=""T_2dc16_row3_col3"">0.9</td>
<td class=""data row3 col4"" id=""T_2dc16_row3_col4"">0.1</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_2dc16_level0_row4"">4</th>
<td class=""data row4 col0"" id=""T_2dc16_row4_col0"">-0.7</td>
<td class=""data row4 col1"" id=""T_2dc16_row4_col1"">-1.0</td>
<td class=""data row4 col2"" id=""T_2dc16_row4_col2"">1.2</td>
<td class=""data row4 col3"" id=""T_2dc16_row4_col3"">-0.5</td>
<td class=""data row4 col4"" id=""T_2dc16_row4_col4"">-0.5</td>
</tr>
<tr>
<th class=""foot0_row_heading level0 foot0_row0"" id=""T_2dc16_level0_foot0_row0"">Sum</th>
<td class=""foot0_data foot0_row0 col0"" id=""T_2dc16_foot0_row0_col0"">1.179</td>
<td class=""foot0_data foot0_row0 col1"" id=""T_2dc16_foot0_row0_col1"">-0.213</td>
<td class=""foot0_data foot0_row0 col2"" id=""T_2dc16_foot0_row0_col2"">0.506</td>
<td class=""foot0_data foot0_row0 col3"" id=""T_2dc16_foot0_row0_col3"">-0.082</td>
<td class=""foot0_data foot0_row0 col4"" id=""T_2dc16_foot0_row0_col4"">-0.430</td>
</tr>
<tr>
<th class=""foot0_row_heading level0 foot0_row1"" id=""T_2dc16_level0_foot0_row1"">Average</th>
<td class=""foot0_data foot0_row1 col0"" id=""T_2dc16_foot0_row1_col0"">0.236</td>
<td class=""foot0_data foot0_row1 col1"" id=""T_2dc16_foot0_row1_col1"">-0.043</td>
<td class=""foot0_data foot0_row1 col2"" id=""T_2dc16_foot0_row1_col2"">0.101</td>
<td class=""foot0_data foot0_row1 col3"" id=""T_2dc16_foot0_row1_col3"">-0.016</td>
<td class=""foot0_data foot0_row1 col4"" id=""T_2dc16_foot0_row1_col4"">-0.086</td>
</tr>
</tbody>
</table></div>
</div>
</section>
</section>
<section id=""Styler-Object-and-HTML"">
<h2>Styler Object and HTML<a class=""headerlink"" href=""#Styler-Object-and-HTML"" title=""Link to this heading"">#</a></h2>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.html""><span class=""doc"">Styler</span></a> was originally constructed to support the wide array of HTML formatting options. Its HTML output creates an HTML <code class=""docutils literal notranslate""><span class=""pre"">&lt;table&gt;</span></code> and leverages CSS styling language to manipulate many parameters including colors, fonts, borders, background, etc. See <a class=""reference external"" href=""https://www.w3schools.com/html/html_tables.asp"">here</a> for more information on styling HTML tables. This allows a lot of flexibility out of the box, and even enables web developers to
integrate DataFrames into their exiting user interface designs.</p>
<p>Below we demonstrate the default output, which looks very similar to the standard DataFrame HTML representation. But the HTML here has already attached some CSS classes to each cell, even if we haven’t yet created any styles. We can view these by calling the <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.to_html.html""><span class=""doc"">.to_html()</span></a> method, which returns the raw HTML as string, which is useful for further processing or adding to a file - read on in <a class=""reference internal"" href=""#More-About-CSS-and-HTML""><span class=""std std-ref"">More about CSS and
HTML</span></a>. This section will also provide a walkthrough for how to convert this default output to represent a DataFrame output that is more communicative. For example how we can build <code class=""docutils literal notranslate""><span class=""pre"">s</span></code>:</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[8]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">([[</span><span class=""mf"">38.0</span><span class=""p"">,</span> <span class=""mf"">2.0</span><span class=""p"">,</span> <span class=""mf"">18.0</span><span class=""p"">,</span> <span class=""mf"">22.0</span><span class=""p"">,</span> <span class=""mi"">21</span><span class=""p"">,</span> <span class=""n"">np</span><span class=""o"">.</span><span class=""n"">nan</span><span class=""p"">],[</span><span class=""mi"">19</span><span class=""p"">,</span> <span class=""mi"">439</span><span class=""p"">,</span> <span class=""mi"">6</span><span class=""p"">,</span> <span class=""mi"">452</span><span class=""p"">,</span> <span class=""mi"">226</span><span class=""p"">,</span><span class=""mi"">232</span><span class=""p"">]],</span>
                  <span class=""n"">index</span><span class=""o"">=</span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">Index</span><span class=""p"">([</span><span class=""s1"">'Tumour (Positive)'</span><span class=""p"">,</span> <span class=""s1"">'Non-Tumour (Negative)'</span><span class=""p"">],</span> <span class=""n"">name</span><span class=""o"">=</span><span class=""s1"">'Actual Label:'</span><span class=""p"">),</span>
                  <span class=""n"">columns</span><span class=""o"">=</span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">MultiIndex</span><span class=""o"">.</span><span class=""n"">from_product</span><span class=""p"">([[</span><span class=""s1"">'Decision Tree'</span><span class=""p"">,</span> <span class=""s1"">'Regression'</span><span class=""p"">,</span> <span class=""s1"">'Random'</span><span class=""p"">],[</span><span class=""s1"">'Tumour'</span><span class=""p"">,</span> <span class=""s1"">'Non-Tumour'</span><span class=""p"">]],</span> <span class=""n"">names</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s1"">'Model:'</span><span class=""p"">,</span> <span class=""s1"">'Predicted:'</span><span class=""p"">]))</span>
<span class=""n"">df</span><span class=""o"">.</span><span class=""n"">style</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[8]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
</style>
<table id=""T_2da97"">
<thead>
<tr>
<th class=""index_name level0"">Model:</th>
<th class=""col_heading level0 col0"" colspan=""2"" id=""T_2da97_level0_col0"">Decision Tree</th>
<th class=""col_heading level0 col2"" colspan=""2"" id=""T_2da97_level0_col2"">Regression</th>
<th class=""col_heading level0 col4"" colspan=""2"" id=""T_2da97_level0_col4"">Random</th>
</tr>
<tr>
<th class=""index_name level1"">Predicted:</th>
<th class=""col_heading level1 col0"" id=""T_2da97_level1_col0"">Tumour</th>
<th class=""col_heading level1 col1"" id=""T_2da97_level1_col1"">Non-Tumour</th>
<th class=""col_heading level1 col2"" id=""T_2da97_level1_col2"">Tumour</th>
<th class=""col_heading level1 col3"" id=""T_2da97_level1_col3"">Non-Tumour</th>
<th class=""col_heading level1 col4"" id=""T_2da97_level1_col4"">Tumour</th>
<th class=""col_heading level1 col5"" id=""T_2da97_level1_col5"">Non-Tumour</th>
</tr>
<tr>
<th class=""index_name level0"">Actual Label:</th>
<th class=""blank col0""> </th>
<th class=""blank col1""> </th>
<th class=""blank col2""> </th>
<th class=""blank col3""> </th>
<th class=""blank col4""> </th>
<th class=""blank col5""> </th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_2da97_level0_row0"">Tumour (Positive)</th>
<td class=""data row0 col0"" id=""T_2da97_row0_col0"">38.000000</td>
<td class=""data row0 col1"" id=""T_2da97_row0_col1"">2.000000</td>
<td class=""data row0 col2"" id=""T_2da97_row0_col2"">18.000000</td>
<td class=""data row0 col3"" id=""T_2da97_row0_col3"">22.000000</td>
<td class=""data row0 col4"" id=""T_2da97_row0_col4"">21</td>
<td class=""data row0 col5"" id=""T_2da97_row0_col5"">nan</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_2da97_level0_row1"">Non-Tumour (Negative)</th>
<td class=""data row1 col0"" id=""T_2da97_row1_col0"">19.000000</td>
<td class=""data row1 col1"" id=""T_2da97_row1_col1"">439.000000</td>
<td class=""data row1 col2"" id=""T_2da97_row1_col2"">6.000000</td>
<td class=""data row1 col3"" id=""T_2da97_row1_col3"">452.000000</td>
<td class=""data row1 col4"" id=""T_2da97_row1_col4"">226</td>
<td class=""data row1 col5"" id=""T_2da97_row1_col5"">232.000000</td>
</tr>
</tbody>
</table></div>
</div>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[10]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">s</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[10]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_270eb  {
  border-collapse: separate;
}
#T_270eb caption {
  caption-side: bottom;
  font-size: 1.3em;
}
#T_270eb .index_name {
  font-style: italic;
  color: darkgrey;
  font-weight: normal;
}
#T_270eb th:not(.index_name) {
  background-color: #000066;
  color: white;
}
#T_270eb th.col_heading {
  text-align: center;
}
#T_270eb th.col_heading.level0 {
  font-size: 1.5em;
}
#T_270eb th.col2 {
  border-left: 1px solid white;
}
#T_270eb .col2 {
  border-left: 1px solid #000066;
}
#T_270eb td {
  text-align: center;
  font-weight: bold;
}
#T_270eb .true {
  background-color: #e6ffe6;
}
#T_270eb .false {
  background-color: #ffe6e6;
}
#T_270eb .border-red {
  border: 2px dashed red;
}
#T_270eb .border-green {
  border: 2px dashed green;
}
#T_270eb td:hover {
  background-color: #ffffb3;
}
#T_270eb .pd-tt {
  visibility: hidden;
  position: absolute;
  z-index: 1;
  border: 1px solid #000066;
  background-color: white;
  color: #000066;
  font-size: 0.8em;
  transform: translate(0px, -24px);
  padding: 0.6em;
  border-radius: 0.5em;
}
#T_270eb #T_270eb_row0_col0:hover .pd-tt {
  visibility: visible;
}
#T_270eb #T_270eb_row0_col0 .pd-tt::after {
  content: ""This model has a very strong true positive rate"";
}
#T_270eb #T_270eb_row0_col3:hover .pd-tt {
  visibility: visible;
}
#T_270eb #T_270eb_row0_col3 .pd-tt::after {
  content: ""This model's total number of false negatives is too high"";
}
</style>
<table id=""T_270eb"">
<caption>Confusion matrix for multiple cancer prediction models.</caption>
<thead>
<tr>
<th class=""index_name level0"">Model:</th>
<th class=""col_heading level0 col0"" colspan=""2"" id=""T_270eb_level0_col0"">Decision Tree</th>
<th class=""col_heading level0 col2"" colspan=""2"" id=""T_270eb_level0_col2"">Regression</th>
</tr>
<tr>
<th class=""index_name level1"">Predicted:</th>
<th class=""col_heading level1 col0"" id=""T_270eb_level1_col0"">Tumour</th>
<th class=""col_heading level1 col1"" id=""T_270eb_level1_col1"">Non-Tumour</th>
<th class=""col_heading level1 col2"" id=""T_270eb_level1_col2"">Tumour</th>
<th class=""col_heading level1 col3"" id=""T_270eb_level1_col3"">Non-Tumour</th>
</tr>
<tr>
<th class=""index_name level0"">Actual Label:</th>
<th class=""blank col0""> </th>
<th class=""blank col1""> </th>
<th class=""blank col2""> </th>
<th class=""blank col3""> </th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_270eb_level0_row0"">Tumour (Positive)</th>
<td class=""data row0 col0 true border-green"" id=""T_270eb_row0_col0"">38<span class=""pd-tt""></span></td>
<td class=""data row0 col1 false"" id=""T_270eb_row0_col1"">2<span class=""pd-tt""></span></td>
<td class=""data row0 col2 true"" id=""T_270eb_row0_col2"">18<span class=""pd-tt""></span></td>
<td class=""data row0 col3 false border-red"" id=""T_270eb_row0_col3"">22<span class=""pd-tt""></span></td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_270eb_level0_row1"">Non-Tumour (Negative)</th>
<td class=""data row1 col0 false"" id=""T_270eb_row1_col0"">19<span class=""pd-tt""></span></td>
<td class=""data row1 col1 true"" id=""T_270eb_row1_col1"">439<span class=""pd-tt""></span></td>
<td class=""data row1 col2 false"" id=""T_270eb_row1_col2"">6<span class=""pd-tt""></span></td>
<td class=""data row1 col3 true"" id=""T_270eb_row1_col3"">452<span class=""pd-tt""></span></td>
</tr>
</tbody>
</table></div>
</div>
<p>The first step we have taken is the create the Styler object from the DataFrame and then select the range of interest by hiding unwanted columns with <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.hide.html""><span class=""doc"">.hide()</span></a>.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[11]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">s</span> <span class=""o"">=</span> <span class=""n"">df</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">format</span><span class=""p"">(</span><span class=""s1"">'</span><span class=""si"">{:.0f}</span><span class=""s1"">'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">hide</span><span class=""p"">([(</span><span class=""s1"">'Random'</span><span class=""p"">,</span> <span class=""s1"">'Tumour'</span><span class=""p"">),</span> <span class=""p"">(</span><span class=""s1"">'Random'</span><span class=""p"">,</span> <span class=""s1"">'Non-Tumour'</span><span class=""p"">)],</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""s2"">""columns""</span><span class=""p"">)</span>
<span class=""n"">s</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[11]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
</style>
<table id=""T_0611e"">
<thead>
<tr>
<th class=""index_name level0"">Model:</th>
<th class=""col_heading level0 col0"" colspan=""2"" id=""T_0611e_level0_col0"">Decision Tree</th>
<th class=""col_heading level0 col2"" colspan=""2"" id=""T_0611e_level0_col2"">Regression</th>
</tr>
<tr>
<th class=""index_name level1"">Predicted:</th>
<th class=""col_heading level1 col0"" id=""T_0611e_level1_col0"">Tumour</th>
<th class=""col_heading level1 col1"" id=""T_0611e_level1_col1"">Non-Tumour</th>
<th class=""col_heading level1 col2"" id=""T_0611e_level1_col2"">Tumour</th>
<th class=""col_heading level1 col3"" id=""T_0611e_level1_col3"">Non-Tumour</th>
</tr>
<tr>
<th class=""index_name level0"">Actual Label:</th>
<th class=""blank col0""> </th>
<th class=""blank col1""> </th>
<th class=""blank col2""> </th>
<th class=""blank col3""> </th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_0611e_level0_row0"">Tumour (Positive)</th>
<td class=""data row0 col0"" id=""T_0611e_row0_col0"">38</td>
<td class=""data row0 col1"" id=""T_0611e_row0_col1"">2</td>
<td class=""data row0 col2"" id=""T_0611e_row0_col2"">18</td>
<td class=""data row0 col3"" id=""T_0611e_row0_col3"">22</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_0611e_level0_row1"">Non-Tumour (Negative)</th>
<td class=""data row1 col0"" id=""T_0611e_row1_col0"">19</td>
<td class=""data row1 col1"" id=""T_0611e_row1_col1"">439</td>
<td class=""data row1 col2"" id=""T_0611e_row1_col2"">6</td>
<td class=""data row1 col3"" id=""T_0611e_row1_col3"">452</td>
</tr>
</tbody>
</table></div>
</div>
</section>
<section id=""Methods-to-Add-Styles"">
<h2>Methods to Add Styles<a class=""headerlink"" href=""#Methods-to-Add-Styles"" title=""Link to this heading"">#</a></h2>
<p>There are <strong>3 primary methods of adding custom CSS styles</strong> to <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.html""><span class=""doc"">Styler</span></a>:</p>
<ul class=""simple"">
<li><p>Using <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.set_table_styles.html""><span class=""doc"">.set_table_styles()</span></a> to control broader areas of the table with specified internal CSS. Although table styles allow the flexibility to add CSS selectors and properties controlling all individual parts of the table, they are unwieldy for individual cell specifications. Also, note that table styles cannot be exported to Excel.</p></li>
<li><p>Using <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.set_td_classes.html""><span class=""doc"">.set_td_classes()</span></a> to directly link either external CSS classes to your data cells or link the internal CSS classes created by <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.set_table_styles.html""><span class=""doc"">.set_table_styles()</span></a>. See <a class=""reference internal"" href=""#Setting-Classes-and-Linking-to-External-CSS""><span class=""std std-ref"">here</span></a>. These cannot be used on column header rows or indexes, and also won’t export to Excel.</p></li>
<li><p>Using the <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.apply.html""><span class=""doc"">.apply()</span></a> and <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.map.html""><span class=""doc"">.map()</span></a> functions to add direct internal CSS to specific data cells. See <a class=""reference internal"" href=""#Styler-Functions""><span class=""std std-ref"">here</span></a>. As of v1.4.0 there are also methods that work directly on column header rows or indexes; <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.apply_index.html""><span class=""doc"">.apply_index()</span></a> and
<a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.map_index.html""><span class=""doc"">.map_index()</span></a>. Note that only these methods add styles that will export to Excel. These methods work in a similar way to <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.apply.html""><span class=""doc"">DataFrame.apply()</span></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.map.html""><span class=""doc"">DataFrame.map()</span></a>.</p></li>
</ul>
</section>
<section id=""Table-Styles"">
<h2>Table Styles<a class=""headerlink"" href=""#Table-Styles"" title=""Link to this heading"">#</a></h2>
<p>Table styles are flexible enough to control all individual parts of the table, including column headers and indexes. However, they can be unwieldy to type for individual data cells or for any kind of conditional formatting, so we recommend that table styles are used for broad styling, such as entire rows or columns at a time.</p>
<p>Table styles are also used to control features which can apply to the whole table at once such as creating a generic hover functionality. The <code class=""docutils literal notranslate""><span class=""pre"">:hover</span></code> pseudo-selector, as well as other pseudo-selectors, can only be used this way.</p>
<p>To replicate the normal format of CSS selectors and properties (attribute value pairs), e.g.</p>
<div class=""highlight-none notranslate""><div class=""highlight""><pre><span></span>tr:hover {
  background-color: #ffff99;
}
</pre></div>
</div>
<p>the necessary format to pass styles to <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.set_table_styles.html""><span class=""doc"">.set_table_styles()</span></a> is as a list of dicts, each with a CSS-selector tag and CSS-properties. Properties can either be a list of 2-tuples, or a regular CSS-string, for example:</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[13]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">cell_hover</span> <span class=""o"">=</span> <span class=""p"">{</span>  <span class=""c1""># for row hover use &lt;tr&gt; instead of &lt;td&gt;</span>
    <span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'td:hover'</span><span class=""p"">,</span>
    <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""p"">[(</span><span class=""s1"">'background-color'</span><span class=""p"">,</span> <span class=""s1"">'#ffffb3'</span><span class=""p"">)]</span>
<span class=""p"">}</span>
<span class=""n"">index_names</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'.index_name'</span><span class=""p"">,</span>
    <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'font-style: italic; color: darkgrey; font-weight:normal;'</span>
<span class=""p"">}</span>
<span class=""n"">headers</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'th:not(.index_name)'</span><span class=""p"">,</span>
    <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'background-color: #000066; color: white;'</span>
<span class=""p"">}</span>
<span class=""n"">s</span><span class=""o"">.</span><span class=""n"">set_table_styles</span><span class=""p"">([</span><span class=""n"">cell_hover</span><span class=""p"">,</span> <span class=""n"">index_names</span><span class=""p"">,</span> <span class=""n"">headers</span><span class=""p"">])</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[13]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_after_hide td:hover {
  background-color: #ffffb3;
}
#T_after_hide .index_name {
  font-style: italic;
  color: darkgrey;
  font-weight: normal;
}
#T_after_hide th:not(.index_name) {
  background-color: #000066;
  color: white;
}
</style>
<table id=""T_after_hide"">
<thead>
<tr>
<th class=""index_name level0"">Model:</th>
<th class=""col_heading level0 col0"" colspan=""2"" id=""T_after_hide_level0_col0"">Decision Tree</th>
<th class=""col_heading level0 col2"" colspan=""2"" id=""T_after_hide_level0_col2"">Regression</th>
</tr>
<tr>
<th class=""index_name level1"">Predicted:</th>
<th class=""col_heading level1 col0"" id=""T_after_hide_level1_col0"">Tumour</th>
<th class=""col_heading level1 col1"" id=""T_after_hide_level1_col1"">Non-Tumour</th>
<th class=""col_heading level1 col2"" id=""T_after_hide_level1_col2"">Tumour</th>
<th class=""col_heading level1 col3"" id=""T_after_hide_level1_col3"">Non-Tumour</th>
</tr>
<tr>
<th class=""index_name level0"">Actual Label:</th>
<th class=""blank col0""> </th>
<th class=""blank col1""> </th>
<th class=""blank col2""> </th>
<th class=""blank col3""> </th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_after_hide_level0_row0"">Tumour (Positive)</th>
<td class=""data row0 col0"" id=""T_after_hide_row0_col0"">38</td>
<td class=""data row0 col1"" id=""T_after_hide_row0_col1"">2</td>
<td class=""data row0 col2"" id=""T_after_hide_row0_col2"">18</td>
<td class=""data row0 col3"" id=""T_after_hide_row0_col3"">22</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_after_hide_level0_row1"">Non-Tumour (Negative)</th>
<td class=""data row1 col0"" id=""T_after_hide_row1_col0"">19</td>
<td class=""data row1 col1"" id=""T_after_hide_row1_col1"">439</td>
<td class=""data row1 col2"" id=""T_after_hide_row1_col2"">6</td>
<td class=""data row1 col3"" id=""T_after_hide_row1_col3"">452</td>
</tr>
</tbody>
</table></div>
</div>
<p>Next we just add a couple more styling artifacts targeting specific parts of the table. Be careful here, since we are <em>chaining methods</em> we need to explicitly instruct the method <strong>not to</strong> <code class=""docutils literal notranslate""><span class=""pre"">overwrite</span></code> the existing styles.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[15]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">s</span><span class=""o"">.</span><span class=""n"">set_table_styles</span><span class=""p"">([</span>
    <span class=""p"">{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'th.col_heading'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'text-align: center;'</span><span class=""p"">},</span>
    <span class=""p"">{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'th.col_heading.level0'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'font-size: 1.5em;'</span><span class=""p"">},</span>
    <span class=""p"">{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'td'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'text-align: center; font-weight: bold;'</span><span class=""p"">},</span>
<span class=""p"">],</span> <span class=""n"">overwrite</span><span class=""o"">=</span><span class=""kc"">False</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[15]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_after_tab_styles1 td:hover {
  background-color: #ffffb3;
}
#T_after_tab_styles1 .index_name {
  font-style: italic;
  color: darkgrey;
  font-weight: normal;
}
#T_after_tab_styles1 th:not(.index_name) {
  background-color: #000066;
  color: white;
}
#T_after_tab_styles1 th.col_heading {
  text-align: center;
}
#T_after_tab_styles1 th.col_heading.level0 {
  font-size: 1.5em;
}
#T_after_tab_styles1 td {
  text-align: center;
  font-weight: bold;
}
</style>
<table id=""T_after_tab_styles1"">
<thead>
<tr>
<th class=""index_name level0"">Model:</th>
<th class=""col_heading level0 col0"" colspan=""2"" id=""T_after_tab_styles1_level0_col0"">Decision Tree</th>
<th class=""col_heading level0 col2"" colspan=""2"" id=""T_after_tab_styles1_level0_col2"">Regression</th>
</tr>
<tr>
<th class=""index_name level1"">Predicted:</th>
<th class=""col_heading level1 col0"" id=""T_after_tab_styles1_level1_col0"">Tumour</th>
<th class=""col_heading level1 col1"" id=""T_after_tab_styles1_level1_col1"">Non-Tumour</th>
<th class=""col_heading level1 col2"" id=""T_after_tab_styles1_level1_col2"">Tumour</th>
<th class=""col_heading level1 col3"" id=""T_after_tab_styles1_level1_col3"">Non-Tumour</th>
</tr>
<tr>
<th class=""index_name level0"">Actual Label:</th>
<th class=""blank col0""> </th>
<th class=""blank col1""> </th>
<th class=""blank col2""> </th>
<th class=""blank col3""> </th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_after_tab_styles1_level0_row0"">Tumour (Positive)</th>
<td class=""data row0 col0"" id=""T_after_tab_styles1_row0_col0"">38</td>
<td class=""data row0 col1"" id=""T_after_tab_styles1_row0_col1"">2</td>
<td class=""data row0 col2"" id=""T_after_tab_styles1_row0_col2"">18</td>
<td class=""data row0 col3"" id=""T_after_tab_styles1_row0_col3"">22</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_after_tab_styles1_level0_row1"">Non-Tumour (Negative)</th>
<td class=""data row1 col0"" id=""T_after_tab_styles1_row1_col0"">19</td>
<td class=""data row1 col1"" id=""T_after_tab_styles1_row1_col1"">439</td>
<td class=""data row1 col2"" id=""T_after_tab_styles1_row1_col2"">6</td>
<td class=""data row1 col3"" id=""T_after_tab_styles1_row1_col3"">452</td>
</tr>
</tbody>
</table></div>
</div>
<p>As a convenience method (<em>since version 1.2.0</em>) we can also pass a <strong>dict</strong> to <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.set_table_styles.html""><span class=""doc"">.set_table_styles()</span></a> which contains row or column keys. Behind the scenes Styler just indexes the keys and adds relevant <code class=""docutils literal notranslate""><span class=""pre"">.col&lt;m&gt;</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">.row&lt;n&gt;</span></code> classes as necessary to the given CSS selectors.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[17]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">s</span><span class=""o"">.</span><span class=""n"">set_table_styles</span><span class=""p"">({</span>
    <span class=""p"">(</span><span class=""s1"">'Regression'</span><span class=""p"">,</span> <span class=""s1"">'Tumour'</span><span class=""p"">):</span> <span class=""p"">[{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'th'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'border-left: 1px solid white'</span><span class=""p"">},</span>
                               <span class=""p"">{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'td'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'border-left: 1px solid #000066'</span><span class=""p"">}]</span>
<span class=""p"">},</span> <span class=""n"">overwrite</span><span class=""o"">=</span><span class=""kc"">False</span><span class=""p"">,</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[17]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_after_tab_styles2 td:hover {
  background-color: #ffffb3;
}
#T_after_tab_styles2 .index_name {
  font-style: italic;
  color: darkgrey;
  font-weight: normal;
}
#T_after_tab_styles2 th:not(.index_name) {
  background-color: #000066;
  color: white;
}
#T_after_tab_styles2 th.col_heading {
  text-align: center;
}
#T_after_tab_styles2 th.col_heading.level0 {
  font-size: 1.5em;
}
#T_after_tab_styles2 td {
  text-align: center;
  font-weight: bold;
}
#T_after_tab_styles2 th.col2 {
  border-left: 1px solid white;
}
#T_after_tab_styles2 td.col2 {
  border-left: 1px solid #000066;
}
</style>
<table id=""T_after_tab_styles2"">
<thead>
<tr>
<th class=""index_name level0"">Model:</th>
<th class=""col_heading level0 col0"" colspan=""2"" id=""T_after_tab_styles2_level0_col0"">Decision Tree</th>
<th class=""col_heading level0 col2"" colspan=""2"" id=""T_after_tab_styles2_level0_col2"">Regression</th>
</tr>
<tr>
<th class=""index_name level1"">Predicted:</th>
<th class=""col_heading level1 col0"" id=""T_after_tab_styles2_level1_col0"">Tumour</th>
<th class=""col_heading level1 col1"" id=""T_after_tab_styles2_level1_col1"">Non-Tumour</th>
<th class=""col_heading level1 col2"" id=""T_after_tab_styles2_level1_col2"">Tumour</th>
<th class=""col_heading level1 col3"" id=""T_after_tab_styles2_level1_col3"">Non-Tumour</th>
</tr>
<tr>
<th class=""index_name level0"">Actual Label:</th>
<th class=""blank col0""> </th>
<th class=""blank col1""> </th>
<th class=""blank col2""> </th>
<th class=""blank col3""> </th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_after_tab_styles2_level0_row0"">Tumour (Positive)</th>
<td class=""data row0 col0"" id=""T_after_tab_styles2_row0_col0"">38</td>
<td class=""data row0 col1"" id=""T_after_tab_styles2_row0_col1"">2</td>
<td class=""data row0 col2"" id=""T_after_tab_styles2_row0_col2"">18</td>
<td class=""data row0 col3"" id=""T_after_tab_styles2_row0_col3"">22</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_after_tab_styles2_level0_row1"">Non-Tumour (Negative)</th>
<td class=""data row1 col0"" id=""T_after_tab_styles2_row1_col0"">19</td>
<td class=""data row1 col1"" id=""T_after_tab_styles2_row1_col1"">439</td>
<td class=""data row1 col2"" id=""T_after_tab_styles2_row1_col2"">6</td>
<td class=""data row1 col3"" id=""T_after_tab_styles2_row1_col3"">452</td>
</tr>
</tbody>
</table></div>
</div>
</section>
<section id=""Setting-Classes-and-Linking-to-External-CSS"">
<h2>Setting Classes and Linking to External CSS<a class=""headerlink"" href=""#Setting-Classes-and-Linking-to-External-CSS"" title=""Link to this heading"">#</a></h2>
<p>If you have designed a website then it is likely you will already have an external CSS file that controls the styling of table and cell objects within it. You may want to use these native files rather than duplicate all the CSS in python (and duplicate any maintenance work).</p>
<section id=""Table-Attributes"">
<h3>Table Attributes<a class=""headerlink"" href=""#Table-Attributes"" title=""Link to this heading"">#</a></h3>
<p>It is very easy to add a <code class=""docutils literal notranslate""><span class=""pre"">class</span></code> to the main <code class=""docutils literal notranslate""><span class=""pre"">&lt;table&gt;</span></code> using <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.set_table_attributes.html""><span class=""doc"">.set_table_attributes()</span></a>. This method can also attach inline styles - read more in <a class=""reference internal"" href=""#CSS-Hierarchies""><span class=""std std-ref"">CSS Hierarchies</span></a>.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[19]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">out</span> <span class=""o"">=</span> <span class=""n"">s</span><span class=""o"">.</span><span class=""n"">set_table_attributes</span><span class=""p"">(</span><span class=""s1"">'class=""my-table-cls""'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">to_html</span><span class=""p"">()</span>
<span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">out</span><span class=""p"">[</span><span class=""n"">out</span><span class=""o"">.</span><span class=""n"">find</span><span class=""p"">(</span><span class=""s1"">'&lt;table'</span><span class=""p"">):][:</span><span class=""mi"">109</span><span class=""p"">])</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt empty docutils container"">
</div>
<div class=""output_area docutils container"">
<div class=""highlight""><pre>
&lt;table id=""T_xyz01"" class=""my-table-cls""&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th class=""index_name level0"" &gt;Model:&lt;/th&gt;
</pre></div></div>
</div>
</section>
<section id=""Data-Cell-CSS-Classes"">
<h3>Data Cell CSS Classes<a class=""headerlink"" href=""#Data-Cell-CSS-Classes"" title=""Link to this heading"">#</a></h3>
<p><em>New in version 1.2.0</em></p>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.set_td_classes.html""><span class=""doc"">.set_td_classes()</span></a> method accepts a DataFrame with matching indices and columns to the underlying <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.html""><span class=""doc"">Styler</span></a>’s DataFrame. That DataFrame will contain strings as css-classes to add to individual data cells: the <code class=""docutils literal notranslate""><span class=""pre"">&lt;td&gt;</span></code> elements of the <code class=""docutils literal notranslate""><span class=""pre"">&lt;table&gt;</span></code>. Rather than use external CSS we will create our classes internally and add them to table style. We will save adding the
borders until the <a class=""reference internal"" href=""#Tooltips-and-Captions""><span class=""std std-ref"">section on tooltips</span></a>.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[20]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">s</span><span class=""o"">.</span><span class=""n"">set_table_styles</span><span class=""p"">([</span>  <span class=""c1""># create internal CSS classes</span>
    <span class=""p"">{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'.true'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'background-color: #e6ffe6;'</span><span class=""p"">},</span>
    <span class=""p"">{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'.false'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'background-color: #ffe6e6;'</span><span class=""p"">},</span>
<span class=""p"">],</span> <span class=""n"">overwrite</span><span class=""o"">=</span><span class=""kc"">False</span><span class=""p"">)</span>
<span class=""n"">cell_color</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">([[</span><span class=""s1"">'true '</span><span class=""p"">,</span> <span class=""s1"">'false '</span><span class=""p"">,</span> <span class=""s1"">'true '</span><span class=""p"">,</span> <span class=""s1"">'false '</span><span class=""p"">],</span>
                           <span class=""p"">[</span><span class=""s1"">'false '</span><span class=""p"">,</span> <span class=""s1"">'true '</span><span class=""p"">,</span> <span class=""s1"">'false '</span><span class=""p"">,</span> <span class=""s1"">'true '</span><span class=""p"">]],</span>
                          <span class=""n"">index</span><span class=""o"">=</span><span class=""n"">df</span><span class=""o"">.</span><span class=""n"">index</span><span class=""p"">,</span>
                          <span class=""n"">columns</span><span class=""o"">=</span><span class=""n"">df</span><span class=""o"">.</span><span class=""n"">columns</span><span class=""p"">[:</span><span class=""mi"">4</span><span class=""p"">])</span>
<span class=""n"">s</span><span class=""o"">.</span><span class=""n"">set_td_classes</span><span class=""p"">(</span><span class=""n"">cell_color</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[20]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_xyz01 td:hover {
  background-color: #ffffb3;
}
#T_xyz01 .index_name {
  font-style: italic;
  color: darkgrey;
  font-weight: normal;
}
#T_xyz01 th:not(.index_name) {
  background-color: #000066;
  color: white;
}
#T_xyz01 th.col_heading {
  text-align: center;
}
#T_xyz01 th.col_heading.level0 {
  font-size: 1.5em;
}
#T_xyz01 td {
  text-align: center;
  font-weight: bold;
}
#T_xyz01 th.col2 {
  border-left: 1px solid white;
}
#T_xyz01 td.col2 {
  border-left: 1px solid #000066;
}
#T_xyz01 .true {
  background-color: #e6ffe6;
}
#T_xyz01 .false {
  background-color: #ffe6e6;
}
</style>
<table class=""my-table-cls"" id=""T_xyz01"">
<thead>
<tr>
<th class=""index_name level0"">Model:</th>
<th class=""col_heading level0 col0"" colspan=""2"" id=""T_xyz01_level0_col0"">Decision Tree</th>
<th class=""col_heading level0 col2"" colspan=""2"" id=""T_xyz01_level0_col2"">Regression</th>
</tr>
<tr>
<th class=""index_name level1"">Predicted:</th>
<th class=""col_heading level1 col0"" id=""T_xyz01_level1_col0"">Tumour</th>
<th class=""col_heading level1 col1"" id=""T_xyz01_level1_col1"">Non-Tumour</th>
<th class=""col_heading level1 col2"" id=""T_xyz01_level1_col2"">Tumour</th>
<th class=""col_heading level1 col3"" id=""T_xyz01_level1_col3"">Non-Tumour</th>
</tr>
<tr>
<th class=""index_name level0"">Actual Label:</th>
<th class=""blank col0""> </th>
<th class=""blank col1""> </th>
<th class=""blank col2""> </th>
<th class=""blank col3""> </th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_xyz01_level0_row0"">Tumour (Positive)</th>
<td class=""data row0 col0 true"" id=""T_xyz01_row0_col0"">38</td>
<td class=""data row0 col1 false"" id=""T_xyz01_row0_col1"">2</td>
<td class=""data row0 col2 true"" id=""T_xyz01_row0_col2"">18</td>
<td class=""data row0 col3 false"" id=""T_xyz01_row0_col3"">22</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_xyz01_level0_row1"">Non-Tumour (Negative)</th>
<td class=""data row1 col0 false"" id=""T_xyz01_row1_col0"">19</td>
<td class=""data row1 col1 true"" id=""T_xyz01_row1_col1"">439</td>
<td class=""data row1 col2 false"" id=""T_xyz01_row1_col2"">6</td>
<td class=""data row1 col3 true"" id=""T_xyz01_row1_col3"">452</td>
</tr>
</tbody>
</table></div>
</div>
</section>
</section>
<section id=""Styler-Functions"">
<h2>Styler Functions<a class=""headerlink"" href=""#Styler-Functions"" title=""Link to this heading"">#</a></h2>
<section id=""Acting-on-Data"">
<h3>Acting on Data<a class=""headerlink"" href=""#Acting-on-Data"" title=""Link to this heading"">#</a></h3>
<p>We use the following methods to pass your style functions. Both of those methods take a function (and some other keyword arguments) and apply it to the DataFrame in a certain way, rendering CSS styles.</p>
<ul class=""simple"">
<li><p><a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.map.html""><span class=""doc"">.map()</span></a> (elementwise): accepts a function that takes a single value and returns a string with the CSS attribute-value pair.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.apply.html""><span class=""doc"">.apply()</span></a> (column-/row-/table-wise): accepts a function that takes a Series or DataFrame and returns a Series, DataFrame, or numpy array with an identical shape where each element is a string with a CSS attribute-value pair. This method passes each column or row of your DataFrame one-at-a-time or the entire table at once, depending on the <code class=""docutils literal notranslate""><span class=""pre"">axis</span></code> keyword argument. For columnwise use <code class=""docutils literal notranslate""><span class=""pre"">axis=0</span></code>, rowwise use <code class=""docutils literal notranslate""><span class=""pre"">axis=1</span></code>, and for the
entire table at once use <code class=""docutils literal notranslate""><span class=""pre"">axis=None</span></code>.</p></li>
</ul>
<p>This method is powerful for applying multiple, complex logic to data cells. We create a new DataFrame to demonstrate this.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[22]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">np</span><span class=""o"">.</span><span class=""n"">random</span><span class=""o"">.</span><span class=""n"">seed</span><span class=""p"">(</span><span class=""mi"">0</span><span class=""p"">)</span>
<span class=""n"">df2</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">(</span><span class=""n"">np</span><span class=""o"">.</span><span class=""n"">random</span><span class=""o"">.</span><span class=""n"">randn</span><span class=""p"">(</span><span class=""mi"">10</span><span class=""p"">,</span><span class=""mi"">4</span><span class=""p"">),</span> <span class=""n"">columns</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s1"">'A'</span><span class=""p"">,</span><span class=""s1"">'B'</span><span class=""p"">,</span><span class=""s1"">'C'</span><span class=""p"">,</span><span class=""s1"">'D'</span><span class=""p"">])</span>
<span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">style</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[22]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
</style>
<table id=""T_449a4"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_449a4_level0_col0"">A</th>
<th class=""col_heading level0 col1"" id=""T_449a4_level0_col1"">B</th>
<th class=""col_heading level0 col2"" id=""T_449a4_level0_col2"">C</th>
<th class=""col_heading level0 col3"" id=""T_449a4_level0_col3"">D</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_449a4_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_449a4_row0_col0"">1.764052</td>
<td class=""data row0 col1"" id=""T_449a4_row0_col1"">0.400157</td>
<td class=""data row0 col2"" id=""T_449a4_row0_col2"">0.978738</td>
<td class=""data row0 col3"" id=""T_449a4_row0_col3"">2.240893</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_449a4_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_449a4_row1_col0"">1.867558</td>
<td class=""data row1 col1"" id=""T_449a4_row1_col1"">-0.977278</td>
<td class=""data row1 col2"" id=""T_449a4_row1_col2"">0.950088</td>
<td class=""data row1 col3"" id=""T_449a4_row1_col3"">-0.151357</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_449a4_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_449a4_row2_col0"">-0.103219</td>
<td class=""data row2 col1"" id=""T_449a4_row2_col1"">0.410599</td>
<td class=""data row2 col2"" id=""T_449a4_row2_col2"">0.144044</td>
<td class=""data row2 col3"" id=""T_449a4_row2_col3"">1.454274</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_449a4_level0_row3"">3</th>
<td class=""data row3 col0"" id=""T_449a4_row3_col0"">0.761038</td>
<td class=""data row3 col1"" id=""T_449a4_row3_col1"">0.121675</td>
<td class=""data row3 col2"" id=""T_449a4_row3_col2"">0.443863</td>
<td class=""data row3 col3"" id=""T_449a4_row3_col3"">0.333674</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_449a4_level0_row4"">4</th>
<td class=""data row4 col0"" id=""T_449a4_row4_col0"">1.494079</td>
<td class=""data row4 col1"" id=""T_449a4_row4_col1"">-0.205158</td>
<td class=""data row4 col2"" id=""T_449a4_row4_col2"">0.313068</td>
<td class=""data row4 col3"" id=""T_449a4_row4_col3"">-0.854096</td>
</tr>
<tr>
<th class=""row_heading level0 row5"" id=""T_449a4_level0_row5"">5</th>
<td class=""data row5 col0"" id=""T_449a4_row5_col0"">-2.552990</td>
<td class=""data row5 col1"" id=""T_449a4_row5_col1"">0.653619</td>
<td class=""data row5 col2"" id=""T_449a4_row5_col2"">0.864436</td>
<td class=""data row5 col3"" id=""T_449a4_row5_col3"">-0.742165</td>
</tr>
<tr>
<th class=""row_heading level0 row6"" id=""T_449a4_level0_row6"">6</th>
<td class=""data row6 col0"" id=""T_449a4_row6_col0"">2.269755</td>
<td class=""data row6 col1"" id=""T_449a4_row6_col1"">-1.454366</td>
<td class=""data row6 col2"" id=""T_449a4_row6_col2"">0.045759</td>
<td class=""data row6 col3"" id=""T_449a4_row6_col3"">-0.187184</td>
</tr>
<tr>
<th class=""row_heading level0 row7"" id=""T_449a4_level0_row7"">7</th>
<td class=""data row7 col0"" id=""T_449a4_row7_col0"">1.532779</td>
<td class=""data row7 col1"" id=""T_449a4_row7_col1"">1.469359</td>
<td class=""data row7 col2"" id=""T_449a4_row7_col2"">0.154947</td>
<td class=""data row7 col3"" id=""T_449a4_row7_col3"">0.378163</td>
</tr>
<tr>
<th class=""row_heading level0 row8"" id=""T_449a4_level0_row8"">8</th>
<td class=""data row8 col0"" id=""T_449a4_row8_col0"">-0.887786</td>
<td class=""data row8 col1"" id=""T_449a4_row8_col1"">-1.980796</td>
<td class=""data row8 col2"" id=""T_449a4_row8_col2"">-0.347912</td>
<td class=""data row8 col3"" id=""T_449a4_row8_col3"">0.156349</td>
</tr>
<tr>
<th class=""row_heading level0 row9"" id=""T_449a4_level0_row9"">9</th>
<td class=""data row9 col0"" id=""T_449a4_row9_col0"">1.230291</td>
<td class=""data row9 col1"" id=""T_449a4_row9_col1"">1.202380</td>
<td class=""data row9 col2"" id=""T_449a4_row9_col2"">-0.387327</td>
<td class=""data row9 col3"" id=""T_449a4_row9_col3"">-0.302303</td>
</tr>
</tbody>
</table></div>
</div>
<p>For example we can build a function that colors text if it is negative, and chain this with a function that partially fades cells of negligible value. Since this looks at each element in turn we use <code class=""docutils literal notranslate""><span class=""pre"">map</span></code>.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[23]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">style_negative</span><span class=""p"">(</span><span class=""n"">v</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">''</span><span class=""p"">):</span>
    <span class=""k"">return</span> <span class=""n"">props</span> <span class=""k"">if</span> <span class=""n"">v</span> <span class=""o"">&lt;</span> <span class=""mi"">0</span> <span class=""k"">else</span> <span class=""kc"">None</span>
<span class=""n"">s2</span> <span class=""o"">=</span> <span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">map</span><span class=""p"">(</span><span class=""n"">style_negative</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">'color:red;'</span><span class=""p"">)</span>\
              <span class=""o"">.</span><span class=""n"">map</span><span class=""p"">(</span><span class=""k"">lambda</span> <span class=""n"">v</span><span class=""p"">:</span> <span class=""s1"">'opacity: 20%;'</span> <span class=""k"">if</span> <span class=""p"">(</span><span class=""n"">v</span> <span class=""o"">&lt;</span> <span class=""mf"">0.3</span><span class=""p"">)</span> <span class=""ow"">and</span> <span class=""p"">(</span><span class=""n"">v</span> <span class=""o"">&gt;</span> <span class=""o"">-</span><span class=""mf"">0.3</span><span class=""p"">)</span> <span class=""k"">else</span> <span class=""kc"">None</span><span class=""p"">)</span>
<span class=""n"">s2</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[23]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_50b1a_row1_col1, #T_50b1a_row4_col3, #T_50b1a_row5_col0, #T_50b1a_row5_col3, #T_50b1a_row6_col1, #T_50b1a_row8_col0, #T_50b1a_row8_col1, #T_50b1a_row8_col2, #T_50b1a_row9_col2, #T_50b1a_row9_col3 {
  color: red;
}
#T_50b1a_row1_col3, #T_50b1a_row2_col0, #T_50b1a_row4_col1, #T_50b1a_row6_col3 {
  color: red;
  opacity: 20%;
}
#T_50b1a_row2_col2, #T_50b1a_row3_col1, #T_50b1a_row6_col2, #T_50b1a_row7_col2, #T_50b1a_row8_col3 {
  opacity: 20%;
}
</style>
<table id=""T_50b1a"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_50b1a_level0_col0"">A</th>
<th class=""col_heading level0 col1"" id=""T_50b1a_level0_col1"">B</th>
<th class=""col_heading level0 col2"" id=""T_50b1a_level0_col2"">C</th>
<th class=""col_heading level0 col3"" id=""T_50b1a_level0_col3"">D</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_50b1a_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_50b1a_row0_col0"">1.764052</td>
<td class=""data row0 col1"" id=""T_50b1a_row0_col1"">0.400157</td>
<td class=""data row0 col2"" id=""T_50b1a_row0_col2"">0.978738</td>
<td class=""data row0 col3"" id=""T_50b1a_row0_col3"">2.240893</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_50b1a_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_50b1a_row1_col0"">1.867558</td>
<td class=""data row1 col1"" id=""T_50b1a_row1_col1"">-0.977278</td>
<td class=""data row1 col2"" id=""T_50b1a_row1_col2"">0.950088</td>
<td class=""data row1 col3"" id=""T_50b1a_row1_col3"">-0.151357</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_50b1a_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_50b1a_row2_col0"">-0.103219</td>
<td class=""data row2 col1"" id=""T_50b1a_row2_col1"">0.410599</td>
<td class=""data row2 col2"" id=""T_50b1a_row2_col2"">0.144044</td>
<td class=""data row2 col3"" id=""T_50b1a_row2_col3"">1.454274</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_50b1a_level0_row3"">3</th>
<td class=""data row3 col0"" id=""T_50b1a_row3_col0"">0.761038</td>
<td class=""data row3 col1"" id=""T_50b1a_row3_col1"">0.121675</td>
<td class=""data row3 col2"" id=""T_50b1a_row3_col2"">0.443863</td>
<td class=""data row3 col3"" id=""T_50b1a_row3_col3"">0.333674</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_50b1a_level0_row4"">4</th>
<td class=""data row4 col0"" id=""T_50b1a_row4_col0"">1.494079</td>
<td class=""data row4 col1"" id=""T_50b1a_row4_col1"">-0.205158</td>
<td class=""data row4 col2"" id=""T_50b1a_row4_col2"">0.313068</td>
<td class=""data row4 col3"" id=""T_50b1a_row4_col3"">-0.854096</td>
</tr>
<tr>
<th class=""row_heading level0 row5"" id=""T_50b1a_level0_row5"">5</th>
<td class=""data row5 col0"" id=""T_50b1a_row5_col0"">-2.552990</td>
<td class=""data row5 col1"" id=""T_50b1a_row5_col1"">0.653619</td>
<td class=""data row5 col2"" id=""T_50b1a_row5_col2"">0.864436</td>
<td class=""data row5 col3"" id=""T_50b1a_row5_col3"">-0.742165</td>
</tr>
<tr>
<th class=""row_heading level0 row6"" id=""T_50b1a_level0_row6"">6</th>
<td class=""data row6 col0"" id=""T_50b1a_row6_col0"">2.269755</td>
<td class=""data row6 col1"" id=""T_50b1a_row6_col1"">-1.454366</td>
<td class=""data row6 col2"" id=""T_50b1a_row6_col2"">0.045759</td>
<td class=""data row6 col3"" id=""T_50b1a_row6_col3"">-0.187184</td>
</tr>
<tr>
<th class=""row_heading level0 row7"" id=""T_50b1a_level0_row7"">7</th>
<td class=""data row7 col0"" id=""T_50b1a_row7_col0"">1.532779</td>
<td class=""data row7 col1"" id=""T_50b1a_row7_col1"">1.469359</td>
<td class=""data row7 col2"" id=""T_50b1a_row7_col2"">0.154947</td>
<td class=""data row7 col3"" id=""T_50b1a_row7_col3"">0.378163</td>
</tr>
<tr>
<th class=""row_heading level0 row8"" id=""T_50b1a_level0_row8"">8</th>
<td class=""data row8 col0"" id=""T_50b1a_row8_col0"">-0.887786</td>
<td class=""data row8 col1"" id=""T_50b1a_row8_col1"">-1.980796</td>
<td class=""data row8 col2"" id=""T_50b1a_row8_col2"">-0.347912</td>
<td class=""data row8 col3"" id=""T_50b1a_row8_col3"">0.156349</td>
</tr>
<tr>
<th class=""row_heading level0 row9"" id=""T_50b1a_level0_row9"">9</th>
<td class=""data row9 col0"" id=""T_50b1a_row9_col0"">1.230291</td>
<td class=""data row9 col1"" id=""T_50b1a_row9_col1"">1.202380</td>
<td class=""data row9 col2"" id=""T_50b1a_row9_col2"">-0.387327</td>
<td class=""data row9 col3"" id=""T_50b1a_row9_col3"">-0.302303</td>
</tr>
</tbody>
</table></div>
</div>
<p>We can also build a function that highlights the maximum value across rows, cols, and the DataFrame all at once. In this case we use <code class=""docutils literal notranslate""><span class=""pre"">apply</span></code>. Below we highlight the maximum in a column.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[25]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">highlight_max</span><span class=""p"">(</span><span class=""n"">s</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">''</span><span class=""p"">):</span>
    <span class=""k"">return</span> <span class=""n"">np</span><span class=""o"">.</span><span class=""n"">where</span><span class=""p"">(</span><span class=""n"">s</span> <span class=""o"">==</span> <span class=""n"">np</span><span class=""o"">.</span><span class=""n"">nanmax</span><span class=""p"">(</span><span class=""n"">s</span><span class=""o"">.</span><span class=""n"">values</span><span class=""p"">),</span> <span class=""n"">props</span><span class=""p"">,</span> <span class=""s1"">''</span><span class=""p"">)</span>
<span class=""n"">s2</span><span class=""o"">.</span><span class=""n"">apply</span><span class=""p"">(</span><span class=""n"">highlight_max</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">'color:white;background-color:darkblue'</span><span class=""p"">,</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[25]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_after_applymap_row0_col2, #T_after_applymap_row0_col3, #T_after_applymap_row6_col0, #T_after_applymap_row7_col1 {
  color: white;
  background-color: darkblue;
}
#T_after_applymap_row1_col1, #T_after_applymap_row4_col3, #T_after_applymap_row5_col0, #T_after_applymap_row5_col3, #T_after_applymap_row6_col1, #T_after_applymap_row8_col0, #T_after_applymap_row8_col1, #T_after_applymap_row8_col2, #T_after_applymap_row9_col2, #T_after_applymap_row9_col3 {
  color: red;
}
#T_after_applymap_row1_col3, #T_after_applymap_row2_col0, #T_after_applymap_row4_col1, #T_after_applymap_row6_col3 {
  color: red;
  opacity: 20%;
}
#T_after_applymap_row2_col2, #T_after_applymap_row3_col1, #T_after_applymap_row6_col2, #T_after_applymap_row7_col2, #T_after_applymap_row8_col3 {
  opacity: 20%;
}
</style>
<table id=""T_after_applymap"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_after_applymap_level0_col0"">A</th>
<th class=""col_heading level0 col1"" id=""T_after_applymap_level0_col1"">B</th>
<th class=""col_heading level0 col2"" id=""T_after_applymap_level0_col2"">C</th>
<th class=""col_heading level0 col3"" id=""T_after_applymap_level0_col3"">D</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_after_applymap_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_after_applymap_row0_col0"">1.764052</td>
<td class=""data row0 col1"" id=""T_after_applymap_row0_col1"">0.400157</td>
<td class=""data row0 col2"" id=""T_after_applymap_row0_col2"">0.978738</td>
<td class=""data row0 col3"" id=""T_after_applymap_row0_col3"">2.240893</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_after_applymap_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_after_applymap_row1_col0"">1.867558</td>
<td class=""data row1 col1"" id=""T_after_applymap_row1_col1"">-0.977278</td>
<td class=""data row1 col2"" id=""T_after_applymap_row1_col2"">0.950088</td>
<td class=""data row1 col3"" id=""T_after_applymap_row1_col3"">-0.151357</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_after_applymap_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_after_applymap_row2_col0"">-0.103219</td>
<td class=""data row2 col1"" id=""T_after_applymap_row2_col1"">0.410599</td>
<td class=""data row2 col2"" id=""T_after_applymap_row2_col2"">0.144044</td>
<td class=""data row2 col3"" id=""T_after_applymap_row2_col3"">1.454274</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_after_applymap_level0_row3"">3</th>
<td class=""data row3 col0"" id=""T_after_applymap_row3_col0"">0.761038</td>
<td class=""data row3 col1"" id=""T_after_applymap_row3_col1"">0.121675</td>
<td class=""data row3 col2"" id=""T_after_applymap_row3_col2"">0.443863</td>
<td class=""data row3 col3"" id=""T_after_applymap_row3_col3"">0.333674</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_after_applymap_level0_row4"">4</th>
<td class=""data row4 col0"" id=""T_after_applymap_row4_col0"">1.494079</td>
<td class=""data row4 col1"" id=""T_after_applymap_row4_col1"">-0.205158</td>
<td class=""data row4 col2"" id=""T_after_applymap_row4_col2"">0.313068</td>
<td class=""data row4 col3"" id=""T_after_applymap_row4_col3"">-0.854096</td>
</tr>
<tr>
<th class=""row_heading level0 row5"" id=""T_after_applymap_level0_row5"">5</th>
<td class=""data row5 col0"" id=""T_after_applymap_row5_col0"">-2.552990</td>
<td class=""data row5 col1"" id=""T_after_applymap_row5_col1"">0.653619</td>
<td class=""data row5 col2"" id=""T_after_applymap_row5_col2"">0.864436</td>
<td class=""data row5 col3"" id=""T_after_applymap_row5_col3"">-0.742165</td>
</tr>
<tr>
<th class=""row_heading level0 row6"" id=""T_after_applymap_level0_row6"">6</th>
<td class=""data row6 col0"" id=""T_after_applymap_row6_col0"">2.269755</td>
<td class=""data row6 col1"" id=""T_after_applymap_row6_col1"">-1.454366</td>
<td class=""data row6 col2"" id=""T_after_applymap_row6_col2"">0.045759</td>
<td class=""data row6 col3"" id=""T_after_applymap_row6_col3"">-0.187184</td>
</tr>
<tr>
<th class=""row_heading level0 row7"" id=""T_after_applymap_level0_row7"">7</th>
<td class=""data row7 col0"" id=""T_after_applymap_row7_col0"">1.532779</td>
<td class=""data row7 col1"" id=""T_after_applymap_row7_col1"">1.469359</td>
<td class=""data row7 col2"" id=""T_after_applymap_row7_col2"">0.154947</td>
<td class=""data row7 col3"" id=""T_after_applymap_row7_col3"">0.378163</td>
</tr>
<tr>
<th class=""row_heading level0 row8"" id=""T_after_applymap_level0_row8"">8</th>
<td class=""data row8 col0"" id=""T_after_applymap_row8_col0"">-0.887786</td>
<td class=""data row8 col1"" id=""T_after_applymap_row8_col1"">-1.980796</td>
<td class=""data row8 col2"" id=""T_after_applymap_row8_col2"">-0.347912</td>
<td class=""data row8 col3"" id=""T_after_applymap_row8_col3"">0.156349</td>
</tr>
<tr>
<th class=""row_heading level0 row9"" id=""T_after_applymap_level0_row9"">9</th>
<td class=""data row9 col0"" id=""T_after_applymap_row9_col0"">1.230291</td>
<td class=""data row9 col1"" id=""T_after_applymap_row9_col1"">1.202380</td>
<td class=""data row9 col2"" id=""T_after_applymap_row9_col2"">-0.387327</td>
<td class=""data row9 col3"" id=""T_after_applymap_row9_col3"">-0.302303</td>
</tr>
</tbody>
</table></div>
</div>
<p>We can use the same function across the different axes, highlighting here the DataFrame maximum in purple, and row maximums in pink.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[27]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">s2</span><span class=""o"">.</span><span class=""n"">apply</span><span class=""p"">(</span><span class=""n"">highlight_max</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">'color:white;background-color:pink;'</span><span class=""p"">,</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">1</span><span class=""p"">)</span>\
  <span class=""o"">.</span><span class=""n"">apply</span><span class=""p"">(</span><span class=""n"">highlight_max</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">'color:white;background-color:purple'</span><span class=""p"">,</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[27]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_after_apply_row0_col2, #T_after_apply_row7_col1 {
  color: white;
  background-color: darkblue;
}
#T_after_apply_row0_col3 {
  color: white;
  background-color: darkblue;
  color: white;
  background-color: pink;
}
#T_after_apply_row1_col0, #T_after_apply_row2_col3, #T_after_apply_row3_col0, #T_after_apply_row4_col0, #T_after_apply_row5_col2, #T_after_apply_row7_col0, #T_after_apply_row9_col0 {
  color: white;
  background-color: pink;
}
#T_after_apply_row1_col1, #T_after_apply_row4_col3, #T_after_apply_row5_col0, #T_after_apply_row5_col3, #T_after_apply_row6_col1, #T_after_apply_row8_col0, #T_after_apply_row8_col1, #T_after_apply_row8_col2, #T_after_apply_row9_col2, #T_after_apply_row9_col3 {
  color: red;
}
#T_after_apply_row1_col3, #T_after_apply_row2_col0, #T_after_apply_row4_col1, #T_after_apply_row6_col3 {
  color: red;
  opacity: 20%;
}
#T_after_apply_row2_col2, #T_after_apply_row3_col1, #T_after_apply_row6_col2, #T_after_apply_row7_col2 {
  opacity: 20%;
}
#T_after_apply_row6_col0 {
  color: white;
  background-color: darkblue;
  color: white;
  background-color: pink;
  color: white;
  background-color: purple;
}
#T_after_apply_row8_col3 {
  opacity: 20%;
  color: white;
  background-color: pink;
}
</style>
<table id=""T_after_apply"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_after_apply_level0_col0"">A</th>
<th class=""col_heading level0 col1"" id=""T_after_apply_level0_col1"">B</th>
<th class=""col_heading level0 col2"" id=""T_after_apply_level0_col2"">C</th>
<th class=""col_heading level0 col3"" id=""T_after_apply_level0_col3"">D</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_after_apply_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_after_apply_row0_col0"">1.764052</td>
<td class=""data row0 col1"" id=""T_after_apply_row0_col1"">0.400157</td>
<td class=""data row0 col2"" id=""T_after_apply_row0_col2"">0.978738</td>
<td class=""data row0 col3"" id=""T_after_apply_row0_col3"">2.240893</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_after_apply_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_after_apply_row1_col0"">1.867558</td>
<td class=""data row1 col1"" id=""T_after_apply_row1_col1"">-0.977278</td>
<td class=""data row1 col2"" id=""T_after_apply_row1_col2"">0.950088</td>
<td class=""data row1 col3"" id=""T_after_apply_row1_col3"">-0.151357</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_after_apply_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_after_apply_row2_col0"">-0.103219</td>
<td class=""data row2 col1"" id=""T_after_apply_row2_col1"">0.410599</td>
<td class=""data row2 col2"" id=""T_after_apply_row2_col2"">0.144044</td>
<td class=""data row2 col3"" id=""T_after_apply_row2_col3"">1.454274</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_after_apply_level0_row3"">3</th>
<td class=""data row3 col0"" id=""T_after_apply_row3_col0"">0.761038</td>
<td class=""data row3 col1"" id=""T_after_apply_row3_col1"">0.121675</td>
<td class=""data row3 col2"" id=""T_after_apply_row3_col2"">0.443863</td>
<td class=""data row3 col3"" id=""T_after_apply_row3_col3"">0.333674</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_after_apply_level0_row4"">4</th>
<td class=""data row4 col0"" id=""T_after_apply_row4_col0"">1.494079</td>
<td class=""data row4 col1"" id=""T_after_apply_row4_col1"">-0.205158</td>
<td class=""data row4 col2"" id=""T_after_apply_row4_col2"">0.313068</td>
<td class=""data row4 col3"" id=""T_after_apply_row4_col3"">-0.854096</td>
</tr>
<tr>
<th class=""row_heading level0 row5"" id=""T_after_apply_level0_row5"">5</th>
<td class=""data row5 col0"" id=""T_after_apply_row5_col0"">-2.552990</td>
<td class=""data row5 col1"" id=""T_after_apply_row5_col1"">0.653619</td>
<td class=""data row5 col2"" id=""T_after_apply_row5_col2"">0.864436</td>
<td class=""data row5 col3"" id=""T_after_apply_row5_col3"">-0.742165</td>
</tr>
<tr>
<th class=""row_heading level0 row6"" id=""T_after_apply_level0_row6"">6</th>
<td class=""data row6 col0"" id=""T_after_apply_row6_col0"">2.269755</td>
<td class=""data row6 col1"" id=""T_after_apply_row6_col1"">-1.454366</td>
<td class=""data row6 col2"" id=""T_after_apply_row6_col2"">0.045759</td>
<td class=""data row6 col3"" id=""T_after_apply_row6_col3"">-0.187184</td>
</tr>
<tr>
<th class=""row_heading level0 row7"" id=""T_after_apply_level0_row7"">7</th>
<td class=""data row7 col0"" id=""T_after_apply_row7_col0"">1.532779</td>
<td class=""data row7 col1"" id=""T_after_apply_row7_col1"">1.469359</td>
<td class=""data row7 col2"" id=""T_after_apply_row7_col2"">0.154947</td>
<td class=""data row7 col3"" id=""T_after_apply_row7_col3"">0.378163</td>
</tr>
<tr>
<th class=""row_heading level0 row8"" id=""T_after_apply_level0_row8"">8</th>
<td class=""data row8 col0"" id=""T_after_apply_row8_col0"">-0.887786</td>
<td class=""data row8 col1"" id=""T_after_apply_row8_col1"">-1.980796</td>
<td class=""data row8 col2"" id=""T_after_apply_row8_col2"">-0.347912</td>
<td class=""data row8 col3"" id=""T_after_apply_row8_col3"">0.156349</td>
</tr>
<tr>
<th class=""row_heading level0 row9"" id=""T_after_apply_level0_row9"">9</th>
<td class=""data row9 col0"" id=""T_after_apply_row9_col0"">1.230291</td>
<td class=""data row9 col1"" id=""T_after_apply_row9_col1"">1.202380</td>
<td class=""data row9 col2"" id=""T_after_apply_row9_col2"">-0.387327</td>
<td class=""data row9 col3"" id=""T_after_apply_row9_col3"">-0.302303</td>
</tr>
</tbody>
</table></div>
</div>
<p>This last example shows how some styles have been overwritten by others. In general the most recent style applied is active but you can read more in the <a class=""reference internal"" href=""#CSS-Hierarchies""><span class=""std std-ref"">section on CSS hierarchies</span></a>. You can also apply these styles to more granular parts of the DataFrame - read more in section on <a class=""reference internal"" href=""#Finer-Control-with-Slicing""><span class=""std std-ref"">subset slicing</span></a>.</p>
<p>It is possible to replicate some of this functionality using just classes but it can be more cumbersome. See <a class=""reference internal"" href=""#Optimization""><span class=""std std-ref"">item 3) of Optimization</span></a></p>
<div class=""admonition note"">
<p><em>Debugging Tip</em>: If you’re having trouble writing your style function, try just passing it into <code class=""docutils literal notranslate""><span class=""pre"">DataFrame.apply</span></code>. Internally, <code class=""docutils literal notranslate""><span class=""pre"">Styler.apply</span></code> uses <code class=""docutils literal notranslate""><span class=""pre"">DataFrame.apply</span></code> so the result should be the same, and with <code class=""docutils literal notranslate""><span class=""pre"">DataFrame.apply</span></code> you will be able to inspect the CSS string output of your intended function in each cell.</p>
</div>
</section>
<section id=""Acting-on-the-Index-and-Column-Headers"">
<h3>Acting on the Index and Column Headers<a class=""headerlink"" href=""#Acting-on-the-Index-and-Column-Headers"" title=""Link to this heading"">#</a></h3>
<p>Similar application is achieved for headers by using:</p>
<ul class=""simple"">
<li><p><a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.map_index.html""><span class=""doc"">.map_index()</span></a> (elementwise): accepts a function that takes a single value and returns a string with the CSS attribute-value pair.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.apply_index.html""><span class=""doc"">.apply_index()</span></a> (level-wise): accepts a function that takes a Series and returns a Series, or numpy array with an identical shape where each element is a string with a CSS attribute-value pair. This method passes each level of your Index one-at-a-time. To style the index use <code class=""docutils literal notranslate""><span class=""pre"">axis=0</span></code> and to style the column headers use <code class=""docutils literal notranslate""><span class=""pre"">axis=1</span></code>.</p></li>
</ul>
<p>You can select a <code class=""docutils literal notranslate""><span class=""pre"">level</span></code> of a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> but currently no similar <code class=""docutils literal notranslate""><span class=""pre"">subset</span></code> application is available for these methods.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[29]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">s2</span><span class=""o"">.</span><span class=""n"">map_index</span><span class=""p"">(</span><span class=""k"">lambda</span> <span class=""n"">v</span><span class=""p"">:</span> <span class=""s2"">""color:pink;""</span> <span class=""k"">if</span> <span class=""n"">v</span><span class=""o"">&gt;</span><span class=""mi"">4</span> <span class=""k"">else</span> <span class=""s2"">""color:darkblue;""</span><span class=""p"">,</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">)</span>
<span class=""n"">s2</span><span class=""o"">.</span><span class=""n"">apply_index</span><span class=""p"">(</span><span class=""k"">lambda</span> <span class=""n"">s</span><span class=""p"">:</span> <span class=""n"">np</span><span class=""o"">.</span><span class=""n"">where</span><span class=""p"">(</span><span class=""n"">s</span><span class=""o"">.</span><span class=""n"">isin</span><span class=""p"">([</span><span class=""s2"">""A""</span><span class=""p"">,</span> <span class=""s2"">""B""</span><span class=""p"">]),</span> <span class=""s2"">""color:pink;""</span><span class=""p"">,</span> <span class=""s2"">""color:darkblue;""</span><span class=""p"">),</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">1</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[29]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_after_apply_again_row0_col2, #T_after_apply_again_row7_col1 {
  color: white;
  background-color: darkblue;
}
#T_after_apply_again_row0_col3 {
  color: white;
  background-color: darkblue;
  color: white;
  background-color: pink;
}
#T_after_apply_again_row1_col0, #T_after_apply_again_row2_col3, #T_after_apply_again_row3_col0, #T_after_apply_again_row4_col0, #T_after_apply_again_row5_col2, #T_after_apply_again_row7_col0, #T_after_apply_again_row9_col0 {
  color: white;
  background-color: pink;
}
#T_after_apply_again_row1_col1, #T_after_apply_again_row4_col3, #T_after_apply_again_row5_col0, #T_after_apply_again_row5_col3, #T_after_apply_again_row6_col1, #T_after_apply_again_row8_col0, #T_after_apply_again_row8_col1, #T_after_apply_again_row8_col2, #T_after_apply_again_row9_col2, #T_after_apply_again_row9_col3 {
  color: red;
}
#T_after_apply_again_row1_col3, #T_after_apply_again_row2_col0, #T_after_apply_again_row4_col1, #T_after_apply_again_row6_col3 {
  color: red;
  opacity: 20%;
}
#T_after_apply_again_row2_col2, #T_after_apply_again_row3_col1, #T_after_apply_again_row6_col2, #T_after_apply_again_row7_col2 {
  opacity: 20%;
}
#T_after_apply_again_row6_col0 {
  color: white;
  background-color: darkblue;
  color: white;
  background-color: pink;
  color: white;
  background-color: purple;
}
#T_after_apply_again_row8_col3 {
  opacity: 20%;
  color: white;
  background-color: pink;
}
#T_after_apply_again_level0_row0, #T_after_apply_again_level0_row1, #T_after_apply_again_level0_row2, #T_after_apply_again_level0_row3, #T_after_apply_again_level0_row4 {
  color: darkblue;
}
#T_after_apply_again_level0_row5, #T_after_apply_again_level0_row6, #T_after_apply_again_level0_row7, #T_after_apply_again_level0_row8, #T_after_apply_again_level0_row9 {
  color: pink;
}
#T_after_apply_again_level0_col0, #T_after_apply_again_level0_col1 {
  color: pink;
}
#T_after_apply_again_level0_col2, #T_after_apply_again_level0_col3 {
  color: darkblue;
}
</style>
<table id=""T_after_apply_again"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_after_apply_again_level0_col0"">A</th>
<th class=""col_heading level0 col1"" id=""T_after_apply_again_level0_col1"">B</th>
<th class=""col_heading level0 col2"" id=""T_after_apply_again_level0_col2"">C</th>
<th class=""col_heading level0 col3"" id=""T_after_apply_again_level0_col3"">D</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_after_apply_again_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_after_apply_again_row0_col0"">1.764052</td>
<td class=""data row0 col1"" id=""T_after_apply_again_row0_col1"">0.400157</td>
<td class=""data row0 col2"" id=""T_after_apply_again_row0_col2"">0.978738</td>
<td class=""data row0 col3"" id=""T_after_apply_again_row0_col3"">2.240893</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_after_apply_again_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_after_apply_again_row1_col0"">1.867558</td>
<td class=""data row1 col1"" id=""T_after_apply_again_row1_col1"">-0.977278</td>
<td class=""data row1 col2"" id=""T_after_apply_again_row1_col2"">0.950088</td>
<td class=""data row1 col3"" id=""T_after_apply_again_row1_col3"">-0.151357</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_after_apply_again_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_after_apply_again_row2_col0"">-0.103219</td>
<td class=""data row2 col1"" id=""T_after_apply_again_row2_col1"">0.410599</td>
<td class=""data row2 col2"" id=""T_after_apply_again_row2_col2"">0.144044</td>
<td class=""data row2 col3"" id=""T_after_apply_again_row2_col3"">1.454274</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_after_apply_again_level0_row3"">3</th>
<td class=""data row3 col0"" id=""T_after_apply_again_row3_col0"">0.761038</td>
<td class=""data row3 col1"" id=""T_after_apply_again_row3_col1"">0.121675</td>
<td class=""data row3 col2"" id=""T_after_apply_again_row3_col2"">0.443863</td>
<td class=""data row3 col3"" id=""T_after_apply_again_row3_col3"">0.333674</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_after_apply_again_level0_row4"">4</th>
<td class=""data row4 col0"" id=""T_after_apply_again_row4_col0"">1.494079</td>
<td class=""data row4 col1"" id=""T_after_apply_again_row4_col1"">-0.205158</td>
<td class=""data row4 col2"" id=""T_after_apply_again_row4_col2"">0.313068</td>
<td class=""data row4 col3"" id=""T_after_apply_again_row4_col3"">-0.854096</td>
</tr>
<tr>
<th class=""row_heading level0 row5"" id=""T_after_apply_again_level0_row5"">5</th>
<td class=""data row5 col0"" id=""T_after_apply_again_row5_col0"">-2.552990</td>
<td class=""data row5 col1"" id=""T_after_apply_again_row5_col1"">0.653619</td>
<td class=""data row5 col2"" id=""T_after_apply_again_row5_col2"">0.864436</td>
<td class=""data row5 col3"" id=""T_after_apply_again_row5_col3"">-0.742165</td>
</tr>
<tr>
<th class=""row_heading level0 row6"" id=""T_after_apply_again_level0_row6"">6</th>
<td class=""data row6 col0"" id=""T_after_apply_again_row6_col0"">2.269755</td>
<td class=""data row6 col1"" id=""T_after_apply_again_row6_col1"">-1.454366</td>
<td class=""data row6 col2"" id=""T_after_apply_again_row6_col2"">0.045759</td>
<td class=""data row6 col3"" id=""T_after_apply_again_row6_col3"">-0.187184</td>
</tr>
<tr>
<th class=""row_heading level0 row7"" id=""T_after_apply_again_level0_row7"">7</th>
<td class=""data row7 col0"" id=""T_after_apply_again_row7_col0"">1.532779</td>
<td class=""data row7 col1"" id=""T_after_apply_again_row7_col1"">1.469359</td>
<td class=""data row7 col2"" id=""T_after_apply_again_row7_col2"">0.154947</td>
<td class=""data row7 col3"" id=""T_after_apply_again_row7_col3"">0.378163</td>
</tr>
<tr>
<th class=""row_heading level0 row8"" id=""T_after_apply_again_level0_row8"">8</th>
<td class=""data row8 col0"" id=""T_after_apply_again_row8_col0"">-0.887786</td>
<td class=""data row8 col1"" id=""T_after_apply_again_row8_col1"">-1.980796</td>
<td class=""data row8 col2"" id=""T_after_apply_again_row8_col2"">-0.347912</td>
<td class=""data row8 col3"" id=""T_after_apply_again_row8_col3"">0.156349</td>
</tr>
<tr>
<th class=""row_heading level0 row9"" id=""T_after_apply_again_level0_row9"">9</th>
<td class=""data row9 col0"" id=""T_after_apply_again_row9_col0"">1.230291</td>
<td class=""data row9 col1"" id=""T_after_apply_again_row9_col1"">1.202380</td>
<td class=""data row9 col2"" id=""T_after_apply_again_row9_col2"">-0.387327</td>
<td class=""data row9 col3"" id=""T_after_apply_again_row9_col3"">-0.302303</td>
</tr>
</tbody>
</table></div>
</div>
</section>
</section>
<section id=""Tooltips-and-Captions"">
<h2>Tooltips and Captions<a class=""headerlink"" href=""#Tooltips-and-Captions"" title=""Link to this heading"">#</a></h2>
<p>Table captions can be added with the <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.set_caption.html""><span class=""doc"">.set_caption()</span></a> method. You can use table styles to control the CSS relevant to the caption.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[30]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">s</span><span class=""o"">.</span><span class=""n"">set_caption</span><span class=""p"">(</span><span class=""s2"">""Confusion matrix for multiple cancer prediction models.""</span><span class=""p"">)</span>\
 <span class=""o"">.</span><span class=""n"">set_table_styles</span><span class=""p"">([{</span>
     <span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'caption'</span><span class=""p"">,</span>
     <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'caption-side: bottom; font-size:1.25em;'</span>
 <span class=""p"">}],</span> <span class=""n"">overwrite</span><span class=""o"">=</span><span class=""kc"">False</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[30]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_after_classes td:hover {
  background-color: #ffffb3;
}
#T_after_classes .index_name {
  font-style: italic;
  color: darkgrey;
  font-weight: normal;
}
#T_after_classes th:not(.index_name) {
  background-color: #000066;
  color: white;
}
#T_after_classes th.col_heading {
  text-align: center;
}
#T_after_classes th.col_heading.level0 {
  font-size: 1.5em;
}
#T_after_classes td {
  text-align: center;
  font-weight: bold;
}
#T_after_classes th.col2 {
  border-left: 1px solid white;
}
#T_after_classes td.col2 {
  border-left: 1px solid #000066;
}
#T_after_classes .true {
  background-color: #e6ffe6;
}
#T_after_classes .false {
  background-color: #ffe6e6;
}
#T_after_classes caption {
  caption-side: bottom;
  font-size: 1.25em;
}
</style>
<table class=""my-table-cls"" id=""T_after_classes"">
<caption>Confusion matrix for multiple cancer prediction models.</caption>
<thead>
<tr>
<th class=""index_name level0"">Model:</th>
<th class=""col_heading level0 col0"" colspan=""2"" id=""T_after_classes_level0_col0"">Decision Tree</th>
<th class=""col_heading level0 col2"" colspan=""2"" id=""T_after_classes_level0_col2"">Regression</th>
</tr>
<tr>
<th class=""index_name level1"">Predicted:</th>
<th class=""col_heading level1 col0"" id=""T_after_classes_level1_col0"">Tumour</th>
<th class=""col_heading level1 col1"" id=""T_after_classes_level1_col1"">Non-Tumour</th>
<th class=""col_heading level1 col2"" id=""T_after_classes_level1_col2"">Tumour</th>
<th class=""col_heading level1 col3"" id=""T_after_classes_level1_col3"">Non-Tumour</th>
</tr>
<tr>
<th class=""index_name level0"">Actual Label:</th>
<th class=""blank col0""> </th>
<th class=""blank col1""> </th>
<th class=""blank col2""> </th>
<th class=""blank col3""> </th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_after_classes_level0_row0"">Tumour (Positive)</th>
<td class=""data row0 col0 true"" id=""T_after_classes_row0_col0"">38</td>
<td class=""data row0 col1 false"" id=""T_after_classes_row0_col1"">2</td>
<td class=""data row0 col2 true"" id=""T_after_classes_row0_col2"">18</td>
<td class=""data row0 col3 false"" id=""T_after_classes_row0_col3"">22</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_after_classes_level0_row1"">Non-Tumour (Negative)</th>
<td class=""data row1 col0 false"" id=""T_after_classes_row1_col0"">19</td>
<td class=""data row1 col1 true"" id=""T_after_classes_row1_col1"">439</td>
<td class=""data row1 col2 false"" id=""T_after_classes_row1_col2"">6</td>
<td class=""data row1 col3 true"" id=""T_after_classes_row1_col3"">452</td>
</tr>
</tbody>
</table></div>
</div>
<p>Adding tooltips (<em>since version 1.3.0</em>) can be done using the <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.set_tooltips.html""><span class=""doc"">.set_tooltips()</span></a> method in the same way you can add CSS classes to data cells by providing a string based DataFrame with intersecting indices and columns. You don’t have to specify a <code class=""docutils literal notranslate""><span class=""pre"">css_class</span></code> name or any css <code class=""docutils literal notranslate""><span class=""pre"">props</span></code> for the tooltips, since there are standard defaults, but the option is there if you want more visual control.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[32]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">tt</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">([[</span><span class=""s1"">'This model has a very strong true positive rate'</span><span class=""p"">,</span>
                    <span class=""s2"">""This model's total number of false negatives is too high""</span><span class=""p"">]],</span>
                  <span class=""n"">index</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s1"">'Tumour (Positive)'</span><span class=""p"">],</span> <span class=""n"">columns</span><span class=""o"">=</span><span class=""n"">df</span><span class=""o"">.</span><span class=""n"">columns</span><span class=""p"">[[</span><span class=""mi"">0</span><span class=""p"">,</span><span class=""mi"">3</span><span class=""p"">]])</span>
<span class=""n"">s</span><span class=""o"">.</span><span class=""n"">set_tooltips</span><span class=""p"">(</span><span class=""n"">tt</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">'visibility: hidden; position: absolute; z-index: 1; border: 1px solid #000066;'</span>
                         <span class=""s1"">'background-color: white; color: #000066; font-size: 0.8em;'</span>
                         <span class=""s1"">'transform: translate(0px, -24px); padding: 0.6em; border-radius: 0.5em;'</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[32]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_after_caption td:hover {
  background-color: #ffffb3;
}
#T_after_caption .index_name {
  font-style: italic;
  color: darkgrey;
  font-weight: normal;
}
#T_after_caption th:not(.index_name) {
  background-color: #000066;
  color: white;
}
#T_after_caption th.col_heading {
  text-align: center;
}
#T_after_caption th.col_heading.level0 {
  font-size: 1.5em;
}
#T_after_caption td {
  text-align: center;
  font-weight: bold;
}
#T_after_caption th.col2 {
  border-left: 1px solid white;
}
#T_after_caption td.col2 {
  border-left: 1px solid #000066;
}
#T_after_caption .true {
  background-color: #e6ffe6;
}
#T_after_caption .false {
  background-color: #ffe6e6;
}
#T_after_caption caption {
  caption-side: bottom;
  font-size: 1.25em;
}
#T_after_caption .pd-t {
  visibility: hidden;
  position: absolute;
  z-index: 1;
  border: 1px solid #000066;
  background-color: white;
  color: #000066;
  font-size: 0.8em;
  transform: translate(0px, -24px);
  padding: 0.6em;
  border-radius: 0.5em;
}
#T_after_caption #T_after_caption_row0_col0:hover .pd-t {
  visibility: visible;
}
#T_after_caption #T_after_caption_row0_col0 .pd-t::after {
  content: ""This model has a very strong true positive rate"";
}
#T_after_caption #T_after_caption_row0_col3:hover .pd-t {
  visibility: visible;
}
#T_after_caption #T_after_caption_row0_col3 .pd-t::after {
  content: ""This model's total number of false negatives is too high"";
}
</style>
<table class=""my-table-cls"" id=""T_after_caption"">
<caption>Confusion matrix for multiple cancer prediction models.</caption>
<thead>
<tr>
<th class=""index_name level0"">Model:</th>
<th class=""col_heading level0 col0"" colspan=""2"" id=""T_after_caption_level0_col0"">Decision Tree</th>
<th class=""col_heading level0 col2"" colspan=""2"" id=""T_after_caption_level0_col2"">Regression</th>
</tr>
<tr>
<th class=""index_name level1"">Predicted:</th>
<th class=""col_heading level1 col0"" id=""T_after_caption_level1_col0"">Tumour</th>
<th class=""col_heading level1 col1"" id=""T_after_caption_level1_col1"">Non-Tumour</th>
<th class=""col_heading level1 col2"" id=""T_after_caption_level1_col2"">Tumour</th>
<th class=""col_heading level1 col3"" id=""T_after_caption_level1_col3"">Non-Tumour</th>
</tr>
<tr>
<th class=""index_name level0"">Actual Label:</th>
<th class=""blank col0""> </th>
<th class=""blank col1""> </th>
<th class=""blank col2""> </th>
<th class=""blank col3""> </th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_after_caption_level0_row0"">Tumour (Positive)</th>
<td class=""data row0 col0 true"" id=""T_after_caption_row0_col0"">38<span class=""pd-t""></span></td>
<td class=""data row0 col1 false"" id=""T_after_caption_row0_col1"">2<span class=""pd-t""></span></td>
<td class=""data row0 col2 true"" id=""T_after_caption_row0_col2"">18<span class=""pd-t""></span></td>
<td class=""data row0 col3 false"" id=""T_after_caption_row0_col3"">22<span class=""pd-t""></span></td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_after_caption_level0_row1"">Non-Tumour (Negative)</th>
<td class=""data row1 col0 false"" id=""T_after_caption_row1_col0"">19<span class=""pd-t""></span></td>
<td class=""data row1 col1 true"" id=""T_after_caption_row1_col1"">439<span class=""pd-t""></span></td>
<td class=""data row1 col2 false"" id=""T_after_caption_row1_col2"">6<span class=""pd-t""></span></td>
<td class=""data row1 col3 true"" id=""T_after_caption_row1_col3"">452<span class=""pd-t""></span></td>
</tr>
</tbody>
</table></div>
</div>
<p>The only thing left to do for our table is to add the highlighting borders to draw the audience attention to the tooltips. We will create internal CSS classes as before using table styles. <strong>Setting classes always overwrites</strong> so we need to make sure we add the previous classes.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[34]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">s</span><span class=""o"">.</span><span class=""n"">set_table_styles</span><span class=""p"">([</span>  <span class=""c1""># create internal CSS classes</span>
    <span class=""p"">{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'.border-red'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'border: 2px dashed red;'</span><span class=""p"">},</span>
    <span class=""p"">{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'.border-green'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'border: 2px dashed green;'</span><span class=""p"">},</span>
<span class=""p"">],</span> <span class=""n"">overwrite</span><span class=""o"">=</span><span class=""kc"">False</span><span class=""p"">)</span>
<span class=""n"">cell_border</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">([[</span><span class=""s1"">'border-green '</span><span class=""p"">,</span> <span class=""s1"">' '</span><span class=""p"">,</span> <span class=""s1"">' '</span><span class=""p"">,</span> <span class=""s1"">'border-red '</span><span class=""p"">],</span>
                           <span class=""p"">[</span><span class=""s1"">' '</span><span class=""p"">,</span> <span class=""s1"">' '</span><span class=""p"">,</span> <span class=""s1"">' '</span><span class=""p"">,</span> <span class=""s1"">' '</span><span class=""p"">]],</span>
                          <span class=""n"">index</span><span class=""o"">=</span><span class=""n"">df</span><span class=""o"">.</span><span class=""n"">index</span><span class=""p"">,</span>
                          <span class=""n"">columns</span><span class=""o"">=</span><span class=""n"">df</span><span class=""o"">.</span><span class=""n"">columns</span><span class=""p"">[:</span><span class=""mi"">4</span><span class=""p"">])</span>
<span class=""n"">s</span><span class=""o"">.</span><span class=""n"">set_td_classes</span><span class=""p"">(</span><span class=""n"">cell_color</span> <span class=""o"">+</span> <span class=""n"">cell_border</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[34]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_after_tooltips td:hover {
  background-color: #ffffb3;
}
#T_after_tooltips .index_name {
  font-style: italic;
  color: darkgrey;
  font-weight: normal;
}
#T_after_tooltips th:not(.index_name) {
  background-color: #000066;
  color: white;
}
#T_after_tooltips th.col_heading {
  text-align: center;
}
#T_after_tooltips th.col_heading.level0 {
  font-size: 1.5em;
}
#T_after_tooltips td {
  text-align: center;
  font-weight: bold;
}
#T_after_tooltips th.col2 {
  border-left: 1px solid white;
}
#T_after_tooltips td.col2 {
  border-left: 1px solid #000066;
}
#T_after_tooltips .true {
  background-color: #e6ffe6;
}
#T_after_tooltips .false {
  background-color: #ffe6e6;
}
#T_after_tooltips caption {
  caption-side: bottom;
  font-size: 1.25em;
}
#T_after_tooltips .border-red {
  border: 2px dashed red;
}
#T_after_tooltips .border-green {
  border: 2px dashed green;
}
#T_after_tooltips .pd-t {
  visibility: hidden;
  position: absolute;
  z-index: 1;
  border: 1px solid #000066;
  background-color: white;
  color: #000066;
  font-size: 0.8em;
  transform: translate(0px, -24px);
  padding: 0.6em;
  border-radius: 0.5em;
}
#T_after_tooltips #T_after_tooltips_row0_col0:hover .pd-t {
  visibility: visible;
}
#T_after_tooltips #T_after_tooltips_row0_col0 .pd-t::after {
  content: ""This model has a very strong true positive rate"";
}
#T_after_tooltips #T_after_tooltips_row0_col3:hover .pd-t {
  visibility: visible;
}
#T_after_tooltips #T_after_tooltips_row0_col3 .pd-t::after {
  content: ""This model's total number of false negatives is too high"";
}
</style>
<table class=""my-table-cls"" id=""T_after_tooltips"">
<caption>Confusion matrix for multiple cancer prediction models.</caption>
<thead>
<tr>
<th class=""index_name level0"">Model:</th>
<th class=""col_heading level0 col0"" colspan=""2"" id=""T_after_tooltips_level0_col0"">Decision Tree</th>
<th class=""col_heading level0 col2"" colspan=""2"" id=""T_after_tooltips_level0_col2"">Regression</th>
</tr>
<tr>
<th class=""index_name level1"">Predicted:</th>
<th class=""col_heading level1 col0"" id=""T_after_tooltips_level1_col0"">Tumour</th>
<th class=""col_heading level1 col1"" id=""T_after_tooltips_level1_col1"">Non-Tumour</th>
<th class=""col_heading level1 col2"" id=""T_after_tooltips_level1_col2"">Tumour</th>
<th class=""col_heading level1 col3"" id=""T_after_tooltips_level1_col3"">Non-Tumour</th>
</tr>
<tr>
<th class=""index_name level0"">Actual Label:</th>
<th class=""blank col0""> </th>
<th class=""blank col1""> </th>
<th class=""blank col2""> </th>
<th class=""blank col3""> </th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_after_tooltips_level0_row0"">Tumour (Positive)</th>
<td class=""data row0 col0 true border-green"" id=""T_after_tooltips_row0_col0"">38<span class=""pd-t""></span></td>
<td class=""data row0 col1 false"" id=""T_after_tooltips_row0_col1"">2<span class=""pd-t""></span></td>
<td class=""data row0 col2 true"" id=""T_after_tooltips_row0_col2"">18<span class=""pd-t""></span></td>
<td class=""data row0 col3 false border-red"" id=""T_after_tooltips_row0_col3"">22<span class=""pd-t""></span></td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_after_tooltips_level0_row1"">Non-Tumour (Negative)</th>
<td class=""data row1 col0 false"" id=""T_after_tooltips_row1_col0"">19<span class=""pd-t""></span></td>
<td class=""data row1 col1 true"" id=""T_after_tooltips_row1_col1"">439<span class=""pd-t""></span></td>
<td class=""data row1 col2 false"" id=""T_after_tooltips_row1_col2"">6<span class=""pd-t""></span></td>
<td class=""data row1 col3 true"" id=""T_after_tooltips_row1_col3"">452<span class=""pd-t""></span></td>
</tr>
</tbody>
</table></div>
</div>
</section>
<section id=""Finer-Control-with-Slicing"">
<h2>Finer Control with Slicing<a class=""headerlink"" href=""#Finer-Control-with-Slicing"" title=""Link to this heading"">#</a></h2>
<p>The examples we have shown so far for the <code class=""docutils literal notranslate""><span class=""pre"">Styler.apply</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">Styler.map</span></code> functions have not demonstrated the use of the <code class=""docutils literal notranslate""><span class=""pre"">subset</span></code> argument. This is a useful argument which permits a lot of flexibility: it allows you to apply styles to specific rows or columns, without having to code that logic into your <code class=""docutils literal notranslate""><span class=""pre"">style</span></code> function.</p>
<p>The value passed to <code class=""docutils literal notranslate""><span class=""pre"">subset</span></code> behaves similar to slicing a DataFrame;</p>
<ul class=""simple"">
<li><p>A scalar is treated as a column label</p></li>
<li><p>A list (or Series or NumPy array) is treated as multiple column labels</p></li>
<li><p>A tuple is treated as <code class=""docutils literal notranslate""><span class=""pre"">(row_indexer,</span> <span class=""pre"">column_indexer)</span></code></p></li>
</ul>
<p>Consider using <code class=""docutils literal notranslate""><span class=""pre"">pd.IndexSlice</span></code> to construct the tuple for the last one. We will create a MultiIndexed DataFrame to demonstrate the functionality.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[36]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df3</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">(</span><span class=""n"">np</span><span class=""o"">.</span><span class=""n"">random</span><span class=""o"">.</span><span class=""n"">randn</span><span class=""p"">(</span><span class=""mi"">4</span><span class=""p"">,</span><span class=""mi"">4</span><span class=""p"">),</span>
                   <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">MultiIndex</span><span class=""o"">.</span><span class=""n"">from_product</span><span class=""p"">([[</span><span class=""s1"">'A'</span><span class=""p"">,</span> <span class=""s1"">'B'</span><span class=""p"">],</span> <span class=""p"">[</span><span class=""s1"">'r1'</span><span class=""p"">,</span> <span class=""s1"">'r2'</span><span class=""p"">]]),</span>
                   <span class=""n"">columns</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s1"">'c1'</span><span class=""p"">,</span><span class=""s1"">'c2'</span><span class=""p"">,</span><span class=""s1"">'c3'</span><span class=""p"">,</span><span class=""s1"">'c4'</span><span class=""p"">])</span>
<span class=""n"">df3</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[36]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<div>
<style scoped="""">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border=""1"" class=""dataframe"">
<thead>
<tr style=""text-align: right;"">
<th></th>
<th></th>
<th>c1</th>
<th>c2</th>
<th>c3</th>
<th>c4</th>
</tr>
</thead>
<tbody>
<tr>
<th rowspan=""2"" valign=""top"">A</th>
<th>r1</th>
<td>-1.048553</td>
<td>-1.420018</td>
<td>-1.706270</td>
<td>1.950775</td>
</tr>
<tr>
<th>r2</th>
<td>-0.509652</td>
<td>-0.438074</td>
<td>-1.252795</td>
<td>0.777490</td>
</tr>
<tr>
<th rowspan=""2"" valign=""top"">B</th>
<th>r1</th>
<td>-1.613898</td>
<td>-0.212740</td>
<td>-0.895467</td>
<td>0.386902</td>
</tr>
<tr>
<th>r2</th>
<td>-0.510805</td>
<td>-1.180632</td>
<td>-0.028182</td>
<td>0.428332</td>
</tr>
</tbody>
</table>
</div></div>
</div>
<p>We will use subset to highlight the maximum in the third and fourth columns with red text. We will highlight the subset sliced region in yellow.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[37]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">slice_</span> <span class=""o"">=</span> <span class=""p"">[</span><span class=""s1"">'c3'</span><span class=""p"">,</span> <span class=""s1"">'c4'</span><span class=""p"">]</span>
<span class=""n"">df3</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">apply</span><span class=""p"">(</span><span class=""n"">highlight_max</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">'color:red;'</span><span class=""p"">,</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">,</span> <span class=""n"">subset</span><span class=""o"">=</span><span class=""n"">slice_</span><span class=""p"">)</span>\
         <span class=""o"">.</span><span class=""n"">set_properties</span><span class=""p"">(</span><span class=""o"">**</span><span class=""p"">{</span><span class=""s1"">'background-color'</span><span class=""p"">:</span> <span class=""s1"">'#ffffb3'</span><span class=""p"">},</span> <span class=""n"">subset</span><span class=""o"">=</span><span class=""n"">slice_</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[37]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_1087a_row0_col2, #T_1087a_row1_col2, #T_1087a_row1_col3, #T_1087a_row2_col2, #T_1087a_row2_col3, #T_1087a_row3_col3 {
  background-color: #ffffb3;
}
#T_1087a_row0_col3, #T_1087a_row3_col2 {
  color: red;
  background-color: #ffffb3;
}
</style>
<table id=""T_1087a"">
<thead>
<tr>
<th class=""blank""> </th>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_1087a_level0_col0"">c1</th>
<th class=""col_heading level0 col1"" id=""T_1087a_level0_col1"">c2</th>
<th class=""col_heading level0 col2"" id=""T_1087a_level0_col2"">c3</th>
<th class=""col_heading level0 col3"" id=""T_1087a_level0_col3"">c4</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_1087a_level0_row0"" rowspan=""2"">A</th>
<th class=""row_heading level1 row0"" id=""T_1087a_level1_row0"">r1</th>
<td class=""data row0 col0"" id=""T_1087a_row0_col0"">-1.048553</td>
<td class=""data row0 col1"" id=""T_1087a_row0_col1"">-1.420018</td>
<td class=""data row0 col2"" id=""T_1087a_row0_col2"">-1.706270</td>
<td class=""data row0 col3"" id=""T_1087a_row0_col3"">1.950775</td>
</tr>
<tr>
<th class=""row_heading level1 row1"" id=""T_1087a_level1_row1"">r2</th>
<td class=""data row1 col0"" id=""T_1087a_row1_col0"">-0.509652</td>
<td class=""data row1 col1"" id=""T_1087a_row1_col1"">-0.438074</td>
<td class=""data row1 col2"" id=""T_1087a_row1_col2"">-1.252795</td>
<td class=""data row1 col3"" id=""T_1087a_row1_col3"">0.777490</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_1087a_level0_row2"" rowspan=""2"">B</th>
<th class=""row_heading level1 row2"" id=""T_1087a_level1_row2"">r1</th>
<td class=""data row2 col0"" id=""T_1087a_row2_col0"">-1.613898</td>
<td class=""data row2 col1"" id=""T_1087a_row2_col1"">-0.212740</td>
<td class=""data row2 col2"" id=""T_1087a_row2_col2"">-0.895467</td>
<td class=""data row2 col3"" id=""T_1087a_row2_col3"">0.386902</td>
</tr>
<tr>
<th class=""row_heading level1 row3"" id=""T_1087a_level1_row3"">r2</th>
<td class=""data row3 col0"" id=""T_1087a_row3_col0"">-0.510805</td>
<td class=""data row3 col1"" id=""T_1087a_row3_col1"">-1.180632</td>
<td class=""data row3 col2"" id=""T_1087a_row3_col2"">-0.028182</td>
<td class=""data row3 col3"" id=""T_1087a_row3_col3"">0.428332</td>
</tr>
</tbody>
</table></div>
</div>
<p>If combined with the <code class=""docutils literal notranslate""><span class=""pre"">IndexSlice</span></code> as suggested then it can index across both dimensions with greater flexibility.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[38]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">idx</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">IndexSlice</span>
<span class=""n"">slice_</span> <span class=""o"">=</span> <span class=""n"">idx</span><span class=""p"">[</span><span class=""n"">idx</span><span class=""p"">[:,</span><span class=""s1"">'r1'</span><span class=""p"">],</span> <span class=""n"">idx</span><span class=""p"">[</span><span class=""s1"">'c2'</span><span class=""p"">:</span><span class=""s1"">'c4'</span><span class=""p"">]]</span>
<span class=""n"">df3</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">apply</span><span class=""p"">(</span><span class=""n"">highlight_max</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">'color:red;'</span><span class=""p"">,</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">,</span> <span class=""n"">subset</span><span class=""o"">=</span><span class=""n"">slice_</span><span class=""p"">)</span>\
         <span class=""o"">.</span><span class=""n"">set_properties</span><span class=""p"">(</span><span class=""o"">**</span><span class=""p"">{</span><span class=""s1"">'background-color'</span><span class=""p"">:</span> <span class=""s1"">'#ffffb3'</span><span class=""p"">},</span> <span class=""n"">subset</span><span class=""o"">=</span><span class=""n"">slice_</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[38]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_27aaa_row0_col1, #T_27aaa_row0_col2, #T_27aaa_row2_col3 {
  background-color: #ffffb3;
}
#T_27aaa_row0_col3, #T_27aaa_row2_col1, #T_27aaa_row2_col2 {
  color: red;
  background-color: #ffffb3;
}
</style>
<table id=""T_27aaa"">
<thead>
<tr>
<th class=""blank""> </th>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_27aaa_level0_col0"">c1</th>
<th class=""col_heading level0 col1"" id=""T_27aaa_level0_col1"">c2</th>
<th class=""col_heading level0 col2"" id=""T_27aaa_level0_col2"">c3</th>
<th class=""col_heading level0 col3"" id=""T_27aaa_level0_col3"">c4</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_27aaa_level0_row0"" rowspan=""2"">A</th>
<th class=""row_heading level1 row0"" id=""T_27aaa_level1_row0"">r1</th>
<td class=""data row0 col0"" id=""T_27aaa_row0_col0"">-1.048553</td>
<td class=""data row0 col1"" id=""T_27aaa_row0_col1"">-1.420018</td>
<td class=""data row0 col2"" id=""T_27aaa_row0_col2"">-1.706270</td>
<td class=""data row0 col3"" id=""T_27aaa_row0_col3"">1.950775</td>
</tr>
<tr>
<th class=""row_heading level1 row1"" id=""T_27aaa_level1_row1"">r2</th>
<td class=""data row1 col0"" id=""T_27aaa_row1_col0"">-0.509652</td>
<td class=""data row1 col1"" id=""T_27aaa_row1_col1"">-0.438074</td>
<td class=""data row1 col2"" id=""T_27aaa_row1_col2"">-1.252795</td>
<td class=""data row1 col3"" id=""T_27aaa_row1_col3"">0.777490</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_27aaa_level0_row2"" rowspan=""2"">B</th>
<th class=""row_heading level1 row2"" id=""T_27aaa_level1_row2"">r1</th>
<td class=""data row2 col0"" id=""T_27aaa_row2_col0"">-1.613898</td>
<td class=""data row2 col1"" id=""T_27aaa_row2_col1"">-0.212740</td>
<td class=""data row2 col2"" id=""T_27aaa_row2_col2"">-0.895467</td>
<td class=""data row2 col3"" id=""T_27aaa_row2_col3"">0.386902</td>
</tr>
<tr>
<th class=""row_heading level1 row3"" id=""T_27aaa_level1_row3"">r2</th>
<td class=""data row3 col0"" id=""T_27aaa_row3_col0"">-0.510805</td>
<td class=""data row3 col1"" id=""T_27aaa_row3_col1"">-1.180632</td>
<td class=""data row3 col2"" id=""T_27aaa_row3_col2"">-0.028182</td>
<td class=""data row3 col3"" id=""T_27aaa_row3_col3"">0.428332</td>
</tr>
</tbody>
</table></div>
</div>
<p>This also provides the flexibility to sub select rows when used with the <code class=""docutils literal notranslate""><span class=""pre"">axis=1</span></code>.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[39]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">slice_</span> <span class=""o"">=</span> <span class=""n"">idx</span><span class=""p"">[</span><span class=""n"">idx</span><span class=""p"">[:,</span><span class=""s1"">'r2'</span><span class=""p"">],</span> <span class=""p"">:]</span>
<span class=""n"">df3</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">apply</span><span class=""p"">(</span><span class=""n"">highlight_max</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">'color:red;'</span><span class=""p"">,</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">1</span><span class=""p"">,</span> <span class=""n"">subset</span><span class=""o"">=</span><span class=""n"">slice_</span><span class=""p"">)</span>\
         <span class=""o"">.</span><span class=""n"">set_properties</span><span class=""p"">(</span><span class=""o"">**</span><span class=""p"">{</span><span class=""s1"">'background-color'</span><span class=""p"">:</span> <span class=""s1"">'#ffffb3'</span><span class=""p"">},</span> <span class=""n"">subset</span><span class=""o"">=</span><span class=""n"">slice_</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[39]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_cbe4e_row1_col0, #T_cbe4e_row1_col1, #T_cbe4e_row1_col2, #T_cbe4e_row3_col0, #T_cbe4e_row3_col1, #T_cbe4e_row3_col2 {
  background-color: #ffffb3;
}
#T_cbe4e_row1_col3, #T_cbe4e_row3_col3 {
  color: red;
  background-color: #ffffb3;
}
</style>
<table id=""T_cbe4e"">
<thead>
<tr>
<th class=""blank""> </th>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_cbe4e_level0_col0"">c1</th>
<th class=""col_heading level0 col1"" id=""T_cbe4e_level0_col1"">c2</th>
<th class=""col_heading level0 col2"" id=""T_cbe4e_level0_col2"">c3</th>
<th class=""col_heading level0 col3"" id=""T_cbe4e_level0_col3"">c4</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_cbe4e_level0_row0"" rowspan=""2"">A</th>
<th class=""row_heading level1 row0"" id=""T_cbe4e_level1_row0"">r1</th>
<td class=""data row0 col0"" id=""T_cbe4e_row0_col0"">-1.048553</td>
<td class=""data row0 col1"" id=""T_cbe4e_row0_col1"">-1.420018</td>
<td class=""data row0 col2"" id=""T_cbe4e_row0_col2"">-1.706270</td>
<td class=""data row0 col3"" id=""T_cbe4e_row0_col3"">1.950775</td>
</tr>
<tr>
<th class=""row_heading level1 row1"" id=""T_cbe4e_level1_row1"">r2</th>
<td class=""data row1 col0"" id=""T_cbe4e_row1_col0"">-0.509652</td>
<td class=""data row1 col1"" id=""T_cbe4e_row1_col1"">-0.438074</td>
<td class=""data row1 col2"" id=""T_cbe4e_row1_col2"">-1.252795</td>
<td class=""data row1 col3"" id=""T_cbe4e_row1_col3"">0.777490</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_cbe4e_level0_row2"" rowspan=""2"">B</th>
<th class=""row_heading level1 row2"" id=""T_cbe4e_level1_row2"">r1</th>
<td class=""data row2 col0"" id=""T_cbe4e_row2_col0"">-1.613898</td>
<td class=""data row2 col1"" id=""T_cbe4e_row2_col1"">-0.212740</td>
<td class=""data row2 col2"" id=""T_cbe4e_row2_col2"">-0.895467</td>
<td class=""data row2 col3"" id=""T_cbe4e_row2_col3"">0.386902</td>
</tr>
<tr>
<th class=""row_heading level1 row3"" id=""T_cbe4e_level1_row3"">r2</th>
<td class=""data row3 col0"" id=""T_cbe4e_row3_col0"">-0.510805</td>
<td class=""data row3 col1"" id=""T_cbe4e_row3_col1"">-1.180632</td>
<td class=""data row3 col2"" id=""T_cbe4e_row3_col2"">-0.028182</td>
<td class=""data row3 col3"" id=""T_cbe4e_row3_col3"">0.428332</td>
</tr>
</tbody>
</table></div>
</div>
<p>There is also scope to provide <strong>conditional filtering</strong>.</p>
<p>Suppose we want to highlight the maximum across columns 2 and 4 only in the case that the sum of columns 1 and 3 is less than -2.0 <em>(essentially excluding rows</em> <code class=""docutils literal notranslate""><span class=""pre"">(:,'r2')</span></code><em>)</em>.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[40]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">slice_</span> <span class=""o"">=</span> <span class=""n"">idx</span><span class=""p"">[</span><span class=""n"">idx</span><span class=""p"">[(</span><span class=""n"">df3</span><span class=""p"">[</span><span class=""s1"">'c1'</span><span class=""p"">]</span> <span class=""o"">+</span> <span class=""n"">df3</span><span class=""p"">[</span><span class=""s1"">'c3'</span><span class=""p"">])</span> <span class=""o"">&lt;</span> <span class=""o"">-</span><span class=""mf"">2.0</span><span class=""p"">],</span> <span class=""p"">[</span><span class=""s1"">'c2'</span><span class=""p"">,</span> <span class=""s1"">'c4'</span><span class=""p"">]]</span>
<span class=""n"">df3</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">apply</span><span class=""p"">(</span><span class=""n"">highlight_max</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">'color:red;'</span><span class=""p"">,</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">1</span><span class=""p"">,</span> <span class=""n"">subset</span><span class=""o"">=</span><span class=""n"">slice_</span><span class=""p"">)</span>\
         <span class=""o"">.</span><span class=""n"">set_properties</span><span class=""p"">(</span><span class=""o"">**</span><span class=""p"">{</span><span class=""s1"">'background-color'</span><span class=""p"">:</span> <span class=""s1"">'#ffffb3'</span><span class=""p"">},</span> <span class=""n"">subset</span><span class=""o"">=</span><span class=""n"">slice_</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[40]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_521c2_row0_col1, #T_521c2_row2_col1 {
  background-color: #ffffb3;
}
#T_521c2_row0_col3, #T_521c2_row2_col3 {
  color: red;
  background-color: #ffffb3;
}
</style>
<table id=""T_521c2"">
<thead>
<tr>
<th class=""blank""> </th>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_521c2_level0_col0"">c1</th>
<th class=""col_heading level0 col1"" id=""T_521c2_level0_col1"">c2</th>
<th class=""col_heading level0 col2"" id=""T_521c2_level0_col2"">c3</th>
<th class=""col_heading level0 col3"" id=""T_521c2_level0_col3"">c4</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_521c2_level0_row0"" rowspan=""2"">A</th>
<th class=""row_heading level1 row0"" id=""T_521c2_level1_row0"">r1</th>
<td class=""data row0 col0"" id=""T_521c2_row0_col0"">-1.048553</td>
<td class=""data row0 col1"" id=""T_521c2_row0_col1"">-1.420018</td>
<td class=""data row0 col2"" id=""T_521c2_row0_col2"">-1.706270</td>
<td class=""data row0 col3"" id=""T_521c2_row0_col3"">1.950775</td>
</tr>
<tr>
<th class=""row_heading level1 row1"" id=""T_521c2_level1_row1"">r2</th>
<td class=""data row1 col0"" id=""T_521c2_row1_col0"">-0.509652</td>
<td class=""data row1 col1"" id=""T_521c2_row1_col1"">-0.438074</td>
<td class=""data row1 col2"" id=""T_521c2_row1_col2"">-1.252795</td>
<td class=""data row1 col3"" id=""T_521c2_row1_col3"">0.777490</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_521c2_level0_row2"" rowspan=""2"">B</th>
<th class=""row_heading level1 row2"" id=""T_521c2_level1_row2"">r1</th>
<td class=""data row2 col0"" id=""T_521c2_row2_col0"">-1.613898</td>
<td class=""data row2 col1"" id=""T_521c2_row2_col1"">-0.212740</td>
<td class=""data row2 col2"" id=""T_521c2_row2_col2"">-0.895467</td>
<td class=""data row2 col3"" id=""T_521c2_row2_col3"">0.386902</td>
</tr>
<tr>
<th class=""row_heading level1 row3"" id=""T_521c2_level1_row3"">r2</th>
<td class=""data row3 col0"" id=""T_521c2_row3_col0"">-0.510805</td>
<td class=""data row3 col1"" id=""T_521c2_row3_col1"">-1.180632</td>
<td class=""data row3 col2"" id=""T_521c2_row3_col2"">-0.028182</td>
<td class=""data row3 col3"" id=""T_521c2_row3_col3"">0.428332</td>
</tr>
</tbody>
</table></div>
</div>
<p>Only label-based slicing is supported right now, not positional, and not callables.</p>
<p>If your style function uses a <code class=""docutils literal notranslate""><span class=""pre"">subset</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">axis</span></code> keyword argument, consider wrapping your function in a <code class=""docutils literal notranslate""><span class=""pre"">functools.partial</span></code>, partialing out that keyword.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">my_func2</span> <span class=""o"">=</span> <span class=""n"">functools</span><span class=""o"">.</span><span class=""n"">partial</span><span class=""p"">(</span><span class=""n"">my_func</span><span class=""p"">,</span> <span class=""n"">subset</span><span class=""o"">=</span><span class=""mi"">42</span><span class=""p"">)</span>
</pre></div>
</div>
</section>
<section id=""Optimization"">
<h2>Optimization<a class=""headerlink"" href=""#Optimization"" title=""Link to this heading"">#</a></h2>
<p>Generally, for smaller tables and most cases, the rendered HTML does not need to be optimized, and we don’t really recommend it. There are two cases where it is worth considering:</p>
<ul class=""simple"">
<li><p>If you are rendering and styling a very large HTML table, certain browsers have performance issues.</p></li>
<li><p>If you are using <code class=""docutils literal notranslate""><span class=""pre"">Styler</span></code> to dynamically create part of online user interfaces and want to improve network performance.</p></li>
</ul>
<p>Here we recommend the following steps to implement:</p>
<section id=""1.-Remove-UUID-and-cell_ids"">
<h3>1. Remove UUID and cell_ids<a class=""headerlink"" href=""#1.-Remove-UUID-and-cell_ids"" title=""Link to this heading"">#</a></h3>
<p>Ignore the <code class=""docutils literal notranslate""><span class=""pre"">uuid</span></code> and set <code class=""docutils literal notranslate""><span class=""pre"">cell_ids</span></code> to <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>. This will prevent unnecessary HTML.</p>
<div class=""admonition warning"">
<p>This is sub-optimal:</p>
</div>
<div class=""nbinput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[41]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df4</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">([[</span><span class=""mi"">1</span><span class=""p"">,</span><span class=""mi"">2</span><span class=""p"">],[</span><span class=""mi"">3</span><span class=""p"">,</span><span class=""mi"">4</span><span class=""p"">]])</span>
<span class=""n"">s4</span> <span class=""o"">=</span> <span class=""n"">df4</span><span class=""o"">.</span><span class=""n"">style</span>
</pre></div>
</div>
</div>
<div class=""admonition note"">
<p>This is better:</p>
</div>
<div class=""nbinput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[42]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">pandas.io.formats.style</span> <span class=""kn"">import</span> <span class=""n"">Styler</span>
<span class=""n"">s4</span> <span class=""o"">=</span> <span class=""n"">Styler</span><span class=""p"">(</span><span class=""n"">df4</span><span class=""p"">,</span> <span class=""n"">uuid_len</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">,</span> <span class=""n"">cell_ids</span><span class=""o"">=</span><span class=""kc"">False</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
</section>
<section id=""2.-Use-table-styles"">
<h3>2. Use table styles<a class=""headerlink"" href=""#2.-Use-table-styles"" title=""Link to this heading"">#</a></h3>
<p>Use table styles where possible (e.g. for all cells or rows or columns at a time) since the CSS is nearly always more efficient than other formats.</p>
<div class=""admonition warning"">
<p>This is sub-optimal:</p>
</div>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[43]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">props</span> <span class=""o"">=</span> <span class=""s1"">'font-family: ""Times New Roman"", Times, serif; color: #e83e8c; font-size:1.3em;'</span>
<span class=""n"">df4</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">map</span><span class=""p"">(</span><span class=""k"">lambda</span> <span class=""n"">x</span><span class=""p"">:</span> <span class=""n"">props</span><span class=""p"">,</span> <span class=""n"">subset</span><span class=""o"">=</span><span class=""p"">[</span><span class=""mi"">1</span><span class=""p"">])</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[43]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_f3579_row0_col1, #T_f3579_row1_col1 {
  font-family: ""Times New Roman"", Times, serif;
  color: #e83e8c;
  font-size: 1.3em;
}
</style>
<table id=""T_f3579"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_f3579_level0_col0"">0</th>
<th class=""col_heading level0 col1"" id=""T_f3579_level0_col1"">1</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_f3579_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_f3579_row0_col0"">1</td>
<td class=""data row0 col1"" id=""T_f3579_row0_col1"">2</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_f3579_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_f3579_row1_col0"">3</td>
<td class=""data row1 col1"" id=""T_f3579_row1_col1"">4</td>
</tr>
</tbody>
</table></div>
</div>
<div class=""admonition note"">
<p>This is better:</p>
</div>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[44]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df4</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">set_table_styles</span><span class=""p"">([{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'td.col1'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""n"">props</span><span class=""p"">}])</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[44]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_c4fd9 td.col1 {
  font-family: ""Times New Roman"", Times, serif;
  color: #e83e8c;
  font-size: 1.3em;
}
</style>
<table id=""T_c4fd9"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_c4fd9_level0_col0"">0</th>
<th class=""col_heading level0 col1"" id=""T_c4fd9_level0_col1"">1</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_c4fd9_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_c4fd9_row0_col0"">1</td>
<td class=""data row0 col1"" id=""T_c4fd9_row0_col1"">2</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_c4fd9_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_c4fd9_row1_col0"">3</td>
<td class=""data row1 col1"" id=""T_c4fd9_row1_col1"">4</td>
</tr>
</tbody>
</table></div>
</div>
</section>
<section id=""3.-Set-classes-instead-of-using-Styler-functions"">
<h3>3. Set classes instead of using Styler functions<a class=""headerlink"" href=""#3.-Set-classes-instead-of-using-Styler-functions"" title=""Link to this heading"">#</a></h3>
<p>For large DataFrames where the same style is applied to many cells it can be more efficient to declare the styles as classes and then apply those classes to data cells, rather than directly applying styles to cells. It is, however, probably still easier to use the Styler function api when you are not concerned about optimization.</p>
<div class=""admonition warning"">
<p>This is sub-optimal:</p>
</div>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[45]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">apply</span><span class=""p"">(</span><span class=""n"">highlight_max</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">'color:white;background-color:darkblue;'</span><span class=""p"">,</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">)</span>\
         <span class=""o"">.</span><span class=""n"">apply</span><span class=""p"">(</span><span class=""n"">highlight_max</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">'color:white;background-color:pink;'</span><span class=""p"">,</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">1</span><span class=""p"">)</span>\
         <span class=""o"">.</span><span class=""n"">apply</span><span class=""p"">(</span><span class=""n"">highlight_max</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">'color:white;background-color:purple'</span><span class=""p"">,</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[45]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_926cb_row0_col2, #T_926cb_row7_col1 {
  color: white;
  background-color: darkblue;
}
#T_926cb_row0_col3 {
  color: white;
  background-color: darkblue;
  color: white;
  background-color: pink;
}
#T_926cb_row1_col0, #T_926cb_row2_col3, #T_926cb_row3_col0, #T_926cb_row4_col0, #T_926cb_row5_col2, #T_926cb_row7_col0, #T_926cb_row8_col3, #T_926cb_row9_col0 {
  color: white;
  background-color: pink;
}
#T_926cb_row6_col0 {
  color: white;
  background-color: darkblue;
  color: white;
  background-color: pink;
  color: white;
  background-color: purple;
}
</style>
<table id=""T_926cb"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_926cb_level0_col0"">A</th>
<th class=""col_heading level0 col1"" id=""T_926cb_level0_col1"">B</th>
<th class=""col_heading level0 col2"" id=""T_926cb_level0_col2"">C</th>
<th class=""col_heading level0 col3"" id=""T_926cb_level0_col3"">D</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_926cb_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_926cb_row0_col0"">1.764052</td>
<td class=""data row0 col1"" id=""T_926cb_row0_col1"">0.400157</td>
<td class=""data row0 col2"" id=""T_926cb_row0_col2"">0.978738</td>
<td class=""data row0 col3"" id=""T_926cb_row0_col3"">2.240893</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_926cb_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_926cb_row1_col0"">1.867558</td>
<td class=""data row1 col1"" id=""T_926cb_row1_col1"">-0.977278</td>
<td class=""data row1 col2"" id=""T_926cb_row1_col2"">0.950088</td>
<td class=""data row1 col3"" id=""T_926cb_row1_col3"">-0.151357</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_926cb_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_926cb_row2_col0"">-0.103219</td>
<td class=""data row2 col1"" id=""T_926cb_row2_col1"">0.410599</td>
<td class=""data row2 col2"" id=""T_926cb_row2_col2"">0.144044</td>
<td class=""data row2 col3"" id=""T_926cb_row2_col3"">1.454274</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_926cb_level0_row3"">3</th>
<td class=""data row3 col0"" id=""T_926cb_row3_col0"">0.761038</td>
<td class=""data row3 col1"" id=""T_926cb_row3_col1"">0.121675</td>
<td class=""data row3 col2"" id=""T_926cb_row3_col2"">0.443863</td>
<td class=""data row3 col3"" id=""T_926cb_row3_col3"">0.333674</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_926cb_level0_row4"">4</th>
<td class=""data row4 col0"" id=""T_926cb_row4_col0"">1.494079</td>
<td class=""data row4 col1"" id=""T_926cb_row4_col1"">-0.205158</td>
<td class=""data row4 col2"" id=""T_926cb_row4_col2"">0.313068</td>
<td class=""data row4 col3"" id=""T_926cb_row4_col3"">-0.854096</td>
</tr>
<tr>
<th class=""row_heading level0 row5"" id=""T_926cb_level0_row5"">5</th>
<td class=""data row5 col0"" id=""T_926cb_row5_col0"">-2.552990</td>
<td class=""data row5 col1"" id=""T_926cb_row5_col1"">0.653619</td>
<td class=""data row5 col2"" id=""T_926cb_row5_col2"">0.864436</td>
<td class=""data row5 col3"" id=""T_926cb_row5_col3"">-0.742165</td>
</tr>
<tr>
<th class=""row_heading level0 row6"" id=""T_926cb_level0_row6"">6</th>
<td class=""data row6 col0"" id=""T_926cb_row6_col0"">2.269755</td>
<td class=""data row6 col1"" id=""T_926cb_row6_col1"">-1.454366</td>
<td class=""data row6 col2"" id=""T_926cb_row6_col2"">0.045759</td>
<td class=""data row6 col3"" id=""T_926cb_row6_col3"">-0.187184</td>
</tr>
<tr>
<th class=""row_heading level0 row7"" id=""T_926cb_level0_row7"">7</th>
<td class=""data row7 col0"" id=""T_926cb_row7_col0"">1.532779</td>
<td class=""data row7 col1"" id=""T_926cb_row7_col1"">1.469359</td>
<td class=""data row7 col2"" id=""T_926cb_row7_col2"">0.154947</td>
<td class=""data row7 col3"" id=""T_926cb_row7_col3"">0.378163</td>
</tr>
<tr>
<th class=""row_heading level0 row8"" id=""T_926cb_level0_row8"">8</th>
<td class=""data row8 col0"" id=""T_926cb_row8_col0"">-0.887786</td>
<td class=""data row8 col1"" id=""T_926cb_row8_col1"">-1.980796</td>
<td class=""data row8 col2"" id=""T_926cb_row8_col2"">-0.347912</td>
<td class=""data row8 col3"" id=""T_926cb_row8_col3"">0.156349</td>
</tr>
<tr>
<th class=""row_heading level0 row9"" id=""T_926cb_level0_row9"">9</th>
<td class=""data row9 col0"" id=""T_926cb_row9_col0"">1.230291</td>
<td class=""data row9 col1"" id=""T_926cb_row9_col1"">1.202380</td>
<td class=""data row9 col2"" id=""T_926cb_row9_col2"">-0.387327</td>
<td class=""data row9 col3"" id=""T_926cb_row9_col3"">-0.302303</td>
</tr>
</tbody>
</table></div>
</div>
<div class=""admonition note"">
<p>This is better:</p>
</div>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[46]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">build</span> <span class=""o"">=</span> <span class=""k"">lambda</span> <span class=""n"">x</span><span class=""p"">:</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">(</span><span class=""n"">x</span><span class=""p"">,</span> <span class=""n"">index</span><span class=""o"">=</span><span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">index</span><span class=""p"">,</span> <span class=""n"">columns</span><span class=""o"">=</span><span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">columns</span><span class=""p"">)</span>
<span class=""n"">cls1</span> <span class=""o"">=</span> <span class=""n"">build</span><span class=""p"">(</span><span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">apply</span><span class=""p"">(</span><span class=""n"">highlight_max</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">'cls-1 '</span><span class=""p"">,</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">))</span>
<span class=""n"">cls2</span> <span class=""o"">=</span> <span class=""n"">build</span><span class=""p"">(</span><span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">apply</span><span class=""p"">(</span><span class=""n"">highlight_max</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">'cls-2 '</span><span class=""p"">,</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">1</span><span class=""p"">,</span> <span class=""n"">result_type</span><span class=""o"">=</span><span class=""s1"">'expand'</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">values</span><span class=""p"">)</span>
<span class=""n"">cls3</span> <span class=""o"">=</span> <span class=""n"">build</span><span class=""p"">(</span><span class=""n"">highlight_max</span><span class=""p"">(</span><span class=""n"">df2</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">'cls-3 '</span><span class=""p"">))</span>
<span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">set_table_styles</span><span class=""p"">([</span>
    <span class=""p"">{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'.cls-1'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'color:white;background-color:darkblue;'</span><span class=""p"">},</span>
    <span class=""p"">{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'.cls-2'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'color:white;background-color:pink;'</span><span class=""p"">},</span>
    <span class=""p"">{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'.cls-3'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'color:white;background-color:purple;'</span><span class=""p"">}</span>
<span class=""p"">])</span><span class=""o"">.</span><span class=""n"">set_td_classes</span><span class=""p"">(</span><span class=""n"">cls1</span> <span class=""o"">+</span> <span class=""n"">cls2</span> <span class=""o"">+</span> <span class=""n"">cls3</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[46]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_5ee45 .cls-1 {
  color: white;
  background-color: darkblue;
}
#T_5ee45 .cls-2 {
  color: white;
  background-color: pink;
}
#T_5ee45 .cls-3 {
  color: white;
  background-color: purple;
}
</style>
<table id=""T_5ee45"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_5ee45_level0_col0"">A</th>
<th class=""col_heading level0 col1"" id=""T_5ee45_level0_col1"">B</th>
<th class=""col_heading level0 col2"" id=""T_5ee45_level0_col2"">C</th>
<th class=""col_heading level0 col3"" id=""T_5ee45_level0_col3"">D</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_5ee45_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_5ee45_row0_col0"">1.764052</td>
<td class=""data row0 col1"" id=""T_5ee45_row0_col1"">0.400157</td>
<td class=""data row0 col2 cls-1"" id=""T_5ee45_row0_col2"">0.978738</td>
<td class=""data row0 col3 cls-1 cls-2"" id=""T_5ee45_row0_col3"">2.240893</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_5ee45_level0_row1"">1</th>
<td class=""data row1 col0 cls-2"" id=""T_5ee45_row1_col0"">1.867558</td>
<td class=""data row1 col1"" id=""T_5ee45_row1_col1"">-0.977278</td>
<td class=""data row1 col2"" id=""T_5ee45_row1_col2"">0.950088</td>
<td class=""data row1 col3"" id=""T_5ee45_row1_col3"">-0.151357</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_5ee45_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_5ee45_row2_col0"">-0.103219</td>
<td class=""data row2 col1"" id=""T_5ee45_row2_col1"">0.410599</td>
<td class=""data row2 col2"" id=""T_5ee45_row2_col2"">0.144044</td>
<td class=""data row2 col3 cls-2"" id=""T_5ee45_row2_col3"">1.454274</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_5ee45_level0_row3"">3</th>
<td class=""data row3 col0 cls-2"" id=""T_5ee45_row3_col0"">0.761038</td>
<td class=""data row3 col1"" id=""T_5ee45_row3_col1"">0.121675</td>
<td class=""data row3 col2"" id=""T_5ee45_row3_col2"">0.443863</td>
<td class=""data row3 col3"" id=""T_5ee45_row3_col3"">0.333674</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_5ee45_level0_row4"">4</th>
<td class=""data row4 col0 cls-2"" id=""T_5ee45_row4_col0"">1.494079</td>
<td class=""data row4 col1"" id=""T_5ee45_row4_col1"">-0.205158</td>
<td class=""data row4 col2"" id=""T_5ee45_row4_col2"">0.313068</td>
<td class=""data row4 col3"" id=""T_5ee45_row4_col3"">-0.854096</td>
</tr>
<tr>
<th class=""row_heading level0 row5"" id=""T_5ee45_level0_row5"">5</th>
<td class=""data row5 col0"" id=""T_5ee45_row5_col0"">-2.552990</td>
<td class=""data row5 col1"" id=""T_5ee45_row5_col1"">0.653619</td>
<td class=""data row5 col2 cls-2"" id=""T_5ee45_row5_col2"">0.864436</td>
<td class=""data row5 col3"" id=""T_5ee45_row5_col3"">-0.742165</td>
</tr>
<tr>
<th class=""row_heading level0 row6"" id=""T_5ee45_level0_row6"">6</th>
<td class=""data row6 col0 cls-1 cls-2 cls-3"" id=""T_5ee45_row6_col0"">2.269755</td>
<td class=""data row6 col1"" id=""T_5ee45_row6_col1"">-1.454366</td>
<td class=""data row6 col2"" id=""T_5ee45_row6_col2"">0.045759</td>
<td class=""data row6 col3"" id=""T_5ee45_row6_col3"">-0.187184</td>
</tr>
<tr>
<th class=""row_heading level0 row7"" id=""T_5ee45_level0_row7"">7</th>
<td class=""data row7 col0 cls-2"" id=""T_5ee45_row7_col0"">1.532779</td>
<td class=""data row7 col1 cls-1"" id=""T_5ee45_row7_col1"">1.469359</td>
<td class=""data row7 col2"" id=""T_5ee45_row7_col2"">0.154947</td>
<td class=""data row7 col3"" id=""T_5ee45_row7_col3"">0.378163</td>
</tr>
<tr>
<th class=""row_heading level0 row8"" id=""T_5ee45_level0_row8"">8</th>
<td class=""data row8 col0"" id=""T_5ee45_row8_col0"">-0.887786</td>
<td class=""data row8 col1"" id=""T_5ee45_row8_col1"">-1.980796</td>
<td class=""data row8 col2"" id=""T_5ee45_row8_col2"">-0.347912</td>
<td class=""data row8 col3 cls-2"" id=""T_5ee45_row8_col3"">0.156349</td>
</tr>
<tr>
<th class=""row_heading level0 row9"" id=""T_5ee45_level0_row9"">9</th>
<td class=""data row9 col0 cls-2"" id=""T_5ee45_row9_col0"">1.230291</td>
<td class=""data row9 col1"" id=""T_5ee45_row9_col1"">1.202380</td>
<td class=""data row9 col2"" id=""T_5ee45_row9_col2"">-0.387327</td>
<td class=""data row9 col3"" id=""T_5ee45_row9_col3"">-0.302303</td>
</tr>
</tbody>
</table></div>
</div>
</section>
<section id=""4.-Don't-use-tooltips"">
<h3>4. Don’t use tooltips<a class=""headerlink"" href=""#4.-Don't-use-tooltips"" title=""Link to this heading"">#</a></h3>
<p>Tooltips require <code class=""docutils literal notranslate""><span class=""pre"">cell_ids</span></code> to work and they generate extra HTML elements for <em>every</em> data cell.</p>
</section>
<section id=""5.-If-every-byte-counts-use-string-replacement"">
<h3>5. If every byte counts use string replacement<a class=""headerlink"" href=""#5.-If-every-byte-counts-use-string-replacement"" title=""Link to this heading"">#</a></h3>
<p>You can remove unnecessary HTML, or shorten the default class names by replacing the default css dict. You can read a little more about CSS <a class=""reference internal"" href=""#More-About-CSS-and-HTML""><span class=""std std-ref"">below</span></a>.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[47]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">my_css</span> <span class=""o"">=</span> <span class=""p"">{</span>
    <span class=""s2"">""row_heading""</span><span class=""p"">:</span> <span class=""s2"">""""</span><span class=""p"">,</span>
    <span class=""s2"">""col_heading""</span><span class=""p"">:</span> <span class=""s2"">""""</span><span class=""p"">,</span>
    <span class=""s2"">""index_name""</span><span class=""p"">:</span> <span class=""s2"">""""</span><span class=""p"">,</span>
    <span class=""s2"">""col""</span><span class=""p"">:</span> <span class=""s2"">""c""</span><span class=""p"">,</span>
    <span class=""s2"">""row""</span><span class=""p"">:</span> <span class=""s2"">""r""</span><span class=""p"">,</span>
    <span class=""s2"">""col_trim""</span><span class=""p"">:</span> <span class=""s2"">""""</span><span class=""p"">,</span>
    <span class=""s2"">""row_trim""</span><span class=""p"">:</span> <span class=""s2"">""""</span><span class=""p"">,</span>
    <span class=""s2"">""level""</span><span class=""p"">:</span> <span class=""s2"">""l""</span><span class=""p"">,</span>
    <span class=""s2"">""data""</span><span class=""p"">:</span> <span class=""s2"">""""</span><span class=""p"">,</span>
    <span class=""s2"">""blank""</span><span class=""p"">:</span> <span class=""s2"">""""</span><span class=""p"">,</span>
<span class=""p"">}</span>
<span class=""n"">html</span> <span class=""o"">=</span> <span class=""n"">Styler</span><span class=""p"">(</span><span class=""n"">df4</span><span class=""p"">,</span> <span class=""n"">uuid_len</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">,</span> <span class=""n"">cell_ids</span><span class=""o"">=</span><span class=""kc"">False</span><span class=""p"">)</span>
<span class=""n"">html</span><span class=""o"">.</span><span class=""n"">set_table_styles</span><span class=""p"">([{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'td'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""n"">props</span><span class=""p"">},</span>
                       <span class=""p"">{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'.c1'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'color:green;'</span><span class=""p"">},</span>
                       <span class=""p"">{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'.l0'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'color:blue;'</span><span class=""p"">}],</span>
                      <span class=""n"">css_class_names</span><span class=""o"">=</span><span class=""n"">my_css</span><span class=""p"">)</span>
<span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">html</span><span class=""o"">.</span><span class=""n"">to_html</span><span class=""p"">())</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt empty docutils container"">
</div>
<div class=""output_area docutils container"">
<div class=""highlight""><pre>
&lt;style type=""text/css""&gt;
#T_ td {
  font-family: ""Times New Roman"", Times, serif;
  color: #e83e8c;
  font-size: 1.3em;
}
#T_ .c1 {
  color: green;
}
#T_ .l0 {
  color: blue;
}
&lt;/style&gt;
&lt;table id=""T_""&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th class="" l0"" &gt;&amp;nbsp;&lt;/th&gt;
      &lt;th class="" l0 c0"" &gt;0&lt;/th&gt;
      &lt;th class="" l0 c1"" &gt;1&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th class="" l0 r0"" &gt;0&lt;/th&gt;
      &lt;td class="" r0 c0"" &gt;1&lt;/td&gt;
      &lt;td class="" r0 c1"" &gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th class="" l0 r1"" &gt;1&lt;/th&gt;
      &lt;td class="" r1 c0"" &gt;3&lt;/td&gt;
      &lt;td class="" r1 c1"" &gt;4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

</pre></div></div>
</div>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[48]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">html</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[48]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_ td {
  font-family: ""Times New Roman"", Times, serif;
  color: #e83e8c;
  font-size: 1.3em;
}
#T_ .c1 {
  color: green;
}
#T_ .l0 {
  color: blue;
}
</style>
<table id=""T_"">
<thead>
<tr>
<th class=""l0""> </th>
<th class=""l0 c0"">0</th>
<th class=""l0 c1"">1</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""l0 r0"">0</th>
<td class=""r0 c0"">1</td>
<td class=""r0 c1"">2</td>
</tr>
<tr>
<th class=""l0 r1"">1</th>
<td class=""r1 c0"">3</td>
<td class=""r1 c1"">4</td>
</tr>
</tbody>
</table></div>
</div>
</section>
</section>
<section id=""Builtin-Styles"">
<h2>Builtin Styles<a class=""headerlink"" href=""#Builtin-Styles"" title=""Link to this heading"">#</a></h2>
<p>Some styling functions are common enough that we’ve “built them in” to the <code class=""docutils literal notranslate""><span class=""pre"">Styler</span></code>, so you don’t have to write them and apply them yourself. The current list of such functions is:</p>
<ul class=""simple"">
<li><p><a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.highlight_null.html""><span class=""doc"">.highlight_null</span></a>: for use with identifying missing data.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.highlight_min.html""><span class=""doc"">.highlight_min</span></a> and <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.highlight_max.html""><span class=""doc"">.highlight_max</span></a>: for use with identifying extremeties in data.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.highlight_between.html""><span class=""doc"">.highlight_between</span></a> and <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.highlight_quantile.html""><span class=""doc"">.highlight_quantile</span></a>: for use with identifying classes within data.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.background_gradient.html""><span class=""doc"">.background_gradient</span></a>: a flexible method for highlighting cells based on their, or other, values on a numeric scale.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.text_gradient.html""><span class=""doc"">.text_gradient</span></a>: similar method for highlighting text based on their, or other, values on a numeric scale.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.bar.html""><span class=""doc"">.bar</span></a>: to display mini-charts within cell backgrounds.</p></li>
</ul>
<p>The individual documentation on each function often gives more examples of their arguments.</p>
<section id=""Highlight-Null"">
<h3>Highlight Null<a class=""headerlink"" href=""#Highlight-Null"" title=""Link to this heading"">#</a></h3>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[49]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">iloc</span><span class=""p"">[</span><span class=""mi"">0</span><span class=""p"">,</span><span class=""mi"">2</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">np</span><span class=""o"">.</span><span class=""n"">nan</span>
<span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">iloc</span><span class=""p"">[</span><span class=""mi"">4</span><span class=""p"">,</span><span class=""mi"">3</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">np</span><span class=""o"">.</span><span class=""n"">nan</span>
<span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">loc</span><span class=""p"">[:</span><span class=""mi"">4</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">highlight_null</span><span class=""p"">(</span><span class=""n"">color</span><span class=""o"">=</span><span class=""s1"">'yellow'</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[49]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_60103_row0_col2, #T_60103_row4_col3 {
  background-color: yellow;
}
</style>
<table id=""T_60103"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_60103_level0_col0"">A</th>
<th class=""col_heading level0 col1"" id=""T_60103_level0_col1"">B</th>
<th class=""col_heading level0 col2"" id=""T_60103_level0_col2"">C</th>
<th class=""col_heading level0 col3"" id=""T_60103_level0_col3"">D</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_60103_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_60103_row0_col0"">1.764052</td>
<td class=""data row0 col1"" id=""T_60103_row0_col1"">0.400157</td>
<td class=""data row0 col2"" id=""T_60103_row0_col2"">nan</td>
<td class=""data row0 col3"" id=""T_60103_row0_col3"">2.240893</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_60103_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_60103_row1_col0"">1.867558</td>
<td class=""data row1 col1"" id=""T_60103_row1_col1"">-0.977278</td>
<td class=""data row1 col2"" id=""T_60103_row1_col2"">0.950088</td>
<td class=""data row1 col3"" id=""T_60103_row1_col3"">-0.151357</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_60103_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_60103_row2_col0"">-0.103219</td>
<td class=""data row2 col1"" id=""T_60103_row2_col1"">0.410599</td>
<td class=""data row2 col2"" id=""T_60103_row2_col2"">0.144044</td>
<td class=""data row2 col3"" id=""T_60103_row2_col3"">1.454274</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_60103_level0_row3"">3</th>
<td class=""data row3 col0"" id=""T_60103_row3_col0"">0.761038</td>
<td class=""data row3 col1"" id=""T_60103_row3_col1"">0.121675</td>
<td class=""data row3 col2"" id=""T_60103_row3_col2"">0.443863</td>
<td class=""data row3 col3"" id=""T_60103_row3_col3"">0.333674</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_60103_level0_row4"">4</th>
<td class=""data row4 col0"" id=""T_60103_row4_col0"">1.494079</td>
<td class=""data row4 col1"" id=""T_60103_row4_col1"">-0.205158</td>
<td class=""data row4 col2"" id=""T_60103_row4_col2"">0.313068</td>
<td class=""data row4 col3"" id=""T_60103_row4_col3"">nan</td>
</tr>
</tbody>
</table></div>
</div>
</section>
<section id=""Highlight-Min-or-Max"">
<h3>Highlight Min or Max<a class=""headerlink"" href=""#Highlight-Min-or-Max"" title=""Link to this heading"">#</a></h3>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[50]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">loc</span><span class=""p"">[:</span><span class=""mi"">4</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">highlight_max</span><span class=""p"">(</span><span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">1</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">'color:white; font-weight:bold; background-color:darkblue;'</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[50]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_bbf20_row0_col3, #T_bbf20_row1_col0, #T_bbf20_row2_col3, #T_bbf20_row3_col0, #T_bbf20_row4_col0 {
  color: white;
  font-weight: bold;
  background-color: darkblue;
}
</style>
<table id=""T_bbf20"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_bbf20_level0_col0"">A</th>
<th class=""col_heading level0 col1"" id=""T_bbf20_level0_col1"">B</th>
<th class=""col_heading level0 col2"" id=""T_bbf20_level0_col2"">C</th>
<th class=""col_heading level0 col3"" id=""T_bbf20_level0_col3"">D</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_bbf20_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_bbf20_row0_col0"">1.764052</td>
<td class=""data row0 col1"" id=""T_bbf20_row0_col1"">0.400157</td>
<td class=""data row0 col2"" id=""T_bbf20_row0_col2"">nan</td>
<td class=""data row0 col3"" id=""T_bbf20_row0_col3"">2.240893</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_bbf20_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_bbf20_row1_col0"">1.867558</td>
<td class=""data row1 col1"" id=""T_bbf20_row1_col1"">-0.977278</td>
<td class=""data row1 col2"" id=""T_bbf20_row1_col2"">0.950088</td>
<td class=""data row1 col3"" id=""T_bbf20_row1_col3"">-0.151357</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_bbf20_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_bbf20_row2_col0"">-0.103219</td>
<td class=""data row2 col1"" id=""T_bbf20_row2_col1"">0.410599</td>
<td class=""data row2 col2"" id=""T_bbf20_row2_col2"">0.144044</td>
<td class=""data row2 col3"" id=""T_bbf20_row2_col3"">1.454274</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_bbf20_level0_row3"">3</th>
<td class=""data row3 col0"" id=""T_bbf20_row3_col0"">0.761038</td>
<td class=""data row3 col1"" id=""T_bbf20_row3_col1"">0.121675</td>
<td class=""data row3 col2"" id=""T_bbf20_row3_col2"">0.443863</td>
<td class=""data row3 col3"" id=""T_bbf20_row3_col3"">0.333674</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_bbf20_level0_row4"">4</th>
<td class=""data row4 col0"" id=""T_bbf20_row4_col0"">1.494079</td>
<td class=""data row4 col1"" id=""T_bbf20_row4_col1"">-0.205158</td>
<td class=""data row4 col2"" id=""T_bbf20_row4_col2"">0.313068</td>
<td class=""data row4 col3"" id=""T_bbf20_row4_col3"">nan</td>
</tr>
</tbody>
</table></div>
</div>
</section>
<section id=""Highlight-Between"">
<h3>Highlight Between<a class=""headerlink"" href=""#Highlight-Between"" title=""Link to this heading"">#</a></h3>
<p>This method accepts ranges as float, or NumPy arrays or Series provided the indexes match.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[51]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">left</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">Series</span><span class=""p"">([</span><span class=""mf"">1.0</span><span class=""p"">,</span> <span class=""mf"">0.0</span><span class=""p"">,</span> <span class=""mf"">1.0</span><span class=""p"">],</span> <span class=""n"">index</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s2"">""A""</span><span class=""p"">,</span> <span class=""s2"">""B""</span><span class=""p"">,</span> <span class=""s2"">""D""</span><span class=""p"">])</span>
<span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">loc</span><span class=""p"">[:</span><span class=""mi"">4</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">highlight_between</span><span class=""p"">(</span><span class=""n"">left</span><span class=""o"">=</span><span class=""n"">left</span><span class=""p"">,</span> <span class=""n"">right</span><span class=""o"">=</span><span class=""mf"">1.5</span><span class=""p"">,</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">1</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">'color:white; background-color:purple;'</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[51]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_157ff_row0_col1, #T_157ff_row2_col1, #T_157ff_row2_col3, #T_157ff_row3_col1, #T_157ff_row4_col0 {
  color: white;
  background-color: purple;
}
</style>
<table id=""T_157ff"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_157ff_level0_col0"">A</th>
<th class=""col_heading level0 col1"" id=""T_157ff_level0_col1"">B</th>
<th class=""col_heading level0 col2"" id=""T_157ff_level0_col2"">C</th>
<th class=""col_heading level0 col3"" id=""T_157ff_level0_col3"">D</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_157ff_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_157ff_row0_col0"">1.764052</td>
<td class=""data row0 col1"" id=""T_157ff_row0_col1"">0.400157</td>
<td class=""data row0 col2"" id=""T_157ff_row0_col2"">nan</td>
<td class=""data row0 col3"" id=""T_157ff_row0_col3"">2.240893</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_157ff_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_157ff_row1_col0"">1.867558</td>
<td class=""data row1 col1"" id=""T_157ff_row1_col1"">-0.977278</td>
<td class=""data row1 col2"" id=""T_157ff_row1_col2"">0.950088</td>
<td class=""data row1 col3"" id=""T_157ff_row1_col3"">-0.151357</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_157ff_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_157ff_row2_col0"">-0.103219</td>
<td class=""data row2 col1"" id=""T_157ff_row2_col1"">0.410599</td>
<td class=""data row2 col2"" id=""T_157ff_row2_col2"">0.144044</td>
<td class=""data row2 col3"" id=""T_157ff_row2_col3"">1.454274</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_157ff_level0_row3"">3</th>
<td class=""data row3 col0"" id=""T_157ff_row3_col0"">0.761038</td>
<td class=""data row3 col1"" id=""T_157ff_row3_col1"">0.121675</td>
<td class=""data row3 col2"" id=""T_157ff_row3_col2"">0.443863</td>
<td class=""data row3 col3"" id=""T_157ff_row3_col3"">0.333674</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_157ff_level0_row4"">4</th>
<td class=""data row4 col0"" id=""T_157ff_row4_col0"">1.494079</td>
<td class=""data row4 col1"" id=""T_157ff_row4_col1"">-0.205158</td>
<td class=""data row4 col2"" id=""T_157ff_row4_col2"">0.313068</td>
<td class=""data row4 col3"" id=""T_157ff_row4_col3"">nan</td>
</tr>
</tbody>
</table></div>
</div>
</section>
<section id=""Highlight-Quantile"">
<h3>Highlight Quantile<a class=""headerlink"" href=""#Highlight-Quantile"" title=""Link to this heading"">#</a></h3>
<p>Useful for detecting the highest or lowest percentile values</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[52]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">loc</span><span class=""p"">[:</span><span class=""mi"">4</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">highlight_quantile</span><span class=""p"">(</span><span class=""n"">q_left</span><span class=""o"">=</span><span class=""mf"">0.85</span><span class=""p"">,</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""kc"">None</span><span class=""p"">,</span> <span class=""n"">color</span><span class=""o"">=</span><span class=""s1"">'yellow'</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[52]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_48add_row0_col0, #T_48add_row0_col3, #T_48add_row1_col0 {
  background-color: yellow;
}
</style>
<table id=""T_48add"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_48add_level0_col0"">A</th>
<th class=""col_heading level0 col1"" id=""T_48add_level0_col1"">B</th>
<th class=""col_heading level0 col2"" id=""T_48add_level0_col2"">C</th>
<th class=""col_heading level0 col3"" id=""T_48add_level0_col3"">D</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_48add_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_48add_row0_col0"">1.764052</td>
<td class=""data row0 col1"" id=""T_48add_row0_col1"">0.400157</td>
<td class=""data row0 col2"" id=""T_48add_row0_col2"">nan</td>
<td class=""data row0 col3"" id=""T_48add_row0_col3"">2.240893</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_48add_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_48add_row1_col0"">1.867558</td>
<td class=""data row1 col1"" id=""T_48add_row1_col1"">-0.977278</td>
<td class=""data row1 col2"" id=""T_48add_row1_col2"">0.950088</td>
<td class=""data row1 col3"" id=""T_48add_row1_col3"">-0.151357</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_48add_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_48add_row2_col0"">-0.103219</td>
<td class=""data row2 col1"" id=""T_48add_row2_col1"">0.410599</td>
<td class=""data row2 col2"" id=""T_48add_row2_col2"">0.144044</td>
<td class=""data row2 col3"" id=""T_48add_row2_col3"">1.454274</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_48add_level0_row3"">3</th>
<td class=""data row3 col0"" id=""T_48add_row3_col0"">0.761038</td>
<td class=""data row3 col1"" id=""T_48add_row3_col1"">0.121675</td>
<td class=""data row3 col2"" id=""T_48add_row3_col2"">0.443863</td>
<td class=""data row3 col3"" id=""T_48add_row3_col3"">0.333674</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_48add_level0_row4"">4</th>
<td class=""data row4 col0"" id=""T_48add_row4_col0"">1.494079</td>
<td class=""data row4 col1"" id=""T_48add_row4_col1"">-0.205158</td>
<td class=""data row4 col2"" id=""T_48add_row4_col2"">0.313068</td>
<td class=""data row4 col3"" id=""T_48add_row4_col3"">nan</td>
</tr>
</tbody>
</table></div>
</div>
</section>
<section id=""Background-Gradient-and-Text-Gradient"">
<h3>Background Gradient and Text Gradient<a class=""headerlink"" href=""#Background-Gradient-and-Text-Gradient"" title=""Link to this heading"">#</a></h3>
<p>You can create “heatmaps” with the <code class=""docutils literal notranslate""><span class=""pre"">background_gradient</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">text_gradient</span></code> methods. These require matplotlib, and we’ll use <a class=""reference external"" href=""http://seaborn.pydata.org/"">Seaborn</a> to get a nice colormap.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[53]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">seaborn</span> <span class=""k"">as</span> <span class=""nn"">sns</span>
<span class=""n"">cm</span> <span class=""o"">=</span> <span class=""n"">sns</span><span class=""o"">.</span><span class=""n"">light_palette</span><span class=""p"">(</span><span class=""s2"">""green""</span><span class=""p"">,</span> <span class=""n"">as_cmap</span><span class=""o"">=</span><span class=""kc"">True</span><span class=""p"">)</span>

<span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">background_gradient</span><span class=""p"">(</span><span class=""n"">cmap</span><span class=""o"">=</span><span class=""n"">cm</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[53]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_5948f_row0_col0 {
  background-color: #188c18;
  color: #f1f1f1;
}
#T_5948f_row0_col1 {
  background-color: #49a449;
  color: #f1f1f1;
}
#T_5948f_row0_col2, #T_5948f_row4_col3 {
  background-color: #000000;
  color: #f1f1f1;
}
#T_5948f_row0_col3, #T_5948f_row1_col2, #T_5948f_row6_col0, #T_5948f_row7_col1 {
  background-color: #008000;
  color: #f1f1f1;
}
#T_5948f_row1_col0 {
  background-color: #138913;
  color: #f1f1f1;
}
#T_5948f_row1_col1 {
  background-color: #a6d2a6;
  color: #000000;
}
#T_5948f_row1_col3 {
  background-color: #bddcbd;
  color: #000000;
}
#T_5948f_row2_col0 {
  background-color: #73b873;
  color: #f1f1f1;
}
#T_5948f_row2_col1 {
  background-color: #48a348;
  color: #f1f1f1;
}
#T_5948f_row2_col2 {
  background-color: #8ec58e;
  color: #000000;
}
#T_5948f_row2_col3 {
  background-color: #3e9e3e;
  color: #f1f1f1;
}
#T_5948f_row3_col0 {
  background-color: #4aa44a;
  color: #f1f1f1;
}
#T_5948f_row3_col1 {
  background-color: #5bad5b;
  color: #f1f1f1;
}
#T_5948f_row3_col2 {
  background-color: #58ab58;
  color: #f1f1f1;
}
#T_5948f_row3_col3 {
  background-color: #96c996;
  color: #000000;
}
#T_5948f_row4_col0 {
  background-color: #269226;
  color: #f1f1f1;
}
#T_5948f_row4_col1 {
  background-color: #72b872;
  color: #f1f1f1;
}
#T_5948f_row4_col2 {
  background-color: #6fb76f;
  color: #f1f1f1;
}
#T_5948f_row5_col0, #T_5948f_row5_col3, #T_5948f_row8_col1, #T_5948f_row9_col2 {
  background-color: #ebf3eb;
  color: #000000;
}
#T_5948f_row5_col1 {
  background-color: #379b37;
  color: #f1f1f1;
}
#T_5948f_row5_col2 {
  background-color: #0f870f;
  color: #f1f1f1;
}
#T_5948f_row6_col1 {
  background-color: #c7e1c7;
  color: #000000;
}
#T_5948f_row6_col2 {
  background-color: #9fce9f;
  color: #000000;
}
#T_5948f_row6_col3 {
  background-color: #bfdebf;
  color: #000000;
}
#T_5948f_row7_col0 {
  background-color: #249224;
  color: #f1f1f1;
}
#T_5948f_row7_col2 {
  background-color: #8cc58c;
  color: #000000;
}
#T_5948f_row7_col3 {
  background-color: #92c892;
  color: #000000;
}
#T_5948f_row8_col0 {
  background-color: #9acb9a;
  color: #000000;
}
#T_5948f_row8_col2 {
  background-color: #e4f0e4;
  color: #000000;
}
#T_5948f_row8_col3 {
  background-color: #a4d0a4;
  color: #000000;
}
#T_5948f_row9_col0 {
  background-color: #339933;
  color: #f1f1f1;
}
#T_5948f_row9_col1 {
  background-color: #118911;
  color: #f1f1f1;
}
#T_5948f_row9_col3 {
  background-color: #c9e2c8;
  color: #000000;
}
</style>
<table id=""T_5948f"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_5948f_level0_col0"">A</th>
<th class=""col_heading level0 col1"" id=""T_5948f_level0_col1"">B</th>
<th class=""col_heading level0 col2"" id=""T_5948f_level0_col2"">C</th>
<th class=""col_heading level0 col3"" id=""T_5948f_level0_col3"">D</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_5948f_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_5948f_row0_col0"">1.764052</td>
<td class=""data row0 col1"" id=""T_5948f_row0_col1"">0.400157</td>
<td class=""data row0 col2"" id=""T_5948f_row0_col2"">nan</td>
<td class=""data row0 col3"" id=""T_5948f_row0_col3"">2.240893</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_5948f_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_5948f_row1_col0"">1.867558</td>
<td class=""data row1 col1"" id=""T_5948f_row1_col1"">-0.977278</td>
<td class=""data row1 col2"" id=""T_5948f_row1_col2"">0.950088</td>
<td class=""data row1 col3"" id=""T_5948f_row1_col3"">-0.151357</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_5948f_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_5948f_row2_col0"">-0.103219</td>
<td class=""data row2 col1"" id=""T_5948f_row2_col1"">0.410599</td>
<td class=""data row2 col2"" id=""T_5948f_row2_col2"">0.144044</td>
<td class=""data row2 col3"" id=""T_5948f_row2_col3"">1.454274</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_5948f_level0_row3"">3</th>
<td class=""data row3 col0"" id=""T_5948f_row3_col0"">0.761038</td>
<td class=""data row3 col1"" id=""T_5948f_row3_col1"">0.121675</td>
<td class=""data row3 col2"" id=""T_5948f_row3_col2"">0.443863</td>
<td class=""data row3 col3"" id=""T_5948f_row3_col3"">0.333674</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_5948f_level0_row4"">4</th>
<td class=""data row4 col0"" id=""T_5948f_row4_col0"">1.494079</td>
<td class=""data row4 col1"" id=""T_5948f_row4_col1"">-0.205158</td>
<td class=""data row4 col2"" id=""T_5948f_row4_col2"">0.313068</td>
<td class=""data row4 col3"" id=""T_5948f_row4_col3"">nan</td>
</tr>
<tr>
<th class=""row_heading level0 row5"" id=""T_5948f_level0_row5"">5</th>
<td class=""data row5 col0"" id=""T_5948f_row5_col0"">-2.552990</td>
<td class=""data row5 col1"" id=""T_5948f_row5_col1"">0.653619</td>
<td class=""data row5 col2"" id=""T_5948f_row5_col2"">0.864436</td>
<td class=""data row5 col3"" id=""T_5948f_row5_col3"">-0.742165</td>
</tr>
<tr>
<th class=""row_heading level0 row6"" id=""T_5948f_level0_row6"">6</th>
<td class=""data row6 col0"" id=""T_5948f_row6_col0"">2.269755</td>
<td class=""data row6 col1"" id=""T_5948f_row6_col1"">-1.454366</td>
<td class=""data row6 col2"" id=""T_5948f_row6_col2"">0.045759</td>
<td class=""data row6 col3"" id=""T_5948f_row6_col3"">-0.187184</td>
</tr>
<tr>
<th class=""row_heading level0 row7"" id=""T_5948f_level0_row7"">7</th>
<td class=""data row7 col0"" id=""T_5948f_row7_col0"">1.532779</td>
<td class=""data row7 col1"" id=""T_5948f_row7_col1"">1.469359</td>
<td class=""data row7 col2"" id=""T_5948f_row7_col2"">0.154947</td>
<td class=""data row7 col3"" id=""T_5948f_row7_col3"">0.378163</td>
</tr>
<tr>
<th class=""row_heading level0 row8"" id=""T_5948f_level0_row8"">8</th>
<td class=""data row8 col0"" id=""T_5948f_row8_col0"">-0.887786</td>
<td class=""data row8 col1"" id=""T_5948f_row8_col1"">-1.980796</td>
<td class=""data row8 col2"" id=""T_5948f_row8_col2"">-0.347912</td>
<td class=""data row8 col3"" id=""T_5948f_row8_col3"">0.156349</td>
</tr>
<tr>
<th class=""row_heading level0 row9"" id=""T_5948f_level0_row9"">9</th>
<td class=""data row9 col0"" id=""T_5948f_row9_col0"">1.230291</td>
<td class=""data row9 col1"" id=""T_5948f_row9_col1"">1.202380</td>
<td class=""data row9 col2"" id=""T_5948f_row9_col2"">-0.387327</td>
<td class=""data row9 col3"" id=""T_5948f_row9_col3"">-0.302303</td>
</tr>
</tbody>
</table></div>
</div>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[54]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">text_gradient</span><span class=""p"">(</span><span class=""n"">cmap</span><span class=""o"">=</span><span class=""n"">cm</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[54]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_50053_row0_col0 {
  color: #188c18;
}
#T_50053_row0_col1 {
  color: #49a449;
}
#T_50053_row0_col2, #T_50053_row4_col3 {
  color: #000000;
}
#T_50053_row0_col3, #T_50053_row1_col2, #T_50053_row6_col0, #T_50053_row7_col1 {
  color: #008000;
}
#T_50053_row1_col0 {
  color: #138913;
}
#T_50053_row1_col1 {
  color: #a6d2a6;
}
#T_50053_row1_col3 {
  color: #bddcbd;
}
#T_50053_row2_col0 {
  color: #73b873;
}
#T_50053_row2_col1 {
  color: #48a348;
}
#T_50053_row2_col2 {
  color: #8ec58e;
}
#T_50053_row2_col3 {
  color: #3e9e3e;
}
#T_50053_row3_col0 {
  color: #4aa44a;
}
#T_50053_row3_col1 {
  color: #5bad5b;
}
#T_50053_row3_col2 {
  color: #58ab58;
}
#T_50053_row3_col3 {
  color: #96c996;
}
#T_50053_row4_col0 {
  color: #269226;
}
#T_50053_row4_col1 {
  color: #72b872;
}
#T_50053_row4_col2 {
  color: #6fb76f;
}
#T_50053_row5_col0, #T_50053_row5_col3, #T_50053_row8_col1, #T_50053_row9_col2 {
  color: #ebf3eb;
}
#T_50053_row5_col1 {
  color: #379b37;
}
#T_50053_row5_col2 {
  color: #0f870f;
}
#T_50053_row6_col1 {
  color: #c7e1c7;
}
#T_50053_row6_col2 {
  color: #9fce9f;
}
#T_50053_row6_col3 {
  color: #bfdebf;
}
#T_50053_row7_col0 {
  color: #249224;
}
#T_50053_row7_col2 {
  color: #8cc58c;
}
#T_50053_row7_col3 {
  color: #92c892;
}
#T_50053_row8_col0 {
  color: #9acb9a;
}
#T_50053_row8_col2 {
  color: #e4f0e4;
}
#T_50053_row8_col3 {
  color: #a4d0a4;
}
#T_50053_row9_col0 {
  color: #339933;
}
#T_50053_row9_col1 {
  color: #118911;
}
#T_50053_row9_col3 {
  color: #c9e2c8;
}
</style>
<table id=""T_50053"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_50053_level0_col0"">A</th>
<th class=""col_heading level0 col1"" id=""T_50053_level0_col1"">B</th>
<th class=""col_heading level0 col2"" id=""T_50053_level0_col2"">C</th>
<th class=""col_heading level0 col3"" id=""T_50053_level0_col3"">D</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_50053_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_50053_row0_col0"">1.764052</td>
<td class=""data row0 col1"" id=""T_50053_row0_col1"">0.400157</td>
<td class=""data row0 col2"" id=""T_50053_row0_col2"">nan</td>
<td class=""data row0 col3"" id=""T_50053_row0_col3"">2.240893</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_50053_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_50053_row1_col0"">1.867558</td>
<td class=""data row1 col1"" id=""T_50053_row1_col1"">-0.977278</td>
<td class=""data row1 col2"" id=""T_50053_row1_col2"">0.950088</td>
<td class=""data row1 col3"" id=""T_50053_row1_col3"">-0.151357</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_50053_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_50053_row2_col0"">-0.103219</td>
<td class=""data row2 col1"" id=""T_50053_row2_col1"">0.410599</td>
<td class=""data row2 col2"" id=""T_50053_row2_col2"">0.144044</td>
<td class=""data row2 col3"" id=""T_50053_row2_col3"">1.454274</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_50053_level0_row3"">3</th>
<td class=""data row3 col0"" id=""T_50053_row3_col0"">0.761038</td>
<td class=""data row3 col1"" id=""T_50053_row3_col1"">0.121675</td>
<td class=""data row3 col2"" id=""T_50053_row3_col2"">0.443863</td>
<td class=""data row3 col3"" id=""T_50053_row3_col3"">0.333674</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_50053_level0_row4"">4</th>
<td class=""data row4 col0"" id=""T_50053_row4_col0"">1.494079</td>
<td class=""data row4 col1"" id=""T_50053_row4_col1"">-0.205158</td>
<td class=""data row4 col2"" id=""T_50053_row4_col2"">0.313068</td>
<td class=""data row4 col3"" id=""T_50053_row4_col3"">nan</td>
</tr>
<tr>
<th class=""row_heading level0 row5"" id=""T_50053_level0_row5"">5</th>
<td class=""data row5 col0"" id=""T_50053_row5_col0"">-2.552990</td>
<td class=""data row5 col1"" id=""T_50053_row5_col1"">0.653619</td>
<td class=""data row5 col2"" id=""T_50053_row5_col2"">0.864436</td>
<td class=""data row5 col3"" id=""T_50053_row5_col3"">-0.742165</td>
</tr>
<tr>
<th class=""row_heading level0 row6"" id=""T_50053_level0_row6"">6</th>
<td class=""data row6 col0"" id=""T_50053_row6_col0"">2.269755</td>
<td class=""data row6 col1"" id=""T_50053_row6_col1"">-1.454366</td>
<td class=""data row6 col2"" id=""T_50053_row6_col2"">0.045759</td>
<td class=""data row6 col3"" id=""T_50053_row6_col3"">-0.187184</td>
</tr>
<tr>
<th class=""row_heading level0 row7"" id=""T_50053_level0_row7"">7</th>
<td class=""data row7 col0"" id=""T_50053_row7_col0"">1.532779</td>
<td class=""data row7 col1"" id=""T_50053_row7_col1"">1.469359</td>
<td class=""data row7 col2"" id=""T_50053_row7_col2"">0.154947</td>
<td class=""data row7 col3"" id=""T_50053_row7_col3"">0.378163</td>
</tr>
<tr>
<th class=""row_heading level0 row8"" id=""T_50053_level0_row8"">8</th>
<td class=""data row8 col0"" id=""T_50053_row8_col0"">-0.887786</td>
<td class=""data row8 col1"" id=""T_50053_row8_col1"">-1.980796</td>
<td class=""data row8 col2"" id=""T_50053_row8_col2"">-0.347912</td>
<td class=""data row8 col3"" id=""T_50053_row8_col3"">0.156349</td>
</tr>
<tr>
<th class=""row_heading level0 row9"" id=""T_50053_level0_row9"">9</th>
<td class=""data row9 col0"" id=""T_50053_row9_col0"">1.230291</td>
<td class=""data row9 col1"" id=""T_50053_row9_col1"">1.202380</td>
<td class=""data row9 col2"" id=""T_50053_row9_col2"">-0.387327</td>
<td class=""data row9 col3"" id=""T_50053_row9_col3"">-0.302303</td>
</tr>
</tbody>
</table></div>
</div>
<p><a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.background_gradient.html""><span class=""doc"">.background_gradient</span></a> and <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.text_gradient.html""><span class=""doc"">.text_gradient</span></a> have a number of keyword arguments to customise the gradients and colors. See the documentation.</p>
</section>
<section id=""Set-properties"">
<h3>Set properties<a class=""headerlink"" href=""#Set-properties"" title=""Link to this heading"">#</a></h3>
<p>Use <code class=""docutils literal notranslate""><span class=""pre"">Styler.set_properties</span></code> when the style doesn’t actually depend on the values. This is just a simple wrapper for <code class=""docutils literal notranslate""><span class=""pre"">.map</span></code> where the function returns the same properties for all cells.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[55]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">loc</span><span class=""p"">[:</span><span class=""mi"">4</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">set_properties</span><span class=""p"">(</span><span class=""o"">**</span><span class=""p"">{</span><span class=""s1"">'background-color'</span><span class=""p"">:</span> <span class=""s1"">'black'</span><span class=""p"">,</span>
                           <span class=""s1"">'color'</span><span class=""p"">:</span> <span class=""s1"">'lawngreen'</span><span class=""p"">,</span>
                           <span class=""s1"">'border-color'</span><span class=""p"">:</span> <span class=""s1"">'white'</span><span class=""p"">})</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[55]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_b3656_row0_col0, #T_b3656_row0_col1, #T_b3656_row0_col2, #T_b3656_row0_col3, #T_b3656_row1_col0, #T_b3656_row1_col1, #T_b3656_row1_col2, #T_b3656_row1_col3, #T_b3656_row2_col0, #T_b3656_row2_col1, #T_b3656_row2_col2, #T_b3656_row2_col3, #T_b3656_row3_col0, #T_b3656_row3_col1, #T_b3656_row3_col2, #T_b3656_row3_col3, #T_b3656_row4_col0, #T_b3656_row4_col1, #T_b3656_row4_col2, #T_b3656_row4_col3 {
  background-color: black;
  color: lawngreen;
  border-color: white;
}
</style>
<table id=""T_b3656"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_b3656_level0_col0"">A</th>
<th class=""col_heading level0 col1"" id=""T_b3656_level0_col1"">B</th>
<th class=""col_heading level0 col2"" id=""T_b3656_level0_col2"">C</th>
<th class=""col_heading level0 col3"" id=""T_b3656_level0_col3"">D</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_b3656_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_b3656_row0_col0"">1.764052</td>
<td class=""data row0 col1"" id=""T_b3656_row0_col1"">0.400157</td>
<td class=""data row0 col2"" id=""T_b3656_row0_col2"">nan</td>
<td class=""data row0 col3"" id=""T_b3656_row0_col3"">2.240893</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_b3656_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_b3656_row1_col0"">1.867558</td>
<td class=""data row1 col1"" id=""T_b3656_row1_col1"">-0.977278</td>
<td class=""data row1 col2"" id=""T_b3656_row1_col2"">0.950088</td>
<td class=""data row1 col3"" id=""T_b3656_row1_col3"">-0.151357</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_b3656_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_b3656_row2_col0"">-0.103219</td>
<td class=""data row2 col1"" id=""T_b3656_row2_col1"">0.410599</td>
<td class=""data row2 col2"" id=""T_b3656_row2_col2"">0.144044</td>
<td class=""data row2 col3"" id=""T_b3656_row2_col3"">1.454274</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_b3656_level0_row3"">3</th>
<td class=""data row3 col0"" id=""T_b3656_row3_col0"">0.761038</td>
<td class=""data row3 col1"" id=""T_b3656_row3_col1"">0.121675</td>
<td class=""data row3 col2"" id=""T_b3656_row3_col2"">0.443863</td>
<td class=""data row3 col3"" id=""T_b3656_row3_col3"">0.333674</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_b3656_level0_row4"">4</th>
<td class=""data row4 col0"" id=""T_b3656_row4_col0"">1.494079</td>
<td class=""data row4 col1"" id=""T_b3656_row4_col1"">-0.205158</td>
<td class=""data row4 col2"" id=""T_b3656_row4_col2"">0.313068</td>
<td class=""data row4 col3"" id=""T_b3656_row4_col3"">nan</td>
</tr>
</tbody>
</table></div>
</div>
</section>
<section id=""Bar-charts"">
<h3>Bar charts<a class=""headerlink"" href=""#Bar-charts"" title=""Link to this heading"">#</a></h3>
<p>You can include “bar charts” in your DataFrame.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[56]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">bar</span><span class=""p"">(</span><span class=""n"">subset</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s1"">'A'</span><span class=""p"">,</span> <span class=""s1"">'B'</span><span class=""p"">],</span> <span class=""n"">color</span><span class=""o"">=</span><span class=""s1"">'#d65f5f'</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[56]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_138e7_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 52.9%, #d65f5f 52.9%, #d65f5f 89.5%, transparent 89.5%);
}
#T_138e7_row0_col1 {
  width: 10em;
  background: linear-gradient(90deg, transparent 57.4%, #d65f5f 57.4%, #d65f5f 69.0%, transparent 69.0%);
}
#T_138e7_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 52.9%, #d65f5f 52.9%, #d65f5f 91.7%, transparent 91.7%);
}
#T_138e7_row1_col1 {
  width: 10em;
  background: linear-gradient(90deg, transparent 29.1%, #d65f5f 29.1%, #d65f5f 57.4%, transparent 57.4%);
}
#T_138e7_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.8%, #d65f5f 50.8%, #d65f5f 52.9%, transparent 52.9%);
}
#T_138e7_row2_col1 {
  width: 10em;
  background: linear-gradient(90deg, transparent 57.4%, #d65f5f 57.4%, #d65f5f 69.3%, transparent 69.3%);
}
#T_138e7_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 52.9%, #d65f5f 52.9%, #d65f5f 68.7%, transparent 68.7%);
}
#T_138e7_row3_col1 {
  width: 10em;
  background: linear-gradient(90deg, transparent 57.4%, #d65f5f 57.4%, #d65f5f 60.9%, transparent 60.9%);
}
#T_138e7_row4_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 52.9%, #d65f5f 52.9%, #d65f5f 83.9%, transparent 83.9%);
}
#T_138e7_row4_col1 {
  width: 10em;
  background: linear-gradient(90deg, transparent 51.5%, #d65f5f 51.5%, #d65f5f 57.4%, transparent 57.4%);
}
#T_138e7_row5_col0 {
  width: 10em;
  background: linear-gradient(90deg, #d65f5f 52.9%, transparent 52.9%);
}
#T_138e7_row5_col1 {
  width: 10em;
  background: linear-gradient(90deg, transparent 57.4%, #d65f5f 57.4%, #d65f5f 76.4%, transparent 76.4%);
}
#T_138e7_row6_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 52.9%, #d65f5f 52.9%, #d65f5f 100.0%, transparent 100.0%);
}
#T_138e7_row6_col1 {
  width: 10em;
  background: linear-gradient(90deg, transparent 15.3%, #d65f5f 15.3%, #d65f5f 57.4%, transparent 57.4%);
}
#T_138e7_row7_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 52.9%, #d65f5f 52.9%, #d65f5f 84.7%, transparent 84.7%);
}
#T_138e7_row7_col1 {
  width: 10em;
  background: linear-gradient(90deg, transparent 57.4%, #d65f5f 57.4%, #d65f5f 100.0%, transparent 100.0%);
}
#T_138e7_row8_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 34.5%, #d65f5f 34.5%, #d65f5f 52.9%, transparent 52.9%);
}
#T_138e7_row8_col1 {
  width: 10em;
  background: linear-gradient(90deg, #d65f5f 57.4%, transparent 57.4%);
}
#T_138e7_row9_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 52.9%, #d65f5f 52.9%, #d65f5f 78.4%, transparent 78.4%);
}
#T_138e7_row9_col1 {
  width: 10em;
  background: linear-gradient(90deg, transparent 57.4%, #d65f5f 57.4%, #d65f5f 92.3%, transparent 92.3%);
}
</style>
<table id=""T_138e7"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_138e7_level0_col0"">A</th>
<th class=""col_heading level0 col1"" id=""T_138e7_level0_col1"">B</th>
<th class=""col_heading level0 col2"" id=""T_138e7_level0_col2"">C</th>
<th class=""col_heading level0 col3"" id=""T_138e7_level0_col3"">D</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_138e7_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_138e7_row0_col0"">1.764052</td>
<td class=""data row0 col1"" id=""T_138e7_row0_col1"">0.400157</td>
<td class=""data row0 col2"" id=""T_138e7_row0_col2"">nan</td>
<td class=""data row0 col3"" id=""T_138e7_row0_col3"">2.240893</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_138e7_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_138e7_row1_col0"">1.867558</td>
<td class=""data row1 col1"" id=""T_138e7_row1_col1"">-0.977278</td>
<td class=""data row1 col2"" id=""T_138e7_row1_col2"">0.950088</td>
<td class=""data row1 col3"" id=""T_138e7_row1_col3"">-0.151357</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_138e7_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_138e7_row2_col0"">-0.103219</td>
<td class=""data row2 col1"" id=""T_138e7_row2_col1"">0.410599</td>
<td class=""data row2 col2"" id=""T_138e7_row2_col2"">0.144044</td>
<td class=""data row2 col3"" id=""T_138e7_row2_col3"">1.454274</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_138e7_level0_row3"">3</th>
<td class=""data row3 col0"" id=""T_138e7_row3_col0"">0.761038</td>
<td class=""data row3 col1"" id=""T_138e7_row3_col1"">0.121675</td>
<td class=""data row3 col2"" id=""T_138e7_row3_col2"">0.443863</td>
<td class=""data row3 col3"" id=""T_138e7_row3_col3"">0.333674</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_138e7_level0_row4"">4</th>
<td class=""data row4 col0"" id=""T_138e7_row4_col0"">1.494079</td>
<td class=""data row4 col1"" id=""T_138e7_row4_col1"">-0.205158</td>
<td class=""data row4 col2"" id=""T_138e7_row4_col2"">0.313068</td>
<td class=""data row4 col3"" id=""T_138e7_row4_col3"">nan</td>
</tr>
<tr>
<th class=""row_heading level0 row5"" id=""T_138e7_level0_row5"">5</th>
<td class=""data row5 col0"" id=""T_138e7_row5_col0"">-2.552990</td>
<td class=""data row5 col1"" id=""T_138e7_row5_col1"">0.653619</td>
<td class=""data row5 col2"" id=""T_138e7_row5_col2"">0.864436</td>
<td class=""data row5 col3"" id=""T_138e7_row5_col3"">-0.742165</td>
</tr>
<tr>
<th class=""row_heading level0 row6"" id=""T_138e7_level0_row6"">6</th>
<td class=""data row6 col0"" id=""T_138e7_row6_col0"">2.269755</td>
<td class=""data row6 col1"" id=""T_138e7_row6_col1"">-1.454366</td>
<td class=""data row6 col2"" id=""T_138e7_row6_col2"">0.045759</td>
<td class=""data row6 col3"" id=""T_138e7_row6_col3"">-0.187184</td>
</tr>
<tr>
<th class=""row_heading level0 row7"" id=""T_138e7_level0_row7"">7</th>
<td class=""data row7 col0"" id=""T_138e7_row7_col0"">1.532779</td>
<td class=""data row7 col1"" id=""T_138e7_row7_col1"">1.469359</td>
<td class=""data row7 col2"" id=""T_138e7_row7_col2"">0.154947</td>
<td class=""data row7 col3"" id=""T_138e7_row7_col3"">0.378163</td>
</tr>
<tr>
<th class=""row_heading level0 row8"" id=""T_138e7_level0_row8"">8</th>
<td class=""data row8 col0"" id=""T_138e7_row8_col0"">-0.887786</td>
<td class=""data row8 col1"" id=""T_138e7_row8_col1"">-1.980796</td>
<td class=""data row8 col2"" id=""T_138e7_row8_col2"">-0.347912</td>
<td class=""data row8 col3"" id=""T_138e7_row8_col3"">0.156349</td>
</tr>
<tr>
<th class=""row_heading level0 row9"" id=""T_138e7_level0_row9"">9</th>
<td class=""data row9 col0"" id=""T_138e7_row9_col0"">1.230291</td>
<td class=""data row9 col1"" id=""T_138e7_row9_col1"">1.202380</td>
<td class=""data row9 col2"" id=""T_138e7_row9_col2"">-0.387327</td>
<td class=""data row9 col3"" id=""T_138e7_row9_col3"">-0.302303</td>
</tr>
</tbody>
</table></div>
</div>
<p>Additional keyword arguments give more control on centering and positioning, and you can pass a list of <code class=""docutils literal notranslate""><span class=""pre"">[color_negative,</span> <span class=""pre"">color_positive]</span></code> to highlight lower and higher values or a matplotlib colormap.</p>
<p>To showcase an example here’s how you can change the above with the new <code class=""docutils literal notranslate""><span class=""pre"">align</span></code> option, combined with setting <code class=""docutils literal notranslate""><span class=""pre"">vmin</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">vmax</span></code> limits, the <code class=""docutils literal notranslate""><span class=""pre"">width</span></code> of the figure, and underlying css <code class=""docutils literal notranslate""><span class=""pre"">props</span></code> of cells, leaving space to display the text and the bars. We also use <code class=""docutils literal notranslate""><span class=""pre"">text_gradient</span></code> to color the text the same as the bars using a matplotlib colormap (although in this case the visualization is probably better without this additional effect).</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[57]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">format</span><span class=""p"">(</span><span class=""s1"">'</span><span class=""si"">{:.3f}</span><span class=""s1"">'</span><span class=""p"">,</span> <span class=""n"">na_rep</span><span class=""o"">=</span><span class=""s2"">""""</span><span class=""p"">)</span>\
         <span class=""o"">.</span><span class=""n"">bar</span><span class=""p"">(</span><span class=""n"">align</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">,</span> <span class=""n"">vmin</span><span class=""o"">=-</span><span class=""mf"">2.5</span><span class=""p"">,</span> <span class=""n"">vmax</span><span class=""o"">=</span><span class=""mf"">2.5</span><span class=""p"">,</span> <span class=""n"">cmap</span><span class=""o"">=</span><span class=""s2"">""bwr""</span><span class=""p"">,</span> <span class=""n"">height</span><span class=""o"">=</span><span class=""mi"">50</span><span class=""p"">,</span>
              <span class=""n"">width</span><span class=""o"">=</span><span class=""mi"">60</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s2"">""width: 120px; border-right: 1px solid black;""</span><span class=""p"">)</span>\
         <span class=""o"">.</span><span class=""n"">text_gradient</span><span class=""p"">(</span><span class=""n"">cmap</span><span class=""o"">=</span><span class=""s2"">""bwr""</span><span class=""p"">,</span> <span class=""n"">vmin</span><span class=""o"">=-</span><span class=""mf"">2.5</span><span class=""p"">,</span> <span class=""n"">vmax</span><span class=""o"">=</span><span class=""mf"">2.5</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[57]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_cd283_row0_col0 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ff4a4a 30.0%, #ff4a4a 51.2%, transparent 51.2%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ff4a4a;
}
#T_cd283_row0_col1 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ffd6d6 30.0%, #ffd6d6 34.8%, transparent 34.8%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ffd6d6;
}
#T_cd283_row0_col2, #T_cd283_row4_col3 {
  width: 120px;
  border-right: 1px solid black;
  color: #000000;
}
#T_cd283_row0_col3 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ff1a1a 30.0%, #ff1a1a 56.9%, transparent 56.9%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ff1a1a;
}
#T_cd283_row1_col0 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ff4040 30.0%, #ff4040 52.4%, transparent 52.4%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ff4040;
}
#T_cd283_row1_col1 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 18.3%, #9a9aff 18.3%, #9a9aff 30.0%, transparent 30.0%) no-repeat center;
  background-size: 100% 50.0%;
  color: #9a9aff;
}
#T_cd283_row1_col2 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ff9e9e 30.0%, #ff9e9e 41.4%, transparent 41.4%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ff9e9e;
}
#T_cd283_row1_col3 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 28.2%, #f0f0ff 28.2%, #f0f0ff 30.0%, transparent 30.0%) no-repeat center;
  background-size: 100% 50.0%;
  color: #f0f0ff;
}
#T_cd283_row2_col0 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 28.8%, #f4f4ff 28.8%, #f4f4ff 30.0%, transparent 30.0%) no-repeat center;
  background-size: 100% 50.0%;
  color: #f4f4ff;
}
#T_cd283_row2_col1 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ffd4d4 30.0%, #ffd4d4 34.9%, transparent 34.9%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ffd4d4;
}
#T_cd283_row2_col2 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #fff0f0 30.0%, #fff0f0 31.7%, transparent 31.7%) no-repeat center;
  background-size: 100% 50.0%;
  color: #fff0f0;
}
#T_cd283_row2_col3 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ff6a6a 30.0%, #ff6a6a 47.5%, transparent 47.5%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ff6a6a;
}
#T_cd283_row3_col0 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ffb2b2 30.0%, #ffb2b2 39.1%, transparent 39.1%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ffb2b2;
}
#T_cd283_row3_col1 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #fff2f2 30.0%, #fff2f2 31.5%, transparent 31.5%) no-repeat center;
  background-size: 100% 50.0%;
  color: #fff2f2;
}
#T_cd283_row3_col2 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ffd2d2 30.0%, #ffd2d2 35.3%, transparent 35.3%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ffd2d2;
}
#T_cd283_row3_col3 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ffdcdc 30.0%, #ffdcdc 34.0%, transparent 34.0%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ffdcdc;
}
#T_cd283_row4_col0 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ff6666 30.0%, #ff6666 47.9%, transparent 47.9%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ff6666;
}
#T_cd283_row4_col1 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 27.5%, #eaeaff 27.5%, #eaeaff 30.0%, transparent 30.0%) no-repeat center;
  background-size: 100% 50.0%;
  color: #eaeaff;
}
#T_cd283_row4_col2 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ffdede 30.0%, #ffdede 33.8%, transparent 33.8%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ffdede;
}
#T_cd283_row5_col0 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, #0000ff 30.0%, transparent 30.0%) no-repeat center;
  background-size: 100% 50.0%;
  color: #0000ff;
}
#T_cd283_row5_col1 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ffbcbc 30.0%, #ffbcbc 37.8%, transparent 37.8%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ffbcbc;
}
#T_cd283_row5_col2 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ffa6a6 30.0%, #ffa6a6 40.4%, transparent 40.4%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ffa6a6;
}
#T_cd283_row5_col3 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 21.1%, #b4b4ff 21.1%, #b4b4ff 30.0%, transparent 30.0%) no-repeat center;
  background-size: 100% 50.0%;
  color: #b4b4ff;
}
#T_cd283_row6_col0 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ff1616 30.0%, #ff1616 57.2%, transparent 57.2%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ff1616;
}
#T_cd283_row6_col1 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 12.5%, #6a6aff 12.5%, #6a6aff 30.0%, transparent 30.0%) no-repeat center;
  background-size: 100% 50.0%;
  color: #6a6aff;
}
#T_cd283_row6_col2 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #fffafa 30.0%, #fffafa 30.5%, transparent 30.5%) no-repeat center;
  background-size: 100% 50.0%;
  color: #fffafa;
}
#T_cd283_row6_col3 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 27.8%, #ececff 27.8%, #ececff 30.0%, transparent 30.0%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ececff;
}
#T_cd283_row7_col0 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ff6262 30.0%, #ff6262 48.4%, transparent 48.4%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ff6262;
}
#T_cd283_row7_col1 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ff6868 30.0%, #ff6868 47.6%, transparent 47.6%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ff6868;
}
#T_cd283_row7_col2 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #fff0f0 30.0%, #fff0f0 31.9%, transparent 31.9%) no-repeat center;
  background-size: 100% 50.0%;
  color: #fff0f0;
}
#T_cd283_row7_col3 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ffd8d8 30.0%, #ffd8d8 34.5%, transparent 34.5%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ffd8d8;
}
#T_cd283_row8_col0 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 19.3%, #a4a4ff 19.3%, #a4a4ff 30.0%, transparent 30.0%) no-repeat center;
  background-size: 100% 50.0%;
  color: #a4a4ff;
}
#T_cd283_row8_col1 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 6.2%, #3434ff 6.2%, #3434ff 30.0%, transparent 30.0%) no-repeat center;
  background-size: 100% 50.0%;
  color: #3434ff;
}
#T_cd283_row8_col2 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 25.8%, #dcdcff 25.8%, #dcdcff 30.0%, transparent 30.0%) no-repeat center;
  background-size: 100% 50.0%;
  color: #dcdcff;
}
#T_cd283_row8_col3 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ffeeee 30.0%, #ffeeee 31.9%, transparent 31.9%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ffeeee;
}
#T_cd283_row9_col0 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ff8282 30.0%, #ff8282 44.8%, transparent 44.8%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ff8282;
}
#T_cd283_row9_col1 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 30.0%, #ff8484 30.0%, #ff8484 44.4%, transparent 44.4%) no-repeat center;
  background-size: 100% 50.0%;
  color: #ff8484;
}
#T_cd283_row9_col2 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 25.4%, #d8d8ff 25.4%, #d8d8ff 30.0%, transparent 30.0%) no-repeat center;
  background-size: 100% 50.0%;
  color: #d8d8ff;
}
#T_cd283_row9_col3 {
  width: 120px;
  border-right: 1px solid black;
  background: linear-gradient(90deg, transparent 26.4%, #e0e0ff 26.4%, #e0e0ff 30.0%, transparent 30.0%) no-repeat center;
  background-size: 100% 50.0%;
  color: #e0e0ff;
}
</style>
<table id=""T_cd283"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_cd283_level0_col0"">A</th>
<th class=""col_heading level0 col1"" id=""T_cd283_level0_col1"">B</th>
<th class=""col_heading level0 col2"" id=""T_cd283_level0_col2"">C</th>
<th class=""col_heading level0 col3"" id=""T_cd283_level0_col3"">D</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_cd283_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_cd283_row0_col0"">1.764</td>
<td class=""data row0 col1"" id=""T_cd283_row0_col1"">0.400</td>
<td class=""data row0 col2"" id=""T_cd283_row0_col2""></td>
<td class=""data row0 col3"" id=""T_cd283_row0_col3"">2.241</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_cd283_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_cd283_row1_col0"">1.868</td>
<td class=""data row1 col1"" id=""T_cd283_row1_col1"">-0.977</td>
<td class=""data row1 col2"" id=""T_cd283_row1_col2"">0.950</td>
<td class=""data row1 col3"" id=""T_cd283_row1_col3"">-0.151</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_cd283_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_cd283_row2_col0"">-0.103</td>
<td class=""data row2 col1"" id=""T_cd283_row2_col1"">0.411</td>
<td class=""data row2 col2"" id=""T_cd283_row2_col2"">0.144</td>
<td class=""data row2 col3"" id=""T_cd283_row2_col3"">1.454</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_cd283_level0_row3"">3</th>
<td class=""data row3 col0"" id=""T_cd283_row3_col0"">0.761</td>
<td class=""data row3 col1"" id=""T_cd283_row3_col1"">0.122</td>
<td class=""data row3 col2"" id=""T_cd283_row3_col2"">0.444</td>
<td class=""data row3 col3"" id=""T_cd283_row3_col3"">0.334</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_cd283_level0_row4"">4</th>
<td class=""data row4 col0"" id=""T_cd283_row4_col0"">1.494</td>
<td class=""data row4 col1"" id=""T_cd283_row4_col1"">-0.205</td>
<td class=""data row4 col2"" id=""T_cd283_row4_col2"">0.313</td>
<td class=""data row4 col3"" id=""T_cd283_row4_col3""></td>
</tr>
<tr>
<th class=""row_heading level0 row5"" id=""T_cd283_level0_row5"">5</th>
<td class=""data row5 col0"" id=""T_cd283_row5_col0"">-2.553</td>
<td class=""data row5 col1"" id=""T_cd283_row5_col1"">0.654</td>
<td class=""data row5 col2"" id=""T_cd283_row5_col2"">0.864</td>
<td class=""data row5 col3"" id=""T_cd283_row5_col3"">-0.742</td>
</tr>
<tr>
<th class=""row_heading level0 row6"" id=""T_cd283_level0_row6"">6</th>
<td class=""data row6 col0"" id=""T_cd283_row6_col0"">2.270</td>
<td class=""data row6 col1"" id=""T_cd283_row6_col1"">-1.454</td>
<td class=""data row6 col2"" id=""T_cd283_row6_col2"">0.046</td>
<td class=""data row6 col3"" id=""T_cd283_row6_col3"">-0.187</td>
</tr>
<tr>
<th class=""row_heading level0 row7"" id=""T_cd283_level0_row7"">7</th>
<td class=""data row7 col0"" id=""T_cd283_row7_col0"">1.533</td>
<td class=""data row7 col1"" id=""T_cd283_row7_col1"">1.469</td>
<td class=""data row7 col2"" id=""T_cd283_row7_col2"">0.155</td>
<td class=""data row7 col3"" id=""T_cd283_row7_col3"">0.378</td>
</tr>
<tr>
<th class=""row_heading level0 row8"" id=""T_cd283_level0_row8"">8</th>
<td class=""data row8 col0"" id=""T_cd283_row8_col0"">-0.888</td>
<td class=""data row8 col1"" id=""T_cd283_row8_col1"">-1.981</td>
<td class=""data row8 col2"" id=""T_cd283_row8_col2"">-0.348</td>
<td class=""data row8 col3"" id=""T_cd283_row8_col3"">0.156</td>
</tr>
<tr>
<th class=""row_heading level0 row9"" id=""T_cd283_level0_row9"">9</th>
<td class=""data row9 col0"" id=""T_cd283_row9_col0"">1.230</td>
<td class=""data row9 col1"" id=""T_cd283_row9_col1"">1.202</td>
<td class=""data row9 col2"" id=""T_cd283_row9_col2"">-0.387</td>
<td class=""data row9 col3"" id=""T_cd283_row9_col3"">-0.302</td>
</tr>
</tbody>
</table></div>
</div>
<p>The following example aims to give a highlight of the behavior of the new align options:</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[59]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">HTML</span><span class=""p"">(</span><span class=""n"">head</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[59]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<table>
<thead>
<th>Align</th>
<th>All Negative</th>
<th>Both Neg and Pos</th>
<th>All Positive</th>
<th>Large Positive</th>
</thead>

<tr><th>left</th><td><style type=""text/css"">
#T_a6ccb_row0_col0 {
  width: 10em;
}
#T_a6ccb_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, #d65f5f 50.0%, transparent 50.0%);
}
#T_a6ccb_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, #d65f5f 87.5%, transparent 87.5%);
}
#T_a6ccb_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, #d65f5f 100.0%, transparent 100.0%);
}
</style>
<table id=""T_a6ccb"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_a6ccb_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_a6ccb_row0_col0"">-100</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_a6ccb_row1_col0"">-60</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_a6ccb_row2_col0"">-30</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_a6ccb_row3_col0"">-20</td>
</tr>
</tbody>
</table>
</td><td><style type=""text/css"">
#T_ffe60_row0_col0 {
  width: 10em;
}
#T_ffe60_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, #d65f5f 5.0%, transparent 5.0%);
}
#T_ffe60_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, #5fba7d 10.0%, transparent 10.0%);
}
#T_ffe60_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, #5fba7d 100.0%, transparent 100.0%);
}
</style>
<table id=""T_ffe60"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_ffe60_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_ffe60_row0_col0"">-10</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_ffe60_row1_col0"">-5</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_ffe60_row2_col0"">0</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_ffe60_row3_col0"">90</td>
</tr>
</tbody>
</table>
</td><td><style type=""text/css"">
#T_a4972_row0_col0 {
  width: 10em;
}
#T_a4972_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, #5fba7d 11.1%, transparent 11.1%);
}
#T_a4972_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, #5fba7d 44.4%, transparent 44.4%);
}
#T_a4972_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, #5fba7d 100.0%, transparent 100.0%);
}
</style>
<table id=""T_a4972"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_a4972_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_a4972_row0_col0"">10</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_a4972_row1_col0"">20</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_a4972_row2_col0"">50</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_a4972_row3_col0"">100</td>
</tr>
</tbody>
</table>
</td><td><style type=""text/css"">
#T_99935_row0_col0 {
  width: 10em;
}
#T_99935_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, #5fba7d 100.0%, transparent 100.0%);
}
#T_99935_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, #5fba7d 33.3%, transparent 33.3%);
}
#T_99935_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, #5fba7d 66.7%, transparent 66.7%);
}
</style>
<table id=""T_99935"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_99935_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_99935_row0_col0"">100</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_99935_row1_col0"">103</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_99935_row2_col0"">101</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_99935_row3_col0"">102</td>
</tr>
</tbody>
</table>
</td></tr><tr><th>right</th><td><style type=""text/css"">
#T_c35af_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, #d65f5f 100.0%, transparent 100.0%);
}
#T_c35af_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #d65f5f 50.0%, #d65f5f 100.0%, transparent 100.0%);
}
#T_c35af_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 87.5%, #d65f5f 87.5%, #d65f5f 100.0%, transparent 100.0%);
}
#T_c35af_row3_col0 {
  width: 10em;
}
</style>
<table id=""T_c35af"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_c35af_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_c35af_row0_col0"">-100</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_c35af_row1_col0"">-60</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_c35af_row2_col0"">-30</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_c35af_row3_col0"">-20</td>
</tr>
</tbody>
</table>
</td><td><style type=""text/css"">
#T_b7ae4_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, #d65f5f 100.0%, transparent 100.0%);
}
#T_b7ae4_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 5.0%, #d65f5f 5.0%, #d65f5f 100.0%, transparent 100.0%);
}
#T_b7ae4_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 10.0%, #5fba7d 10.0%, #5fba7d 100.0%, transparent 100.0%);
}
#T_b7ae4_row3_col0 {
  width: 10em;
}
</style>
<table id=""T_b7ae4"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_b7ae4_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_b7ae4_row0_col0"">-10</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_b7ae4_row1_col0"">-5</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_b7ae4_row2_col0"">0</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_b7ae4_row3_col0"">90</td>
</tr>
</tbody>
</table>
</td><td><style type=""text/css"">
#T_091c7_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, #5fba7d 100.0%, transparent 100.0%);
}
#T_091c7_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 11.1%, #5fba7d 11.1%, #5fba7d 100.0%, transparent 100.0%);
}
#T_091c7_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 44.4%, #5fba7d 44.4%, #5fba7d 100.0%, transparent 100.0%);
}
#T_091c7_row3_col0 {
  width: 10em;
}
</style>
<table id=""T_091c7"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_091c7_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_091c7_row0_col0"">10</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_091c7_row1_col0"">20</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_091c7_row2_col0"">50</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_091c7_row3_col0"">100</td>
</tr>
</tbody>
</table>
</td><td><style type=""text/css"">
#T_53d68_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, #5fba7d 100.0%, transparent 100.0%);
}
#T_53d68_row1_col0 {
  width: 10em;
}
#T_53d68_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 33.3%, #5fba7d 33.3%, #5fba7d 100.0%, transparent 100.0%);
}
#T_53d68_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 66.7%, #5fba7d 66.7%, #5fba7d 100.0%, transparent 100.0%);
}
</style>
<table id=""T_53d68"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_53d68_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_53d68_row0_col0"">100</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_53d68_row1_col0"">103</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_53d68_row2_col0"">101</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_53d68_row3_col0"">102</td>
</tr>
</tbody>
</table>
</td></tr><tr><th>zero</th><td><style type=""text/css"">
#T_9f93a_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, #d65f5f 50.0%, transparent 50.0%);
}
#T_9f93a_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 20.0%, #d65f5f 20.0%, #d65f5f 50.0%, transparent 50.0%);
}
#T_9f93a_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 35.0%, #d65f5f 35.0%, #d65f5f 50.0%, transparent 50.0%);
}
#T_9f93a_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 40.0%, #d65f5f 40.0%, #d65f5f 50.0%, transparent 50.0%);
}
</style>
<table id=""T_9f93a"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_9f93a_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_9f93a_row0_col0"">-100</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_9f93a_row1_col0"">-60</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_9f93a_row2_col0"">-30</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_9f93a_row3_col0"">-20</td>
</tr>
</tbody>
</table>
</td><td><style type=""text/css"">
#T_1e98a_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 44.4%, #d65f5f 44.4%, #d65f5f 50.0%, transparent 50.0%);
}
#T_1e98a_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 47.2%, #d65f5f 47.2%, #d65f5f 50.0%, transparent 50.0%);
}
#T_1e98a_row2_col0 {
  width: 10em;
}
#T_1e98a_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 100.0%, transparent 100.0%);
}
</style>
<table id=""T_1e98a"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_1e98a_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_1e98a_row0_col0"">-10</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_1e98a_row1_col0"">-5</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_1e98a_row2_col0"">0</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_1e98a_row3_col0"">90</td>
</tr>
</tbody>
</table>
</td><td><style type=""text/css"">
#T_f55b4_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 55.0%, transparent 55.0%);
}
#T_f55b4_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 60.0%, transparent 60.0%);
}
#T_f55b4_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 75.0%, transparent 75.0%);
}
#T_f55b4_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 100.0%, transparent 100.0%);
}
</style>
<table id=""T_f55b4"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_f55b4_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_f55b4_row0_col0"">10</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_f55b4_row1_col0"">20</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_f55b4_row2_col0"">50</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_f55b4_row3_col0"">100</td>
</tr>
</tbody>
</table>
</td><td><style type=""text/css"">
#T_e994f_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 98.5%, transparent 98.5%);
}
#T_e994f_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 100.0%, transparent 100.0%);
}
#T_e994f_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 99.0%, transparent 99.0%);
}
#T_e994f_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 99.5%, transparent 99.5%);
}
</style>
<table id=""T_e994f"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_e994f_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_e994f_row0_col0"">100</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_e994f_row1_col0"">103</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_e994f_row2_col0"">101</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_e994f_row3_col0"">102</td>
</tr>
</tbody>
</table>
</td></tr><tr><th>mid</th><td><style type=""text/css"">
#T_6d718_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, #d65f5f 100.0%, transparent 100.0%);
}
#T_6d718_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 40.0%, #d65f5f 40.0%, #d65f5f 100.0%, transparent 100.0%);
}
#T_6d718_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 70.0%, #d65f5f 70.0%, #d65f5f 100.0%, transparent 100.0%);
}
#T_6d718_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 80.0%, #d65f5f 80.0%, #d65f5f 100.0%, transparent 100.0%);
}
</style>
<table id=""T_6d718"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_6d718_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_6d718_row0_col0"">-100</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_6d718_row1_col0"">-60</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_6d718_row2_col0"">-30</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_6d718_row3_col0"">-20</td>
</tr>
</tbody>
</table>
</td><td><style type=""text/css"">
#T_b9faf_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, #d65f5f 10.0%, transparent 10.0%);
}
#T_b9faf_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 5.0%, #d65f5f 5.0%, #d65f5f 10.0%, transparent 10.0%);
}
#T_b9faf_row2_col0 {
  width: 10em;
}
#T_b9faf_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 10.0%, #5fba7d 10.0%, #5fba7d 100.0%, transparent 100.0%);
}
</style>
<table id=""T_b9faf"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_b9faf_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_b9faf_row0_col0"">-10</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_b9faf_row1_col0"">-5</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_b9faf_row2_col0"">0</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_b9faf_row3_col0"">90</td>
</tr>
</tbody>
</table>
</td><td><style type=""text/css"">
#T_24d1a_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, #5fba7d 10.0%, transparent 10.0%);
}
#T_24d1a_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, #5fba7d 20.0%, transparent 20.0%);
}
#T_24d1a_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, #5fba7d 50.0%, transparent 50.0%);
}
#T_24d1a_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, #5fba7d 100.0%, transparent 100.0%);
}
</style>
<table id=""T_24d1a"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_24d1a_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_24d1a_row0_col0"">10</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_24d1a_row1_col0"">20</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_24d1a_row2_col0"">50</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_24d1a_row3_col0"">100</td>
</tr>
</tbody>
</table>
</td><td><style type=""text/css"">
#T_90197_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, #5fba7d 97.1%, transparent 97.1%);
}
#T_90197_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, #5fba7d 100.0%, transparent 100.0%);
}
#T_90197_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, #5fba7d 98.1%, transparent 98.1%);
}
#T_90197_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, #5fba7d 99.0%, transparent 99.0%);
}
</style>
<table id=""T_90197"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_90197_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_90197_row0_col0"">100</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_90197_row1_col0"">103</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_90197_row2_col0"">101</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_90197_row3_col0"">102</td>
</tr>
</tbody>
</table>
</td></tr><tr><th>mean</th><td><style type=""text/css"">
#T_4f502_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, #d65f5f 50.0%, transparent 50.0%);
}
#T_4f502_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 42.1%, #d65f5f 42.1%, #d65f5f 50.0%, transparent 50.0%);
}
#T_4f502_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 73.7%, transparent 73.7%);
}
#T_4f502_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 84.2%, transparent 84.2%);
}
</style>
<table id=""T_4f502"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_4f502_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_4f502_row0_col0"">-100</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_4f502_row1_col0"">-60</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_4f502_row2_col0"">-30</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_4f502_row3_col0"">-20</td>
</tr>
</tbody>
</table>
</td><td><style type=""text/css"">
#T_0520c_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 29.8%, #d65f5f 29.8%, #d65f5f 50.0%, transparent 50.0%);
}
#T_0520c_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 33.3%, #d65f5f 33.3%, #d65f5f 50.0%, transparent 50.0%);
}
#T_0520c_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 36.8%, #d65f5f 36.8%, #d65f5f 50.0%, transparent 50.0%);
}
#T_0520c_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 100.0%, transparent 100.0%);
}
</style>
<table id=""T_0520c"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_0520c_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_0520c_row0_col0"">-10</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_0520c_row1_col0"">-5</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_0520c_row2_col0"">0</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_0520c_row3_col0"">90</td>
</tr>
</tbody>
</table>
</td><td><style type=""text/css"">
#T_ccd98_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 18.2%, #d65f5f 18.2%, #d65f5f 50.0%, transparent 50.0%);
}
#T_ccd98_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 27.3%, #d65f5f 27.3%, #d65f5f 50.0%, transparent 50.0%);
}
#T_ccd98_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 54.5%, transparent 54.5%);
}
#T_ccd98_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 100.0%, transparent 100.0%);
}
</style>
<table id=""T_ccd98"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_ccd98_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_ccd98_row0_col0"">10</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_ccd98_row1_col0"">20</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_ccd98_row2_col0"">50</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_ccd98_row3_col0"">100</td>
</tr>
</tbody>
</table>
</td><td><style type=""text/css"">
#T_5a183_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, #d65f5f 50.0%, transparent 50.0%);
}
#T_5a183_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 100.0%, transparent 100.0%);
}
#T_5a183_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 33.3%, #d65f5f 33.3%, #d65f5f 50.0%, transparent 50.0%);
}
#T_5a183_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 66.7%, transparent 66.7%);
}
</style>
<table id=""T_5a183"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_5a183_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_5a183_row0_col0"">100</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_5a183_row1_col0"">103</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_5a183_row2_col0"">101</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_5a183_row3_col0"">102</td>
</tr>
</tbody>
</table>
</td></tr><tr><th>99</th><td><style type=""text/css"">
#T_78865_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, #d65f5f 50.0%, transparent 50.0%);
}
#T_78865_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 10.1%, #d65f5f 10.1%, #d65f5f 50.0%, transparent 50.0%);
}
#T_78865_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 17.6%, #d65f5f 17.6%, #d65f5f 50.0%, transparent 50.0%);
}
#T_78865_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 20.1%, #d65f5f 20.1%, #d65f5f 50.0%, transparent 50.0%);
}
</style>
<table id=""T_78865"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_78865_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_78865_row0_col0"">-100</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_78865_row1_col0"">-60</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_78865_row2_col0"">-30</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_78865_row3_col0"">-20</td>
</tr>
</tbody>
</table>
</td><td><style type=""text/css"">
#T_717b5_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, #d65f5f 50.0%, transparent 50.0%);
}
#T_717b5_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 2.3%, #d65f5f 2.3%, #d65f5f 50.0%, transparent 50.0%);
}
#T_717b5_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 4.6%, #d65f5f 4.6%, #d65f5f 50.0%, transparent 50.0%);
}
#T_717b5_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 45.9%, #d65f5f 45.9%, #d65f5f 50.0%, transparent 50.0%);
}
</style>
<table id=""T_717b5"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_717b5_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_717b5_row0_col0"">-10</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_717b5_row1_col0"">-5</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_717b5_row2_col0"">0</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_717b5_row3_col0"">90</td>
</tr>
</tbody>
</table>
</td><td><style type=""text/css"">
#T_40891_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, #d65f5f 50.0%, transparent 50.0%);
}
#T_40891_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 5.6%, #d65f5f 5.6%, #d65f5f 50.0%, transparent 50.0%);
}
#T_40891_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 22.5%, #d65f5f 22.5%, #d65f5f 50.0%, transparent 50.0%);
}
#T_40891_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 50.6%, transparent 50.6%);
}
</style>
<table id=""T_40891"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_40891_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_40891_row0_col0"">10</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_40891_row1_col0"">20</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_40891_row2_col0"">50</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_40891_row3_col0"">100</td>
</tr>
</tbody>
</table>
</td><td><style type=""text/css"">
#T_23ab7_row0_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 62.5%, transparent 62.5%);
}
#T_23ab7_row1_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 100.0%, transparent 100.0%);
}
#T_23ab7_row2_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 75.0%, transparent 75.0%);
}
#T_23ab7_row3_col0 {
  width: 10em;
  background: linear-gradient(90deg, transparent 50.0%, #5fba7d 50.0%, #5fba7d 87.5%, transparent 87.5%);
}
</style>
<table id=""T_23ab7"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_23ab7_level0_col0""></th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_23ab7_row0_col0"">100</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_23ab7_row1_col0"">103</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_23ab7_row2_col0"">101</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_23ab7_row3_col0"">102</td>
</tr>
</tbody>
</table>
</td></tr>

</table></div>
</div>
</section>
</section>
<section id=""Sharing-styles"">
<h2>Sharing styles<a class=""headerlink"" href=""#Sharing-styles"" title=""Link to this heading"">#</a></h2>
<p>Say you have a lovely style built up for a DataFrame, and now you want to apply the same style to a second DataFrame. Export the style with <code class=""docutils literal notranslate""><span class=""pre"">df1.style.export</span></code>, and import it on the second DataFrame with <code class=""docutils literal notranslate""><span class=""pre"">df1.style.set</span></code></p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[60]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">style1</span> <span class=""o"">=</span> <span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">style</span>\
            <span class=""o"">.</span><span class=""n"">map</span><span class=""p"">(</span><span class=""n"">style_negative</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">'color:red;'</span><span class=""p"">)</span>\
            <span class=""o"">.</span><span class=""n"">map</span><span class=""p"">(</span><span class=""k"">lambda</span> <span class=""n"">v</span><span class=""p"">:</span> <span class=""s1"">'opacity: 20%;'</span> <span class=""k"">if</span> <span class=""p"">(</span><span class=""n"">v</span> <span class=""o"">&lt;</span> <span class=""mf"">0.3</span><span class=""p"">)</span> <span class=""ow"">and</span> <span class=""p"">(</span><span class=""n"">v</span> <span class=""o"">&gt;</span> <span class=""o"">-</span><span class=""mf"">0.3</span><span class=""p"">)</span> <span class=""k"">else</span> <span class=""kc"">None</span><span class=""p"">)</span>\
            <span class=""o"">.</span><span class=""n"">set_table_styles</span><span class=""p"">([{</span><span class=""s2"">""selector""</span><span class=""p"">:</span> <span class=""s2"">""th""</span><span class=""p"">,</span> <span class=""s2"">""props""</span><span class=""p"">:</span> <span class=""s2"">""color: blue;""</span><span class=""p"">}])</span>\
            <span class=""o"">.</span><span class=""n"">hide</span><span class=""p"">(</span><span class=""n"">axis</span><span class=""o"">=</span><span class=""s2"">""index""</span><span class=""p"">)</span>
<span class=""n"">style1</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[60]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_222f7 th {
  color: blue;
}
#T_222f7_row1_col1, #T_222f7_row5_col0, #T_222f7_row5_col3, #T_222f7_row6_col1, #T_222f7_row8_col0, #T_222f7_row8_col1, #T_222f7_row8_col2, #T_222f7_row9_col2, #T_222f7_row9_col3 {
  color: red;
}
#T_222f7_row1_col3, #T_222f7_row2_col0, #T_222f7_row4_col1, #T_222f7_row6_col3 {
  color: red;
  opacity: 20%;
}
#T_222f7_row2_col2, #T_222f7_row3_col1, #T_222f7_row6_col2, #T_222f7_row7_col2, #T_222f7_row8_col3 {
  opacity: 20%;
}
</style>
<table id=""T_222f7"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_222f7_level0_col0"">A</th>
<th class=""col_heading level0 col1"" id=""T_222f7_level0_col1"">B</th>
<th class=""col_heading level0 col2"" id=""T_222f7_level0_col2"">C</th>
<th class=""col_heading level0 col3"" id=""T_222f7_level0_col3"">D</th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_222f7_row0_col0"">1.764052</td>
<td class=""data row0 col1"" id=""T_222f7_row0_col1"">0.400157</td>
<td class=""data row0 col2"" id=""T_222f7_row0_col2"">nan</td>
<td class=""data row0 col3"" id=""T_222f7_row0_col3"">2.240893</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_222f7_row1_col0"">1.867558</td>
<td class=""data row1 col1"" id=""T_222f7_row1_col1"">-0.977278</td>
<td class=""data row1 col2"" id=""T_222f7_row1_col2"">0.950088</td>
<td class=""data row1 col3"" id=""T_222f7_row1_col3"">-0.151357</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_222f7_row2_col0"">-0.103219</td>
<td class=""data row2 col1"" id=""T_222f7_row2_col1"">0.410599</td>
<td class=""data row2 col2"" id=""T_222f7_row2_col2"">0.144044</td>
<td class=""data row2 col3"" id=""T_222f7_row2_col3"">1.454274</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_222f7_row3_col0"">0.761038</td>
<td class=""data row3 col1"" id=""T_222f7_row3_col1"">0.121675</td>
<td class=""data row3 col2"" id=""T_222f7_row3_col2"">0.443863</td>
<td class=""data row3 col3"" id=""T_222f7_row3_col3"">0.333674</td>
</tr>
<tr>
<td class=""data row4 col0"" id=""T_222f7_row4_col0"">1.494079</td>
<td class=""data row4 col1"" id=""T_222f7_row4_col1"">-0.205158</td>
<td class=""data row4 col2"" id=""T_222f7_row4_col2"">0.313068</td>
<td class=""data row4 col3"" id=""T_222f7_row4_col3"">nan</td>
</tr>
<tr>
<td class=""data row5 col0"" id=""T_222f7_row5_col0"">-2.552990</td>
<td class=""data row5 col1"" id=""T_222f7_row5_col1"">0.653619</td>
<td class=""data row5 col2"" id=""T_222f7_row5_col2"">0.864436</td>
<td class=""data row5 col3"" id=""T_222f7_row5_col3"">-0.742165</td>
</tr>
<tr>
<td class=""data row6 col0"" id=""T_222f7_row6_col0"">2.269755</td>
<td class=""data row6 col1"" id=""T_222f7_row6_col1"">-1.454366</td>
<td class=""data row6 col2"" id=""T_222f7_row6_col2"">0.045759</td>
<td class=""data row6 col3"" id=""T_222f7_row6_col3"">-0.187184</td>
</tr>
<tr>
<td class=""data row7 col0"" id=""T_222f7_row7_col0"">1.532779</td>
<td class=""data row7 col1"" id=""T_222f7_row7_col1"">1.469359</td>
<td class=""data row7 col2"" id=""T_222f7_row7_col2"">0.154947</td>
<td class=""data row7 col3"" id=""T_222f7_row7_col3"">0.378163</td>
</tr>
<tr>
<td class=""data row8 col0"" id=""T_222f7_row8_col0"">-0.887786</td>
<td class=""data row8 col1"" id=""T_222f7_row8_col1"">-1.980796</td>
<td class=""data row8 col2"" id=""T_222f7_row8_col2"">-0.347912</td>
<td class=""data row8 col3"" id=""T_222f7_row8_col3"">0.156349</td>
</tr>
<tr>
<td class=""data row9 col0"" id=""T_222f7_row9_col0"">1.230291</td>
<td class=""data row9 col1"" id=""T_222f7_row9_col1"">1.202380</td>
<td class=""data row9 col2"" id=""T_222f7_row9_col2"">-0.387327</td>
<td class=""data row9 col3"" id=""T_222f7_row9_col3"">-0.302303</td>
</tr>
</tbody>
</table></div>
</div>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[61]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">style2</span> <span class=""o"">=</span> <span class=""n"">df3</span><span class=""o"">.</span><span class=""n"">style</span>
<span class=""n"">style2</span><span class=""o"">.</span><span class=""n"">use</span><span class=""p"">(</span><span class=""n"">style1</span><span class=""o"">.</span><span class=""n"">export</span><span class=""p"">())</span>
<span class=""n"">style2</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[61]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_cb294 th {
  color: blue;
}
#T_cb294_row0_col0, #T_cb294_row0_col1, #T_cb294_row0_col2, #T_cb294_row1_col0, #T_cb294_row1_col1, #T_cb294_row1_col2, #T_cb294_row2_col0, #T_cb294_row2_col2, #T_cb294_row3_col0, #T_cb294_row3_col1 {
  color: red;
}
#T_cb294_row2_col1, #T_cb294_row3_col2 {
  color: red;
  opacity: 20%;
}
</style>
<table id=""T_cb294"">
<thead>
<tr>
<th class=""col_heading level0 col0"" id=""T_cb294_level0_col0"">c1</th>
<th class=""col_heading level0 col1"" id=""T_cb294_level0_col1"">c2</th>
<th class=""col_heading level0 col2"" id=""T_cb294_level0_col2"">c3</th>
<th class=""col_heading level0 col3"" id=""T_cb294_level0_col3"">c4</th>
</tr>
</thead>
<tbody>
<tr>
<td class=""data row0 col0"" id=""T_cb294_row0_col0"">-1.048553</td>
<td class=""data row0 col1"" id=""T_cb294_row0_col1"">-1.420018</td>
<td class=""data row0 col2"" id=""T_cb294_row0_col2"">-1.706270</td>
<td class=""data row0 col3"" id=""T_cb294_row0_col3"">1.950775</td>
</tr>
<tr>
<td class=""data row1 col0"" id=""T_cb294_row1_col0"">-0.509652</td>
<td class=""data row1 col1"" id=""T_cb294_row1_col1"">-0.438074</td>
<td class=""data row1 col2"" id=""T_cb294_row1_col2"">-1.252795</td>
<td class=""data row1 col3"" id=""T_cb294_row1_col3"">0.777490</td>
</tr>
<tr>
<td class=""data row2 col0"" id=""T_cb294_row2_col0"">-1.613898</td>
<td class=""data row2 col1"" id=""T_cb294_row2_col1"">-0.212740</td>
<td class=""data row2 col2"" id=""T_cb294_row2_col2"">-0.895467</td>
<td class=""data row2 col3"" id=""T_cb294_row2_col3"">0.386902</td>
</tr>
<tr>
<td class=""data row3 col0"" id=""T_cb294_row3_col0"">-0.510805</td>
<td class=""data row3 col1"" id=""T_cb294_row3_col1"">-1.180632</td>
<td class=""data row3 col2"" id=""T_cb294_row3_col2"">-0.028182</td>
<td class=""data row3 col3"" id=""T_cb294_row3_col3"">0.428332</td>
</tr>
</tbody>
</table></div>
</div>
<p>Notice that you’re able to share the styles even though they’re data aware. The styles are re-evaluated on the new DataFrame they’ve been <code class=""docutils literal notranslate""><span class=""pre"">use</span></code>d upon.</p>
</section>
<section id=""Limitations"">
<h2>Limitations<a class=""headerlink"" href=""#Limitations"" title=""Link to this heading"">#</a></h2>
<ul class=""simple"">
<li><p>DataFrame only (use <code class=""docutils literal notranslate""><span class=""pre"">Series.to_frame().style</span></code>)</p></li>
<li><p>The index and columns do not need to be unique, but certain styling functions can only work with unique indexes.</p></li>
<li><p>No large repr, and construction performance isn’t great; although we have some <a class=""reference internal"" href=""#Optimization""><span class=""std std-ref"">HTML optimizations</span></a></p></li>
<li><p>You can only apply styles, you can’t insert new HTML entities, except via subclassing.</p></li>
</ul>
</section>
<section id=""Other-Fun-and-Useful-Stuff"">
<h2>Other Fun and Useful Stuff<a class=""headerlink"" href=""#Other-Fun-and-Useful-Stuff"" title=""Link to this heading"">#</a></h2>
<p>Here are a few interesting examples.</p>
<section id=""Widgets"">
<h3>Widgets<a class=""headerlink"" href=""#Widgets"" title=""Link to this heading"">#</a></h3>
<p><code class=""docutils literal notranslate""><span class=""pre"">Styler</span></code> interacts pretty well with widgets. If you’re viewing this online instead of running the notebook yourself, you’re missing out on interactively adjusting the color palette.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[62]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">ipywidgets</span> <span class=""kn"">import</span> <span class=""n"">widgets</span>
<span class=""nd"">@widgets</span><span class=""o"">.</span><span class=""n"">interact</span>
<span class=""k"">def</span> <span class=""nf"">f</span><span class=""p"">(</span><span class=""n"">h_neg</span><span class=""o"">=</span><span class=""p"">(</span><span class=""mi"">0</span><span class=""p"">,</span> <span class=""mi"">359</span><span class=""p"">,</span> <span class=""mi"">1</span><span class=""p"">),</span> <span class=""n"">h_pos</span><span class=""o"">=</span><span class=""p"">(</span><span class=""mi"">0</span><span class=""p"">,</span> <span class=""mi"">359</span><span class=""p"">),</span> <span class=""n"">s</span><span class=""o"">=</span><span class=""p"">(</span><span class=""mf"">0.</span><span class=""p"">,</span> <span class=""mf"">99.9</span><span class=""p"">),</span> <span class=""n"">l</span><span class=""o"">=</span><span class=""p"">(</span><span class=""mf"">0.</span><span class=""p"">,</span> <span class=""mf"">99.9</span><span class=""p"">)):</span>
    <span class=""k"">return</span> <span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">background_gradient</span><span class=""p"">(</span>
        <span class=""n"">cmap</span><span class=""o"">=</span><span class=""n"">sns</span><span class=""o"">.</span><span class=""n"">palettes</span><span class=""o"">.</span><span class=""n"">diverging_palette</span><span class=""p"">(</span><span class=""n"">h_neg</span><span class=""o"">=</span><span class=""n"">h_neg</span><span class=""p"">,</span> <span class=""n"">h_pos</span><span class=""o"">=</span><span class=""n"">h_pos</span><span class=""p"">,</span> <span class=""n"">s</span><span class=""o"">=</span><span class=""n"">s</span><span class=""p"">,</span> <span class=""n"">l</span><span class=""o"">=</span><span class=""n"">l</span><span class=""p"">,</span>
                                            <span class=""n"">as_cmap</span><span class=""o"">=</span><span class=""kc"">True</span><span class=""p"">)</span>
    <span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt empty docutils container"">
</div>
<div class=""output_area docutils container"">
<script type=""application/vnd.jupyter.widget-view+json"">{""version_major"": 2, ""version_minor"": 0, ""model_id"": ""bf83a63a5f8245b58351a5875ea55836""}</script></div>
</div>
</section>
<section id=""Magnify"">
<h3>Magnify<a class=""headerlink"" href=""#Magnify"" title=""Link to this heading"">#</a></h3>
<div class=""nbinput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[63]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""k"">def</span> <span class=""nf"">magnify</span><span class=""p"">():</span>
    <span class=""k"">return</span> <span class=""p"">[</span><span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">selector</span><span class=""o"">=</span><span class=""s2"">""th""</span><span class=""p"">,</span>
                 <span class=""n"">props</span><span class=""o"">=</span><span class=""p"">[(</span><span class=""s2"">""font-size""</span><span class=""p"">,</span> <span class=""s2"">""4pt""</span><span class=""p"">)]),</span>
            <span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">selector</span><span class=""o"">=</span><span class=""s2"">""td""</span><span class=""p"">,</span>
                 <span class=""n"">props</span><span class=""o"">=</span><span class=""p"">[(</span><span class=""s1"">'padding'</span><span class=""p"">,</span> <span class=""s2"">""0em 0em""</span><span class=""p"">)]),</span>
            <span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">selector</span><span class=""o"">=</span><span class=""s2"">""th:hover""</span><span class=""p"">,</span>
                 <span class=""n"">props</span><span class=""o"">=</span><span class=""p"">[(</span><span class=""s2"">""font-size""</span><span class=""p"">,</span> <span class=""s2"">""12pt""</span><span class=""p"">)]),</span>
            <span class=""nb"">dict</span><span class=""p"">(</span><span class=""n"">selector</span><span class=""o"">=</span><span class=""s2"">""tr:hover td:hover""</span><span class=""p"">,</span>
                 <span class=""n"">props</span><span class=""o"">=</span><span class=""p"">[(</span><span class=""s1"">'max-width'</span><span class=""p"">,</span> <span class=""s1"">'200px'</span><span class=""p"">),</span>
                        <span class=""p"">(</span><span class=""s1"">'font-size'</span><span class=""p"">,</span> <span class=""s1"">'12pt'</span><span class=""p"">)])</span>
<span class=""p"">]</span>
</pre></div>
</div>
</div>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[64]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">np</span><span class=""o"">.</span><span class=""n"">random</span><span class=""o"">.</span><span class=""n"">seed</span><span class=""p"">(</span><span class=""mi"">25</span><span class=""p"">)</span>
<span class=""n"">cmap</span> <span class=""o"">=</span> <span class=""n"">cmap</span><span class=""o"">=</span><span class=""n"">sns</span><span class=""o"">.</span><span class=""n"">diverging_palette</span><span class=""p"">(</span><span class=""mi"">5</span><span class=""p"">,</span> <span class=""mi"">250</span><span class=""p"">,</span> <span class=""n"">as_cmap</span><span class=""o"">=</span><span class=""kc"">True</span><span class=""p"">)</span>
<span class=""n"">bigdf</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">(</span><span class=""n"">np</span><span class=""o"">.</span><span class=""n"">random</span><span class=""o"">.</span><span class=""n"">randn</span><span class=""p"">(</span><span class=""mi"">20</span><span class=""p"">,</span> <span class=""mi"">25</span><span class=""p"">))</span><span class=""o"">.</span><span class=""n"">cumsum</span><span class=""p"">()</span>

<span class=""n"">bigdf</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">background_gradient</span><span class=""p"">(</span><span class=""n"">cmap</span><span class=""p"">,</span> <span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">1</span><span class=""p"">)</span>\
    <span class=""o"">.</span><span class=""n"">set_properties</span><span class=""p"">(</span><span class=""o"">**</span><span class=""p"">{</span><span class=""s1"">'max-width'</span><span class=""p"">:</span> <span class=""s1"">'80px'</span><span class=""p"">,</span> <span class=""s1"">'font-size'</span><span class=""p"">:</span> <span class=""s1"">'1pt'</span><span class=""p"">})</span>\
    <span class=""o"">.</span><span class=""n"">set_caption</span><span class=""p"">(</span><span class=""s2"">""Hover to magnify""</span><span class=""p"">)</span>\
    <span class=""o"">.</span><span class=""n"">format</span><span class=""p"">(</span><span class=""n"">precision</span><span class=""o"">=</span><span class=""mi"">2</span><span class=""p"">)</span>\
    <span class=""o"">.</span><span class=""n"">set_table_styles</span><span class=""p"">(</span><span class=""n"">magnify</span><span class=""p"">())</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[64]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_84484 th {
  font-size: 4pt;
}
#T_84484 td {
  padding: 0em 0em;
}
#T_84484 th:hover {
  font-size: 12pt;
}
#T_84484 tr:hover td:hover {
  max-width: 200px;
  font-size: 12pt;
}
#T_84484_row0_col0, #T_84484_row1_col24, #T_84484_row8_col18 {
  background-color: #eaecf0;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col1, #T_84484_row13_col22 {
  background-color: #b6c9e0;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col2, #T_84484_row1_col17, #T_84484_row10_col12 {
  background-color: #e9b1bc;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col3, #T_84484_row1_col10, #T_84484_row6_col6, #T_84484_row13_col8 {
  background-color: #ebc2ca;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col4, #T_84484_row13_col19, #T_84484_row19_col16 {
  background-color: #e8aab6;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col5, #T_84484_row1_col19 {
  background-color: #efdcdf;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col6, #T_84484_row3_col8, #T_84484_row6_col8 {
  background-color: #ebc1c9;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col7 {
  background-color: #82a4cf;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col8, #T_84484_row9_col21 {
  background-color: #dd5f78;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col9, #T_84484_row2_col24 {
  background-color: #c1d0e3;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col10, #T_84484_row3_col15, #T_84484_row6_col16, #T_84484_row14_col15, #T_84484_row18_col16 {
  background-color: #e8adb8;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col11, #T_84484_row5_col17, #T_84484_row10_col3, #T_84484_row12_col18 {
  background-color: #efdade;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col12, #T_84484_row9_col24, #T_84484_row10_col1 {
  background-color: #6e96c8;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col13 {
  background-color: #e48fa0;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col14, #T_84484_row3_col12, #T_84484_row9_col3, #T_84484_row9_col10, #T_84484_row9_col13, #T_84484_row13_col13 {
  background-color: #f2eff0;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col15, #T_84484_row8_col17, #T_84484_row10_col2 {
  background-color: #e595a5;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col16 {
  background-color: #abc1dc;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col17, #T_84484_row6_col14, #T_84484_row12_col15, #T_84484_row13_col17 {
  background-color: #e7a3b0;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col18, #T_84484_row3_col20, #T_84484_row17_col20 {
  background-color: #b5c8df;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col19, #T_84484_row4_col3, #T_84484_row5_col12, #T_84484_row13_col3 {
  background-color: #edcdd3;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col20, #T_84484_row9_col1, #T_84484_row16_col1 {
  background-color: #648fc5;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col21, #T_84484_row1_col21, #T_84484_row2_col21, #T_84484_row3_col21, #T_84484_row4_col21, #T_84484_row5_col21, #T_84484_row6_col21, #T_84484_row7_col21, #T_84484_row8_col16, #T_84484_row9_col16, #T_84484_row10_col16, #T_84484_row10_col21, #T_84484_row11_col16, #T_84484_row12_col21, #T_84484_row13_col21, #T_84484_row14_col21, #T_84484_row15_col21, #T_84484_row16_col21, #T_84484_row17_col21, #T_84484_row18_col21, #T_84484_row19_col21 {
  background-color: #d73c5b;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col22, #T_84484_row1_col7, #T_84484_row2_col7, #T_84484_row3_col4, #T_84484_row3_col7, #T_84484_row4_col4, #T_84484_row5_col4, #T_84484_row6_col24, #T_84484_row7_col24, #T_84484_row8_col4, #T_84484_row9_col4, #T_84484_row10_col4, #T_84484_row11_col4, #T_84484_row12_col7, #T_84484_row13_col7, #T_84484_row14_col24, #T_84484_row15_col23, #T_84484_row16_col23, #T_84484_row17_col23, #T_84484_row18_col7, #T_84484_row19_col23 {
  background-color: #4479bb;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col23 {
  background-color: #cdd9e7;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row0_col24 {
  background-color: #e18093;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row1_col0 {
  background-color: #e0798d;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row1_col1 {
  background-color: #adc2dd;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row1_col2, #T_84484_row8_col5, #T_84484_row11_col19 {
  background-color: #e69ead;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row1_col3, #T_84484_row1_col13, #T_84484_row18_col8 {
  background-color: #e6a0ae;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row1_col4, #T_84484_row5_col18, #T_84484_row6_col10, #T_84484_row10_col11, #T_84484_row11_col10, #T_84484_row17_col10 {
  background-color: #c9d6e6;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row1_col5 {
  background-color: #f0e0e3;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row1_col6 {
  background-color: #da506b;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row1_col8 {
  background-color: #e17e92;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row1_col9, #T_84484_row5_col10, #T_84484_row14_col11, #T_84484_row16_col6 {
  background-color: #bccce1;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row1_col11, #T_84484_row15_col14 {
  background-color: #f0dee2;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row1_col12, #T_84484_row12_col10, #T_84484_row16_col10 {
  background-color: #aec3dd;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row1_col14, #T_84484_row9_col14 {
  background-color: #e07389;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row1_col15, #T_84484_row12_col19 {
  background-color: #e69dab;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row1_col16 {
  background-color: #eab8c2;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row1_col18, #T_84484_row6_col9, #T_84484_row7_col3, #T_84484_row11_col8 {
  background-color: #eff0f2;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row1_col20, #T_84484_row2_col20, #T_84484_row7_col22 {
  background-color: #9fb8d8;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row1_col22, #T_84484_row14_col1, #T_84484_row17_col22, #T_84484_row19_col0 {
  background-color: #85a6d0;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row1_col23, #T_84484_row19_col9 {
  background-color: #d7dfea;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row2_col0, #T_84484_row7_col0, #T_84484_row7_col15, #T_84484_row8_col13 {
  background-color: #f2eeef;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row2_col1, #T_84484_row4_col1 {
  background-color: #5887c1;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row2_col2, #T_84484_row14_col5, #T_84484_row18_col5, #T_84484_row19_col2, #T_84484_row19_col3, #T_84484_row19_col5 {
  background-color: #ebbfc8;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row2_col3, #T_84484_row3_col3 {
  background-color: #c5d3e4;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row2_col4, #T_84484_row10_col23 {
  background-color: #81a3ce;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row2_col5, #T_84484_row7_col13, #T_84484_row9_col9, #T_84484_row16_col17 {
  background-color: #e8ebf0;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row2_col6, #T_84484_row2_col14, #T_84484_row13_col14 {
  background-color: #e38a9c;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row2_col8, #T_84484_row3_col2 {
  background-color: #eabbc4;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row2_col9 {
  background-color: #769ccb;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row2_col10, #T_84484_row3_col10, #T_84484_row12_col6, #T_84484_row17_col6 {
  background-color: #d1dbe8;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row2_col11, #T_84484_row2_col16, #T_84484_row2_col17, #T_84484_row5_col13, #T_84484_row6_col0, #T_84484_row13_col18 {
  background-color: #e3e8ee;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row2_col12, #T_84484_row5_col11 {
  background-color: #dee4ec;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row2_col13, #T_84484_row5_col0, #T_84484_row5_col15, #T_84484_row17_col18, #T_84484_row19_col13 {
  background-color: #f1eaeb;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row2_col15, #T_84484_row5_col9, #T_84484_row8_col3, #T_84484_row10_col10, #T_84484_row17_col17 {
  background-color: #f1e7e9;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row2_col18, #T_84484_row9_col20 {
  background-color: #b8c9e0;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row2_col19, #T_84484_row4_col8 {
  background-color: #f2eded;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row2_col22, #T_84484_row14_col23 {
  background-color: #608dc4;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row2_col23, #T_84484_row5_col22, #T_84484_row13_col1, #T_84484_row16_col22 {
  background-color: #8dacd2;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row3_col0, #T_84484_row8_col9, #T_84484_row9_col8, #T_84484_row11_col18 {
  background-color: #eed4d9;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row3_col1, #T_84484_row15_col4, #T_84484_row15_col24, #T_84484_row16_col7, #T_84484_row18_col4 {
  background-color: #5383bf;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row3_col5, #T_84484_row11_col9 {
  background-color: #e4e9ee;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row3_col6 {
  background-color: #e28194;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row3_col9 {
  background-color: #b0c4dd;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row3_col11, #T_84484_row4_col9 {
  background-color: #c0cfe3;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row3_col13, #T_84484_row15_col9 {
  background-color: #ccd8e7;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row3_col14 {
  background-color: #e3889a;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row3_col16, #T_84484_row15_col19, #T_84484_row16_col2 {
  background-color: #dfe5ed;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row3_col17, #T_84484_row11_col2, #T_84484_row14_col18 {
  background-color: #eed6db;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row3_col18, #T_84484_row8_col23 {
  background-color: #a6bdda;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row3_col19, #T_84484_row4_col17, #T_84484_row7_col10, #T_84484_row8_col10 {
  background-color: #edccd2;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row3_col22, #T_84484_row17_col24 {
  background-color: #7299c9;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row3_col23 {
  background-color: #8cabd2;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row3_col24 {
  background-color: #cbd7e6;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row4_col0, #T_84484_row8_col2, #T_84484_row9_col17 {
  background-color: #e59aa9;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row4_col2, #T_84484_row7_col6, #T_84484_row15_col15, #T_84484_row18_col2, #T_84484_row18_col19 {
  background-color: #ecc9d0;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row4_col5, #T_84484_row6_col5, #T_84484_row6_col15, #T_84484_row10_col6 {
  background-color: #f0e4e6;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row4_col6 {
  background-color: #e38b9d;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row4_col7, #T_84484_row11_col23, #T_84484_row17_col4, #T_84484_row17_col7 {
  background-color: #5182bf;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row4_col10, #T_84484_row7_col11, #T_84484_row14_col9 {
  background-color: #e6eaef;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row4_col11, #T_84484_row16_col19 {
  background-color: #c7d4e5;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row4_col12, #T_84484_row7_col12, #T_84484_row10_col13 {
  background-color: #e7eaef;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row4_col13, #T_84484_row10_col9, #T_84484_row10_col18, #T_84484_row17_col2 {
  background-color: #f0e1e4;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row4_col14 {
  background-color: #e17c90;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row4_col15, #T_84484_row19_col8 {
  background-color: #e7a8b5;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row4_col16, #T_84484_row5_col5, #T_84484_row6_col12, #T_84484_row10_col20, #T_84484_row14_col6, #T_84484_row18_col14 {
  background-color: #f1e5e7;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row4_col18, #T_84484_row9_col22 {
  background-color: #b2c6de;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row4_col19, #T_84484_row12_col8, #T_84484_row12_col17, #T_84484_row13_col6, #T_84484_row16_col16, #T_84484_row17_col8 {
  background-color: #edcad1;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row4_col20, #T_84484_row9_col23, #T_84484_row12_col11 {
  background-color: #9eb8d8;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row4_col22 {
  background-color: #7b9fcd;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row4_col23, #T_84484_row6_col23, #T_84484_row14_col12 {
  background-color: #94b0d4;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row4_col24, #T_84484_row17_col13 {
  background-color: #a1b9d9;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row5_col1 {
  background-color: #638ec5;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row5_col2, #T_84484_row6_col17, #T_84484_row18_col17, #T_84484_row19_col17 {
  background-color: #edd0d6;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row5_col3, #T_84484_row14_col8, #T_84484_row15_col17, #T_84484_row17_col16 {
  background-color: #ecc6ce;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row5_col6 {
  background-color: #e28497;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row5_col7, #T_84484_row18_col1 {
  background-color: #6d95c8;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row5_col8, #T_84484_row13_col20, #T_84484_row14_col3, #T_84484_row14_col20, #T_84484_row15_col8 {
  background-color: #f0e3e5;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row5_col14 {
  background-color: #e17a8f;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row5_col16, #T_84484_row8_col6, #T_84484_row9_col5, #T_84484_row9_col15, #T_84484_row12_col2 {
  background-color: #ecc5cc;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row5_col19, #T_84484_row14_col19, #T_84484_row18_col18 {
  background-color: #eed2d7;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row5_col20, #T_84484_row11_col22, #T_84484_row19_col20 {
  background-color: #b4c7df;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row5_col23, #T_84484_row6_col20 {
  background-color: #a2bad9;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row5_col24 {
  background-color: #7198c9;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row6_col1 {
  background-color: #4f80be;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row6_col2, #T_84484_row15_col5, #T_84484_row17_col3, #T_84484_row19_col14 {
  background-color: #efdde0;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row6_col3, #T_84484_row13_col12, #T_84484_row17_col15 {
  background-color: #edeef1;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row6_col4, #T_84484_row9_col7, #T_84484_row18_col0 {
  background-color: #6a93c7;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row6_col7, #T_84484_row7_col1, #T_84484_row10_col7 {
  background-color: #759bca;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row6_col11 {
  background-color: #c3d1e4;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row6_col13, #T_84484_row10_col0, #T_84484_row18_col9 {
  background-color: #c4d2e4;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row6_col18, #T_84484_row11_col6 {
  background-color: #d5deea;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row6_col19 {
  background-color: #e69caa;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row6_col22 {
  background-color: #7fa2ce;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row7_col2, #T_84484_row10_col8 {
  background-color: #ebbec6;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row7_col4, #T_84484_row19_col7 {
  background-color: #5585c0;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row7_col5 {
  background-color: #e9b5bf;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row7_col7, #T_84484_row17_col0 {
  background-color: #628ec4;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row7_col8 {
  background-color: #e28396;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row7_col9, #T_84484_row13_col15 {
  background-color: #e7a7b4;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row7_col14, #T_84484_row12_col16 {
  background-color: #dc5c76;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row7_col16 {
  background-color: #db5771;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row7_col17, #T_84484_row9_col19 {
  background-color: #e492a3;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row7_col18, #T_84484_row9_col18, #T_84484_row14_col13, #T_84484_row18_col11 {
  background-color: #d8e0eb;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row7_col19, #T_84484_row12_col14 {
  background-color: #e491a1;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row7_col20, #T_84484_row9_col0, #T_84484_row15_col6, #T_84484_row16_col18 {
  background-color: #dae1eb;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row7_col23, #T_84484_row16_col9 {
  background-color: #95b1d5;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row8_col0 {
  background-color: #d0dae8;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row8_col1 {
  background-color: #487cbc;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row8_col7 {
  background-color: #4d7fbe;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row8_col8 {
  background-color: #e494a4;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row8_col11, #T_84484_row19_col10 {
  background-color: #d3dce9;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row8_col12 {
  background-color: #e9b4be;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row8_col14 {
  background-color: #d94a67;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row8_col15, #T_84484_row11_col3, #T_84484_row16_col15, #T_84484_row18_col6 {
  background-color: #f2ebec;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row8_col19, #T_84484_row11_col14, #T_84484_row14_col16 {
  background-color: #e0748a;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row8_col20, #T_84484_row13_col10, #T_84484_row15_col10 {
  background-color: #dbe2eb;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row8_col21 {
  background-color: #da516c;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row8_col22, #T_84484_row14_col0 {
  background-color: #90aed3;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row8_col24, #T_84484_row12_col24, #T_84484_row13_col4 {
  background-color: #5c8ac2;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row9_col2, #T_84484_row11_col15 {
  background-color: #e599a8;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row9_col6, #T_84484_row16_col14, #T_84484_row17_col14, #T_84484_row18_col10 {
  background-color: #ebedf1;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row9_col11, #T_84484_row12_col9, #T_84484_row15_col20 {
  background-color: #dce3ec;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row9_col12, #T_84484_row13_col5, #T_84484_row14_col2 {
  background-color: #e9b2bd;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row10_col5, #T_84484_row11_col17 {
  background-color: #eab7c1;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row10_col14 {
  background-color: #dd657d;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row10_col15 {
  background-color: #e6a1af;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row10_col17 {
  background-color: #df7086;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row10_col19 {
  background-color: #e28698;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row10_col22, #T_84484_row18_col13 {
  background-color: #cfdae7;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row10_col24, #T_84484_row13_col23 {
  background-color: #6f97c9;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row11_col0, #T_84484_row11_col13 {
  background-color: #a7bedb;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row11_col1 {
  background-color: #6791c6;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row11_col5 {
  background-color: #e2e7ee;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row11_col7 {
  background-color: #477bbb;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row11_col11 {
  background-color: #a5bcda;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row11_col12, #T_84484_row12_col12, #T_84484_row13_col9 {
  background-color: #f1e8ea;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row11_col20, #T_84484_row14_col10, #T_84484_row15_col18, #T_84484_row19_col15, #T_84484_row19_col19 {
  background-color: #f2f1f1;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row11_col21 {
  background-color: #d8415f;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row11_col24, #T_84484_row16_col4 {
  background-color: #457abb;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row12_col0, #T_84484_row16_col13 {
  background-color: #91afd4;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row12_col1 {
  background-color: #7a9fcc;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row12_col3, #T_84484_row16_col8, #T_84484_row19_col18 {
  background-color: #efd7dc;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row12_col4, #T_84484_row18_col23 {
  background-color: #5484c0;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row12_col5, #T_84484_row15_col2 {
  background-color: #edcfd5;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row12_col13 {
  background-color: #c8d5e5;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row12_col20, #T_84484_row15_col3, #T_84484_row17_col5, #T_84484_row19_col6 {
  background-color: #f1f1f2;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row12_col22 {
  background-color: #aac0dc;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row12_col23, #T_84484_row19_col4 {
  background-color: #497dbc;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row13_col0, #T_84484_row17_col11, #T_84484_row18_col20 {
  background-color: #bacbe1;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row13_col2 {
  background-color: #e7a5b2;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row13_col11 {
  background-color: #b9cae0;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row13_col16 {
  background-color: #db546f;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row13_col24, #T_84484_row14_col4, #T_84484_row15_col1 {
  background-color: #5e8bc3;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row14_col7 {
  background-color: #6b94c7;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row14_col14, #T_84484_row15_col16 {
  background-color: #e8abb7;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row14_col17 {
  background-color: #e7a4b1;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row14_col22 {
  background-color: #99b4d6;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row15_col0, #T_84484_row15_col7, #T_84484_row19_col12 {
  background-color: #5786c1;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row15_col11 {
  background-color: #9bb6d7;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row15_col12, #T_84484_row17_col1 {
  background-color: #739aca;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row15_col13, #T_84484_row16_col11 {
  background-color: #b1c5de;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row15_col22 {
  background-color: #92b0d4;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row16_col0 {
  background-color: #6892c6;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row16_col3, #T_84484_row17_col19 {
  background-color: #eeeff2;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row16_col5 {
  background-color: #e0e6ed;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row16_col12 {
  background-color: #4b7ebd;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row16_col20, #T_84484_row19_col11 {
  background-color: #bdcde2;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row16_col24 {
  background-color: #5a88c2;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row17_col9 {
  background-color: #84a5cf;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row17_col12 {
  background-color: #5f8cc3;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row18_col3 {
  background-color: #e8aeba;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row18_col12 {
  background-color: #4c7ebd;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row18_col15 {
  background-color: #efd9dd;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row18_col22, #T_84484_row19_col22 {
  background-color: #9db7d7;
  color: #000000;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row18_col24 {
  background-color: #89a9d1;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row19_col1 {
  background-color: #5b89c2;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
#T_84484_row19_col24 {
  background-color: #88a8d0;
  color: #f1f1f1;
  max-width: 80px;
  font-size: 1pt;
}
</style>
<table id=""T_84484"">
<caption>Hover to magnify</caption>
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_84484_level0_col0"">0</th>
<th class=""col_heading level0 col1"" id=""T_84484_level0_col1"">1</th>
<th class=""col_heading level0 col2"" id=""T_84484_level0_col2"">2</th>
<th class=""col_heading level0 col3"" id=""T_84484_level0_col3"">3</th>
<th class=""col_heading level0 col4"" id=""T_84484_level0_col4"">4</th>
<th class=""col_heading level0 col5"" id=""T_84484_level0_col5"">5</th>
<th class=""col_heading level0 col6"" id=""T_84484_level0_col6"">6</th>
<th class=""col_heading level0 col7"" id=""T_84484_level0_col7"">7</th>
<th class=""col_heading level0 col8"" id=""T_84484_level0_col8"">8</th>
<th class=""col_heading level0 col9"" id=""T_84484_level0_col9"">9</th>
<th class=""col_heading level0 col10"" id=""T_84484_level0_col10"">10</th>
<th class=""col_heading level0 col11"" id=""T_84484_level0_col11"">11</th>
<th class=""col_heading level0 col12"" id=""T_84484_level0_col12"">12</th>
<th class=""col_heading level0 col13"" id=""T_84484_level0_col13"">13</th>
<th class=""col_heading level0 col14"" id=""T_84484_level0_col14"">14</th>
<th class=""col_heading level0 col15"" id=""T_84484_level0_col15"">15</th>
<th class=""col_heading level0 col16"" id=""T_84484_level0_col16"">16</th>
<th class=""col_heading level0 col17"" id=""T_84484_level0_col17"">17</th>
<th class=""col_heading level0 col18"" id=""T_84484_level0_col18"">18</th>
<th class=""col_heading level0 col19"" id=""T_84484_level0_col19"">19</th>
<th class=""col_heading level0 col20"" id=""T_84484_level0_col20"">20</th>
<th class=""col_heading level0 col21"" id=""T_84484_level0_col21"">21</th>
<th class=""col_heading level0 col22"" id=""T_84484_level0_col22"">22</th>
<th class=""col_heading level0 col23"" id=""T_84484_level0_col23"">23</th>
<th class=""col_heading level0 col24"" id=""T_84484_level0_col24"">24</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_84484_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_84484_row0_col0"">0.23</td>
<td class=""data row0 col1"" id=""T_84484_row0_col1"">1.03</td>
<td class=""data row0 col2"" id=""T_84484_row0_col2"">-0.84</td>
<td class=""data row0 col3"" id=""T_84484_row0_col3"">-0.59</td>
<td class=""data row0 col4"" id=""T_84484_row0_col4"">-0.96</td>
<td class=""data row0 col5"" id=""T_84484_row0_col5"">-0.22</td>
<td class=""data row0 col6"" id=""T_84484_row0_col6"">-0.62</td>
<td class=""data row0 col7"" id=""T_84484_row0_col7"">1.84</td>
<td class=""data row0 col8"" id=""T_84484_row0_col8"">-2.05</td>
<td class=""data row0 col9"" id=""T_84484_row0_col9"">0.87</td>
<td class=""data row0 col10"" id=""T_84484_row0_col10"">-0.92</td>
<td class=""data row0 col11"" id=""T_84484_row0_col11"">-0.23</td>
<td class=""data row0 col12"" id=""T_84484_row0_col12"">2.15</td>
<td class=""data row0 col13"" id=""T_84484_row0_col13"">-1.33</td>
<td class=""data row0 col14"" id=""T_84484_row0_col14"">0.08</td>
<td class=""data row0 col15"" id=""T_84484_row0_col15"">-1.25</td>
<td class=""data row0 col16"" id=""T_84484_row0_col16"">1.20</td>
<td class=""data row0 col17"" id=""T_84484_row0_col17"">-1.05</td>
<td class=""data row0 col18"" id=""T_84484_row0_col18"">1.06</td>
<td class=""data row0 col19"" id=""T_84484_row0_col19"">-0.42</td>
<td class=""data row0 col20"" id=""T_84484_row0_col20"">2.29</td>
<td class=""data row0 col21"" id=""T_84484_row0_col21"">-2.59</td>
<td class=""data row0 col22"" id=""T_84484_row0_col22"">2.82</td>
<td class=""data row0 col23"" id=""T_84484_row0_col23"">0.68</td>
<td class=""data row0 col24"" id=""T_84484_row0_col24"">-1.58</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_84484_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_84484_row1_col0"">-1.75</td>
<td class=""data row1 col1"" id=""T_84484_row1_col1"">1.56</td>
<td class=""data row1 col2"" id=""T_84484_row1_col2"">-1.13</td>
<td class=""data row1 col3"" id=""T_84484_row1_col3"">-1.10</td>
<td class=""data row1 col4"" id=""T_84484_row1_col4"">1.03</td>
<td class=""data row1 col5"" id=""T_84484_row1_col5"">0.00</td>
<td class=""data row1 col6"" id=""T_84484_row1_col6"">-2.46</td>
<td class=""data row1 col7"" id=""T_84484_row1_col7"">3.45</td>
<td class=""data row1 col8"" id=""T_84484_row1_col8"">-1.66</td>
<td class=""data row1 col9"" id=""T_84484_row1_col9"">1.27</td>
<td class=""data row1 col10"" id=""T_84484_row1_col10"">-0.52</td>
<td class=""data row1 col11"" id=""T_84484_row1_col11"">-0.02</td>
<td class=""data row1 col12"" id=""T_84484_row1_col12"">1.52</td>
<td class=""data row1 col13"" id=""T_84484_row1_col13"">-1.09</td>
<td class=""data row1 col14"" id=""T_84484_row1_col14"">-1.86</td>
<td class=""data row1 col15"" id=""T_84484_row1_col15"">-1.13</td>
<td class=""data row1 col16"" id=""T_84484_row1_col16"">-0.68</td>
<td class=""data row1 col17"" id=""T_84484_row1_col17"">-0.81</td>
<td class=""data row1 col18"" id=""T_84484_row1_col18"">0.35</td>
<td class=""data row1 col19"" id=""T_84484_row1_col19"">-0.06</td>
<td class=""data row1 col20"" id=""T_84484_row1_col20"">1.79</td>
<td class=""data row1 col21"" id=""T_84484_row1_col21"">-2.82</td>
<td class=""data row1 col22"" id=""T_84484_row1_col22"">2.26</td>
<td class=""data row1 col23"" id=""T_84484_row1_col23"">0.78</td>
<td class=""data row1 col24"" id=""T_84484_row1_col24"">0.44</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_84484_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_84484_row2_col0"">-0.65</td>
<td class=""data row2 col1"" id=""T_84484_row2_col1"">3.22</td>
<td class=""data row2 col2"" id=""T_84484_row2_col2"">-1.76</td>
<td class=""data row2 col3"" id=""T_84484_row2_col3"">0.52</td>
<td class=""data row2 col4"" id=""T_84484_row2_col4"">2.20</td>
<td class=""data row2 col5"" id=""T_84484_row2_col5"">-0.37</td>
<td class=""data row2 col6"" id=""T_84484_row2_col6"">-3.00</td>
<td class=""data row2 col7"" id=""T_84484_row2_col7"">3.73</td>
<td class=""data row2 col8"" id=""T_84484_row2_col8"">-1.87</td>
<td class=""data row2 col9"" id=""T_84484_row2_col9"">2.46</td>
<td class=""data row2 col10"" id=""T_84484_row2_col10"">0.21</td>
<td class=""data row2 col11"" id=""T_84484_row2_col11"">-0.24</td>
<td class=""data row2 col12"" id=""T_84484_row2_col12"">-0.10</td>
<td class=""data row2 col13"" id=""T_84484_row2_col13"">-0.78</td>
<td class=""data row2 col14"" id=""T_84484_row2_col14"">-3.02</td>
<td class=""data row2 col15"" id=""T_84484_row2_col15"">-0.82</td>
<td class=""data row2 col16"" id=""T_84484_row2_col16"">-0.21</td>
<td class=""data row2 col17"" id=""T_84484_row2_col17"">-0.23</td>
<td class=""data row2 col18"" id=""T_84484_row2_col18"">0.86</td>
<td class=""data row2 col19"" id=""T_84484_row2_col19"">-0.68</td>
<td class=""data row2 col20"" id=""T_84484_row2_col20"">1.45</td>
<td class=""data row2 col21"" id=""T_84484_row2_col21"">-4.89</td>
<td class=""data row2 col22"" id=""T_84484_row2_col22"">3.03</td>
<td class=""data row2 col23"" id=""T_84484_row2_col23"">1.91</td>
<td class=""data row2 col24"" id=""T_84484_row2_col24"">0.61</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_84484_level0_row3"">3</th>
<td class=""data row3 col0"" id=""T_84484_row3_col0"">-1.62</td>
<td class=""data row3 col1"" id=""T_84484_row3_col1"">3.71</td>
<td class=""data row3 col2"" id=""T_84484_row3_col2"">-2.31</td>
<td class=""data row3 col3"" id=""T_84484_row3_col3"">0.43</td>
<td class=""data row3 col4"" id=""T_84484_row3_col4"">4.17</td>
<td class=""data row3 col5"" id=""T_84484_row3_col5"">-0.43</td>
<td class=""data row3 col6"" id=""T_84484_row3_col6"">-3.86</td>
<td class=""data row3 col7"" id=""T_84484_row3_col7"">4.16</td>
<td class=""data row3 col8"" id=""T_84484_row3_col8"">-2.15</td>
<td class=""data row3 col9"" id=""T_84484_row3_col9"">1.08</td>
<td class=""data row3 col10"" id=""T_84484_row3_col10"">0.12</td>
<td class=""data row3 col11"" id=""T_84484_row3_col11"">0.60</td>
<td class=""data row3 col12"" id=""T_84484_row3_col12"">-0.89</td>
<td class=""data row3 col13"" id=""T_84484_row3_col13"">0.27</td>
<td class=""data row3 col14"" id=""T_84484_row3_col14"">-3.67</td>
<td class=""data row3 col15"" id=""T_84484_row3_col15"">-2.71</td>
<td class=""data row3 col16"" id=""T_84484_row3_col16"">-0.31</td>
<td class=""data row3 col17"" id=""T_84484_row3_col17"">-1.59</td>
<td class=""data row3 col18"" id=""T_84484_row3_col18"">1.35</td>
<td class=""data row3 col19"" id=""T_84484_row3_col19"">-1.83</td>
<td class=""data row3 col20"" id=""T_84484_row3_col20"">0.91</td>
<td class=""data row3 col21"" id=""T_84484_row3_col21"">-5.80</td>
<td class=""data row3 col22"" id=""T_84484_row3_col22"">2.81</td>
<td class=""data row3 col23"" id=""T_84484_row3_col23"">2.11</td>
<td class=""data row3 col24"" id=""T_84484_row3_col24"">0.28</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_84484_level0_row4"">4</th>
<td class=""data row4 col0"" id=""T_84484_row4_col0"">-3.35</td>
<td class=""data row4 col1"" id=""T_84484_row4_col1"">4.48</td>
<td class=""data row4 col2"" id=""T_84484_row4_col2"">-1.86</td>
<td class=""data row4 col3"" id=""T_84484_row4_col3"">-1.70</td>
<td class=""data row4 col4"" id=""T_84484_row4_col4"">5.19</td>
<td class=""data row4 col5"" id=""T_84484_row4_col5"">-1.02</td>
<td class=""data row4 col6"" id=""T_84484_row4_col6"">-3.81</td>
<td class=""data row4 col7"" id=""T_84484_row4_col7"">4.72</td>
<td class=""data row4 col8"" id=""T_84484_row4_col8"">-0.72</td>
<td class=""data row4 col9"" id=""T_84484_row4_col9"">1.08</td>
<td class=""data row4 col10"" id=""T_84484_row4_col10"">-0.18</td>
<td class=""data row4 col11"" id=""T_84484_row4_col11"">0.83</td>
<td class=""data row4 col12"" id=""T_84484_row4_col12"">-0.22</td>
<td class=""data row4 col13"" id=""T_84484_row4_col13"">-1.08</td>
<td class=""data row4 col14"" id=""T_84484_row4_col14"">-4.27</td>
<td class=""data row4 col15"" id=""T_84484_row4_col15"">-2.88</td>
<td class=""data row4 col16"" id=""T_84484_row4_col16"">-0.97</td>
<td class=""data row4 col17"" id=""T_84484_row4_col17"">-1.78</td>
<td class=""data row4 col18"" id=""T_84484_row4_col18"">1.53</td>
<td class=""data row4 col19"" id=""T_84484_row4_col19"">-1.80</td>
<td class=""data row4 col20"" id=""T_84484_row4_col20"">2.21</td>
<td class=""data row4 col21"" id=""T_84484_row4_col21"">-6.34</td>
<td class=""data row4 col22"" id=""T_84484_row4_col22"">3.34</td>
<td class=""data row4 col23"" id=""T_84484_row4_col23"">2.49</td>
<td class=""data row4 col24"" id=""T_84484_row4_col24"">2.09</td>
</tr>
<tr>
<th class=""row_heading level0 row5"" id=""T_84484_level0_row5"">5</th>
<td class=""data row5 col0"" id=""T_84484_row5_col0"">-0.84</td>
<td class=""data row5 col1"" id=""T_84484_row5_col1"">4.23</td>
<td class=""data row5 col2"" id=""T_84484_row5_col2"">-1.65</td>
<td class=""data row5 col3"" id=""T_84484_row5_col3"">-2.00</td>
<td class=""data row5 col4"" id=""T_84484_row5_col4"">5.34</td>
<td class=""data row5 col5"" id=""T_84484_row5_col5"">-0.99</td>
<td class=""data row5 col6"" id=""T_84484_row5_col6"">-4.13</td>
<td class=""data row5 col7"" id=""T_84484_row5_col7"">3.94</td>
<td class=""data row5 col8"" id=""T_84484_row5_col8"">-1.06</td>
<td class=""data row5 col9"" id=""T_84484_row5_col9"">-0.94</td>
<td class=""data row5 col10"" id=""T_84484_row5_col10"">1.24</td>
<td class=""data row5 col11"" id=""T_84484_row5_col11"">0.09</td>
<td class=""data row5 col12"" id=""T_84484_row5_col12"">-1.78</td>
<td class=""data row5 col13"" id=""T_84484_row5_col13"">-0.11</td>
<td class=""data row5 col14"" id=""T_84484_row5_col14"">-4.45</td>
<td class=""data row5 col15"" id=""T_84484_row5_col15"">-0.85</td>
<td class=""data row5 col16"" id=""T_84484_row5_col16"">-2.06</td>
<td class=""data row5 col17"" id=""T_84484_row5_col17"">-1.35</td>
<td class=""data row5 col18"" id=""T_84484_row5_col18"">0.80</td>
<td class=""data row5 col19"" id=""T_84484_row5_col19"">-1.63</td>
<td class=""data row5 col20"" id=""T_84484_row5_col20"">1.54</td>
<td class=""data row5 col21"" id=""T_84484_row5_col21"">-6.51</td>
<td class=""data row5 col22"" id=""T_84484_row5_col22"">2.80</td>
<td class=""data row5 col23"" id=""T_84484_row5_col23"">2.14</td>
<td class=""data row5 col24"" id=""T_84484_row5_col24"">3.77</td>
</tr>
<tr>
<th class=""row_heading level0 row6"" id=""T_84484_level0_row6"">6</th>
<td class=""data row6 col0"" id=""T_84484_row6_col0"">-0.74</td>
<td class=""data row6 col1"" id=""T_84484_row6_col1"">5.35</td>
<td class=""data row6 col2"" id=""T_84484_row6_col2"">-2.11</td>
<td class=""data row6 col3"" id=""T_84484_row6_col3"">-1.13</td>
<td class=""data row6 col4"" id=""T_84484_row6_col4"">4.20</td>
<td class=""data row6 col5"" id=""T_84484_row6_col5"">-1.85</td>
<td class=""data row6 col6"" id=""T_84484_row6_col6"">-3.20</td>
<td class=""data row6 col7"" id=""T_84484_row6_col7"">3.76</td>
<td class=""data row6 col8"" id=""T_84484_row6_col8"">-3.22</td>
<td class=""data row6 col9"" id=""T_84484_row6_col9"">-1.23</td>
<td class=""data row6 col10"" id=""T_84484_row6_col10"">0.34</td>
<td class=""data row6 col11"" id=""T_84484_row6_col11"">0.57</td>
<td class=""data row6 col12"" id=""T_84484_row6_col12"">-1.82</td>
<td class=""data row6 col13"" id=""T_84484_row6_col13"">0.54</td>
<td class=""data row6 col14"" id=""T_84484_row6_col14"">-4.43</td>
<td class=""data row6 col15"" id=""T_84484_row6_col15"">-1.83</td>
<td class=""data row6 col16"" id=""T_84484_row6_col16"">-4.03</td>
<td class=""data row6 col17"" id=""T_84484_row6_col17"">-2.62</td>
<td class=""data row6 col18"" id=""T_84484_row6_col18"">-0.20</td>
<td class=""data row6 col19"" id=""T_84484_row6_col19"">-4.68</td>
<td class=""data row6 col20"" id=""T_84484_row6_col20"">1.93</td>
<td class=""data row6 col21"" id=""T_84484_row6_col21"">-8.46</td>
<td class=""data row6 col22"" id=""T_84484_row6_col22"">3.34</td>
<td class=""data row6 col23"" id=""T_84484_row6_col23"">2.52</td>
<td class=""data row6 col24"" id=""T_84484_row6_col24"">5.81</td>
</tr>
<tr>
<th class=""row_heading level0 row7"" id=""T_84484_level0_row7"">7</th>
<td class=""data row7 col0"" id=""T_84484_row7_col0"">-0.44</td>
<td class=""data row7 col1"" id=""T_84484_row7_col1"">4.69</td>
<td class=""data row7 col2"" id=""T_84484_row7_col2"">-2.30</td>
<td class=""data row7 col3"" id=""T_84484_row7_col3"">-0.21</td>
<td class=""data row7 col4"" id=""T_84484_row7_col4"">5.93</td>
<td class=""data row7 col5"" id=""T_84484_row7_col5"">-2.63</td>
<td class=""data row7 col6"" id=""T_84484_row7_col6"">-1.83</td>
<td class=""data row7 col7"" id=""T_84484_row7_col7"">5.46</td>
<td class=""data row7 col8"" id=""T_84484_row7_col8"">-4.50</td>
<td class=""data row7 col9"" id=""T_84484_row7_col9"">-3.16</td>
<td class=""data row7 col10"" id=""T_84484_row7_col10"">-1.73</td>
<td class=""data row7 col11"" id=""T_84484_row7_col11"">0.18</td>
<td class=""data row7 col12"" id=""T_84484_row7_col12"">0.11</td>
<td class=""data row7 col13"" id=""T_84484_row7_col13"">0.04</td>
<td class=""data row7 col14"" id=""T_84484_row7_col14"">-5.99</td>
<td class=""data row7 col15"" id=""T_84484_row7_col15"">-0.45</td>
<td class=""data row7 col16"" id=""T_84484_row7_col16"">-6.20</td>
<td class=""data row7 col17"" id=""T_84484_row7_col17"">-3.89</td>
<td class=""data row7 col18"" id=""T_84484_row7_col18"">0.71</td>
<td class=""data row7 col19"" id=""T_84484_row7_col19"">-3.95</td>
<td class=""data row7 col20"" id=""T_84484_row7_col20"">0.67</td>
<td class=""data row7 col21"" id=""T_84484_row7_col21"">-7.26</td>
<td class=""data row7 col22"" id=""T_84484_row7_col22"">2.97</td>
<td class=""data row7 col23"" id=""T_84484_row7_col23"">3.39</td>
<td class=""data row7 col24"" id=""T_84484_row7_col24"">6.66</td>
</tr>
<tr>
<th class=""row_heading level0 row8"" id=""T_84484_level0_row8"">8</th>
<td class=""data row8 col0"" id=""T_84484_row8_col0"">0.92</td>
<td class=""data row8 col1"" id=""T_84484_row8_col1"">5.80</td>
<td class=""data row8 col2"" id=""T_84484_row8_col2"">-3.33</td>
<td class=""data row8 col3"" id=""T_84484_row8_col3"">-0.65</td>
<td class=""data row8 col4"" id=""T_84484_row8_col4"">5.99</td>
<td class=""data row8 col5"" id=""T_84484_row8_col5"">-3.19</td>
<td class=""data row8 col6"" id=""T_84484_row8_col6"">-1.83</td>
<td class=""data row8 col7"" id=""T_84484_row8_col7"">5.63</td>
<td class=""data row8 col8"" id=""T_84484_row8_col8"">-3.53</td>
<td class=""data row8 col9"" id=""T_84484_row8_col9"">-1.30</td>
<td class=""data row8 col10"" id=""T_84484_row8_col10"">-1.61</td>
<td class=""data row8 col11"" id=""T_84484_row8_col11"">0.82</td>
<td class=""data row8 col12"" id=""T_84484_row8_col12"">-2.45</td>
<td class=""data row8 col13"" id=""T_84484_row8_col13"">-0.40</td>
<td class=""data row8 col14"" id=""T_84484_row8_col14"">-6.06</td>
<td class=""data row8 col15"" id=""T_84484_row8_col15"">-0.52</td>
<td class=""data row8 col16"" id=""T_84484_row8_col16"">-6.60</td>
<td class=""data row8 col17"" id=""T_84484_row8_col17"">-3.48</td>
<td class=""data row8 col18"" id=""T_84484_row8_col18"">-0.04</td>
<td class=""data row8 col19"" id=""T_84484_row8_col19"">-4.60</td>
<td class=""data row8 col20"" id=""T_84484_row8_col20"">0.51</td>
<td class=""data row8 col21"" id=""T_84484_row8_col21"">-5.85</td>
<td class=""data row8 col22"" id=""T_84484_row8_col22"">3.23</td>
<td class=""data row8 col23"" id=""T_84484_row8_col23"">2.40</td>
<td class=""data row8 col24"" id=""T_84484_row8_col24"">5.08</td>
</tr>
<tr>
<th class=""row_heading level0 row9"" id=""T_84484_level0_row9"">9</th>
<td class=""data row9 col0"" id=""T_84484_row9_col0"">0.38</td>
<td class=""data row9 col1"" id=""T_84484_row9_col1"">5.54</td>
<td class=""data row9 col2"" id=""T_84484_row9_col2"">-4.49</td>
<td class=""data row9 col3"" id=""T_84484_row9_col3"">-0.80</td>
<td class=""data row9 col4"" id=""T_84484_row9_col4"">7.05</td>
<td class=""data row9 col5"" id=""T_84484_row9_col5"">-2.64</td>
<td class=""data row9 col6"" id=""T_84484_row9_col6"">-0.44</td>
<td class=""data row9 col7"" id=""T_84484_row9_col7"">5.35</td>
<td class=""data row9 col8"" id=""T_84484_row9_col8"">-1.96</td>
<td class=""data row9 col9"" id=""T_84484_row9_col9"">-0.33</td>
<td class=""data row9 col10"" id=""T_84484_row9_col10"">-0.80</td>
<td class=""data row9 col11"" id=""T_84484_row9_col11"">0.26</td>
<td class=""data row9 col12"" id=""T_84484_row9_col12"">-3.37</td>
<td class=""data row9 col13"" id=""T_84484_row9_col13"">-0.82</td>
<td class=""data row9 col14"" id=""T_84484_row9_col14"">-6.05</td>
<td class=""data row9 col15"" id=""T_84484_row9_col15"">-2.61</td>
<td class=""data row9 col16"" id=""T_84484_row9_col16"">-8.45</td>
<td class=""data row9 col17"" id=""T_84484_row9_col17"">-4.45</td>
<td class=""data row9 col18"" id=""T_84484_row9_col18"">0.41</td>
<td class=""data row9 col19"" id=""T_84484_row9_col19"">-4.71</td>
<td class=""data row9 col20"" id=""T_84484_row9_col20"">1.89</td>
<td class=""data row9 col21"" id=""T_84484_row9_col21"">-6.93</td>
<td class=""data row9 col22"" id=""T_84484_row9_col22"">2.14</td>
<td class=""data row9 col23"" id=""T_84484_row9_col23"">3.00</td>
<td class=""data row9 col24"" id=""T_84484_row9_col24"">5.16</td>
</tr>
<tr>
<th class=""row_heading level0 row10"" id=""T_84484_level0_row10"">10</th>
<td class=""data row10 col0"" id=""T_84484_row10_col0"">2.06</td>
<td class=""data row10 col1"" id=""T_84484_row10_col1"">5.84</td>
<td class=""data row10 col2"" id=""T_84484_row10_col2"">-3.90</td>
<td class=""data row10 col3"" id=""T_84484_row10_col3"">-0.98</td>
<td class=""data row10 col4"" id=""T_84484_row10_col4"">7.78</td>
<td class=""data row10 col5"" id=""T_84484_row10_col5"">-2.49</td>
<td class=""data row10 col6"" id=""T_84484_row10_col6"">-0.59</td>
<td class=""data row10 col7"" id=""T_84484_row10_col7"">5.59</td>
<td class=""data row10 col8"" id=""T_84484_row10_col8"">-2.22</td>
<td class=""data row10 col9"" id=""T_84484_row10_col9"">-0.71</td>
<td class=""data row10 col10"" id=""T_84484_row10_col10"">-0.46</td>
<td class=""data row10 col11"" id=""T_84484_row10_col11"">1.80</td>
<td class=""data row10 col12"" id=""T_84484_row10_col12"">-2.79</td>
<td class=""data row10 col13"" id=""T_84484_row10_col13"">0.48</td>
<td class=""data row10 col14"" id=""T_84484_row10_col14"">-5.97</td>
<td class=""data row10 col15"" id=""T_84484_row10_col15"">-3.44</td>
<td class=""data row10 col16"" id=""T_84484_row10_col16"">-7.77</td>
<td class=""data row10 col17"" id=""T_84484_row10_col17"">-5.49</td>
<td class=""data row10 col18"" id=""T_84484_row10_col18"">-0.70</td>
<td class=""data row10 col19"" id=""T_84484_row10_col19"">-4.61</td>
<td class=""data row10 col20"" id=""T_84484_row10_col20"">-0.52</td>
<td class=""data row10 col21"" id=""T_84484_row10_col21"">-7.72</td>
<td class=""data row10 col22"" id=""T_84484_row10_col22"">1.54</td>
<td class=""data row10 col23"" id=""T_84484_row10_col23"">5.02</td>
<td class=""data row10 col24"" id=""T_84484_row10_col24"">5.81</td>
</tr>
<tr>
<th class=""row_heading level0 row11"" id=""T_84484_level0_row11"">11</th>
<td class=""data row11 col0"" id=""T_84484_row11_col0"">1.86</td>
<td class=""data row11 col1"" id=""T_84484_row11_col1"">4.47</td>
<td class=""data row11 col2"" id=""T_84484_row11_col2"">-2.17</td>
<td class=""data row11 col3"" id=""T_84484_row11_col3"">-1.38</td>
<td class=""data row11 col4"" id=""T_84484_row11_col4"">5.90</td>
<td class=""data row11 col5"" id=""T_84484_row11_col5"">-0.49</td>
<td class=""data row11 col6"" id=""T_84484_row11_col6"">0.02</td>
<td class=""data row11 col7"" id=""T_84484_row11_col7"">5.78</td>
<td class=""data row11 col8"" id=""T_84484_row11_col8"">-1.04</td>
<td class=""data row11 col9"" id=""T_84484_row11_col9"">-0.60</td>
<td class=""data row11 col10"" id=""T_84484_row11_col10"">0.49</td>
<td class=""data row11 col11"" id=""T_84484_row11_col11"">1.96</td>
<td class=""data row11 col12"" id=""T_84484_row11_col12"">-1.47</td>
<td class=""data row11 col13"" id=""T_84484_row11_col13"">1.88</td>
<td class=""data row11 col14"" id=""T_84484_row11_col14"">-5.92</td>
<td class=""data row11 col15"" id=""T_84484_row11_col15"">-4.55</td>
<td class=""data row11 col16"" id=""T_84484_row11_col16"">-8.15</td>
<td class=""data row11 col17"" id=""T_84484_row11_col17"">-3.42</td>
<td class=""data row11 col18"" id=""T_84484_row11_col18"">-2.24</td>
<td class=""data row11 col19"" id=""T_84484_row11_col19"">-4.33</td>
<td class=""data row11 col20"" id=""T_84484_row11_col20"">-1.17</td>
<td class=""data row11 col21"" id=""T_84484_row11_col21"">-7.90</td>
<td class=""data row11 col22"" id=""T_84484_row11_col22"">1.36</td>
<td class=""data row11 col23"" id=""T_84484_row11_col23"">5.31</td>
<td class=""data row11 col24"" id=""T_84484_row11_col24"">5.83</td>
</tr>
<tr>
<th class=""row_heading level0 row12"" id=""T_84484_level0_row12"">12</th>
<td class=""data row12 col0"" id=""T_84484_row12_col0"">3.19</td>
<td class=""data row12 col1"" id=""T_84484_row12_col1"">4.22</td>
<td class=""data row12 col2"" id=""T_84484_row12_col2"">-3.06</td>
<td class=""data row12 col3"" id=""T_84484_row12_col3"">-2.27</td>
<td class=""data row12 col4"" id=""T_84484_row12_col4"">5.93</td>
<td class=""data row12 col5"" id=""T_84484_row12_col5"">-2.64</td>
<td class=""data row12 col6"" id=""T_84484_row12_col6"">0.33</td>
<td class=""data row12 col7"" id=""T_84484_row12_col7"">6.72</td>
<td class=""data row12 col8"" id=""T_84484_row12_col8"">-2.84</td>
<td class=""data row12 col9"" id=""T_84484_row12_col9"">-0.20</td>
<td class=""data row12 col10"" id=""T_84484_row12_col10"">1.89</td>
<td class=""data row12 col11"" id=""T_84484_row12_col11"">2.63</td>
<td class=""data row12 col12"" id=""T_84484_row12_col12"">-1.53</td>
<td class=""data row12 col13"" id=""T_84484_row12_col13"">0.75</td>
<td class=""data row12 col14"" id=""T_84484_row12_col14"">-5.27</td>
<td class=""data row12 col15"" id=""T_84484_row12_col15"">-4.53</td>
<td class=""data row12 col16"" id=""T_84484_row12_col16"">-7.57</td>
<td class=""data row12 col17"" id=""T_84484_row12_col17"">-2.85</td>
<td class=""data row12 col18"" id=""T_84484_row12_col18"">-2.17</td>
<td class=""data row12 col19"" id=""T_84484_row12_col19"">-4.78</td>
<td class=""data row12 col20"" id=""T_84484_row12_col20"">-1.13</td>
<td class=""data row12 col21"" id=""T_84484_row12_col21"">-8.99</td>
<td class=""data row12 col22"" id=""T_84484_row12_col22"">2.11</td>
<td class=""data row12 col23"" id=""T_84484_row12_col23"">6.42</td>
<td class=""data row12 col24"" id=""T_84484_row12_col24"">5.60</td>
</tr>
<tr>
<th class=""row_heading level0 row13"" id=""T_84484_level0_row13"">13</th>
<td class=""data row13 col0"" id=""T_84484_row13_col0"">2.31</td>
<td class=""data row13 col1"" id=""T_84484_row13_col1"">4.45</td>
<td class=""data row13 col2"" id=""T_84484_row13_col2"">-3.87</td>
<td class=""data row13 col3"" id=""T_84484_row13_col3"">-2.05</td>
<td class=""data row13 col4"" id=""T_84484_row13_col4"">6.76</td>
<td class=""data row13 col5"" id=""T_84484_row13_col5"">-3.25</td>
<td class=""data row13 col6"" id=""T_84484_row13_col6"">-2.17</td>
<td class=""data row13 col7"" id=""T_84484_row13_col7"">7.99</td>
<td class=""data row13 col8"" id=""T_84484_row13_col8"">-2.56</td>
<td class=""data row13 col9"" id=""T_84484_row13_col9"">-0.80</td>
<td class=""data row13 col10"" id=""T_84484_row13_col10"">0.71</td>
<td class=""data row13 col11"" id=""T_84484_row13_col11"">2.33</td>
<td class=""data row13 col12"" id=""T_84484_row13_col12"">-0.16</td>
<td class=""data row13 col13"" id=""T_84484_row13_col13"">-0.46</td>
<td class=""data row13 col14"" id=""T_84484_row13_col14"">-5.10</td>
<td class=""data row13 col15"" id=""T_84484_row13_col15"">-3.79</td>
<td class=""data row13 col16"" id=""T_84484_row13_col16"">-7.58</td>
<td class=""data row13 col17"" id=""T_84484_row13_col17"">-4.00</td>
<td class=""data row13 col18"" id=""T_84484_row13_col18"">0.33</td>
<td class=""data row13 col19"" id=""T_84484_row13_col19"">-3.67</td>
<td class=""data row13 col20"" id=""T_84484_row13_col20"">-1.05</td>
<td class=""data row13 col21"" id=""T_84484_row13_col21"">-8.71</td>
<td class=""data row13 col22"" id=""T_84484_row13_col22"">2.47</td>
<td class=""data row13 col23"" id=""T_84484_row13_col23"">5.87</td>
<td class=""data row13 col24"" id=""T_84484_row13_col24"">6.71</td>
</tr>
<tr>
<th class=""row_heading level0 row14"" id=""T_84484_level0_row14"">14</th>
<td class=""data row14 col0"" id=""T_84484_row14_col0"">3.78</td>
<td class=""data row14 col1"" id=""T_84484_row14_col1"">4.33</td>
<td class=""data row14 col2"" id=""T_84484_row14_col2"">-3.88</td>
<td class=""data row14 col3"" id=""T_84484_row14_col3"">-1.58</td>
<td class=""data row14 col4"" id=""T_84484_row14_col4"">6.22</td>
<td class=""data row14 col5"" id=""T_84484_row14_col5"">-3.23</td>
<td class=""data row14 col6"" id=""T_84484_row14_col6"">-1.46</td>
<td class=""data row14 col7"" id=""T_84484_row14_col7"">5.57</td>
<td class=""data row14 col8"" id=""T_84484_row14_col8"">-2.93</td>
<td class=""data row14 col9"" id=""T_84484_row14_col9"">-0.33</td>
<td class=""data row14 col10"" id=""T_84484_row14_col10"">-0.97</td>
<td class=""data row14 col11"" id=""T_84484_row14_col11"">1.72</td>
<td class=""data row14 col12"" id=""T_84484_row14_col12"">3.61</td>
<td class=""data row14 col13"" id=""T_84484_row14_col13"">0.29</td>
<td class=""data row14 col14"" id=""T_84484_row14_col14"">-4.21</td>
<td class=""data row14 col15"" id=""T_84484_row14_col15"">-4.10</td>
<td class=""data row14 col16"" id=""T_84484_row14_col16"">-6.68</td>
<td class=""data row14 col17"" id=""T_84484_row14_col17"">-4.50</td>
<td class=""data row14 col18"" id=""T_84484_row14_col18"">-2.19</td>
<td class=""data row14 col19"" id=""T_84484_row14_col19"">-2.43</td>
<td class=""data row14 col20"" id=""T_84484_row14_col20"">-1.64</td>
<td class=""data row14 col21"" id=""T_84484_row14_col21"">-9.36</td>
<td class=""data row14 col22"" id=""T_84484_row14_col22"">3.36</td>
<td class=""data row14 col23"" id=""T_84484_row14_col23"">6.11</td>
<td class=""data row14 col24"" id=""T_84484_row14_col24"">7.53</td>
</tr>
<tr>
<th class=""row_heading level0 row15"" id=""T_84484_level0_row15"">15</th>
<td class=""data row15 col0"" id=""T_84484_row15_col0"">5.64</td>
<td class=""data row15 col1"" id=""T_84484_row15_col1"">5.31</td>
<td class=""data row15 col2"" id=""T_84484_row15_col2"">-3.98</td>
<td class=""data row15 col3"" id=""T_84484_row15_col3"">-2.26</td>
<td class=""data row15 col4"" id=""T_84484_row15_col4"">5.91</td>
<td class=""data row15 col5"" id=""T_84484_row15_col5"">-3.30</td>
<td class=""data row15 col6"" id=""T_84484_row15_col6"">-1.03</td>
<td class=""data row15 col7"" id=""T_84484_row15_col7"">5.68</td>
<td class=""data row15 col8"" id=""T_84484_row15_col8"">-3.06</td>
<td class=""data row15 col9"" id=""T_84484_row15_col9"">-0.33</td>
<td class=""data row15 col10"" id=""T_84484_row15_col10"">-1.16</td>
<td class=""data row15 col11"" id=""T_84484_row15_col11"">2.19</td>
<td class=""data row15 col12"" id=""T_84484_row15_col12"">4.20</td>
<td class=""data row15 col13"" id=""T_84484_row15_col13"">1.01</td>
<td class=""data row15 col14"" id=""T_84484_row15_col14"">-3.22</td>
<td class=""data row15 col15"" id=""T_84484_row15_col15"">-4.31</td>
<td class=""data row15 col16"" id=""T_84484_row15_col16"">-5.74</td>
<td class=""data row15 col17"" id=""T_84484_row15_col17"">-4.44</td>
<td class=""data row15 col18"" id=""T_84484_row15_col18"">-2.30</td>
<td class=""data row15 col19"" id=""T_84484_row15_col19"">-1.36</td>
<td class=""data row15 col20"" id=""T_84484_row15_col20"">-1.20</td>
<td class=""data row15 col21"" id=""T_84484_row15_col21"">-11.27</td>
<td class=""data row15 col22"" id=""T_84484_row15_col22"">2.59</td>
<td class=""data row15 col23"" id=""T_84484_row15_col23"">6.69</td>
<td class=""data row15 col24"" id=""T_84484_row15_col24"">5.91</td>
</tr>
<tr>
<th class=""row_heading level0 row16"" id=""T_84484_level0_row16"">16</th>
<td class=""data row16 col0"" id=""T_84484_row16_col0"">4.08</td>
<td class=""data row16 col1"" id=""T_84484_row16_col1"">4.34</td>
<td class=""data row16 col2"" id=""T_84484_row16_col2"">-2.44</td>
<td class=""data row16 col3"" id=""T_84484_row16_col3"">-3.30</td>
<td class=""data row16 col4"" id=""T_84484_row16_col4"">6.04</td>
<td class=""data row16 col5"" id=""T_84484_row16_col5"">-2.52</td>
<td class=""data row16 col6"" id=""T_84484_row16_col6"">-0.47</td>
<td class=""data row16 col7"" id=""T_84484_row16_col7"">5.28</td>
<td class=""data row16 col8"" id=""T_84484_row16_col8"">-4.84</td>
<td class=""data row16 col9"" id=""T_84484_row16_col9"">1.58</td>
<td class=""data row16 col10"" id=""T_84484_row16_col10"">0.23</td>
<td class=""data row16 col11"" id=""T_84484_row16_col11"">0.10</td>
<td class=""data row16 col12"" id=""T_84484_row16_col12"">5.79</td>
<td class=""data row16 col13"" id=""T_84484_row16_col13"">1.80</td>
<td class=""data row16 col14"" id=""T_84484_row16_col14"">-3.13</td>
<td class=""data row16 col15"" id=""T_84484_row16_col15"">-3.85</td>
<td class=""data row16 col16"" id=""T_84484_row16_col16"">-5.53</td>
<td class=""data row16 col17"" id=""T_84484_row16_col17"">-2.97</td>
<td class=""data row16 col18"" id=""T_84484_row16_col18"">-2.13</td>
<td class=""data row16 col19"" id=""T_84484_row16_col19"">-1.15</td>
<td class=""data row16 col20"" id=""T_84484_row16_col20"">-0.56</td>
<td class=""data row16 col21"" id=""T_84484_row16_col21"">-13.13</td>
<td class=""data row16 col22"" id=""T_84484_row16_col22"">2.07</td>
<td class=""data row16 col23"" id=""T_84484_row16_col23"">6.16</td>
<td class=""data row16 col24"" id=""T_84484_row16_col24"">4.94</td>
</tr>
<tr>
<th class=""row_heading level0 row17"" id=""T_84484_level0_row17"">17</th>
<td class=""data row17 col0"" id=""T_84484_row17_col0"">5.64</td>
<td class=""data row17 col1"" id=""T_84484_row17_col1"">4.57</td>
<td class=""data row17 col2"" id=""T_84484_row17_col2"">-3.53</td>
<td class=""data row17 col3"" id=""T_84484_row17_col3"">-3.76</td>
<td class=""data row17 col4"" id=""T_84484_row17_col4"">6.58</td>
<td class=""data row17 col5"" id=""T_84484_row17_col5"">-2.58</td>
<td class=""data row17 col6"" id=""T_84484_row17_col6"">-0.75</td>
<td class=""data row17 col7"" id=""T_84484_row17_col7"">6.58</td>
<td class=""data row17 col8"" id=""T_84484_row17_col8"">-4.78</td>
<td class=""data row17 col9"" id=""T_84484_row17_col9"">3.63</td>
<td class=""data row17 col10"" id=""T_84484_row17_col10"">-0.29</td>
<td class=""data row17 col11"" id=""T_84484_row17_col11"">0.56</td>
<td class=""data row17 col12"" id=""T_84484_row17_col12"">5.76</td>
<td class=""data row17 col13"" id=""T_84484_row17_col13"">2.05</td>
<td class=""data row17 col14"" id=""T_84484_row17_col14"">-2.27</td>
<td class=""data row17 col15"" id=""T_84484_row17_col15"">-2.31</td>
<td class=""data row17 col16"" id=""T_84484_row17_col16"">-4.95</td>
<td class=""data row17 col17"" id=""T_84484_row17_col17"">-3.16</td>
<td class=""data row17 col18"" id=""T_84484_row17_col18"">-3.06</td>
<td class=""data row17 col19"" id=""T_84484_row17_col19"">-2.43</td>
<td class=""data row17 col20"" id=""T_84484_row17_col20"">0.84</td>
<td class=""data row17 col21"" id=""T_84484_row17_col21"">-12.57</td>
<td class=""data row17 col22"" id=""T_84484_row17_col22"">3.56</td>
<td class=""data row17 col23"" id=""T_84484_row17_col23"">7.36</td>
<td class=""data row17 col24"" id=""T_84484_row17_col24"">4.70</td>
</tr>
<tr>
<th class=""row_heading level0 row18"" id=""T_84484_level0_row18"">18</th>
<td class=""data row18 col0"" id=""T_84484_row18_col0"">5.99</td>
<td class=""data row18 col1"" id=""T_84484_row18_col1"">5.82</td>
<td class=""data row18 col2"" id=""T_84484_row18_col2"">-2.85</td>
<td class=""data row18 col3"" id=""T_84484_row18_col3"">-4.15</td>
<td class=""data row18 col4"" id=""T_84484_row18_col4"">7.12</td>
<td class=""data row18 col5"" id=""T_84484_row18_col5"">-3.32</td>
<td class=""data row18 col6"" id=""T_84484_row18_col6"">-1.21</td>
<td class=""data row18 col7"" id=""T_84484_row18_col7"">7.93</td>
<td class=""data row18 col8"" id=""T_84484_row18_col8"">-4.85</td>
<td class=""data row18 col9"" id=""T_84484_row18_col9"">1.44</td>
<td class=""data row18 col10"" id=""T_84484_row18_col10"">-0.63</td>
<td class=""data row18 col11"" id=""T_84484_row18_col11"">0.35</td>
<td class=""data row18 col12"" id=""T_84484_row18_col12"">7.47</td>
<td class=""data row18 col13"" id=""T_84484_row18_col13"">0.87</td>
<td class=""data row18 col14"" id=""T_84484_row18_col14"">-1.52</td>
<td class=""data row18 col15"" id=""T_84484_row18_col15"">-2.09</td>
<td class=""data row18 col16"" id=""T_84484_row18_col16"">-4.23</td>
<td class=""data row18 col17"" id=""T_84484_row18_col17"">-2.55</td>
<td class=""data row18 col18"" id=""T_84484_row18_col18"">-2.46</td>
<td class=""data row18 col19"" id=""T_84484_row18_col19"">-2.89</td>
<td class=""data row18 col20"" id=""T_84484_row18_col20"">1.90</td>
<td class=""data row18 col21"" id=""T_84484_row18_col21"">-9.74</td>
<td class=""data row18 col22"" id=""T_84484_row18_col22"">3.43</td>
<td class=""data row18 col23"" id=""T_84484_row18_col23"">7.07</td>
<td class=""data row18 col24"" id=""T_84484_row18_col24"">4.39</td>
</tr>
<tr>
<th class=""row_heading level0 row19"" id=""T_84484_level0_row19"">19</th>
<td class=""data row19 col0"" id=""T_84484_row19_col0"">4.03</td>
<td class=""data row19 col1"" id=""T_84484_row19_col1"">6.23</td>
<td class=""data row19 col2"" id=""T_84484_row19_col2"">-4.10</td>
<td class=""data row19 col3"" id=""T_84484_row19_col3"">-4.11</td>
<td class=""data row19 col4"" id=""T_84484_row19_col4"">7.19</td>
<td class=""data row19 col5"" id=""T_84484_row19_col5"">-4.10</td>
<td class=""data row19 col6"" id=""T_84484_row19_col6"">-1.52</td>
<td class=""data row19 col7"" id=""T_84484_row19_col7"">6.53</td>
<td class=""data row19 col8"" id=""T_84484_row19_col8"">-5.21</td>
<td class=""data row19 col9"" id=""T_84484_row19_col9"">-0.24</td>
<td class=""data row19 col10"" id=""T_84484_row19_col10"">0.01</td>
<td class=""data row19 col11"" id=""T_84484_row19_col11"">1.16</td>
<td class=""data row19 col12"" id=""T_84484_row19_col12"">6.43</td>
<td class=""data row19 col13"" id=""T_84484_row19_col13"">-1.97</td>
<td class=""data row19 col14"" id=""T_84484_row19_col14"">-2.64</td>
<td class=""data row19 col15"" id=""T_84484_row19_col15"">-1.66</td>
<td class=""data row19 col16"" id=""T_84484_row19_col16"">-5.20</td>
<td class=""data row19 col17"" id=""T_84484_row19_col17"">-3.25</td>
<td class=""data row19 col18"" id=""T_84484_row19_col18"">-2.87</td>
<td class=""data row19 col19"" id=""T_84484_row19_col19"">-1.65</td>
<td class=""data row19 col20"" id=""T_84484_row19_col20"">1.64</td>
<td class=""data row19 col21"" id=""T_84484_row19_col21"">-10.66</td>
<td class=""data row19 col22"" id=""T_84484_row19_col22"">2.83</td>
<td class=""data row19 col23"" id=""T_84484_row19_col23"">7.48</td>
<td class=""data row19 col24"" id=""T_84484_row19_col24"">3.94</td>
</tr>
</tbody>
</table></div>
</div>
</section>
<section id=""Sticky-Headers"">
<h3>Sticky Headers<a class=""headerlink"" href=""#Sticky-Headers"" title=""Link to this heading"">#</a></h3>
<p>If you display a large matrix or DataFrame in a notebook, but you want to always see the column and row headers you can use the <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.set_sticky.html""><span class=""doc"">.set_sticky</span></a> method which manipulates the table styles CSS.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[65]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">bigdf</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">(</span><span class=""n"">np</span><span class=""o"">.</span><span class=""n"">random</span><span class=""o"">.</span><span class=""n"">randn</span><span class=""p"">(</span><span class=""mi"">16</span><span class=""p"">,</span> <span class=""mi"">100</span><span class=""p"">))</span>
<span class=""n"">bigdf</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">set_sticky</span><span class=""p"">(</span><span class=""n"">axis</span><span class=""o"">=</span><span class=""s2"">""index""</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[65]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_ed112 thead tr th:nth-child(1) {
  position: sticky;
  background-color: inherit;
  left: 0px;
  z-index: 3 !important;
}
#T_ed112 tbody tr th:nth-child(1) {
  position: sticky;
  background-color: inherit;
  left: 0px;
  z-index: 1;
}
</style>
<table id=""T_ed112"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_ed112_level0_col0"">0</th>
<th class=""col_heading level0 col1"" id=""T_ed112_level0_col1"">1</th>
<th class=""col_heading level0 col2"" id=""T_ed112_level0_col2"">2</th>
<th class=""col_heading level0 col3"" id=""T_ed112_level0_col3"">3</th>
<th class=""col_heading level0 col4"" id=""T_ed112_level0_col4"">4</th>
<th class=""col_heading level0 col5"" id=""T_ed112_level0_col5"">5</th>
<th class=""col_heading level0 col6"" id=""T_ed112_level0_col6"">6</th>
<th class=""col_heading level0 col7"" id=""T_ed112_level0_col7"">7</th>
<th class=""col_heading level0 col8"" id=""T_ed112_level0_col8"">8</th>
<th class=""col_heading level0 col9"" id=""T_ed112_level0_col9"">9</th>
<th class=""col_heading level0 col10"" id=""T_ed112_level0_col10"">10</th>
<th class=""col_heading level0 col11"" id=""T_ed112_level0_col11"">11</th>
<th class=""col_heading level0 col12"" id=""T_ed112_level0_col12"">12</th>
<th class=""col_heading level0 col13"" id=""T_ed112_level0_col13"">13</th>
<th class=""col_heading level0 col14"" id=""T_ed112_level0_col14"">14</th>
<th class=""col_heading level0 col15"" id=""T_ed112_level0_col15"">15</th>
<th class=""col_heading level0 col16"" id=""T_ed112_level0_col16"">16</th>
<th class=""col_heading level0 col17"" id=""T_ed112_level0_col17"">17</th>
<th class=""col_heading level0 col18"" id=""T_ed112_level0_col18"">18</th>
<th class=""col_heading level0 col19"" id=""T_ed112_level0_col19"">19</th>
<th class=""col_heading level0 col20"" id=""T_ed112_level0_col20"">20</th>
<th class=""col_heading level0 col21"" id=""T_ed112_level0_col21"">21</th>
<th class=""col_heading level0 col22"" id=""T_ed112_level0_col22"">22</th>
<th class=""col_heading level0 col23"" id=""T_ed112_level0_col23"">23</th>
<th class=""col_heading level0 col24"" id=""T_ed112_level0_col24"">24</th>
<th class=""col_heading level0 col25"" id=""T_ed112_level0_col25"">25</th>
<th class=""col_heading level0 col26"" id=""T_ed112_level0_col26"">26</th>
<th class=""col_heading level0 col27"" id=""T_ed112_level0_col27"">27</th>
<th class=""col_heading level0 col28"" id=""T_ed112_level0_col28"">28</th>
<th class=""col_heading level0 col29"" id=""T_ed112_level0_col29"">29</th>
<th class=""col_heading level0 col30"" id=""T_ed112_level0_col30"">30</th>
<th class=""col_heading level0 col31"" id=""T_ed112_level0_col31"">31</th>
<th class=""col_heading level0 col32"" id=""T_ed112_level0_col32"">32</th>
<th class=""col_heading level0 col33"" id=""T_ed112_level0_col33"">33</th>
<th class=""col_heading level0 col34"" id=""T_ed112_level0_col34"">34</th>
<th class=""col_heading level0 col35"" id=""T_ed112_level0_col35"">35</th>
<th class=""col_heading level0 col36"" id=""T_ed112_level0_col36"">36</th>
<th class=""col_heading level0 col37"" id=""T_ed112_level0_col37"">37</th>
<th class=""col_heading level0 col38"" id=""T_ed112_level0_col38"">38</th>
<th class=""col_heading level0 col39"" id=""T_ed112_level0_col39"">39</th>
<th class=""col_heading level0 col40"" id=""T_ed112_level0_col40"">40</th>
<th class=""col_heading level0 col41"" id=""T_ed112_level0_col41"">41</th>
<th class=""col_heading level0 col42"" id=""T_ed112_level0_col42"">42</th>
<th class=""col_heading level0 col43"" id=""T_ed112_level0_col43"">43</th>
<th class=""col_heading level0 col44"" id=""T_ed112_level0_col44"">44</th>
<th class=""col_heading level0 col45"" id=""T_ed112_level0_col45"">45</th>
<th class=""col_heading level0 col46"" id=""T_ed112_level0_col46"">46</th>
<th class=""col_heading level0 col47"" id=""T_ed112_level0_col47"">47</th>
<th class=""col_heading level0 col48"" id=""T_ed112_level0_col48"">48</th>
<th class=""col_heading level0 col49"" id=""T_ed112_level0_col49"">49</th>
<th class=""col_heading level0 col50"" id=""T_ed112_level0_col50"">50</th>
<th class=""col_heading level0 col51"" id=""T_ed112_level0_col51"">51</th>
<th class=""col_heading level0 col52"" id=""T_ed112_level0_col52"">52</th>
<th class=""col_heading level0 col53"" id=""T_ed112_level0_col53"">53</th>
<th class=""col_heading level0 col54"" id=""T_ed112_level0_col54"">54</th>
<th class=""col_heading level0 col55"" id=""T_ed112_level0_col55"">55</th>
<th class=""col_heading level0 col56"" id=""T_ed112_level0_col56"">56</th>
<th class=""col_heading level0 col57"" id=""T_ed112_level0_col57"">57</th>
<th class=""col_heading level0 col58"" id=""T_ed112_level0_col58"">58</th>
<th class=""col_heading level0 col59"" id=""T_ed112_level0_col59"">59</th>
<th class=""col_heading level0 col60"" id=""T_ed112_level0_col60"">60</th>
<th class=""col_heading level0 col61"" id=""T_ed112_level0_col61"">61</th>
<th class=""col_heading level0 col62"" id=""T_ed112_level0_col62"">62</th>
<th class=""col_heading level0 col63"" id=""T_ed112_level0_col63"">63</th>
<th class=""col_heading level0 col64"" id=""T_ed112_level0_col64"">64</th>
<th class=""col_heading level0 col65"" id=""T_ed112_level0_col65"">65</th>
<th class=""col_heading level0 col66"" id=""T_ed112_level0_col66"">66</th>
<th class=""col_heading level0 col67"" id=""T_ed112_level0_col67"">67</th>
<th class=""col_heading level0 col68"" id=""T_ed112_level0_col68"">68</th>
<th class=""col_heading level0 col69"" id=""T_ed112_level0_col69"">69</th>
<th class=""col_heading level0 col70"" id=""T_ed112_level0_col70"">70</th>
<th class=""col_heading level0 col71"" id=""T_ed112_level0_col71"">71</th>
<th class=""col_heading level0 col72"" id=""T_ed112_level0_col72"">72</th>
<th class=""col_heading level0 col73"" id=""T_ed112_level0_col73"">73</th>
<th class=""col_heading level0 col74"" id=""T_ed112_level0_col74"">74</th>
<th class=""col_heading level0 col75"" id=""T_ed112_level0_col75"">75</th>
<th class=""col_heading level0 col76"" id=""T_ed112_level0_col76"">76</th>
<th class=""col_heading level0 col77"" id=""T_ed112_level0_col77"">77</th>
<th class=""col_heading level0 col78"" id=""T_ed112_level0_col78"">78</th>
<th class=""col_heading level0 col79"" id=""T_ed112_level0_col79"">79</th>
<th class=""col_heading level0 col80"" id=""T_ed112_level0_col80"">80</th>
<th class=""col_heading level0 col81"" id=""T_ed112_level0_col81"">81</th>
<th class=""col_heading level0 col82"" id=""T_ed112_level0_col82"">82</th>
<th class=""col_heading level0 col83"" id=""T_ed112_level0_col83"">83</th>
<th class=""col_heading level0 col84"" id=""T_ed112_level0_col84"">84</th>
<th class=""col_heading level0 col85"" id=""T_ed112_level0_col85"">85</th>
<th class=""col_heading level0 col86"" id=""T_ed112_level0_col86"">86</th>
<th class=""col_heading level0 col87"" id=""T_ed112_level0_col87"">87</th>
<th class=""col_heading level0 col88"" id=""T_ed112_level0_col88"">88</th>
<th class=""col_heading level0 col89"" id=""T_ed112_level0_col89"">89</th>
<th class=""col_heading level0 col90"" id=""T_ed112_level0_col90"">90</th>
<th class=""col_heading level0 col91"" id=""T_ed112_level0_col91"">91</th>
<th class=""col_heading level0 col92"" id=""T_ed112_level0_col92"">92</th>
<th class=""col_heading level0 col93"" id=""T_ed112_level0_col93"">93</th>
<th class=""col_heading level0 col94"" id=""T_ed112_level0_col94"">94</th>
<th class=""col_heading level0 col95"" id=""T_ed112_level0_col95"">95</th>
<th class=""col_heading level0 col96"" id=""T_ed112_level0_col96"">96</th>
<th class=""col_heading level0 col97"" id=""T_ed112_level0_col97"">97</th>
<th class=""col_heading level0 col98"" id=""T_ed112_level0_col98"">98</th>
<th class=""col_heading level0 col99"" id=""T_ed112_level0_col99"">99</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_ed112_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_ed112_row0_col0"">-0.773866</td>
<td class=""data row0 col1"" id=""T_ed112_row0_col1"">-0.240521</td>
<td class=""data row0 col2"" id=""T_ed112_row0_col2"">-0.217165</td>
<td class=""data row0 col3"" id=""T_ed112_row0_col3"">1.173609</td>
<td class=""data row0 col4"" id=""T_ed112_row0_col4"">0.686390</td>
<td class=""data row0 col5"" id=""T_ed112_row0_col5"">0.008358</td>
<td class=""data row0 col6"" id=""T_ed112_row0_col6"">0.696232</td>
<td class=""data row0 col7"" id=""T_ed112_row0_col7"">0.173166</td>
<td class=""data row0 col8"" id=""T_ed112_row0_col8"">0.620498</td>
<td class=""data row0 col9"" id=""T_ed112_row0_col9"">0.504067</td>
<td class=""data row0 col10"" id=""T_ed112_row0_col10"">0.428066</td>
<td class=""data row0 col11"" id=""T_ed112_row0_col11"">-0.051824</td>
<td class=""data row0 col12"" id=""T_ed112_row0_col12"">0.719915</td>
<td class=""data row0 col13"" id=""T_ed112_row0_col13"">0.057165</td>
<td class=""data row0 col14"" id=""T_ed112_row0_col14"">0.562808</td>
<td class=""data row0 col15"" id=""T_ed112_row0_col15"">-0.369536</td>
<td class=""data row0 col16"" id=""T_ed112_row0_col16"">0.483399</td>
<td class=""data row0 col17"" id=""T_ed112_row0_col17"">0.620765</td>
<td class=""data row0 col18"" id=""T_ed112_row0_col18"">-0.354342</td>
<td class=""data row0 col19"" id=""T_ed112_row0_col19"">-1.469471</td>
<td class=""data row0 col20"" id=""T_ed112_row0_col20"">-1.937266</td>
<td class=""data row0 col21"" id=""T_ed112_row0_col21"">0.038031</td>
<td class=""data row0 col22"" id=""T_ed112_row0_col22"">-1.518162</td>
<td class=""data row0 col23"" id=""T_ed112_row0_col23"">-0.417599</td>
<td class=""data row0 col24"" id=""T_ed112_row0_col24"">0.386717</td>
<td class=""data row0 col25"" id=""T_ed112_row0_col25"">0.716193</td>
<td class=""data row0 col26"" id=""T_ed112_row0_col26"">0.489961</td>
<td class=""data row0 col27"" id=""T_ed112_row0_col27"">0.733957</td>
<td class=""data row0 col28"" id=""T_ed112_row0_col28"">0.914415</td>
<td class=""data row0 col29"" id=""T_ed112_row0_col29"">0.679894</td>
<td class=""data row0 col30"" id=""T_ed112_row0_col30"">0.255448</td>
<td class=""data row0 col31"" id=""T_ed112_row0_col31"">-0.508338</td>
<td class=""data row0 col32"" id=""T_ed112_row0_col32"">0.332030</td>
<td class=""data row0 col33"" id=""T_ed112_row0_col33"">-0.111107</td>
<td class=""data row0 col34"" id=""T_ed112_row0_col34"">-0.251983</td>
<td class=""data row0 col35"" id=""T_ed112_row0_col35"">-1.456620</td>
<td class=""data row0 col36"" id=""T_ed112_row0_col36"">0.409630</td>
<td class=""data row0 col37"" id=""T_ed112_row0_col37"">1.062320</td>
<td class=""data row0 col38"" id=""T_ed112_row0_col38"">-0.577115</td>
<td class=""data row0 col39"" id=""T_ed112_row0_col39"">0.718796</td>
<td class=""data row0 col40"" id=""T_ed112_row0_col40"">-0.399260</td>
<td class=""data row0 col41"" id=""T_ed112_row0_col41"">-1.311389</td>
<td class=""data row0 col42"" id=""T_ed112_row0_col42"">0.649122</td>
<td class=""data row0 col43"" id=""T_ed112_row0_col43"">0.091566</td>
<td class=""data row0 col44"" id=""T_ed112_row0_col44"">0.628872</td>
<td class=""data row0 col45"" id=""T_ed112_row0_col45"">0.297894</td>
<td class=""data row0 col46"" id=""T_ed112_row0_col46"">-0.142290</td>
<td class=""data row0 col47"" id=""T_ed112_row0_col47"">-0.542291</td>
<td class=""data row0 col48"" id=""T_ed112_row0_col48"">-0.914290</td>
<td class=""data row0 col49"" id=""T_ed112_row0_col49"">1.144514</td>
<td class=""data row0 col50"" id=""T_ed112_row0_col50"">0.313584</td>
<td class=""data row0 col51"" id=""T_ed112_row0_col51"">1.182635</td>
<td class=""data row0 col52"" id=""T_ed112_row0_col52"">1.214235</td>
<td class=""data row0 col53"" id=""T_ed112_row0_col53"">-0.416446</td>
<td class=""data row0 col54"" id=""T_ed112_row0_col54"">-1.653940</td>
<td class=""data row0 col55"" id=""T_ed112_row0_col55"">-2.550787</td>
<td class=""data row0 col56"" id=""T_ed112_row0_col56"">0.442473</td>
<td class=""data row0 col57"" id=""T_ed112_row0_col57"">0.052127</td>
<td class=""data row0 col58"" id=""T_ed112_row0_col58"">-0.464469</td>
<td class=""data row0 col59"" id=""T_ed112_row0_col59"">-0.523852</td>
<td class=""data row0 col60"" id=""T_ed112_row0_col60"">0.989726</td>
<td class=""data row0 col61"" id=""T_ed112_row0_col61"">-1.325539</td>
<td class=""data row0 col62"" id=""T_ed112_row0_col62"">-0.199687</td>
<td class=""data row0 col63"" id=""T_ed112_row0_col63"">-1.226727</td>
<td class=""data row0 col64"" id=""T_ed112_row0_col64"">0.290018</td>
<td class=""data row0 col65"" id=""T_ed112_row0_col65"">1.164574</td>
<td class=""data row0 col66"" id=""T_ed112_row0_col66"">0.817841</td>
<td class=""data row0 col67"" id=""T_ed112_row0_col67"">-0.309509</td>
<td class=""data row0 col68"" id=""T_ed112_row0_col68"">0.496599</td>
<td class=""data row0 col69"" id=""T_ed112_row0_col69"">0.943536</td>
<td class=""data row0 col70"" id=""T_ed112_row0_col70"">-0.091850</td>
<td class=""data row0 col71"" id=""T_ed112_row0_col71"">-2.802658</td>
<td class=""data row0 col72"" id=""T_ed112_row0_col72"">2.126219</td>
<td class=""data row0 col73"" id=""T_ed112_row0_col73"">-0.521161</td>
<td class=""data row0 col74"" id=""T_ed112_row0_col74"">0.288098</td>
<td class=""data row0 col75"" id=""T_ed112_row0_col75"">-0.454663</td>
<td class=""data row0 col76"" id=""T_ed112_row0_col76"">-1.676143</td>
<td class=""data row0 col77"" id=""T_ed112_row0_col77"">-0.357661</td>
<td class=""data row0 col78"" id=""T_ed112_row0_col78"">-0.788960</td>
<td class=""data row0 col79"" id=""T_ed112_row0_col79"">0.185911</td>
<td class=""data row0 col80"" id=""T_ed112_row0_col80"">-0.017106</td>
<td class=""data row0 col81"" id=""T_ed112_row0_col81"">2.454020</td>
<td class=""data row0 col82"" id=""T_ed112_row0_col82"">1.832706</td>
<td class=""data row0 col83"" id=""T_ed112_row0_col83"">-0.911743</td>
<td class=""data row0 col84"" id=""T_ed112_row0_col84"">-0.655873</td>
<td class=""data row0 col85"" id=""T_ed112_row0_col85"">-0.000514</td>
<td class=""data row0 col86"" id=""T_ed112_row0_col86"">-2.226997</td>
<td class=""data row0 col87"" id=""T_ed112_row0_col87"">0.677285</td>
<td class=""data row0 col88"" id=""T_ed112_row0_col88"">-0.140249</td>
<td class=""data row0 col89"" id=""T_ed112_row0_col89"">-0.408407</td>
<td class=""data row0 col90"" id=""T_ed112_row0_col90"">-0.838665</td>
<td class=""data row0 col91"" id=""T_ed112_row0_col91"">0.482228</td>
<td class=""data row0 col92"" id=""T_ed112_row0_col92"">1.243458</td>
<td class=""data row0 col93"" id=""T_ed112_row0_col93"">-0.477394</td>
<td class=""data row0 col94"" id=""T_ed112_row0_col94"">-0.220343</td>
<td class=""data row0 col95"" id=""T_ed112_row0_col95"">-2.463966</td>
<td class=""data row0 col96"" id=""T_ed112_row0_col96"">0.237325</td>
<td class=""data row0 col97"" id=""T_ed112_row0_col97"">-0.307380</td>
<td class=""data row0 col98"" id=""T_ed112_row0_col98"">1.172478</td>
<td class=""data row0 col99"" id=""T_ed112_row0_col99"">0.819492</td>
</tr>
<tr>
<th class=""row_heading level0 row1"" id=""T_ed112_level0_row1"">1</th>
<td class=""data row1 col0"" id=""T_ed112_row1_col0"">0.405906</td>
<td class=""data row1 col1"" id=""T_ed112_row1_col1"">-0.978919</td>
<td class=""data row1 col2"" id=""T_ed112_row1_col2"">1.267526</td>
<td class=""data row1 col3"" id=""T_ed112_row1_col3"">0.145250</td>
<td class=""data row1 col4"" id=""T_ed112_row1_col4"">-1.066786</td>
<td class=""data row1 col5"" id=""T_ed112_row1_col5"">-2.114192</td>
<td class=""data row1 col6"" id=""T_ed112_row1_col6"">-1.128346</td>
<td class=""data row1 col7"" id=""T_ed112_row1_col7"">-1.082523</td>
<td class=""data row1 col8"" id=""T_ed112_row1_col8"">0.372216</td>
<td class=""data row1 col9"" id=""T_ed112_row1_col9"">0.004127</td>
<td class=""data row1 col10"" id=""T_ed112_row1_col10"">-0.211984</td>
<td class=""data row1 col11"" id=""T_ed112_row1_col11"">0.937326</td>
<td class=""data row1 col12"" id=""T_ed112_row1_col12"">-0.935890</td>
<td class=""data row1 col13"" id=""T_ed112_row1_col13"">-1.704118</td>
<td class=""data row1 col14"" id=""T_ed112_row1_col14"">0.611789</td>
<td class=""data row1 col15"" id=""T_ed112_row1_col15"">-1.030015</td>
<td class=""data row1 col16"" id=""T_ed112_row1_col16"">0.636123</td>
<td class=""data row1 col17"" id=""T_ed112_row1_col17"">-1.506193</td>
<td class=""data row1 col18"" id=""T_ed112_row1_col18"">1.736609</td>
<td class=""data row1 col19"" id=""T_ed112_row1_col19"">1.392958</td>
<td class=""data row1 col20"" id=""T_ed112_row1_col20"">1.009424</td>
<td class=""data row1 col21"" id=""T_ed112_row1_col21"">0.353266</td>
<td class=""data row1 col22"" id=""T_ed112_row1_col22"">0.697339</td>
<td class=""data row1 col23"" id=""T_ed112_row1_col23"">-0.297424</td>
<td class=""data row1 col24"" id=""T_ed112_row1_col24"">0.428702</td>
<td class=""data row1 col25"" id=""T_ed112_row1_col25"">-0.145346</td>
<td class=""data row1 col26"" id=""T_ed112_row1_col26"">-0.333553</td>
<td class=""data row1 col27"" id=""T_ed112_row1_col27"">-0.974699</td>
<td class=""data row1 col28"" id=""T_ed112_row1_col28"">0.665314</td>
<td class=""data row1 col29"" id=""T_ed112_row1_col29"">0.971944</td>
<td class=""data row1 col30"" id=""T_ed112_row1_col30"">0.121950</td>
<td class=""data row1 col31"" id=""T_ed112_row1_col31"">-1.439668</td>
<td class=""data row1 col32"" id=""T_ed112_row1_col32"">1.018808</td>
<td class=""data row1 col33"" id=""T_ed112_row1_col33"">1.442399</td>
<td class=""data row1 col34"" id=""T_ed112_row1_col34"">-0.199585</td>
<td class=""data row1 col35"" id=""T_ed112_row1_col35"">-1.165916</td>
<td class=""data row1 col36"" id=""T_ed112_row1_col36"">0.645656</td>
<td class=""data row1 col37"" id=""T_ed112_row1_col37"">1.436466</td>
<td class=""data row1 col38"" id=""T_ed112_row1_col38"">-0.921215</td>
<td class=""data row1 col39"" id=""T_ed112_row1_col39"">1.293906</td>
<td class=""data row1 col40"" id=""T_ed112_row1_col40"">-2.706443</td>
<td class=""data row1 col41"" id=""T_ed112_row1_col41"">1.460928</td>
<td class=""data row1 col42"" id=""T_ed112_row1_col42"">-0.823197</td>
<td class=""data row1 col43"" id=""T_ed112_row1_col43"">0.292952</td>
<td class=""data row1 col44"" id=""T_ed112_row1_col44"">-1.448992</td>
<td class=""data row1 col45"" id=""T_ed112_row1_col45"">0.026692</td>
<td class=""data row1 col46"" id=""T_ed112_row1_col46"">-0.975883</td>
<td class=""data row1 col47"" id=""T_ed112_row1_col47"">0.392823</td>
<td class=""data row1 col48"" id=""T_ed112_row1_col48"">0.442166</td>
<td class=""data row1 col49"" id=""T_ed112_row1_col49"">0.745741</td>
<td class=""data row1 col50"" id=""T_ed112_row1_col50"">1.187982</td>
<td class=""data row1 col51"" id=""T_ed112_row1_col51"">-0.218570</td>
<td class=""data row1 col52"" id=""T_ed112_row1_col52"">0.305288</td>
<td class=""data row1 col53"" id=""T_ed112_row1_col53"">0.054932</td>
<td class=""data row1 col54"" id=""T_ed112_row1_col54"">-1.476953</td>
<td class=""data row1 col55"" id=""T_ed112_row1_col55"">-0.114434</td>
<td class=""data row1 col56"" id=""T_ed112_row1_col56"">0.014103</td>
<td class=""data row1 col57"" id=""T_ed112_row1_col57"">0.825394</td>
<td class=""data row1 col58"" id=""T_ed112_row1_col58"">-0.060654</td>
<td class=""data row1 col59"" id=""T_ed112_row1_col59"">-0.413688</td>
<td class=""data row1 col60"" id=""T_ed112_row1_col60"">0.974836</td>
<td class=""data row1 col61"" id=""T_ed112_row1_col61"">1.339210</td>
<td class=""data row1 col62"" id=""T_ed112_row1_col62"">1.034838</td>
<td class=""data row1 col63"" id=""T_ed112_row1_col63"">0.040775</td>
<td class=""data row1 col64"" id=""T_ed112_row1_col64"">0.705001</td>
<td class=""data row1 col65"" id=""T_ed112_row1_col65"">0.017796</td>
<td class=""data row1 col66"" id=""T_ed112_row1_col66"">1.867681</td>
<td class=""data row1 col67"" id=""T_ed112_row1_col67"">-0.390173</td>
<td class=""data row1 col68"" id=""T_ed112_row1_col68"">2.285277</td>
<td class=""data row1 col69"" id=""T_ed112_row1_col69"">2.311464</td>
<td class=""data row1 col70"" id=""T_ed112_row1_col70"">-0.085070</td>
<td class=""data row1 col71"" id=""T_ed112_row1_col71"">-0.648115</td>
<td class=""data row1 col72"" id=""T_ed112_row1_col72"">0.576300</td>
<td class=""data row1 col73"" id=""T_ed112_row1_col73"">-0.790087</td>
<td class=""data row1 col74"" id=""T_ed112_row1_col74"">-1.183798</td>
<td class=""data row1 col75"" id=""T_ed112_row1_col75"">-1.334558</td>
<td class=""data row1 col76"" id=""T_ed112_row1_col76"">-0.454118</td>
<td class=""data row1 col77"" id=""T_ed112_row1_col77"">0.319302</td>
<td class=""data row1 col78"" id=""T_ed112_row1_col78"">1.706488</td>
<td class=""data row1 col79"" id=""T_ed112_row1_col79"">0.830429</td>
<td class=""data row1 col80"" id=""T_ed112_row1_col80"">0.502476</td>
<td class=""data row1 col81"" id=""T_ed112_row1_col81"">-0.079631</td>
<td class=""data row1 col82"" id=""T_ed112_row1_col82"">0.414635</td>
<td class=""data row1 col83"" id=""T_ed112_row1_col83"">0.332511</td>
<td class=""data row1 col84"" id=""T_ed112_row1_col84"">0.042935</td>
<td class=""data row1 col85"" id=""T_ed112_row1_col85"">-0.160910</td>
<td class=""data row1 col86"" id=""T_ed112_row1_col86"">0.918553</td>
<td class=""data row1 col87"" id=""T_ed112_row1_col87"">-0.292697</td>
<td class=""data row1 col88"" id=""T_ed112_row1_col88"">-1.303834</td>
<td class=""data row1 col89"" id=""T_ed112_row1_col89"">-0.199604</td>
<td class=""data row1 col90"" id=""T_ed112_row1_col90"">0.871023</td>
<td class=""data row1 col91"" id=""T_ed112_row1_col91"">-1.370681</td>
<td class=""data row1 col92"" id=""T_ed112_row1_col92"">-0.205701</td>
<td class=""data row1 col93"" id=""T_ed112_row1_col93"">-0.492973</td>
<td class=""data row1 col94"" id=""T_ed112_row1_col94"">1.123083</td>
<td class=""data row1 col95"" id=""T_ed112_row1_col95"">-0.081842</td>
<td class=""data row1 col96"" id=""T_ed112_row1_col96"">-0.118527</td>
<td class=""data row1 col97"" id=""T_ed112_row1_col97"">0.245838</td>
<td class=""data row1 col98"" id=""T_ed112_row1_col98"">-0.315742</td>
<td class=""data row1 col99"" id=""T_ed112_row1_col99"">-0.511806</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_ed112_level0_row2"">2</th>
<td class=""data row2 col0"" id=""T_ed112_row2_col0"">0.011470</td>
<td class=""data row2 col1"" id=""T_ed112_row2_col1"">-0.036104</td>
<td class=""data row2 col2"" id=""T_ed112_row2_col2"">1.399603</td>
<td class=""data row2 col3"" id=""T_ed112_row2_col3"">-0.418176</td>
<td class=""data row2 col4"" id=""T_ed112_row2_col4"">-0.412229</td>
<td class=""data row2 col5"" id=""T_ed112_row2_col5"">-1.234783</td>
<td class=""data row2 col6"" id=""T_ed112_row2_col6"">-1.121500</td>
<td class=""data row2 col7"" id=""T_ed112_row2_col7"">1.196478</td>
<td class=""data row2 col8"" id=""T_ed112_row2_col8"">-0.569522</td>
<td class=""data row2 col9"" id=""T_ed112_row2_col9"">0.422022</td>
<td class=""data row2 col10"" id=""T_ed112_row2_col10"">-0.220484</td>
<td class=""data row2 col11"" id=""T_ed112_row2_col11"">0.804338</td>
<td class=""data row2 col12"" id=""T_ed112_row2_col12"">2.892667</td>
<td class=""data row2 col13"" id=""T_ed112_row2_col13"">-0.511055</td>
<td class=""data row2 col14"" id=""T_ed112_row2_col14"">-0.168722</td>
<td class=""data row2 col15"" id=""T_ed112_row2_col15"">-1.477996</td>
<td class=""data row2 col16"" id=""T_ed112_row2_col16"">-1.969917</td>
<td class=""data row2 col17"" id=""T_ed112_row2_col17"">0.471354</td>
<td class=""data row2 col18"" id=""T_ed112_row2_col18"">1.698548</td>
<td class=""data row2 col19"" id=""T_ed112_row2_col19"">0.137105</td>
<td class=""data row2 col20"" id=""T_ed112_row2_col20"">-0.762052</td>
<td class=""data row2 col21"" id=""T_ed112_row2_col21"">0.199379</td>
<td class=""data row2 col22"" id=""T_ed112_row2_col22"">-0.964346</td>
<td class=""data row2 col23"" id=""T_ed112_row2_col23"">-0.256692</td>
<td class=""data row2 col24"" id=""T_ed112_row2_col24"">1.265275</td>
<td class=""data row2 col25"" id=""T_ed112_row2_col25"">0.848762</td>
<td class=""data row2 col26"" id=""T_ed112_row2_col26"">-0.784161</td>
<td class=""data row2 col27"" id=""T_ed112_row2_col27"">1.863776</td>
<td class=""data row2 col28"" id=""T_ed112_row2_col28"">-0.355569</td>
<td class=""data row2 col29"" id=""T_ed112_row2_col29"">0.854552</td>
<td class=""data row2 col30"" id=""T_ed112_row2_col30"">0.768061</td>
<td class=""data row2 col31"" id=""T_ed112_row2_col31"">-2.075718</td>
<td class=""data row2 col32"" id=""T_ed112_row2_col32"">-2.501069</td>
<td class=""data row2 col33"" id=""T_ed112_row2_col33"">1.109868</td>
<td class=""data row2 col34"" id=""T_ed112_row2_col34"">0.957545</td>
<td class=""data row2 col35"" id=""T_ed112_row2_col35"">-0.683276</td>
<td class=""data row2 col36"" id=""T_ed112_row2_col36"">0.307764</td>
<td class=""data row2 col37"" id=""T_ed112_row2_col37"">0.733073</td>
<td class=""data row2 col38"" id=""T_ed112_row2_col38"">1.706250</td>
<td class=""data row2 col39"" id=""T_ed112_row2_col39"">-1.118091</td>
<td class=""data row2 col40"" id=""T_ed112_row2_col40"">0.374961</td>
<td class=""data row2 col41"" id=""T_ed112_row2_col41"">-1.414503</td>
<td class=""data row2 col42"" id=""T_ed112_row2_col42"">-0.524183</td>
<td class=""data row2 col43"" id=""T_ed112_row2_col43"">-1.662696</td>
<td class=""data row2 col44"" id=""T_ed112_row2_col44"">0.687921</td>
<td class=""data row2 col45"" id=""T_ed112_row2_col45"">0.521732</td>
<td class=""data row2 col46"" id=""T_ed112_row2_col46"">1.451396</td>
<td class=""data row2 col47"" id=""T_ed112_row2_col47"">-0.833491</td>
<td class=""data row2 col48"" id=""T_ed112_row2_col48"">-0.362796</td>
<td class=""data row2 col49"" id=""T_ed112_row2_col49"">-1.174444</td>
<td class=""data row2 col50"" id=""T_ed112_row2_col50"">-0.813893</td>
<td class=""data row2 col51"" id=""T_ed112_row2_col51"">-0.893220</td>
<td class=""data row2 col52"" id=""T_ed112_row2_col52"">0.770743</td>
<td class=""data row2 col53"" id=""T_ed112_row2_col53"">1.156647</td>
<td class=""data row2 col54"" id=""T_ed112_row2_col54"">-0.647444</td>
<td class=""data row2 col55"" id=""T_ed112_row2_col55"">0.125929</td>
<td class=""data row2 col56"" id=""T_ed112_row2_col56"">0.513600</td>
<td class=""data row2 col57"" id=""T_ed112_row2_col57"">-0.537874</td>
<td class=""data row2 col58"" id=""T_ed112_row2_col58"">1.992052</td>
<td class=""data row2 col59"" id=""T_ed112_row2_col59"">-1.946584</td>
<td class=""data row2 col60"" id=""T_ed112_row2_col60"">-0.104759</td>
<td class=""data row2 col61"" id=""T_ed112_row2_col61"">0.484779</td>
<td class=""data row2 col62"" id=""T_ed112_row2_col62"">-0.290936</td>
<td class=""data row2 col63"" id=""T_ed112_row2_col63"">-0.441075</td>
<td class=""data row2 col64"" id=""T_ed112_row2_col64"">0.542993</td>
<td class=""data row2 col65"" id=""T_ed112_row2_col65"">-1.050038</td>
<td class=""data row2 col66"" id=""T_ed112_row2_col66"">1.630482</td>
<td class=""data row2 col67"" id=""T_ed112_row2_col67"">0.239771</td>
<td class=""data row2 col68"" id=""T_ed112_row2_col68"">-1.177310</td>
<td class=""data row2 col69"" id=""T_ed112_row2_col69"">0.464804</td>
<td class=""data row2 col70"" id=""T_ed112_row2_col70"">-0.966995</td>
<td class=""data row2 col71"" id=""T_ed112_row2_col71"">0.646086</td>
<td class=""data row2 col72"" id=""T_ed112_row2_col72"">0.486899</td>
<td class=""data row2 col73"" id=""T_ed112_row2_col73"">1.022196</td>
<td class=""data row2 col74"" id=""T_ed112_row2_col74"">-2.267827</td>
<td class=""data row2 col75"" id=""T_ed112_row2_col75"">-1.229616</td>
<td class=""data row2 col76"" id=""T_ed112_row2_col76"">1.313805</td>
<td class=""data row2 col77"" id=""T_ed112_row2_col77"">1.073292</td>
<td class=""data row2 col78"" id=""T_ed112_row2_col78"">2.324940</td>
<td class=""data row2 col79"" id=""T_ed112_row2_col79"">-0.542720</td>
<td class=""data row2 col80"" id=""T_ed112_row2_col80"">-1.504292</td>
<td class=""data row2 col81"" id=""T_ed112_row2_col81"">0.777643</td>
<td class=""data row2 col82"" id=""T_ed112_row2_col82"">-0.618553</td>
<td class=""data row2 col83"" id=""T_ed112_row2_col83"">0.011342</td>
<td class=""data row2 col84"" id=""T_ed112_row2_col84"">1.385062</td>
<td class=""data row2 col85"" id=""T_ed112_row2_col85"">1.363552</td>
<td class=""data row2 col86"" id=""T_ed112_row2_col86"">-0.549834</td>
<td class=""data row2 col87"" id=""T_ed112_row2_col87"">0.688896</td>
<td class=""data row2 col88"" id=""T_ed112_row2_col88"">1.361288</td>
<td class=""data row2 col89"" id=""T_ed112_row2_col89"">-0.381137</td>
<td class=""data row2 col90"" id=""T_ed112_row2_col90"">0.797812</td>
<td class=""data row2 col91"" id=""T_ed112_row2_col91"">-1.128198</td>
<td class=""data row2 col92"" id=""T_ed112_row2_col92"">0.369208</td>
<td class=""data row2 col93"" id=""T_ed112_row2_col93"">0.540132</td>
<td class=""data row2 col94"" id=""T_ed112_row2_col94"">0.413853</td>
<td class=""data row2 col95"" id=""T_ed112_row2_col95"">-0.200308</td>
<td class=""data row2 col96"" id=""T_ed112_row2_col96"">-0.969126</td>
<td class=""data row2 col97"" id=""T_ed112_row2_col97"">0.981293</td>
<td class=""data row2 col98"" id=""T_ed112_row2_col98"">-0.009783</td>
<td class=""data row2 col99"" id=""T_ed112_row2_col99"">-0.320020</td>
</tr>
<tr>
<th class=""row_heading level0 row3"" id=""T_ed112_level0_row3"">3</th>
<td class=""data row3 col0"" id=""T_ed112_row3_col0"">-0.574816</td>
<td class=""data row3 col1"" id=""T_ed112_row3_col1"">1.419977</td>
<td class=""data row3 col2"" id=""T_ed112_row3_col2"">0.434813</td>
<td class=""data row3 col3"" id=""T_ed112_row3_col3"">-1.101217</td>
<td class=""data row3 col4"" id=""T_ed112_row3_col4"">-1.586275</td>
<td class=""data row3 col5"" id=""T_ed112_row3_col5"">1.979573</td>
<td class=""data row3 col6"" id=""T_ed112_row3_col6"">0.378298</td>
<td class=""data row3 col7"" id=""T_ed112_row3_col7"">0.782326</td>
<td class=""data row3 col8"" id=""T_ed112_row3_col8"">2.178987</td>
<td class=""data row3 col9"" id=""T_ed112_row3_col9"">0.657564</td>
<td class=""data row3 col10"" id=""T_ed112_row3_col10"">0.683774</td>
<td class=""data row3 col11"" id=""T_ed112_row3_col11"">-0.091000</td>
<td class=""data row3 col12"" id=""T_ed112_row3_col12"">-0.059552</td>
<td class=""data row3 col13"" id=""T_ed112_row3_col13"">-0.738908</td>
<td class=""data row3 col14"" id=""T_ed112_row3_col14"">-0.907653</td>
<td class=""data row3 col15"" id=""T_ed112_row3_col15"">-0.701936</td>
<td class=""data row3 col16"" id=""T_ed112_row3_col16"">0.580039</td>
<td class=""data row3 col17"" id=""T_ed112_row3_col17"">-0.618757</td>
<td class=""data row3 col18"" id=""T_ed112_row3_col18"">0.453684</td>
<td class=""data row3 col19"" id=""T_ed112_row3_col19"">1.665382</td>
<td class=""data row3 col20"" id=""T_ed112_row3_col20"">-0.152321</td>
<td class=""data row3 col21"" id=""T_ed112_row3_col21"">0.880077</td>
<td class=""data row3 col22"" id=""T_ed112_row3_col22"">0.571073</td>
<td class=""data row3 col23"" id=""T_ed112_row3_col23"">-0.604736</td>
<td class=""data row3 col24"" id=""T_ed112_row3_col24"">0.532359</td>
<td class=""data row3 col25"" id=""T_ed112_row3_col25"">0.515031</td>
<td class=""data row3 col26"" id=""T_ed112_row3_col26"">-0.959844</td>
<td class=""data row3 col27"" id=""T_ed112_row3_col27"">-0.887184</td>
<td class=""data row3 col28"" id=""T_ed112_row3_col28"">0.435781</td>
<td class=""data row3 col29"" id=""T_ed112_row3_col29"">0.862093</td>
<td class=""data row3 col30"" id=""T_ed112_row3_col30"">-0.956321</td>
<td class=""data row3 col31"" id=""T_ed112_row3_col31"">-0.625909</td>
<td class=""data row3 col32"" id=""T_ed112_row3_col32"">0.194472</td>
<td class=""data row3 col33"" id=""T_ed112_row3_col33"">0.442490</td>
<td class=""data row3 col34"" id=""T_ed112_row3_col34"">0.526503</td>
<td class=""data row3 col35"" id=""T_ed112_row3_col35"">-0.215274</td>
<td class=""data row3 col36"" id=""T_ed112_row3_col36"">0.090711</td>
<td class=""data row3 col37"" id=""T_ed112_row3_col37"">0.932592</td>
<td class=""data row3 col38"" id=""T_ed112_row3_col38"">0.811999</td>
<td class=""data row3 col39"" id=""T_ed112_row3_col39"">-2.497026</td>
<td class=""data row3 col40"" id=""T_ed112_row3_col40"">0.631545</td>
<td class=""data row3 col41"" id=""T_ed112_row3_col41"">0.321418</td>
<td class=""data row3 col42"" id=""T_ed112_row3_col42"">-0.425549</td>
<td class=""data row3 col43"" id=""T_ed112_row3_col43"">-1.078832</td>
<td class=""data row3 col44"" id=""T_ed112_row3_col44"">0.753444</td>
<td class=""data row3 col45"" id=""T_ed112_row3_col45"">0.199790</td>
<td class=""data row3 col46"" id=""T_ed112_row3_col46"">-0.360526</td>
<td class=""data row3 col47"" id=""T_ed112_row3_col47"">-0.013448</td>
<td class=""data row3 col48"" id=""T_ed112_row3_col48"">-0.819476</td>
<td class=""data row3 col49"" id=""T_ed112_row3_col49"">0.814869</td>
<td class=""data row3 col50"" id=""T_ed112_row3_col50"">0.442118</td>
<td class=""data row3 col51"" id=""T_ed112_row3_col51"">-0.972048</td>
<td class=""data row3 col52"" id=""T_ed112_row3_col52"">-0.060603</td>
<td class=""data row3 col53"" id=""T_ed112_row3_col53"">-2.349825</td>
<td class=""data row3 col54"" id=""T_ed112_row3_col54"">1.265445</td>
<td class=""data row3 col55"" id=""T_ed112_row3_col55"">-0.573257</td>
<td class=""data row3 col56"" id=""T_ed112_row3_col56"">0.429124</td>
<td class=""data row3 col57"" id=""T_ed112_row3_col57"">1.049783</td>
<td class=""data row3 col58"" id=""T_ed112_row3_col58"">1.954773</td>
<td class=""data row3 col59"" id=""T_ed112_row3_col59"">0.071883</td>
<td class=""data row3 col60"" id=""T_ed112_row3_col60"">-0.094209</td>
<td class=""data row3 col61"" id=""T_ed112_row3_col61"">0.265616</td>
<td class=""data row3 col62"" id=""T_ed112_row3_col62"">0.948318</td>
<td class=""data row3 col63"" id=""T_ed112_row3_col63"">0.331645</td>
<td class=""data row3 col64"" id=""T_ed112_row3_col64"">1.343401</td>
<td class=""data row3 col65"" id=""T_ed112_row3_col65"">-0.167934</td>
<td class=""data row3 col66"" id=""T_ed112_row3_col66"">-1.105252</td>
<td class=""data row3 col67"" id=""T_ed112_row3_col67"">-0.167077</td>
<td class=""data row3 col68"" id=""T_ed112_row3_col68"">-0.096576</td>
<td class=""data row3 col69"" id=""T_ed112_row3_col69"">-0.838161</td>
<td class=""data row3 col70"" id=""T_ed112_row3_col70"">-0.208564</td>
<td class=""data row3 col71"" id=""T_ed112_row3_col71"">0.394534</td>
<td class=""data row3 col72"" id=""T_ed112_row3_col72"">0.762533</td>
<td class=""data row3 col73"" id=""T_ed112_row3_col73"">1.235357</td>
<td class=""data row3 col74"" id=""T_ed112_row3_col74"">-0.207282</td>
<td class=""data row3 col75"" id=""T_ed112_row3_col75"">-0.202946</td>
<td class=""data row3 col76"" id=""T_ed112_row3_col76"">-0.468025</td>
<td class=""data row3 col77"" id=""T_ed112_row3_col77"">0.256944</td>
<td class=""data row3 col78"" id=""T_ed112_row3_col78"">2.587584</td>
<td class=""data row3 col79"" id=""T_ed112_row3_col79"">1.186697</td>
<td class=""data row3 col80"" id=""T_ed112_row3_col80"">-1.031903</td>
<td class=""data row3 col81"" id=""T_ed112_row3_col81"">1.428316</td>
<td class=""data row3 col82"" id=""T_ed112_row3_col82"">0.658899</td>
<td class=""data row3 col83"" id=""T_ed112_row3_col83"">-0.046582</td>
<td class=""data row3 col84"" id=""T_ed112_row3_col84"">-0.075422</td>
<td class=""data row3 col85"" id=""T_ed112_row3_col85"">1.329359</td>
<td class=""data row3 col86"" id=""T_ed112_row3_col86"">-0.684267</td>
<td class=""data row3 col87"" id=""T_ed112_row3_col87"">-1.524182</td>
<td class=""data row3 col88"" id=""T_ed112_row3_col88"">2.014061</td>
<td class=""data row3 col89"" id=""T_ed112_row3_col89"">3.770933</td>
<td class=""data row3 col90"" id=""T_ed112_row3_col90"">0.647353</td>
<td class=""data row3 col91"" id=""T_ed112_row3_col91"">-1.021377</td>
<td class=""data row3 col92"" id=""T_ed112_row3_col92"">-0.345493</td>
<td class=""data row3 col93"" id=""T_ed112_row3_col93"">0.582811</td>
<td class=""data row3 col94"" id=""T_ed112_row3_col94"">0.797812</td>
<td class=""data row3 col95"" id=""T_ed112_row3_col95"">1.326020</td>
<td class=""data row3 col96"" id=""T_ed112_row3_col96"">1.422857</td>
<td class=""data row3 col97"" id=""T_ed112_row3_col97"">-3.077007</td>
<td class=""data row3 col98"" id=""T_ed112_row3_col98"">0.184083</td>
<td class=""data row3 col99"" id=""T_ed112_row3_col99"">1.478935</td>
</tr>
<tr>
<th class=""row_heading level0 row4"" id=""T_ed112_level0_row4"">4</th>
<td class=""data row4 col0"" id=""T_ed112_row4_col0"">-0.600142</td>
<td class=""data row4 col1"" id=""T_ed112_row4_col1"">1.929561</td>
<td class=""data row4 col2"" id=""T_ed112_row4_col2"">-2.346771</td>
<td class=""data row4 col3"" id=""T_ed112_row4_col3"">-0.669700</td>
<td class=""data row4 col4"" id=""T_ed112_row4_col4"">-1.165258</td>
<td class=""data row4 col5"" id=""T_ed112_row4_col5"">0.814788</td>
<td class=""data row4 col6"" id=""T_ed112_row4_col6"">0.444449</td>
<td class=""data row4 col7"" id=""T_ed112_row4_col7"">-0.576758</td>
<td class=""data row4 col8"" id=""T_ed112_row4_col8"">0.353091</td>
<td class=""data row4 col9"" id=""T_ed112_row4_col9"">0.408893</td>
<td class=""data row4 col10"" id=""T_ed112_row4_col10"">0.091391</td>
<td class=""data row4 col11"" id=""T_ed112_row4_col11"">-2.294389</td>
<td class=""data row4 col12"" id=""T_ed112_row4_col12"">0.485506</td>
<td class=""data row4 col13"" id=""T_ed112_row4_col13"">-0.081304</td>
<td class=""data row4 col14"" id=""T_ed112_row4_col14"">-0.716272</td>
<td class=""data row4 col15"" id=""T_ed112_row4_col15"">-1.648010</td>
<td class=""data row4 col16"" id=""T_ed112_row4_col16"">1.005361</td>
<td class=""data row4 col17"" id=""T_ed112_row4_col17"">-1.489603</td>
<td class=""data row4 col18"" id=""T_ed112_row4_col18"">0.363098</td>
<td class=""data row4 col19"" id=""T_ed112_row4_col19"">0.758602</td>
<td class=""data row4 col20"" id=""T_ed112_row4_col20"">-1.373847</td>
<td class=""data row4 col21"" id=""T_ed112_row4_col21"">-0.972057</td>
<td class=""data row4 col22"" id=""T_ed112_row4_col22"">1.988537</td>
<td class=""data row4 col23"" id=""T_ed112_row4_col23"">0.319829</td>
<td class=""data row4 col24"" id=""T_ed112_row4_col24"">1.169060</td>
<td class=""data row4 col25"" id=""T_ed112_row4_col25"">0.146585</td>
<td class=""data row4 col26"" id=""T_ed112_row4_col26"">1.030388</td>
<td class=""data row4 col27"" id=""T_ed112_row4_col27"">1.165984</td>
<td class=""data row4 col28"" id=""T_ed112_row4_col28"">1.369563</td>
<td class=""data row4 col29"" id=""T_ed112_row4_col29"">0.730984</td>
<td class=""data row4 col30"" id=""T_ed112_row4_col30"">-1.383696</td>
<td class=""data row4 col31"" id=""T_ed112_row4_col31"">-0.515189</td>
<td class=""data row4 col32"" id=""T_ed112_row4_col32"">-0.808927</td>
<td class=""data row4 col33"" id=""T_ed112_row4_col33"">-1.174651</td>
<td class=""data row4 col34"" id=""T_ed112_row4_col34"">-1.631502</td>
<td class=""data row4 col35"" id=""T_ed112_row4_col35"">-1.123414</td>
<td class=""data row4 col36"" id=""T_ed112_row4_col36"">-0.478155</td>
<td class=""data row4 col37"" id=""T_ed112_row4_col37"">-1.583067</td>
<td class=""data row4 col38"" id=""T_ed112_row4_col38"">1.419074</td>
<td class=""data row4 col39"" id=""T_ed112_row4_col39"">1.668777</td>
<td class=""data row4 col40"" id=""T_ed112_row4_col40"">1.567517</td>
<td class=""data row4 col41"" id=""T_ed112_row4_col41"">0.222103</td>
<td class=""data row4 col42"" id=""T_ed112_row4_col42"">-0.336040</td>
<td class=""data row4 col43"" id=""T_ed112_row4_col43"">-1.352064</td>
<td class=""data row4 col44"" id=""T_ed112_row4_col44"">0.251032</td>
<td class=""data row4 col45"" id=""T_ed112_row4_col45"">-0.401695</td>
<td class=""data row4 col46"" id=""T_ed112_row4_col46"">0.268413</td>
<td class=""data row4 col47"" id=""T_ed112_row4_col47"">-0.012299</td>
<td class=""data row4 col48"" id=""T_ed112_row4_col48"">-0.918953</td>
<td class=""data row4 col49"" id=""T_ed112_row4_col49"">2.921208</td>
<td class=""data row4 col50"" id=""T_ed112_row4_col50"">-0.581588</td>
<td class=""data row4 col51"" id=""T_ed112_row4_col51"">0.672848</td>
<td class=""data row4 col52"" id=""T_ed112_row4_col52"">1.251136</td>
<td class=""data row4 col53"" id=""T_ed112_row4_col53"">1.382263</td>
<td class=""data row4 col54"" id=""T_ed112_row4_col54"">1.429897</td>
<td class=""data row4 col55"" id=""T_ed112_row4_col55"">1.290990</td>
<td class=""data row4 col56"" id=""T_ed112_row4_col56"">-1.272673</td>
<td class=""data row4 col57"" id=""T_ed112_row4_col57"">-0.308611</td>
<td class=""data row4 col58"" id=""T_ed112_row4_col58"">-0.422988</td>
<td class=""data row4 col59"" id=""T_ed112_row4_col59"">-0.675642</td>
<td class=""data row4 col60"" id=""T_ed112_row4_col60"">0.874441</td>
<td class=""data row4 col61"" id=""T_ed112_row4_col61"">1.305736</td>
<td class=""data row4 col62"" id=""T_ed112_row4_col62"">-0.262585</td>
<td class=""data row4 col63"" id=""T_ed112_row4_col63"">-1.099395</td>
<td class=""data row4 col64"" id=""T_ed112_row4_col64"">-0.667101</td>
<td class=""data row4 col65"" id=""T_ed112_row4_col65"">-0.646737</td>
<td class=""data row4 col66"" id=""T_ed112_row4_col66"">-0.556338</td>
<td class=""data row4 col67"" id=""T_ed112_row4_col67"">-0.196591</td>
<td class=""data row4 col68"" id=""T_ed112_row4_col68"">0.119306</td>
<td class=""data row4 col69"" id=""T_ed112_row4_col69"">-0.266455</td>
<td class=""data row4 col70"" id=""T_ed112_row4_col70"">-0.524267</td>
<td class=""data row4 col71"" id=""T_ed112_row4_col71"">2.650951</td>
<td class=""data row4 col72"" id=""T_ed112_row4_col72"">0.097318</td>
<td class=""data row4 col73"" id=""T_ed112_row4_col73"">-0.974697</td>
<td class=""data row4 col74"" id=""T_ed112_row4_col74"">0.189964</td>
<td class=""data row4 col75"" id=""T_ed112_row4_col75"">1.141155</td>
<td class=""data row4 col76"" id=""T_ed112_row4_col76"">-0.064434</td>
<td class=""data row4 col77"" id=""T_ed112_row4_col77"">1.104971</td>
<td class=""data row4 col78"" id=""T_ed112_row4_col78"">-1.508908</td>
<td class=""data row4 col79"" id=""T_ed112_row4_col79"">-0.031833</td>
<td class=""data row4 col80"" id=""T_ed112_row4_col80"">0.803919</td>
<td class=""data row4 col81"" id=""T_ed112_row4_col81"">-0.659221</td>
<td class=""data row4 col82"" id=""T_ed112_row4_col82"">0.939145</td>
<td class=""data row4 col83"" id=""T_ed112_row4_col83"">0.214041</td>
<td class=""data row4 col84"" id=""T_ed112_row4_col84"">-0.531805</td>
<td class=""data row4 col85"" id=""T_ed112_row4_col85"">0.956060</td>
<td class=""data row4 col86"" id=""T_ed112_row4_col86"">0.249328</td>
<td class=""data row4 col87"" id=""T_ed112_row4_col87"">0.637903</td>
<td class=""data row4 col88"" id=""T_ed112_row4_col88"">-0.510158</td>
<td class=""data row4 col89"" id=""T_ed112_row4_col89"">1.850287</td>
<td class=""data row4 col90"" id=""T_ed112_row4_col90"">-0.348407</td>
<td class=""data row4 col91"" id=""T_ed112_row4_col91"">2.001376</td>
<td class=""data row4 col92"" id=""T_ed112_row4_col92"">-0.389643</td>
<td class=""data row4 col93"" id=""T_ed112_row4_col93"">-0.024786</td>
<td class=""data row4 col94"" id=""T_ed112_row4_col94"">-0.470973</td>
<td class=""data row4 col95"" id=""T_ed112_row4_col95"">0.869339</td>
<td class=""data row4 col96"" id=""T_ed112_row4_col96"">0.170667</td>
<td class=""data row4 col97"" id=""T_ed112_row4_col97"">0.598062</td>
<td class=""data row4 col98"" id=""T_ed112_row4_col98"">1.217262</td>
<td class=""data row4 col99"" id=""T_ed112_row4_col99"">1.274013</td>
</tr>
<tr>
<th class=""row_heading level0 row5"" id=""T_ed112_level0_row5"">5</th>
<td class=""data row5 col0"" id=""T_ed112_row5_col0"">-0.389981</td>
<td class=""data row5 col1"" id=""T_ed112_row5_col1"">-0.752441</td>
<td class=""data row5 col2"" id=""T_ed112_row5_col2"">-0.734871</td>
<td class=""data row5 col3"" id=""T_ed112_row5_col3"">3.517318</td>
<td class=""data row5 col4"" id=""T_ed112_row5_col4"">-1.173559</td>
<td class=""data row5 col5"" id=""T_ed112_row5_col5"">-0.004956</td>
<td class=""data row5 col6"" id=""T_ed112_row5_col6"">0.145419</td>
<td class=""data row5 col7"" id=""T_ed112_row5_col7"">2.151368</td>
<td class=""data row5 col8"" id=""T_ed112_row5_col8"">-3.086037</td>
<td class=""data row5 col9"" id=""T_ed112_row5_col9"">-1.569139</td>
<td class=""data row5 col10"" id=""T_ed112_row5_col10"">1.449784</td>
<td class=""data row5 col11"" id=""T_ed112_row5_col11"">-0.868951</td>
<td class=""data row5 col12"" id=""T_ed112_row5_col12"">-1.687716</td>
<td class=""data row5 col13"" id=""T_ed112_row5_col13"">-0.994401</td>
<td class=""data row5 col14"" id=""T_ed112_row5_col14"">1.153266</td>
<td class=""data row5 col15"" id=""T_ed112_row5_col15"">1.803045</td>
<td class=""data row5 col16"" id=""T_ed112_row5_col16"">-0.819059</td>
<td class=""data row5 col17"" id=""T_ed112_row5_col17"">0.847970</td>
<td class=""data row5 col18"" id=""T_ed112_row5_col18"">0.227102</td>
<td class=""data row5 col19"" id=""T_ed112_row5_col19"">-0.500762</td>
<td class=""data row5 col20"" id=""T_ed112_row5_col20"">0.868210</td>
<td class=""data row5 col21"" id=""T_ed112_row5_col21"">1.823540</td>
<td class=""data row5 col22"" id=""T_ed112_row5_col22"">1.161007</td>
<td class=""data row5 col23"" id=""T_ed112_row5_col23"">-0.307606</td>
<td class=""data row5 col24"" id=""T_ed112_row5_col24"">-0.713416</td>
<td class=""data row5 col25"" id=""T_ed112_row5_col25"">0.363560</td>
<td class=""data row5 col26"" id=""T_ed112_row5_col26"">-0.822162</td>
<td class=""data row5 col27"" id=""T_ed112_row5_col27"">2.427681</td>
<td class=""data row5 col28"" id=""T_ed112_row5_col28"">-0.129537</td>
<td class=""data row5 col29"" id=""T_ed112_row5_col29"">-0.078716</td>
<td class=""data row5 col30"" id=""T_ed112_row5_col30"">1.345644</td>
<td class=""data row5 col31"" id=""T_ed112_row5_col31"">-1.286094</td>
<td class=""data row5 col32"" id=""T_ed112_row5_col32"">0.237242</td>
<td class=""data row5 col33"" id=""T_ed112_row5_col33"">-0.136056</td>
<td class=""data row5 col34"" id=""T_ed112_row5_col34"">0.596664</td>
<td class=""data row5 col35"" id=""T_ed112_row5_col35"">-1.412381</td>
<td class=""data row5 col36"" id=""T_ed112_row5_col36"">1.206341</td>
<td class=""data row5 col37"" id=""T_ed112_row5_col37"">0.299860</td>
<td class=""data row5 col38"" id=""T_ed112_row5_col38"">0.705238</td>
<td class=""data row5 col39"" id=""T_ed112_row5_col39"">0.142412</td>
<td class=""data row5 col40"" id=""T_ed112_row5_col40"">-1.059382</td>
<td class=""data row5 col41"" id=""T_ed112_row5_col41"">0.833468</td>
<td class=""data row5 col42"" id=""T_ed112_row5_col42"">1.060015</td>
<td class=""data row5 col43"" id=""T_ed112_row5_col43"">-0.527045</td>
<td class=""data row5 col44"" id=""T_ed112_row5_col44"">-1.135732</td>
<td class=""data row5 col45"" id=""T_ed112_row5_col45"">-1.140983</td>
<td class=""data row5 col46"" id=""T_ed112_row5_col46"">-0.779540</td>
<td class=""data row5 col47"" id=""T_ed112_row5_col47"">-0.640875</td>
<td class=""data row5 col48"" id=""T_ed112_row5_col48"">-1.217196</td>
<td class=""data row5 col49"" id=""T_ed112_row5_col49"">-1.675663</td>
<td class=""data row5 col50"" id=""T_ed112_row5_col50"">0.241263</td>
<td class=""data row5 col51"" id=""T_ed112_row5_col51"">-0.273322</td>
<td class=""data row5 col52"" id=""T_ed112_row5_col52"">-1.697936</td>
<td class=""data row5 col53"" id=""T_ed112_row5_col53"">-0.594943</td>
<td class=""data row5 col54"" id=""T_ed112_row5_col54"">0.101154</td>
<td class=""data row5 col55"" id=""T_ed112_row5_col55"">1.391735</td>
<td class=""data row5 col56"" id=""T_ed112_row5_col56"">-0.426953</td>
<td class=""data row5 col57"" id=""T_ed112_row5_col57"">1.008344</td>
<td class=""data row5 col58"" id=""T_ed112_row5_col58"">-0.818577</td>
<td class=""data row5 col59"" id=""T_ed112_row5_col59"">1.924570</td>
<td class=""data row5 col60"" id=""T_ed112_row5_col60"">-0.578900</td>
<td class=""data row5 col61"" id=""T_ed112_row5_col61"">-0.457395</td>
<td class=""data row5 col62"" id=""T_ed112_row5_col62"">-1.096705</td>
<td class=""data row5 col63"" id=""T_ed112_row5_col63"">0.418522</td>
<td class=""data row5 col64"" id=""T_ed112_row5_col64"">-0.155623</td>
<td class=""data row5 col65"" id=""T_ed112_row5_col65"">0.169706</td>
<td class=""data row5 col66"" id=""T_ed112_row5_col66"">-2.533706</td>
<td class=""data row5 col67"" id=""T_ed112_row5_col67"">0.018904</td>
<td class=""data row5 col68"" id=""T_ed112_row5_col68"">1.434160</td>
<td class=""data row5 col69"" id=""T_ed112_row5_col69"">0.744095</td>
<td class=""data row5 col70"" id=""T_ed112_row5_col70"">0.647626</td>
<td class=""data row5 col71"" id=""T_ed112_row5_col71"">-0.770309</td>
<td class=""data row5 col72"" id=""T_ed112_row5_col72"">2.329141</td>
<td class=""data row5 col73"" id=""T_ed112_row5_col73"">-0.141547</td>
<td class=""data row5 col74"" id=""T_ed112_row5_col74"">-1.761594</td>
<td class=""data row5 col75"" id=""T_ed112_row5_col75"">0.702091</td>
<td class=""data row5 col76"" id=""T_ed112_row5_col76"">-1.531450</td>
<td class=""data row5 col77"" id=""T_ed112_row5_col77"">-0.788427</td>
<td class=""data row5 col78"" id=""T_ed112_row5_col78"">-0.184622</td>
<td class=""data row5 col79"" id=""T_ed112_row5_col79"">-1.942321</td>
<td class=""data row5 col80"" id=""T_ed112_row5_col80"">1.530113</td>
<td class=""data row5 col81"" id=""T_ed112_row5_col81"">0.503406</td>
<td class=""data row5 col82"" id=""T_ed112_row5_col82"">1.105845</td>
<td class=""data row5 col83"" id=""T_ed112_row5_col83"">-0.935120</td>
<td class=""data row5 col84"" id=""T_ed112_row5_col84"">-1.115483</td>
<td class=""data row5 col85"" id=""T_ed112_row5_col85"">-2.249762</td>
<td class=""data row5 col86"" id=""T_ed112_row5_col86"">1.307135</td>
<td class=""data row5 col87"" id=""T_ed112_row5_col87"">0.788412</td>
<td class=""data row5 col88"" id=""T_ed112_row5_col88"">-0.441091</td>
<td class=""data row5 col89"" id=""T_ed112_row5_col89"">0.073561</td>
<td class=""data row5 col90"" id=""T_ed112_row5_col90"">0.812101</td>
<td class=""data row5 col91"" id=""T_ed112_row5_col91"">-0.916146</td>
<td class=""data row5 col92"" id=""T_ed112_row5_col92"">1.573714</td>
<td class=""data row5 col93"" id=""T_ed112_row5_col93"">-0.309508</td>
<td class=""data row5 col94"" id=""T_ed112_row5_col94"">0.499987</td>
<td class=""data row5 col95"" id=""T_ed112_row5_col95"">0.187594</td>
<td class=""data row5 col96"" id=""T_ed112_row5_col96"">0.558913</td>
<td class=""data row5 col97"" id=""T_ed112_row5_col97"">0.903246</td>
<td class=""data row5 col98"" id=""T_ed112_row5_col98"">0.317901</td>
<td class=""data row5 col99"" id=""T_ed112_row5_col99"">-0.809797</td>
</tr>
<tr>
<th class=""row_heading level0 row6"" id=""T_ed112_level0_row6"">6</th>
<td class=""data row6 col0"" id=""T_ed112_row6_col0"">1.128248</td>
<td class=""data row6 col1"" id=""T_ed112_row6_col1"">1.516826</td>
<td class=""data row6 col2"" id=""T_ed112_row6_col2"">-0.186735</td>
<td class=""data row6 col3"" id=""T_ed112_row6_col3"">-0.668157</td>
<td class=""data row6 col4"" id=""T_ed112_row6_col4"">1.132259</td>
<td class=""data row6 col5"" id=""T_ed112_row6_col5"">-0.246648</td>
<td class=""data row6 col6"" id=""T_ed112_row6_col6"">-0.855167</td>
<td class=""data row6 col7"" id=""T_ed112_row6_col7"">0.732283</td>
<td class=""data row6 col8"" id=""T_ed112_row6_col8"">0.931802</td>
<td class=""data row6 col9"" id=""T_ed112_row6_col9"">1.318684</td>
<td class=""data row6 col10"" id=""T_ed112_row6_col10"">-1.198418</td>
<td class=""data row6 col11"" id=""T_ed112_row6_col11"">-1.149318</td>
<td class=""data row6 col12"" id=""T_ed112_row6_col12"">0.586321</td>
<td class=""data row6 col13"" id=""T_ed112_row6_col13"">-1.171937</td>
<td class=""data row6 col14"" id=""T_ed112_row6_col14"">-0.607731</td>
<td class=""data row6 col15"" id=""T_ed112_row6_col15"">2.753747</td>
<td class=""data row6 col16"" id=""T_ed112_row6_col16"">1.479287</td>
<td class=""data row6 col17"" id=""T_ed112_row6_col17"">-1.136365</td>
<td class=""data row6 col18"" id=""T_ed112_row6_col18"">-0.020485</td>
<td class=""data row6 col19"" id=""T_ed112_row6_col19"">0.320444</td>
<td class=""data row6 col20"" id=""T_ed112_row6_col20"">-1.955755</td>
<td class=""data row6 col21"" id=""T_ed112_row6_col21"">0.660402</td>
<td class=""data row6 col22"" id=""T_ed112_row6_col22"">-1.545371</td>
<td class=""data row6 col23"" id=""T_ed112_row6_col23"">0.200519</td>
<td class=""data row6 col24"" id=""T_ed112_row6_col24"">-0.017263</td>
<td class=""data row6 col25"" id=""T_ed112_row6_col25"">1.634686</td>
<td class=""data row6 col26"" id=""T_ed112_row6_col26"">0.599246</td>
<td class=""data row6 col27"" id=""T_ed112_row6_col27"">0.462989</td>
<td class=""data row6 col28"" id=""T_ed112_row6_col28"">0.023721</td>
<td class=""data row6 col29"" id=""T_ed112_row6_col29"">0.225546</td>
<td class=""data row6 col30"" id=""T_ed112_row6_col30"">0.170972</td>
<td class=""data row6 col31"" id=""T_ed112_row6_col31"">-0.027496</td>
<td class=""data row6 col32"" id=""T_ed112_row6_col32"">-0.061233</td>
<td class=""data row6 col33"" id=""T_ed112_row6_col33"">-0.566411</td>
<td class=""data row6 col34"" id=""T_ed112_row6_col34"">-0.669567</td>
<td class=""data row6 col35"" id=""T_ed112_row6_col35"">0.601618</td>
<td class=""data row6 col36"" id=""T_ed112_row6_col36"">0.503656</td>
<td class=""data row6 col37"" id=""T_ed112_row6_col37"">-0.678253</td>
<td class=""data row6 col38"" id=""T_ed112_row6_col38"">-2.907108</td>
<td class=""data row6 col39"" id=""T_ed112_row6_col39"">-1.717123</td>
<td class=""data row6 col40"" id=""T_ed112_row6_col40"">0.397631</td>
<td class=""data row6 col41"" id=""T_ed112_row6_col41"">1.300108</td>
<td class=""data row6 col42"" id=""T_ed112_row6_col42"">0.215821</td>
<td class=""data row6 col43"" id=""T_ed112_row6_col43"">-0.593075</td>
<td class=""data row6 col44"" id=""T_ed112_row6_col44"">-0.225944</td>
<td class=""data row6 col45"" id=""T_ed112_row6_col45"">-0.946057</td>
<td class=""data row6 col46"" id=""T_ed112_row6_col46"">1.000308</td>
<td class=""data row6 col47"" id=""T_ed112_row6_col47"">0.393160</td>
<td class=""data row6 col48"" id=""T_ed112_row6_col48"">1.342074</td>
<td class=""data row6 col49"" id=""T_ed112_row6_col49"">-0.370687</td>
<td class=""data row6 col50"" id=""T_ed112_row6_col50"">-0.166413</td>
<td class=""data row6 col51"" id=""T_ed112_row6_col51"">-0.419814</td>
<td class=""data row6 col52"" id=""T_ed112_row6_col52"">-0.255931</td>
<td class=""data row6 col53"" id=""T_ed112_row6_col53"">1.789478</td>
<td class=""data row6 col54"" id=""T_ed112_row6_col54"">0.282378</td>
<td class=""data row6 col55"" id=""T_ed112_row6_col55"">0.742260</td>
<td class=""data row6 col56"" id=""T_ed112_row6_col56"">-0.050498</td>
<td class=""data row6 col57"" id=""T_ed112_row6_col57"">1.415309</td>
<td class=""data row6 col58"" id=""T_ed112_row6_col58"">0.838166</td>
<td class=""data row6 col59"" id=""T_ed112_row6_col59"">-1.400292</td>
<td class=""data row6 col60"" id=""T_ed112_row6_col60"">-0.937976</td>
<td class=""data row6 col61"" id=""T_ed112_row6_col61"">-1.499148</td>
<td class=""data row6 col62"" id=""T_ed112_row6_col62"">0.801859</td>
<td class=""data row6 col63"" id=""T_ed112_row6_col63"">0.224824</td>
<td class=""data row6 col64"" id=""T_ed112_row6_col64"">0.283572</td>
<td class=""data row6 col65"" id=""T_ed112_row6_col65"">0.643703</td>
<td class=""data row6 col66"" id=""T_ed112_row6_col66"">-1.198465</td>
<td class=""data row6 col67"" id=""T_ed112_row6_col67"">0.527206</td>
<td class=""data row6 col68"" id=""T_ed112_row6_col68"">0.215202</td>
<td class=""data row6 col69"" id=""T_ed112_row6_col69"">0.437048</td>
<td class=""data row6 col70"" id=""T_ed112_row6_col70"">1.312868</td>
<td class=""data row6 col71"" id=""T_ed112_row6_col71"">0.741243</td>
<td class=""data row6 col72"" id=""T_ed112_row6_col72"">0.077988</td>
<td class=""data row6 col73"" id=""T_ed112_row6_col73"">0.006123</td>
<td class=""data row6 col74"" id=""T_ed112_row6_col74"">0.190370</td>
<td class=""data row6 col75"" id=""T_ed112_row6_col75"">0.018007</td>
<td class=""data row6 col76"" id=""T_ed112_row6_col76"">-1.026036</td>
<td class=""data row6 col77"" id=""T_ed112_row6_col77"">-2.378430</td>
<td class=""data row6 col78"" id=""T_ed112_row6_col78"">-1.069949</td>
<td class=""data row6 col79"" id=""T_ed112_row6_col79"">0.843822</td>
<td class=""data row6 col80"" id=""T_ed112_row6_col80"">1.289216</td>
<td class=""data row6 col81"" id=""T_ed112_row6_col81"">-1.423369</td>
<td class=""data row6 col82"" id=""T_ed112_row6_col82"">-0.462887</td>
<td class=""data row6 col83"" id=""T_ed112_row6_col83"">0.197330</td>
<td class=""data row6 col84"" id=""T_ed112_row6_col84"">-0.935076</td>
<td class=""data row6 col85"" id=""T_ed112_row6_col85"">0.441271</td>
<td class=""data row6 col86"" id=""T_ed112_row6_col86"">0.414643</td>
<td class=""data row6 col87"" id=""T_ed112_row6_col87"">-0.377887</td>
<td class=""data row6 col88"" id=""T_ed112_row6_col88"">-0.530515</td>
<td class=""data row6 col89"" id=""T_ed112_row6_col89"">0.621592</td>
<td class=""data row6 col90"" id=""T_ed112_row6_col90"">1.009572</td>
<td class=""data row6 col91"" id=""T_ed112_row6_col91"">0.569718</td>
<td class=""data row6 col92"" id=""T_ed112_row6_col92"">0.175291</td>
<td class=""data row6 col93"" id=""T_ed112_row6_col93"">-0.656279</td>
<td class=""data row6 col94"" id=""T_ed112_row6_col94"">-0.112273</td>
<td class=""data row6 col95"" id=""T_ed112_row6_col95"">-0.392137</td>
<td class=""data row6 col96"" id=""T_ed112_row6_col96"">-1.043558</td>
<td class=""data row6 col97"" id=""T_ed112_row6_col97"">-0.467318</td>
<td class=""data row6 col98"" id=""T_ed112_row6_col98"">-0.384329</td>
<td class=""data row6 col99"" id=""T_ed112_row6_col99"">-2.009207</td>
</tr>
<tr>
<th class=""row_heading level0 row7"" id=""T_ed112_level0_row7"">7</th>
<td class=""data row7 col0"" id=""T_ed112_row7_col0"">0.658598</td>
<td class=""data row7 col1"" id=""T_ed112_row7_col1"">0.101830</td>
<td class=""data row7 col2"" id=""T_ed112_row7_col2"">-0.682781</td>
<td class=""data row7 col3"" id=""T_ed112_row7_col3"">0.229349</td>
<td class=""data row7 col4"" id=""T_ed112_row7_col4"">-0.305657</td>
<td class=""data row7 col5"" id=""T_ed112_row7_col5"">0.404877</td>
<td class=""data row7 col6"" id=""T_ed112_row7_col6"">0.252244</td>
<td class=""data row7 col7"" id=""T_ed112_row7_col7"">-0.837784</td>
<td class=""data row7 col8"" id=""T_ed112_row7_col8"">-0.039624</td>
<td class=""data row7 col9"" id=""T_ed112_row7_col9"">0.329457</td>
<td class=""data row7 col10"" id=""T_ed112_row7_col10"">0.751694</td>
<td class=""data row7 col11"" id=""T_ed112_row7_col11"">1.469070</td>
<td class=""data row7 col12"" id=""T_ed112_row7_col12"">-0.157199</td>
<td class=""data row7 col13"" id=""T_ed112_row7_col13"">1.032628</td>
<td class=""data row7 col14"" id=""T_ed112_row7_col14"">-0.584639</td>
<td class=""data row7 col15"" id=""T_ed112_row7_col15"">-0.925544</td>
<td class=""data row7 col16"" id=""T_ed112_row7_col16"">0.342474</td>
<td class=""data row7 col17"" id=""T_ed112_row7_col17"">-0.969363</td>
<td class=""data row7 col18"" id=""T_ed112_row7_col18"">0.133480</td>
<td class=""data row7 col19"" id=""T_ed112_row7_col19"">-0.385974</td>
<td class=""data row7 col20"" id=""T_ed112_row7_col20"">-0.600278</td>
<td class=""data row7 col21"" id=""T_ed112_row7_col21"">0.281939</td>
<td class=""data row7 col22"" id=""T_ed112_row7_col22"">0.868579</td>
<td class=""data row7 col23"" id=""T_ed112_row7_col23"">1.129803</td>
<td class=""data row7 col24"" id=""T_ed112_row7_col24"">-0.041898</td>
<td class=""data row7 col25"" id=""T_ed112_row7_col25"">0.961193</td>
<td class=""data row7 col26"" id=""T_ed112_row7_col26"">0.131521</td>
<td class=""data row7 col27"" id=""T_ed112_row7_col27"">-0.792889</td>
<td class=""data row7 col28"" id=""T_ed112_row7_col28"">-1.285737</td>
<td class=""data row7 col29"" id=""T_ed112_row7_col29"">0.073934</td>
<td class=""data row7 col30"" id=""T_ed112_row7_col30"">-1.333315</td>
<td class=""data row7 col31"" id=""T_ed112_row7_col31"">-1.044125</td>
<td class=""data row7 col32"" id=""T_ed112_row7_col32"">1.277338</td>
<td class=""data row7 col33"" id=""T_ed112_row7_col33"">1.492257</td>
<td class=""data row7 col34"" id=""T_ed112_row7_col34"">0.411379</td>
<td class=""data row7 col35"" id=""T_ed112_row7_col35"">1.771805</td>
<td class=""data row7 col36"" id=""T_ed112_row7_col36"">-1.111128</td>
<td class=""data row7 col37"" id=""T_ed112_row7_col37"">1.123233</td>
<td class=""data row7 col38"" id=""T_ed112_row7_col38"">-1.019449</td>
<td class=""data row7 col39"" id=""T_ed112_row7_col39"">1.738357</td>
<td class=""data row7 col40"" id=""T_ed112_row7_col40"">-0.690764</td>
<td class=""data row7 col41"" id=""T_ed112_row7_col41"">-0.120710</td>
<td class=""data row7 col42"" id=""T_ed112_row7_col42"">-0.421359</td>
<td class=""data row7 col43"" id=""T_ed112_row7_col43"">-0.727294</td>
<td class=""data row7 col44"" id=""T_ed112_row7_col44"">-0.857759</td>
<td class=""data row7 col45"" id=""T_ed112_row7_col45"">-0.069436</td>
<td class=""data row7 col46"" id=""T_ed112_row7_col46"">-0.328334</td>
<td class=""data row7 col47"" id=""T_ed112_row7_col47"">-0.558180</td>
<td class=""data row7 col48"" id=""T_ed112_row7_col48"">1.063474</td>
<td class=""data row7 col49"" id=""T_ed112_row7_col49"">-0.519133</td>
<td class=""data row7 col50"" id=""T_ed112_row7_col50"">-0.496902</td>
<td class=""data row7 col51"" id=""T_ed112_row7_col51"">1.089589</td>
<td class=""data row7 col52"" id=""T_ed112_row7_col52"">-1.615801</td>
<td class=""data row7 col53"" id=""T_ed112_row7_col53"">0.080174</td>
<td class=""data row7 col54"" id=""T_ed112_row7_col54"">-0.229938</td>
<td class=""data row7 col55"" id=""T_ed112_row7_col55"">-0.498420</td>
<td class=""data row7 col56"" id=""T_ed112_row7_col56"">-0.624615</td>
<td class=""data row7 col57"" id=""T_ed112_row7_col57"">0.059481</td>
<td class=""data row7 col58"" id=""T_ed112_row7_col58"">-0.093158</td>
<td class=""data row7 col59"" id=""T_ed112_row7_col59"">-1.784549</td>
<td class=""data row7 col60"" id=""T_ed112_row7_col60"">-0.503789</td>
<td class=""data row7 col61"" id=""T_ed112_row7_col61"">-0.140528</td>
<td class=""data row7 col62"" id=""T_ed112_row7_col62"">0.002653</td>
<td class=""data row7 col63"" id=""T_ed112_row7_col63"">-0.484930</td>
<td class=""data row7 col64"" id=""T_ed112_row7_col64"">0.055914</td>
<td class=""data row7 col65"" id=""T_ed112_row7_col65"">-0.680948</td>
<td class=""data row7 col66"" id=""T_ed112_row7_col66"">-0.994271</td>
<td class=""data row7 col67"" id=""T_ed112_row7_col67"">1.277052</td>
<td class=""data row7 col68"" id=""T_ed112_row7_col68"">0.037651</td>
<td class=""data row7 col69"" id=""T_ed112_row7_col69"">2.155421</td>
<td class=""data row7 col70"" id=""T_ed112_row7_col70"">-0.437589</td>
<td class=""data row7 col71"" id=""T_ed112_row7_col71"">0.696404</td>
<td class=""data row7 col72"" id=""T_ed112_row7_col72"">0.417752</td>
<td class=""data row7 col73"" id=""T_ed112_row7_col73"">-0.544785</td>
<td class=""data row7 col74"" id=""T_ed112_row7_col74"">1.190690</td>
<td class=""data row7 col75"" id=""T_ed112_row7_col75"">0.978262</td>
<td class=""data row7 col76"" id=""T_ed112_row7_col76"">0.752102</td>
<td class=""data row7 col77"" id=""T_ed112_row7_col77"">0.504472</td>
<td class=""data row7 col78"" id=""T_ed112_row7_col78"">0.139853</td>
<td class=""data row7 col79"" id=""T_ed112_row7_col79"">-0.505089</td>
<td class=""data row7 col80"" id=""T_ed112_row7_col80"">-0.264975</td>
<td class=""data row7 col81"" id=""T_ed112_row7_col81"">-1.603194</td>
<td class=""data row7 col82"" id=""T_ed112_row7_col82"">0.731847</td>
<td class=""data row7 col83"" id=""T_ed112_row7_col83"">0.010903</td>
<td class=""data row7 col84"" id=""T_ed112_row7_col84"">-1.165346</td>
<td class=""data row7 col85"" id=""T_ed112_row7_col85"">-0.125195</td>
<td class=""data row7 col86"" id=""T_ed112_row7_col86"">-1.032685</td>
<td class=""data row7 col87"" id=""T_ed112_row7_col87"">-0.465520</td>
<td class=""data row7 col88"" id=""T_ed112_row7_col88"">1.514808</td>
<td class=""data row7 col89"" id=""T_ed112_row7_col89"">0.304762</td>
<td class=""data row7 col90"" id=""T_ed112_row7_col90"">0.793414</td>
<td class=""data row7 col91"" id=""T_ed112_row7_col91"">0.314635</td>
<td class=""data row7 col92"" id=""T_ed112_row7_col92"">-1.638279</td>
<td class=""data row7 col93"" id=""T_ed112_row7_col93"">0.111737</td>
<td class=""data row7 col94"" id=""T_ed112_row7_col94"">-0.777037</td>
<td class=""data row7 col95"" id=""T_ed112_row7_col95"">0.251783</td>
<td class=""data row7 col96"" id=""T_ed112_row7_col96"">1.126303</td>
<td class=""data row7 col97"" id=""T_ed112_row7_col97"">-0.808798</td>
<td class=""data row7 col98"" id=""T_ed112_row7_col98"">0.422064</td>
<td class=""data row7 col99"" id=""T_ed112_row7_col99"">-0.349264</td>
</tr>
<tr>
<th class=""row_heading level0 row8"" id=""T_ed112_level0_row8"">8</th>
<td class=""data row8 col0"" id=""T_ed112_row8_col0"">-0.356362</td>
<td class=""data row8 col1"" id=""T_ed112_row8_col1"">-0.089227</td>
<td class=""data row8 col2"" id=""T_ed112_row8_col2"">0.609373</td>
<td class=""data row8 col3"" id=""T_ed112_row8_col3"">0.542382</td>
<td class=""data row8 col4"" id=""T_ed112_row8_col4"">-0.768681</td>
<td class=""data row8 col5"" id=""T_ed112_row8_col5"">-0.048074</td>
<td class=""data row8 col6"" id=""T_ed112_row8_col6"">2.015458</td>
<td class=""data row8 col7"" id=""T_ed112_row8_col7"">-1.552351</td>
<td class=""data row8 col8"" id=""T_ed112_row8_col8"">0.251552</td>
<td class=""data row8 col9"" id=""T_ed112_row8_col9"">1.459635</td>
<td class=""data row8 col10"" id=""T_ed112_row8_col10"">0.949707</td>
<td class=""data row8 col11"" id=""T_ed112_row8_col11"">0.339465</td>
<td class=""data row8 col12"" id=""T_ed112_row8_col12"">-0.001372</td>
<td class=""data row8 col13"" id=""T_ed112_row8_col13"">1.798589</td>
<td class=""data row8 col14"" id=""T_ed112_row8_col14"">1.559163</td>
<td class=""data row8 col15"" id=""T_ed112_row8_col15"">0.231783</td>
<td class=""data row8 col16"" id=""T_ed112_row8_col16"">0.423141</td>
<td class=""data row8 col17"" id=""T_ed112_row8_col17"">-0.310530</td>
<td class=""data row8 col18"" id=""T_ed112_row8_col18"">0.353795</td>
<td class=""data row8 col19"" id=""T_ed112_row8_col19"">2.173336</td>
<td class=""data row8 col20"" id=""T_ed112_row8_col20"">-0.196247</td>
<td class=""data row8 col21"" id=""T_ed112_row8_col21"">-0.375636</td>
<td class=""data row8 col22"" id=""T_ed112_row8_col22"">-0.858221</td>
<td class=""data row8 col23"" id=""T_ed112_row8_col23"">0.258410</td>
<td class=""data row8 col24"" id=""T_ed112_row8_col24"">0.656430</td>
<td class=""data row8 col25"" id=""T_ed112_row8_col25"">0.960819</td>
<td class=""data row8 col26"" id=""T_ed112_row8_col26"">1.137893</td>
<td class=""data row8 col27"" id=""T_ed112_row8_col27"">1.553405</td>
<td class=""data row8 col28"" id=""T_ed112_row8_col28"">0.038981</td>
<td class=""data row8 col29"" id=""T_ed112_row8_col29"">-0.632038</td>
<td class=""data row8 col30"" id=""T_ed112_row8_col30"">-0.132009</td>
<td class=""data row8 col31"" id=""T_ed112_row8_col31"">-1.834997</td>
<td class=""data row8 col32"" id=""T_ed112_row8_col32"">-0.242576</td>
<td class=""data row8 col33"" id=""T_ed112_row8_col33"">-0.297879</td>
<td class=""data row8 col34"" id=""T_ed112_row8_col34"">-0.441559</td>
<td class=""data row8 col35"" id=""T_ed112_row8_col35"">-0.769691</td>
<td class=""data row8 col36"" id=""T_ed112_row8_col36"">0.224077</td>
<td class=""data row8 col37"" id=""T_ed112_row8_col37"">-0.153009</td>
<td class=""data row8 col38"" id=""T_ed112_row8_col38"">0.519526</td>
<td class=""data row8 col39"" id=""T_ed112_row8_col39"">-0.680188</td>
<td class=""data row8 col40"" id=""T_ed112_row8_col40"">0.535851</td>
<td class=""data row8 col41"" id=""T_ed112_row8_col41"">0.671496</td>
<td class=""data row8 col42"" id=""T_ed112_row8_col42"">-0.183064</td>
<td class=""data row8 col43"" id=""T_ed112_row8_col43"">0.301234</td>
<td class=""data row8 col44"" id=""T_ed112_row8_col44"">1.288256</td>
<td class=""data row8 col45"" id=""T_ed112_row8_col45"">-2.478240</td>
<td class=""data row8 col46"" id=""T_ed112_row8_col46"">-0.360403</td>
<td class=""data row8 col47"" id=""T_ed112_row8_col47"">0.424067</td>
<td class=""data row8 col48"" id=""T_ed112_row8_col48"">-0.834659</td>
<td class=""data row8 col49"" id=""T_ed112_row8_col49"">-0.128464</td>
<td class=""data row8 col50"" id=""T_ed112_row8_col50"">-0.489013</td>
<td class=""data row8 col51"" id=""T_ed112_row8_col51"">-0.014888</td>
<td class=""data row8 col52"" id=""T_ed112_row8_col52"">-1.461230</td>
<td class=""data row8 col53"" id=""T_ed112_row8_col53"">-1.435223</td>
<td class=""data row8 col54"" id=""T_ed112_row8_col54"">-1.319802</td>
<td class=""data row8 col55"" id=""T_ed112_row8_col55"">1.083675</td>
<td class=""data row8 col56"" id=""T_ed112_row8_col56"">0.979140</td>
<td class=""data row8 col57"" id=""T_ed112_row8_col57"">-0.375291</td>
<td class=""data row8 col58"" id=""T_ed112_row8_col58"">1.110189</td>
<td class=""data row8 col59"" id=""T_ed112_row8_col59"">-1.011351</td>
<td class=""data row8 col60"" id=""T_ed112_row8_col60"">0.587886</td>
<td class=""data row8 col61"" id=""T_ed112_row8_col61"">-0.822775</td>
<td class=""data row8 col62"" id=""T_ed112_row8_col62"">-1.183865</td>
<td class=""data row8 col63"" id=""T_ed112_row8_col63"">1.455173</td>
<td class=""data row8 col64"" id=""T_ed112_row8_col64"">1.134328</td>
<td class=""data row8 col65"" id=""T_ed112_row8_col65"">0.239403</td>
<td class=""data row8 col66"" id=""T_ed112_row8_col66"">-0.837991</td>
<td class=""data row8 col67"" id=""T_ed112_row8_col67"">-1.130932</td>
<td class=""data row8 col68"" id=""T_ed112_row8_col68"">0.783168</td>
<td class=""data row8 col69"" id=""T_ed112_row8_col69"">1.845520</td>
<td class=""data row8 col70"" id=""T_ed112_row8_col70"">1.437072</td>
<td class=""data row8 col71"" id=""T_ed112_row8_col71"">-1.198443</td>
<td class=""data row8 col72"" id=""T_ed112_row8_col72"">1.379098</td>
<td class=""data row8 col73"" id=""T_ed112_row8_col73"">2.129113</td>
<td class=""data row8 col74"" id=""T_ed112_row8_col74"">0.260096</td>
<td class=""data row8 col75"" id=""T_ed112_row8_col75"">-0.011975</td>
<td class=""data row8 col76"" id=""T_ed112_row8_col76"">0.043302</td>
<td class=""data row8 col77"" id=""T_ed112_row8_col77"">0.722941</td>
<td class=""data row8 col78"" id=""T_ed112_row8_col78"">1.028152</td>
<td class=""data row8 col79"" id=""T_ed112_row8_col79"">-0.235806</td>
<td class=""data row8 col80"" id=""T_ed112_row8_col80"">1.145245</td>
<td class=""data row8 col81"" id=""T_ed112_row8_col81"">-1.359598</td>
<td class=""data row8 col82"" id=""T_ed112_row8_col82"">0.232189</td>
<td class=""data row8 col83"" id=""T_ed112_row8_col83"">0.503712</td>
<td class=""data row8 col84"" id=""T_ed112_row8_col84"">-0.614264</td>
<td class=""data row8 col85"" id=""T_ed112_row8_col85"">-0.530606</td>
<td class=""data row8 col86"" id=""T_ed112_row8_col86"">-2.435803</td>
<td class=""data row8 col87"" id=""T_ed112_row8_col87"">-0.255238</td>
<td class=""data row8 col88"" id=""T_ed112_row8_col88"">-0.064423</td>
<td class=""data row8 col89"" id=""T_ed112_row8_col89"">0.784643</td>
<td class=""data row8 col90"" id=""T_ed112_row8_col90"">0.256346</td>
<td class=""data row8 col91"" id=""T_ed112_row8_col91"">0.128023</td>
<td class=""data row8 col92"" id=""T_ed112_row8_col92"">1.414103</td>
<td class=""data row8 col93"" id=""T_ed112_row8_col93"">-1.118659</td>
<td class=""data row8 col94"" id=""T_ed112_row8_col94"">0.877353</td>
<td class=""data row8 col95"" id=""T_ed112_row8_col95"">0.500561</td>
<td class=""data row8 col96"" id=""T_ed112_row8_col96"">0.463651</td>
<td class=""data row8 col97"" id=""T_ed112_row8_col97"">-2.034512</td>
<td class=""data row8 col98"" id=""T_ed112_row8_col98"">-0.981683</td>
<td class=""data row8 col99"" id=""T_ed112_row8_col99"">-0.691944</td>
</tr>
<tr>
<th class=""row_heading level0 row9"" id=""T_ed112_level0_row9"">9</th>
<td class=""data row9 col0"" id=""T_ed112_row9_col0"">-1.113376</td>
<td class=""data row9 col1"" id=""T_ed112_row9_col1"">-1.169402</td>
<td class=""data row9 col2"" id=""T_ed112_row9_col2"">0.680539</td>
<td class=""data row9 col3"" id=""T_ed112_row9_col3"">-1.534212</td>
<td class=""data row9 col4"" id=""T_ed112_row9_col4"">1.653817</td>
<td class=""data row9 col5"" id=""T_ed112_row9_col5"">-1.295181</td>
<td class=""data row9 col6"" id=""T_ed112_row9_col6"">-0.566826</td>
<td class=""data row9 col7"" id=""T_ed112_row9_col7"">0.477014</td>
<td class=""data row9 col8"" id=""T_ed112_row9_col8"">1.413371</td>
<td class=""data row9 col9"" id=""T_ed112_row9_col9"">0.517105</td>
<td class=""data row9 col10"" id=""T_ed112_row9_col10"">1.401153</td>
<td class=""data row9 col11"" id=""T_ed112_row9_col11"">-0.872685</td>
<td class=""data row9 col12"" id=""T_ed112_row9_col12"">0.830957</td>
<td class=""data row9 col13"" id=""T_ed112_row9_col13"">0.181507</td>
<td class=""data row9 col14"" id=""T_ed112_row9_col14"">-0.145616</td>
<td class=""data row9 col15"" id=""T_ed112_row9_col15"">0.694592</td>
<td class=""data row9 col16"" id=""T_ed112_row9_col16"">-0.751208</td>
<td class=""data row9 col17"" id=""T_ed112_row9_col17"">0.324444</td>
<td class=""data row9 col18"" id=""T_ed112_row9_col18"">0.681973</td>
<td class=""data row9 col19"" id=""T_ed112_row9_col19"">-0.054972</td>
<td class=""data row9 col20"" id=""T_ed112_row9_col20"">0.917776</td>
<td class=""data row9 col21"" id=""T_ed112_row9_col21"">-1.024810</td>
<td class=""data row9 col22"" id=""T_ed112_row9_col22"">-0.206446</td>
<td class=""data row9 col23"" id=""T_ed112_row9_col23"">-0.600113</td>
<td class=""data row9 col24"" id=""T_ed112_row9_col24"">0.852805</td>
<td class=""data row9 col25"" id=""T_ed112_row9_col25"">1.455109</td>
<td class=""data row9 col26"" id=""T_ed112_row9_col26"">-0.079769</td>
<td class=""data row9 col27"" id=""T_ed112_row9_col27"">0.076076</td>
<td class=""data row9 col28"" id=""T_ed112_row9_col28"">0.207699</td>
<td class=""data row9 col29"" id=""T_ed112_row9_col29"">-1.850458</td>
<td class=""data row9 col30"" id=""T_ed112_row9_col30"">-0.124124</td>
<td class=""data row9 col31"" id=""T_ed112_row9_col31"">-0.610871</td>
<td class=""data row9 col32"" id=""T_ed112_row9_col32"">-0.883362</td>
<td class=""data row9 col33"" id=""T_ed112_row9_col33"">0.219049</td>
<td class=""data row9 col34"" id=""T_ed112_row9_col34"">-0.685094</td>
<td class=""data row9 col35"" id=""T_ed112_row9_col35"">-0.645330</td>
<td class=""data row9 col36"" id=""T_ed112_row9_col36"">-0.242805</td>
<td class=""data row9 col37"" id=""T_ed112_row9_col37"">-0.775602</td>
<td class=""data row9 col38"" id=""T_ed112_row9_col38"">0.233070</td>
<td class=""data row9 col39"" id=""T_ed112_row9_col39"">2.422642</td>
<td class=""data row9 col40"" id=""T_ed112_row9_col40"">-1.423040</td>
<td class=""data row9 col41"" id=""T_ed112_row9_col41"">-0.582421</td>
<td class=""data row9 col42"" id=""T_ed112_row9_col42"">0.968304</td>
<td class=""data row9 col43"" id=""T_ed112_row9_col43"">-0.701025</td>
<td class=""data row9 col44"" id=""T_ed112_row9_col44"">-0.167850</td>
<td class=""data row9 col45"" id=""T_ed112_row9_col45"">0.277264</td>
<td class=""data row9 col46"" id=""T_ed112_row9_col46"">1.301231</td>
<td class=""data row9 col47"" id=""T_ed112_row9_col47"">0.301205</td>
<td class=""data row9 col48"" id=""T_ed112_row9_col48"">-3.081249</td>
<td class=""data row9 col49"" id=""T_ed112_row9_col49"">-0.562868</td>
<td class=""data row9 col50"" id=""T_ed112_row9_col50"">0.192944</td>
<td class=""data row9 col51"" id=""T_ed112_row9_col51"">-0.664592</td>
<td class=""data row9 col52"" id=""T_ed112_row9_col52"">0.565686</td>
<td class=""data row9 col53"" id=""T_ed112_row9_col53"">0.190913</td>
<td class=""data row9 col54"" id=""T_ed112_row9_col54"">-0.841858</td>
<td class=""data row9 col55"" id=""T_ed112_row9_col55"">-1.856545</td>
<td class=""data row9 col56"" id=""T_ed112_row9_col56"">-1.022777</td>
<td class=""data row9 col57"" id=""T_ed112_row9_col57"">1.295968</td>
<td class=""data row9 col58"" id=""T_ed112_row9_col58"">0.451921</td>
<td class=""data row9 col59"" id=""T_ed112_row9_col59"">0.659955</td>
<td class=""data row9 col60"" id=""T_ed112_row9_col60"">0.065818</td>
<td class=""data row9 col61"" id=""T_ed112_row9_col61"">-0.319586</td>
<td class=""data row9 col62"" id=""T_ed112_row9_col62"">0.253495</td>
<td class=""data row9 col63"" id=""T_ed112_row9_col63"">-1.144646</td>
<td class=""data row9 col64"" id=""T_ed112_row9_col64"">-0.483404</td>
<td class=""data row9 col65"" id=""T_ed112_row9_col65"">0.555902</td>
<td class=""data row9 col66"" id=""T_ed112_row9_col66"">0.807069</td>
<td class=""data row9 col67"" id=""T_ed112_row9_col67"">0.714196</td>
<td class=""data row9 col68"" id=""T_ed112_row9_col68"">0.661196</td>
<td class=""data row9 col69"" id=""T_ed112_row9_col69"">0.053667</td>
<td class=""data row9 col70"" id=""T_ed112_row9_col70"">0.346833</td>
<td class=""data row9 col71"" id=""T_ed112_row9_col71"">-1.288977</td>
<td class=""data row9 col72"" id=""T_ed112_row9_col72"">-0.386734</td>
<td class=""data row9 col73"" id=""T_ed112_row9_col73"">-1.262127</td>
<td class=""data row9 col74"" id=""T_ed112_row9_col74"">0.477495</td>
<td class=""data row9 col75"" id=""T_ed112_row9_col75"">-0.494034</td>
<td class=""data row9 col76"" id=""T_ed112_row9_col76"">-0.911414</td>
<td class=""data row9 col77"" id=""T_ed112_row9_col77"">1.152963</td>
<td class=""data row9 col78"" id=""T_ed112_row9_col78"">-0.342365</td>
<td class=""data row9 col79"" id=""T_ed112_row9_col79"">-0.160187</td>
<td class=""data row9 col80"" id=""T_ed112_row9_col80"">0.470054</td>
<td class=""data row9 col81"" id=""T_ed112_row9_col81"">-0.853063</td>
<td class=""data row9 col82"" id=""T_ed112_row9_col82"">-1.387949</td>
<td class=""data row9 col83"" id=""T_ed112_row9_col83"">-0.257257</td>
<td class=""data row9 col84"" id=""T_ed112_row9_col84"">-1.030690</td>
<td class=""data row9 col85"" id=""T_ed112_row9_col85"">-0.110210</td>
<td class=""data row9 col86"" id=""T_ed112_row9_col86"">0.328911</td>
<td class=""data row9 col87"" id=""T_ed112_row9_col87"">-0.555923</td>
<td class=""data row9 col88"" id=""T_ed112_row9_col88"">0.987713</td>
<td class=""data row9 col89"" id=""T_ed112_row9_col89"">-0.501957</td>
<td class=""data row9 col90"" id=""T_ed112_row9_col90"">2.069887</td>
<td class=""data row9 col91"" id=""T_ed112_row9_col91"">-0.067503</td>
<td class=""data row9 col92"" id=""T_ed112_row9_col92"">0.316029</td>
<td class=""data row9 col93"" id=""T_ed112_row9_col93"">-1.506232</td>
<td class=""data row9 col94"" id=""T_ed112_row9_col94"">2.201621</td>
<td class=""data row9 col95"" id=""T_ed112_row9_col95"">0.492097</td>
<td class=""data row9 col96"" id=""T_ed112_row9_col96"">-0.085193</td>
<td class=""data row9 col97"" id=""T_ed112_row9_col97"">-0.977822</td>
<td class=""data row9 col98"" id=""T_ed112_row9_col98"">1.039147</td>
<td class=""data row9 col99"" id=""T_ed112_row9_col99"">-0.653932</td>
</tr>
<tr>
<th class=""row_heading level0 row10"" id=""T_ed112_level0_row10"">10</th>
<td class=""data row10 col0"" id=""T_ed112_row10_col0"">-0.405638</td>
<td class=""data row10 col1"" id=""T_ed112_row10_col1"">-1.402027</td>
<td class=""data row10 col2"" id=""T_ed112_row10_col2"">-1.166242</td>
<td class=""data row10 col3"" id=""T_ed112_row10_col3"">1.306184</td>
<td class=""data row10 col4"" id=""T_ed112_row10_col4"">0.856283</td>
<td class=""data row10 col5"" id=""T_ed112_row10_col5"">-1.236170</td>
<td class=""data row10 col6"" id=""T_ed112_row10_col6"">-0.646721</td>
<td class=""data row10 col7"" id=""T_ed112_row10_col7"">-1.474064</td>
<td class=""data row10 col8"" id=""T_ed112_row10_col8"">0.082960</td>
<td class=""data row10 col9"" id=""T_ed112_row10_col9"">0.090310</td>
<td class=""data row10 col10"" id=""T_ed112_row10_col10"">-0.169977</td>
<td class=""data row10 col11"" id=""T_ed112_row10_col11"">0.406345</td>
<td class=""data row10 col12"" id=""T_ed112_row10_col12"">0.915427</td>
<td class=""data row10 col13"" id=""T_ed112_row10_col13"">-0.974503</td>
<td class=""data row10 col14"" id=""T_ed112_row10_col14"">0.271637</td>
<td class=""data row10 col15"" id=""T_ed112_row10_col15"">1.539184</td>
<td class=""data row10 col16"" id=""T_ed112_row10_col16"">-0.098866</td>
<td class=""data row10 col17"" id=""T_ed112_row10_col17"">-0.525149</td>
<td class=""data row10 col18"" id=""T_ed112_row10_col18"">1.063933</td>
<td class=""data row10 col19"" id=""T_ed112_row10_col19"">0.085827</td>
<td class=""data row10 col20"" id=""T_ed112_row10_col20"">-0.129622</td>
<td class=""data row10 col21"" id=""T_ed112_row10_col21"">0.947959</td>
<td class=""data row10 col22"" id=""T_ed112_row10_col22"">-0.072496</td>
<td class=""data row10 col23"" id=""T_ed112_row10_col23"">-0.237592</td>
<td class=""data row10 col24"" id=""T_ed112_row10_col24"">0.012549</td>
<td class=""data row10 col25"" id=""T_ed112_row10_col25"">1.065761</td>
<td class=""data row10 col26"" id=""T_ed112_row10_col26"">0.996596</td>
<td class=""data row10 col27"" id=""T_ed112_row10_col27"">-0.172481</td>
<td class=""data row10 col28"" id=""T_ed112_row10_col28"">2.583139</td>
<td class=""data row10 col29"" id=""T_ed112_row10_col29"">-0.028578</td>
<td class=""data row10 col30"" id=""T_ed112_row10_col30"">-0.254856</td>
<td class=""data row10 col31"" id=""T_ed112_row10_col31"">1.328794</td>
<td class=""data row10 col32"" id=""T_ed112_row10_col32"">-1.592951</td>
<td class=""data row10 col33"" id=""T_ed112_row10_col33"">2.434350</td>
<td class=""data row10 col34"" id=""T_ed112_row10_col34"">-0.341500</td>
<td class=""data row10 col35"" id=""T_ed112_row10_col35"">-0.307719</td>
<td class=""data row10 col36"" id=""T_ed112_row10_col36"">-1.333273</td>
<td class=""data row10 col37"" id=""T_ed112_row10_col37"">-1.100845</td>
<td class=""data row10 col38"" id=""T_ed112_row10_col38"">0.209097</td>
<td class=""data row10 col39"" id=""T_ed112_row10_col39"">1.734777</td>
<td class=""data row10 col40"" id=""T_ed112_row10_col40"">0.639632</td>
<td class=""data row10 col41"" id=""T_ed112_row10_col41"">0.424779</td>
<td class=""data row10 col42"" id=""T_ed112_row10_col42"">-0.129327</td>
<td class=""data row10 col43"" id=""T_ed112_row10_col43"">0.905029</td>
<td class=""data row10 col44"" id=""T_ed112_row10_col44"">-0.482909</td>
<td class=""data row10 col45"" id=""T_ed112_row10_col45"">1.731628</td>
<td class=""data row10 col46"" id=""T_ed112_row10_col46"">-2.783425</td>
<td class=""data row10 col47"" id=""T_ed112_row10_col47"">-0.333677</td>
<td class=""data row10 col48"" id=""T_ed112_row10_col48"">-0.110895</td>
<td class=""data row10 col49"" id=""T_ed112_row10_col49"">1.212636</td>
<td class=""data row10 col50"" id=""T_ed112_row10_col50"">-0.208412</td>
<td class=""data row10 col51"" id=""T_ed112_row10_col51"">0.427117</td>
<td class=""data row10 col52"" id=""T_ed112_row10_col52"">1.348563</td>
<td class=""data row10 col53"" id=""T_ed112_row10_col53"">0.043859</td>
<td class=""data row10 col54"" id=""T_ed112_row10_col54"">1.772519</td>
<td class=""data row10 col55"" id=""T_ed112_row10_col55"">-1.416106</td>
<td class=""data row10 col56"" id=""T_ed112_row10_col56"">0.401155</td>
<td class=""data row10 col57"" id=""T_ed112_row10_col57"">0.807157</td>
<td class=""data row10 col58"" id=""T_ed112_row10_col58"">0.303427</td>
<td class=""data row10 col59"" id=""T_ed112_row10_col59"">-1.246288</td>
<td class=""data row10 col60"" id=""T_ed112_row10_col60"">0.178774</td>
<td class=""data row10 col61"" id=""T_ed112_row10_col61"">-0.066126</td>
<td class=""data row10 col62"" id=""T_ed112_row10_col62"">-1.862288</td>
<td class=""data row10 col63"" id=""T_ed112_row10_col63"">1.241295</td>
<td class=""data row10 col64"" id=""T_ed112_row10_col64"">0.377021</td>
<td class=""data row10 col65"" id=""T_ed112_row10_col65"">-0.822320</td>
<td class=""data row10 col66"" id=""T_ed112_row10_col66"">-0.749014</td>
<td class=""data row10 col67"" id=""T_ed112_row10_col67"">1.463652</td>
<td class=""data row10 col68"" id=""T_ed112_row10_col68"">1.602268</td>
<td class=""data row10 col69"" id=""T_ed112_row10_col69"">-1.043877</td>
<td class=""data row10 col70"" id=""T_ed112_row10_col70"">1.185290</td>
<td class=""data row10 col71"" id=""T_ed112_row10_col71"">-0.565783</td>
<td class=""data row10 col72"" id=""T_ed112_row10_col72"">-1.076879</td>
<td class=""data row10 col73"" id=""T_ed112_row10_col73"">1.360241</td>
<td class=""data row10 col74"" id=""T_ed112_row10_col74"">-0.121991</td>
<td class=""data row10 col75"" id=""T_ed112_row10_col75"">0.991043</td>
<td class=""data row10 col76"" id=""T_ed112_row10_col76"">1.007952</td>
<td class=""data row10 col77"" id=""T_ed112_row10_col77"">0.450185</td>
<td class=""data row10 col78"" id=""T_ed112_row10_col78"">-0.744376</td>
<td class=""data row10 col79"" id=""T_ed112_row10_col79"">1.388876</td>
<td class=""data row10 col80"" id=""T_ed112_row10_col80"">-0.316847</td>
<td class=""data row10 col81"" id=""T_ed112_row10_col81"">-0.841655</td>
<td class=""data row10 col82"" id=""T_ed112_row10_col82"">-1.056842</td>
<td class=""data row10 col83"" id=""T_ed112_row10_col83"">-0.500226</td>
<td class=""data row10 col84"" id=""T_ed112_row10_col84"">0.096959</td>
<td class=""data row10 col85"" id=""T_ed112_row10_col85"">1.176896</td>
<td class=""data row10 col86"" id=""T_ed112_row10_col86"">-2.939652</td>
<td class=""data row10 col87"" id=""T_ed112_row10_col87"">1.792213</td>
<td class=""data row10 col88"" id=""T_ed112_row10_col88"">0.316340</td>
<td class=""data row10 col89"" id=""T_ed112_row10_col89"">0.303218</td>
<td class=""data row10 col90"" id=""T_ed112_row10_col90"">1.024967</td>
<td class=""data row10 col91"" id=""T_ed112_row10_col91"">-0.590871</td>
<td class=""data row10 col92"" id=""T_ed112_row10_col92"">-0.453326</td>
<td class=""data row10 col93"" id=""T_ed112_row10_col93"">-0.795981</td>
<td class=""data row10 col94"" id=""T_ed112_row10_col94"">-0.393301</td>
<td class=""data row10 col95"" id=""T_ed112_row10_col95"">-0.374372</td>
<td class=""data row10 col96"" id=""T_ed112_row10_col96"">-1.270199</td>
<td class=""data row10 col97"" id=""T_ed112_row10_col97"">1.618372</td>
<td class=""data row10 col98"" id=""T_ed112_row10_col98"">1.197727</td>
<td class=""data row10 col99"" id=""T_ed112_row10_col99"">-0.914863</td>
</tr>
<tr>
<th class=""row_heading level0 row11"" id=""T_ed112_level0_row11"">11</th>
<td class=""data row11 col0"" id=""T_ed112_row11_col0"">-0.625210</td>
<td class=""data row11 col1"" id=""T_ed112_row11_col1"">0.288911</td>
<td class=""data row11 col2"" id=""T_ed112_row11_col2"">0.288374</td>
<td class=""data row11 col3"" id=""T_ed112_row11_col3"">-1.372667</td>
<td class=""data row11 col4"" id=""T_ed112_row11_col4"">-0.591395</td>
<td class=""data row11 col5"" id=""T_ed112_row11_col5"">-0.478942</td>
<td class=""data row11 col6"" id=""T_ed112_row11_col6"">1.335664</td>
<td class=""data row11 col7"" id=""T_ed112_row11_col7"">-0.459855</td>
<td class=""data row11 col8"" id=""T_ed112_row11_col8"">-1.615975</td>
<td class=""data row11 col9"" id=""T_ed112_row11_col9"">-1.189676</td>
<td class=""data row11 col10"" id=""T_ed112_row11_col10"">0.374767</td>
<td class=""data row11 col11"" id=""T_ed112_row11_col11"">-2.488733</td>
<td class=""data row11 col12"" id=""T_ed112_row11_col12"">0.586656</td>
<td class=""data row11 col13"" id=""T_ed112_row11_col13"">-1.422008</td>
<td class=""data row11 col14"" id=""T_ed112_row11_col14"">0.496030</td>
<td class=""data row11 col15"" id=""T_ed112_row11_col15"">1.911128</td>
<td class=""data row11 col16"" id=""T_ed112_row11_col16"">-0.560660</td>
<td class=""data row11 col17"" id=""T_ed112_row11_col17"">-0.499614</td>
<td class=""data row11 col18"" id=""T_ed112_row11_col18"">-0.372171</td>
<td class=""data row11 col19"" id=""T_ed112_row11_col19"">-1.833069</td>
<td class=""data row11 col20"" id=""T_ed112_row11_col20"">0.237124</td>
<td class=""data row11 col21"" id=""T_ed112_row11_col21"">-0.944446</td>
<td class=""data row11 col22"" id=""T_ed112_row11_col22"">0.912140</td>
<td class=""data row11 col23"" id=""T_ed112_row11_col23"">0.359790</td>
<td class=""data row11 col24"" id=""T_ed112_row11_col24"">-1.359235</td>
<td class=""data row11 col25"" id=""T_ed112_row11_col25"">0.166966</td>
<td class=""data row11 col26"" id=""T_ed112_row11_col26"">-0.047107</td>
<td class=""data row11 col27"" id=""T_ed112_row11_col27"">-0.279789</td>
<td class=""data row11 col28"" id=""T_ed112_row11_col28"">-0.594454</td>
<td class=""data row11 col29"" id=""T_ed112_row11_col29"">-0.739013</td>
<td class=""data row11 col30"" id=""T_ed112_row11_col30"">-1.527645</td>
<td class=""data row11 col31"" id=""T_ed112_row11_col31"">0.401668</td>
<td class=""data row11 col32"" id=""T_ed112_row11_col32"">1.791252</td>
<td class=""data row11 col33"" id=""T_ed112_row11_col33"">-2.774848</td>
<td class=""data row11 col34"" id=""T_ed112_row11_col34"">0.523873</td>
<td class=""data row11 col35"" id=""T_ed112_row11_col35"">2.207585</td>
<td class=""data row11 col36"" id=""T_ed112_row11_col36"">0.488999</td>
<td class=""data row11 col37"" id=""T_ed112_row11_col37"">-0.339283</td>
<td class=""data row11 col38"" id=""T_ed112_row11_col38"">0.131711</td>
<td class=""data row11 col39"" id=""T_ed112_row11_col39"">0.018409</td>
<td class=""data row11 col40"" id=""T_ed112_row11_col40"">1.186551</td>
<td class=""data row11 col41"" id=""T_ed112_row11_col41"">-0.424318</td>
<td class=""data row11 col42"" id=""T_ed112_row11_col42"">1.554994</td>
<td class=""data row11 col43"" id=""T_ed112_row11_col43"">-0.205917</td>
<td class=""data row11 col44"" id=""T_ed112_row11_col44"">-0.934975</td>
<td class=""data row11 col45"" id=""T_ed112_row11_col45"">0.654102</td>
<td class=""data row11 col46"" id=""T_ed112_row11_col46"">-1.227761</td>
<td class=""data row11 col47"" id=""T_ed112_row11_col47"">-0.461025</td>
<td class=""data row11 col48"" id=""T_ed112_row11_col48"">-0.421201</td>
<td class=""data row11 col49"" id=""T_ed112_row11_col49"">-0.058615</td>
<td class=""data row11 col50"" id=""T_ed112_row11_col50"">-0.584563</td>
<td class=""data row11 col51"" id=""T_ed112_row11_col51"">0.336913</td>
<td class=""data row11 col52"" id=""T_ed112_row11_col52"">-0.477102</td>
<td class=""data row11 col53"" id=""T_ed112_row11_col53"">-1.381463</td>
<td class=""data row11 col54"" id=""T_ed112_row11_col54"">0.757745</td>
<td class=""data row11 col55"" id=""T_ed112_row11_col55"">-0.268968</td>
<td class=""data row11 col56"" id=""T_ed112_row11_col56"">0.034870</td>
<td class=""data row11 col57"" id=""T_ed112_row11_col57"">1.231686</td>
<td class=""data row11 col58"" id=""T_ed112_row11_col58"">0.236600</td>
<td class=""data row11 col59"" id=""T_ed112_row11_col59"">1.234720</td>
<td class=""data row11 col60"" id=""T_ed112_row11_col60"">-0.040247</td>
<td class=""data row11 col61"" id=""T_ed112_row11_col61"">0.029582</td>
<td class=""data row11 col62"" id=""T_ed112_row11_col62"">1.034905</td>
<td class=""data row11 col63"" id=""T_ed112_row11_col63"">0.380204</td>
<td class=""data row11 col64"" id=""T_ed112_row11_col64"">-0.012108</td>
<td class=""data row11 col65"" id=""T_ed112_row11_col65"">-0.859511</td>
<td class=""data row11 col66"" id=""T_ed112_row11_col66"">-0.990340</td>
<td class=""data row11 col67"" id=""T_ed112_row11_col67"">-1.205172</td>
<td class=""data row11 col68"" id=""T_ed112_row11_col68"">-1.030178</td>
<td class=""data row11 col69"" id=""T_ed112_row11_col69"">0.426676</td>
<td class=""data row11 col70"" id=""T_ed112_row11_col70"">0.497796</td>
<td class=""data row11 col71"" id=""T_ed112_row11_col71"">-0.876808</td>
<td class=""data row11 col72"" id=""T_ed112_row11_col72"">0.957963</td>
<td class=""data row11 col73"" id=""T_ed112_row11_col73"">0.173016</td>
<td class=""data row11 col74"" id=""T_ed112_row11_col74"">0.131612</td>
<td class=""data row11 col75"" id=""T_ed112_row11_col75"">-1.003556</td>
<td class=""data row11 col76"" id=""T_ed112_row11_col76"">-1.069908</td>
<td class=""data row11 col77"" id=""T_ed112_row11_col77"">-1.799207</td>
<td class=""data row11 col78"" id=""T_ed112_row11_col78"">1.429598</td>
<td class=""data row11 col79"" id=""T_ed112_row11_col79"">-0.116015</td>
<td class=""data row11 col80"" id=""T_ed112_row11_col80"">-1.454980</td>
<td class=""data row11 col81"" id=""T_ed112_row11_col81"">0.261917</td>
<td class=""data row11 col82"" id=""T_ed112_row11_col82"">0.444412</td>
<td class=""data row11 col83"" id=""T_ed112_row11_col83"">0.273290</td>
<td class=""data row11 col84"" id=""T_ed112_row11_col84"">0.844115</td>
<td class=""data row11 col85"" id=""T_ed112_row11_col85"">0.218745</td>
<td class=""data row11 col86"" id=""T_ed112_row11_col86"">-1.033350</td>
<td class=""data row11 col87"" id=""T_ed112_row11_col87"">-1.188295</td>
<td class=""data row11 col88"" id=""T_ed112_row11_col88"">0.058373</td>
<td class=""data row11 col89"" id=""T_ed112_row11_col89"">0.800523</td>
<td class=""data row11 col90"" id=""T_ed112_row11_col90"">-1.627068</td>
<td class=""data row11 col91"" id=""T_ed112_row11_col91"">0.861651</td>
<td class=""data row11 col92"" id=""T_ed112_row11_col92"">0.871018</td>
<td class=""data row11 col93"" id=""T_ed112_row11_col93"">-0.003733</td>
<td class=""data row11 col94"" id=""T_ed112_row11_col94"">-0.243354</td>
<td class=""data row11 col95"" id=""T_ed112_row11_col95"">0.947296</td>
<td class=""data row11 col96"" id=""T_ed112_row11_col96"">0.509406</td>
<td class=""data row11 col97"" id=""T_ed112_row11_col97"">0.044546</td>
<td class=""data row11 col98"" id=""T_ed112_row11_col98"">0.266896</td>
<td class=""data row11 col99"" id=""T_ed112_row11_col99"">1.337165</td>
</tr>
<tr>
<th class=""row_heading level0 row12"" id=""T_ed112_level0_row12"">12</th>
<td class=""data row12 col0"" id=""T_ed112_row12_col0"">0.699142</td>
<td class=""data row12 col1"" id=""T_ed112_row12_col1"">-1.928033</td>
<td class=""data row12 col2"" id=""T_ed112_row12_col2"">0.105363</td>
<td class=""data row12 col3"" id=""T_ed112_row12_col3"">1.042322</td>
<td class=""data row12 col4"" id=""T_ed112_row12_col4"">0.715206</td>
<td class=""data row12 col5"" id=""T_ed112_row12_col5"">-0.763783</td>
<td class=""data row12 col6"" id=""T_ed112_row12_col6"">0.098798</td>
<td class=""data row12 col7"" id=""T_ed112_row12_col7"">-1.157898</td>
<td class=""data row12 col8"" id=""T_ed112_row12_col8"">0.134105</td>
<td class=""data row12 col9"" id=""T_ed112_row12_col9"">0.042041</td>
<td class=""data row12 col10"" id=""T_ed112_row12_col10"">0.674826</td>
<td class=""data row12 col11"" id=""T_ed112_row12_col11"">0.165649</td>
<td class=""data row12 col12"" id=""T_ed112_row12_col12"">-1.622970</td>
<td class=""data row12 col13"" id=""T_ed112_row12_col13"">-3.131274</td>
<td class=""data row12 col14"" id=""T_ed112_row12_col14"">0.597649</td>
<td class=""data row12 col15"" id=""T_ed112_row12_col15"">-1.880331</td>
<td class=""data row12 col16"" id=""T_ed112_row12_col16"">0.663980</td>
<td class=""data row12 col17"" id=""T_ed112_row12_col17"">-0.256033</td>
<td class=""data row12 col18"" id=""T_ed112_row12_col18"">-1.524058</td>
<td class=""data row12 col19"" id=""T_ed112_row12_col19"">0.492799</td>
<td class=""data row12 col20"" id=""T_ed112_row12_col20"">0.221163</td>
<td class=""data row12 col21"" id=""T_ed112_row12_col21"">0.429622</td>
<td class=""data row12 col22"" id=""T_ed112_row12_col22"">-0.659584</td>
<td class=""data row12 col23"" id=""T_ed112_row12_col23"">1.264506</td>
<td class=""data row12 col24"" id=""T_ed112_row12_col24"">-0.032131</td>
<td class=""data row12 col25"" id=""T_ed112_row12_col25"">-2.114907</td>
<td class=""data row12 col26"" id=""T_ed112_row12_col26"">-0.264043</td>
<td class=""data row12 col27"" id=""T_ed112_row12_col27"">0.457835</td>
<td class=""data row12 col28"" id=""T_ed112_row12_col28"">-0.676837</td>
<td class=""data row12 col29"" id=""T_ed112_row12_col29"">-0.629003</td>
<td class=""data row12 col30"" id=""T_ed112_row12_col30"">0.489145</td>
<td class=""data row12 col31"" id=""T_ed112_row12_col31"">-0.551686</td>
<td class=""data row12 col32"" id=""T_ed112_row12_col32"">0.942622</td>
<td class=""data row12 col33"" id=""T_ed112_row12_col33"">-0.512043</td>
<td class=""data row12 col34"" id=""T_ed112_row12_col34"">-0.455893</td>
<td class=""data row12 col35"" id=""T_ed112_row12_col35"">0.021244</td>
<td class=""data row12 col36"" id=""T_ed112_row12_col36"">-0.178035</td>
<td class=""data row12 col37"" id=""T_ed112_row12_col37"">-2.498073</td>
<td class=""data row12 col38"" id=""T_ed112_row12_col38"">-0.171292</td>
<td class=""data row12 col39"" id=""T_ed112_row12_col39"">0.323510</td>
<td class=""data row12 col40"" id=""T_ed112_row12_col40"">-0.545163</td>
<td class=""data row12 col41"" id=""T_ed112_row12_col41"">-0.668909</td>
<td class=""data row12 col42"" id=""T_ed112_row12_col42"">-0.150031</td>
<td class=""data row12 col43"" id=""T_ed112_row12_col43"">0.521620</td>
<td class=""data row12 col44"" id=""T_ed112_row12_col44"">-0.428980</td>
<td class=""data row12 col45"" id=""T_ed112_row12_col45"">0.676463</td>
<td class=""data row12 col46"" id=""T_ed112_row12_col46"">0.369081</td>
<td class=""data row12 col47"" id=""T_ed112_row12_col47"">-0.724832</td>
<td class=""data row12 col48"" id=""T_ed112_row12_col48"">0.793542</td>
<td class=""data row12 col49"" id=""T_ed112_row12_col49"">1.237422</td>
<td class=""data row12 col50"" id=""T_ed112_row12_col50"">0.401275</td>
<td class=""data row12 col51"" id=""T_ed112_row12_col51"">2.141523</td>
<td class=""data row12 col52"" id=""T_ed112_row12_col52"">0.249012</td>
<td class=""data row12 col53"" id=""T_ed112_row12_col53"">0.486755</td>
<td class=""data row12 col54"" id=""T_ed112_row12_col54"">-0.163274</td>
<td class=""data row12 col55"" id=""T_ed112_row12_col55"">0.592222</td>
<td class=""data row12 col56"" id=""T_ed112_row12_col56"">-0.292600</td>
<td class=""data row12 col57"" id=""T_ed112_row12_col57"">-0.547168</td>
<td class=""data row12 col58"" id=""T_ed112_row12_col58"">0.619104</td>
<td class=""data row12 col59"" id=""T_ed112_row12_col59"">-0.013605</td>
<td class=""data row12 col60"" id=""T_ed112_row12_col60"">0.776734</td>
<td class=""data row12 col61"" id=""T_ed112_row12_col61"">0.131424</td>
<td class=""data row12 col62"" id=""T_ed112_row12_col62"">1.189480</td>
<td class=""data row12 col63"" id=""T_ed112_row12_col63"">-0.666317</td>
<td class=""data row12 col64"" id=""T_ed112_row12_col64"">-0.939036</td>
<td class=""data row12 col65"" id=""T_ed112_row12_col65"">1.105515</td>
<td class=""data row12 col66"" id=""T_ed112_row12_col66"">0.621452</td>
<td class=""data row12 col67"" id=""T_ed112_row12_col67"">1.586605</td>
<td class=""data row12 col68"" id=""T_ed112_row12_col68"">-0.760970</td>
<td class=""data row12 col69"" id=""T_ed112_row12_col69"">1.649646</td>
<td class=""data row12 col70"" id=""T_ed112_row12_col70"">0.283199</td>
<td class=""data row12 col71"" id=""T_ed112_row12_col71"">1.275812</td>
<td class=""data row12 col72"" id=""T_ed112_row12_col72"">-0.452012</td>
<td class=""data row12 col73"" id=""T_ed112_row12_col73"">0.301361</td>
<td class=""data row12 col74"" id=""T_ed112_row12_col74"">-0.976951</td>
<td class=""data row12 col75"" id=""T_ed112_row12_col75"">-0.268106</td>
<td class=""data row12 col76"" id=""T_ed112_row12_col76"">-0.079255</td>
<td class=""data row12 col77"" id=""T_ed112_row12_col77"">-1.258332</td>
<td class=""data row12 col78"" id=""T_ed112_row12_col78"">2.216658</td>
<td class=""data row12 col79"" id=""T_ed112_row12_col79"">-1.175988</td>
<td class=""data row12 col80"" id=""T_ed112_row12_col80"">-0.863497</td>
<td class=""data row12 col81"" id=""T_ed112_row12_col81"">-1.653022</td>
<td class=""data row12 col82"" id=""T_ed112_row12_col82"">-0.561514</td>
<td class=""data row12 col83"" id=""T_ed112_row12_col83"">0.450753</td>
<td class=""data row12 col84"" id=""T_ed112_row12_col84"">0.417200</td>
<td class=""data row12 col85"" id=""T_ed112_row12_col85"">0.094676</td>
<td class=""data row12 col86"" id=""T_ed112_row12_col86"">-2.231054</td>
<td class=""data row12 col87"" id=""T_ed112_row12_col87"">1.316862</td>
<td class=""data row12 col88"" id=""T_ed112_row12_col88"">-0.477441</td>
<td class=""data row12 col89"" id=""T_ed112_row12_col89"">0.646654</td>
<td class=""data row12 col90"" id=""T_ed112_row12_col90"">-0.200252</td>
<td class=""data row12 col91"" id=""T_ed112_row12_col91"">1.074354</td>
<td class=""data row12 col92"" id=""T_ed112_row12_col92"">-0.058176</td>
<td class=""data row12 col93"" id=""T_ed112_row12_col93"">0.120990</td>
<td class=""data row12 col94"" id=""T_ed112_row12_col94"">0.222522</td>
<td class=""data row12 col95"" id=""T_ed112_row12_col95"">-0.179507</td>
<td class=""data row12 col96"" id=""T_ed112_row12_col96"">0.421655</td>
<td class=""data row12 col97"" id=""T_ed112_row12_col97"">-0.914341</td>
<td class=""data row12 col98"" id=""T_ed112_row12_col98"">-0.234178</td>
<td class=""data row12 col99"" id=""T_ed112_row12_col99"">0.741524</td>
</tr>
<tr>
<th class=""row_heading level0 row13"" id=""T_ed112_level0_row13"">13</th>
<td class=""data row13 col0"" id=""T_ed112_row13_col0"">0.932714</td>
<td class=""data row13 col1"" id=""T_ed112_row13_col1"">1.423761</td>
<td class=""data row13 col2"" id=""T_ed112_row13_col2"">-1.280835</td>
<td class=""data row13 col3"" id=""T_ed112_row13_col3"">0.347882</td>
<td class=""data row13 col4"" id=""T_ed112_row13_col4"">-0.863171</td>
<td class=""data row13 col5"" id=""T_ed112_row13_col5"">-0.852580</td>
<td class=""data row13 col6"" id=""T_ed112_row13_col6"">1.044933</td>
<td class=""data row13 col7"" id=""T_ed112_row13_col7"">2.094536</td>
<td class=""data row13 col8"" id=""T_ed112_row13_col8"">0.806206</td>
<td class=""data row13 col9"" id=""T_ed112_row13_col9"">0.416201</td>
<td class=""data row13 col10"" id=""T_ed112_row13_col10"">-1.109503</td>
<td class=""data row13 col11"" id=""T_ed112_row13_col11"">0.145302</td>
<td class=""data row13 col12"" id=""T_ed112_row13_col12"">-0.996871</td>
<td class=""data row13 col13"" id=""T_ed112_row13_col13"">0.325456</td>
<td class=""data row13 col14"" id=""T_ed112_row13_col14"">-0.605081</td>
<td class=""data row13 col15"" id=""T_ed112_row13_col15"">1.175326</td>
<td class=""data row13 col16"" id=""T_ed112_row13_col16"">1.645054</td>
<td class=""data row13 col17"" id=""T_ed112_row13_col17"">0.293432</td>
<td class=""data row13 col18"" id=""T_ed112_row13_col18"">-2.766822</td>
<td class=""data row13 col19"" id=""T_ed112_row13_col19"">1.032849</td>
<td class=""data row13 col20"" id=""T_ed112_row13_col20"">0.079115</td>
<td class=""data row13 col21"" id=""T_ed112_row13_col21"">-1.414132</td>
<td class=""data row13 col22"" id=""T_ed112_row13_col22"">1.463376</td>
<td class=""data row13 col23"" id=""T_ed112_row13_col23"">2.335486</td>
<td class=""data row13 col24"" id=""T_ed112_row13_col24"">0.411951</td>
<td class=""data row13 col25"" id=""T_ed112_row13_col25"">-0.048543</td>
<td class=""data row13 col26"" id=""T_ed112_row13_col26"">0.159284</td>
<td class=""data row13 col27"" id=""T_ed112_row13_col27"">-0.651554</td>
<td class=""data row13 col28"" id=""T_ed112_row13_col28"">-1.093128</td>
<td class=""data row13 col29"" id=""T_ed112_row13_col29"">1.568390</td>
<td class=""data row13 col30"" id=""T_ed112_row13_col30"">-0.077807</td>
<td class=""data row13 col31"" id=""T_ed112_row13_col31"">-2.390779</td>
<td class=""data row13 col32"" id=""T_ed112_row13_col32"">-0.842346</td>
<td class=""data row13 col33"" id=""T_ed112_row13_col33"">-0.229675</td>
<td class=""data row13 col34"" id=""T_ed112_row13_col34"">-0.999072</td>
<td class=""data row13 col35"" id=""T_ed112_row13_col35"">-1.367219</td>
<td class=""data row13 col36"" id=""T_ed112_row13_col36"">-0.792042</td>
<td class=""data row13 col37"" id=""T_ed112_row13_col37"">-1.878575</td>
<td class=""data row13 col38"" id=""T_ed112_row13_col38"">1.451452</td>
<td class=""data row13 col39"" id=""T_ed112_row13_col39"">1.266250</td>
<td class=""data row13 col40"" id=""T_ed112_row13_col40"">-0.734315</td>
<td class=""data row13 col41"" id=""T_ed112_row13_col41"">0.266152</td>
<td class=""data row13 col42"" id=""T_ed112_row13_col42"">0.735523</td>
<td class=""data row13 col43"" id=""T_ed112_row13_col43"">-0.430860</td>
<td class=""data row13 col44"" id=""T_ed112_row13_col44"">0.229864</td>
<td class=""data row13 col45"" id=""T_ed112_row13_col45"">0.850083</td>
<td class=""data row13 col46"" id=""T_ed112_row13_col46"">-2.241241</td>
<td class=""data row13 col47"" id=""T_ed112_row13_col47"">1.063850</td>
<td class=""data row13 col48"" id=""T_ed112_row13_col48"">0.289409</td>
<td class=""data row13 col49"" id=""T_ed112_row13_col49"">-0.354360</td>
<td class=""data row13 col50"" id=""T_ed112_row13_col50"">0.113063</td>
<td class=""data row13 col51"" id=""T_ed112_row13_col51"">-0.173006</td>
<td class=""data row13 col52"" id=""T_ed112_row13_col52"">1.386998</td>
<td class=""data row13 col53"" id=""T_ed112_row13_col53"">1.886236</td>
<td class=""data row13 col54"" id=""T_ed112_row13_col54"">0.587119</td>
<td class=""data row13 col55"" id=""T_ed112_row13_col55"">-0.961133</td>
<td class=""data row13 col56"" id=""T_ed112_row13_col56"">0.399295</td>
<td class=""data row13 col57"" id=""T_ed112_row13_col57"">1.461560</td>
<td class=""data row13 col58"" id=""T_ed112_row13_col58"">0.310823</td>
<td class=""data row13 col59"" id=""T_ed112_row13_col59"">0.280220</td>
<td class=""data row13 col60"" id=""T_ed112_row13_col60"">-0.879103</td>
<td class=""data row13 col61"" id=""T_ed112_row13_col61"">-1.326348</td>
<td class=""data row13 col62"" id=""T_ed112_row13_col62"">0.003337</td>
<td class=""data row13 col63"" id=""T_ed112_row13_col63"">-1.085908</td>
<td class=""data row13 col64"" id=""T_ed112_row13_col64"">-0.436723</td>
<td class=""data row13 col65"" id=""T_ed112_row13_col65"">2.111926</td>
<td class=""data row13 col66"" id=""T_ed112_row13_col66"">0.106068</td>
<td class=""data row13 col67"" id=""T_ed112_row13_col67"">0.615597</td>
<td class=""data row13 col68"" id=""T_ed112_row13_col68"">2.152996</td>
<td class=""data row13 col69"" id=""T_ed112_row13_col69"">-0.196155</td>
<td class=""data row13 col70"" id=""T_ed112_row13_col70"">0.025747</td>
<td class=""data row13 col71"" id=""T_ed112_row13_col71"">-0.039061</td>
<td class=""data row13 col72"" id=""T_ed112_row13_col72"">0.656823</td>
<td class=""data row13 col73"" id=""T_ed112_row13_col73"">-0.347105</td>
<td class=""data row13 col74"" id=""T_ed112_row13_col74"">2.513979</td>
<td class=""data row13 col75"" id=""T_ed112_row13_col75"">1.758070</td>
<td class=""data row13 col76"" id=""T_ed112_row13_col76"">1.288473</td>
<td class=""data row13 col77"" id=""T_ed112_row13_col77"">-0.739185</td>
<td class=""data row13 col78"" id=""T_ed112_row13_col78"">-0.691592</td>
<td class=""data row13 col79"" id=""T_ed112_row13_col79"">-0.098728</td>
<td class=""data row13 col80"" id=""T_ed112_row13_col80"">-0.276386</td>
<td class=""data row13 col81"" id=""T_ed112_row13_col81"">0.489981</td>
<td class=""data row13 col82"" id=""T_ed112_row13_col82"">0.516278</td>
<td class=""data row13 col83"" id=""T_ed112_row13_col83"">-0.838258</td>
<td class=""data row13 col84"" id=""T_ed112_row13_col84"">0.596673</td>
<td class=""data row13 col85"" id=""T_ed112_row13_col85"">-0.331053</td>
<td class=""data row13 col86"" id=""T_ed112_row13_col86"">0.521174</td>
<td class=""data row13 col87"" id=""T_ed112_row13_col87"">-0.145023</td>
<td class=""data row13 col88"" id=""T_ed112_row13_col88"">0.836693</td>
<td class=""data row13 col89"" id=""T_ed112_row13_col89"">-1.092166</td>
<td class=""data row13 col90"" id=""T_ed112_row13_col90"">0.361733</td>
<td class=""data row13 col91"" id=""T_ed112_row13_col91"">-1.169981</td>
<td class=""data row13 col92"" id=""T_ed112_row13_col92"">0.046731</td>
<td class=""data row13 col93"" id=""T_ed112_row13_col93"">0.655377</td>
<td class=""data row13 col94"" id=""T_ed112_row13_col94"">-0.756852</td>
<td class=""data row13 col95"" id=""T_ed112_row13_col95"">1.285805</td>
<td class=""data row13 col96"" id=""T_ed112_row13_col96"">-0.095019</td>
<td class=""data row13 col97"" id=""T_ed112_row13_col97"">0.360253</td>
<td class=""data row13 col98"" id=""T_ed112_row13_col98"">1.370621</td>
<td class=""data row13 col99"" id=""T_ed112_row13_col99"">0.083010</td>
</tr>
<tr>
<th class=""row_heading level0 row14"" id=""T_ed112_level0_row14"">14</th>
<td class=""data row14 col0"" id=""T_ed112_row14_col0"">0.888893</td>
<td class=""data row14 col1"" id=""T_ed112_row14_col1"">2.288725</td>
<td class=""data row14 col2"" id=""T_ed112_row14_col2"">-1.032332</td>
<td class=""data row14 col3"" id=""T_ed112_row14_col3"">0.212273</td>
<td class=""data row14 col4"" id=""T_ed112_row14_col4"">-1.091826</td>
<td class=""data row14 col5"" id=""T_ed112_row14_col5"">1.692498</td>
<td class=""data row14 col6"" id=""T_ed112_row14_col6"">1.025367</td>
<td class=""data row14 col7"" id=""T_ed112_row14_col7"">0.550854</td>
<td class=""data row14 col8"" id=""T_ed112_row14_col8"">0.679430</td>
<td class=""data row14 col9"" id=""T_ed112_row14_col9"">-1.335712</td>
<td class=""data row14 col10"" id=""T_ed112_row14_col10"">-0.798341</td>
<td class=""data row14 col11"" id=""T_ed112_row14_col11"">2.265351</td>
<td class=""data row14 col12"" id=""T_ed112_row14_col12"">-1.006938</td>
<td class=""data row14 col13"" id=""T_ed112_row14_col13"">2.059761</td>
<td class=""data row14 col14"" id=""T_ed112_row14_col14"">0.420266</td>
<td class=""data row14 col15"" id=""T_ed112_row14_col15"">-1.189657</td>
<td class=""data row14 col16"" id=""T_ed112_row14_col16"">0.506674</td>
<td class=""data row14 col17"" id=""T_ed112_row14_col17"">0.260847</td>
<td class=""data row14 col18"" id=""T_ed112_row14_col18"">-0.533145</td>
<td class=""data row14 col19"" id=""T_ed112_row14_col19"">0.727267</td>
<td class=""data row14 col20"" id=""T_ed112_row14_col20"">1.412276</td>
<td class=""data row14 col21"" id=""T_ed112_row14_col21"">1.482106</td>
<td class=""data row14 col22"" id=""T_ed112_row14_col22"">-0.996258</td>
<td class=""data row14 col23"" id=""T_ed112_row14_col23"">0.588641</td>
<td class=""data row14 col24"" id=""T_ed112_row14_col24"">-0.412642</td>
<td class=""data row14 col25"" id=""T_ed112_row14_col25"">-0.920733</td>
<td class=""data row14 col26"" id=""T_ed112_row14_col26"">-0.874691</td>
<td class=""data row14 col27"" id=""T_ed112_row14_col27"">0.839002</td>
<td class=""data row14 col28"" id=""T_ed112_row14_col28"">0.501668</td>
<td class=""data row14 col29"" id=""T_ed112_row14_col29"">-0.342493</td>
<td class=""data row14 col30"" id=""T_ed112_row14_col30"">-0.533806</td>
<td class=""data row14 col31"" id=""T_ed112_row14_col31"">-2.146352</td>
<td class=""data row14 col32"" id=""T_ed112_row14_col32"">-0.597339</td>
<td class=""data row14 col33"" id=""T_ed112_row14_col33"">0.115726</td>
<td class=""data row14 col34"" id=""T_ed112_row14_col34"">0.850683</td>
<td class=""data row14 col35"" id=""T_ed112_row14_col35"">-0.752239</td>
<td class=""data row14 col36"" id=""T_ed112_row14_col36"">0.377263</td>
<td class=""data row14 col37"" id=""T_ed112_row14_col37"">-0.561982</td>
<td class=""data row14 col38"" id=""T_ed112_row14_col38"">0.262783</td>
<td class=""data row14 col39"" id=""T_ed112_row14_col39"">-0.356676</td>
<td class=""data row14 col40"" id=""T_ed112_row14_col40"">-0.367462</td>
<td class=""data row14 col41"" id=""T_ed112_row14_col41"">0.753611</td>
<td class=""data row14 col42"" id=""T_ed112_row14_col42"">-1.267414</td>
<td class=""data row14 col43"" id=""T_ed112_row14_col43"">-1.330698</td>
<td class=""data row14 col44"" id=""T_ed112_row14_col44"">-0.536453</td>
<td class=""data row14 col45"" id=""T_ed112_row14_col45"">0.840938</td>
<td class=""data row14 col46"" id=""T_ed112_row14_col46"">-0.763108</td>
<td class=""data row14 col47"" id=""T_ed112_row14_col47"">-0.268100</td>
<td class=""data row14 col48"" id=""T_ed112_row14_col48"">-0.677424</td>
<td class=""data row14 col49"" id=""T_ed112_row14_col49"">1.606831</td>
<td class=""data row14 col50"" id=""T_ed112_row14_col50"">0.151732</td>
<td class=""data row14 col51"" id=""T_ed112_row14_col51"">-2.085701</td>
<td class=""data row14 col52"" id=""T_ed112_row14_col52"">1.219296</td>
<td class=""data row14 col53"" id=""T_ed112_row14_col53"">0.400863</td>
<td class=""data row14 col54"" id=""T_ed112_row14_col54"">0.591165</td>
<td class=""data row14 col55"" id=""T_ed112_row14_col55"">-1.485213</td>
<td class=""data row14 col56"" id=""T_ed112_row14_col56"">1.501979</td>
<td class=""data row14 col57"" id=""T_ed112_row14_col57"">1.196569</td>
<td class=""data row14 col58"" id=""T_ed112_row14_col58"">-0.214154</td>
<td class=""data row14 col59"" id=""T_ed112_row14_col59"">0.339554</td>
<td class=""data row14 col60"" id=""T_ed112_row14_col60"">-0.034446</td>
<td class=""data row14 col61"" id=""T_ed112_row14_col61"">1.176452</td>
<td class=""data row14 col62"" id=""T_ed112_row14_col62"">0.546340</td>
<td class=""data row14 col63"" id=""T_ed112_row14_col63"">-1.255630</td>
<td class=""data row14 col64"" id=""T_ed112_row14_col64"">-1.309210</td>
<td class=""data row14 col65"" id=""T_ed112_row14_col65"">-0.445437</td>
<td class=""data row14 col66"" id=""T_ed112_row14_col66"">0.189437</td>
<td class=""data row14 col67"" id=""T_ed112_row14_col67"">-0.737463</td>
<td class=""data row14 col68"" id=""T_ed112_row14_col68"">0.843767</td>
<td class=""data row14 col69"" id=""T_ed112_row14_col69"">-0.605632</td>
<td class=""data row14 col70"" id=""T_ed112_row14_col70"">-0.060777</td>
<td class=""data row14 col71"" id=""T_ed112_row14_col71"">0.409310</td>
<td class=""data row14 col72"" id=""T_ed112_row14_col72"">1.285569</td>
<td class=""data row14 col73"" id=""T_ed112_row14_col73"">-0.622638</td>
<td class=""data row14 col74"" id=""T_ed112_row14_col74"">1.018193</td>
<td class=""data row14 col75"" id=""T_ed112_row14_col75"">0.880680</td>
<td class=""data row14 col76"" id=""T_ed112_row14_col76"">0.046805</td>
<td class=""data row14 col77"" id=""T_ed112_row14_col77"">-1.818058</td>
<td class=""data row14 col78"" id=""T_ed112_row14_col78"">-0.809829</td>
<td class=""data row14 col79"" id=""T_ed112_row14_col79"">0.875224</td>
<td class=""data row14 col80"" id=""T_ed112_row14_col80"">0.409569</td>
<td class=""data row14 col81"" id=""T_ed112_row14_col81"">-0.116621</td>
<td class=""data row14 col82"" id=""T_ed112_row14_col82"">-1.238919</td>
<td class=""data row14 col83"" id=""T_ed112_row14_col83"">3.305724</td>
<td class=""data row14 col84"" id=""T_ed112_row14_col84"">-0.024121</td>
<td class=""data row14 col85"" id=""T_ed112_row14_col85"">-1.756500</td>
<td class=""data row14 col86"" id=""T_ed112_row14_col86"">1.328958</td>
<td class=""data row14 col87"" id=""T_ed112_row14_col87"">0.507593</td>
<td class=""data row14 col88"" id=""T_ed112_row14_col88"">-0.866554</td>
<td class=""data row14 col89"" id=""T_ed112_row14_col89"">-2.240848</td>
<td class=""data row14 col90"" id=""T_ed112_row14_col90"">-0.661376</td>
<td class=""data row14 col91"" id=""T_ed112_row14_col91"">-0.671824</td>
<td class=""data row14 col92"" id=""T_ed112_row14_col92"">0.215720</td>
<td class=""data row14 col93"" id=""T_ed112_row14_col93"">-0.296326</td>
<td class=""data row14 col94"" id=""T_ed112_row14_col94"">0.481402</td>
<td class=""data row14 col95"" id=""T_ed112_row14_col95"">0.829645</td>
<td class=""data row14 col96"" id=""T_ed112_row14_col96"">-0.721025</td>
<td class=""data row14 col97"" id=""T_ed112_row14_col97"">1.263914</td>
<td class=""data row14 col98"" id=""T_ed112_row14_col98"">0.549047</td>
<td class=""data row14 col99"" id=""T_ed112_row14_col99"">-1.234945</td>
</tr>
<tr>
<th class=""row_heading level0 row15"" id=""T_ed112_level0_row15"">15</th>
<td class=""data row15 col0"" id=""T_ed112_row15_col0"">-1.978838</td>
<td class=""data row15 col1"" id=""T_ed112_row15_col1"">0.721823</td>
<td class=""data row15 col2"" id=""T_ed112_row15_col2"">-0.559067</td>
<td class=""data row15 col3"" id=""T_ed112_row15_col3"">-1.235243</td>
<td class=""data row15 col4"" id=""T_ed112_row15_col4"">0.420716</td>
<td class=""data row15 col5"" id=""T_ed112_row15_col5"">-0.598845</td>
<td class=""data row15 col6"" id=""T_ed112_row15_col6"">0.359576</td>
<td class=""data row15 col7"" id=""T_ed112_row15_col7"">-0.619366</td>
<td class=""data row15 col8"" id=""T_ed112_row15_col8"">-1.757772</td>
<td class=""data row15 col9"" id=""T_ed112_row15_col9"">-1.156251</td>
<td class=""data row15 col10"" id=""T_ed112_row15_col10"">0.705212</td>
<td class=""data row15 col11"" id=""T_ed112_row15_col11"">0.875071</td>
<td class=""data row15 col12"" id=""T_ed112_row15_col12"">-1.020376</td>
<td class=""data row15 col13"" id=""T_ed112_row15_col13"">0.394760</td>
<td class=""data row15 col14"" id=""T_ed112_row15_col14"">-0.147970</td>
<td class=""data row15 col15"" id=""T_ed112_row15_col15"">0.230249</td>
<td class=""data row15 col16"" id=""T_ed112_row15_col16"">1.355203</td>
<td class=""data row15 col17"" id=""T_ed112_row15_col17"">1.794488</td>
<td class=""data row15 col18"" id=""T_ed112_row15_col18"">2.678058</td>
<td class=""data row15 col19"" id=""T_ed112_row15_col19"">-0.153565</td>
<td class=""data row15 col20"" id=""T_ed112_row15_col20"">-0.460959</td>
<td class=""data row15 col21"" id=""T_ed112_row15_col21"">-0.098108</td>
<td class=""data row15 col22"" id=""T_ed112_row15_col22"">-1.407930</td>
<td class=""data row15 col23"" id=""T_ed112_row15_col23"">-2.487702</td>
<td class=""data row15 col24"" id=""T_ed112_row15_col24"">1.823014</td>
<td class=""data row15 col25"" id=""T_ed112_row15_col25"">0.099873</td>
<td class=""data row15 col26"" id=""T_ed112_row15_col26"">-0.517603</td>
<td class=""data row15 col27"" id=""T_ed112_row15_col27"">-0.509311</td>
<td class=""data row15 col28"" id=""T_ed112_row15_col28"">-1.833175</td>
<td class=""data row15 col29"" id=""T_ed112_row15_col29"">-0.900906</td>
<td class=""data row15 col30"" id=""T_ed112_row15_col30"">0.459493</td>
<td class=""data row15 col31"" id=""T_ed112_row15_col31"">-0.655440</td>
<td class=""data row15 col32"" id=""T_ed112_row15_col32"">1.466122</td>
<td class=""data row15 col33"" id=""T_ed112_row15_col33"">-1.531389</td>
<td class=""data row15 col34"" id=""T_ed112_row15_col34"">-0.422106</td>
<td class=""data row15 col35"" id=""T_ed112_row15_col35"">0.421422</td>
<td class=""data row15 col36"" id=""T_ed112_row15_col36"">0.578615</td>
<td class=""data row15 col37"" id=""T_ed112_row15_col37"">0.259795</td>
<td class=""data row15 col38"" id=""T_ed112_row15_col38"">0.018941</td>
<td class=""data row15 col39"" id=""T_ed112_row15_col39"">-0.168726</td>
<td class=""data row15 col40"" id=""T_ed112_row15_col40"">1.611107</td>
<td class=""data row15 col41"" id=""T_ed112_row15_col41"">-1.586550</td>
<td class=""data row15 col42"" id=""T_ed112_row15_col42"">-1.384941</td>
<td class=""data row15 col43"" id=""T_ed112_row15_col43"">0.858377</td>
<td class=""data row15 col44"" id=""T_ed112_row15_col44"">1.033242</td>
<td class=""data row15 col45"" id=""T_ed112_row15_col45"">1.701343</td>
<td class=""data row15 col46"" id=""T_ed112_row15_col46"">1.748344</td>
<td class=""data row15 col47"" id=""T_ed112_row15_col47"">-0.371182</td>
<td class=""data row15 col48"" id=""T_ed112_row15_col48"">-0.843575</td>
<td class=""data row15 col49"" id=""T_ed112_row15_col49"">2.089641</td>
<td class=""data row15 col50"" id=""T_ed112_row15_col50"">-0.345430</td>
<td class=""data row15 col51"" id=""T_ed112_row15_col51"">-1.740556</td>
<td class=""data row15 col52"" id=""T_ed112_row15_col52"">0.141915</td>
<td class=""data row15 col53"" id=""T_ed112_row15_col53"">-2.197138</td>
<td class=""data row15 col54"" id=""T_ed112_row15_col54"">0.689569</td>
<td class=""data row15 col55"" id=""T_ed112_row15_col55"">-0.150025</td>
<td class=""data row15 col56"" id=""T_ed112_row15_col56"">0.287456</td>
<td class=""data row15 col57"" id=""T_ed112_row15_col57"">0.654016</td>
<td class=""data row15 col58"" id=""T_ed112_row15_col58"">-1.521919</td>
<td class=""data row15 col59"" id=""T_ed112_row15_col59"">-0.918008</td>
<td class=""data row15 col60"" id=""T_ed112_row15_col60"">-0.587528</td>
<td class=""data row15 col61"" id=""T_ed112_row15_col61"">0.230636</td>
<td class=""data row15 col62"" id=""T_ed112_row15_col62"">0.262637</td>
<td class=""data row15 col63"" id=""T_ed112_row15_col63"">0.615674</td>
<td class=""data row15 col64"" id=""T_ed112_row15_col64"">0.600044</td>
<td class=""data row15 col65"" id=""T_ed112_row15_col65"">-0.494699</td>
<td class=""data row15 col66"" id=""T_ed112_row15_col66"">-0.743089</td>
<td class=""data row15 col67"" id=""T_ed112_row15_col67"">0.220026</td>
<td class=""data row15 col68"" id=""T_ed112_row15_col68"">-0.242207</td>
<td class=""data row15 col69"" id=""T_ed112_row15_col69"">0.528216</td>
<td class=""data row15 col70"" id=""T_ed112_row15_col70"">-0.328174</td>
<td class=""data row15 col71"" id=""T_ed112_row15_col71"">-1.536517</td>
<td class=""data row15 col72"" id=""T_ed112_row15_col72"">-1.476640</td>
<td class=""data row15 col73"" id=""T_ed112_row15_col73"">-1.162114</td>
<td class=""data row15 col74"" id=""T_ed112_row15_col74"">-1.260222</td>
<td class=""data row15 col75"" id=""T_ed112_row15_col75"">1.106252</td>
<td class=""data row15 col76"" id=""T_ed112_row15_col76"">-1.467408</td>
<td class=""data row15 col77"" id=""T_ed112_row15_col77"">-0.349341</td>
<td class=""data row15 col78"" id=""T_ed112_row15_col78"">-1.841217</td>
<td class=""data row15 col79"" id=""T_ed112_row15_col79"">0.031296</td>
<td class=""data row15 col80"" id=""T_ed112_row15_col80"">-0.076475</td>
<td class=""data row15 col81"" id=""T_ed112_row15_col81"">-0.353383</td>
<td class=""data row15 col82"" id=""T_ed112_row15_col82"">0.807545</td>
<td class=""data row15 col83"" id=""T_ed112_row15_col83"">0.779064</td>
<td class=""data row15 col84"" id=""T_ed112_row15_col84"">-2.398417</td>
<td class=""data row15 col85"" id=""T_ed112_row15_col85"">-0.267828</td>
<td class=""data row15 col86"" id=""T_ed112_row15_col86"">1.549734</td>
<td class=""data row15 col87"" id=""T_ed112_row15_col87"">0.814397</td>
<td class=""data row15 col88"" id=""T_ed112_row15_col88"">0.284770</td>
<td class=""data row15 col89"" id=""T_ed112_row15_col89"">-0.659369</td>
<td class=""data row15 col90"" id=""T_ed112_row15_col90"">0.761040</td>
<td class=""data row15 col91"" id=""T_ed112_row15_col91"">-0.722067</td>
<td class=""data row15 col92"" id=""T_ed112_row15_col92"">0.810332</td>
<td class=""data row15 col93"" id=""T_ed112_row15_col93"">1.501295</td>
<td class=""data row15 col94"" id=""T_ed112_row15_col94"">1.440865</td>
<td class=""data row15 col95"" id=""T_ed112_row15_col95"">-1.367459</td>
<td class=""data row15 col96"" id=""T_ed112_row15_col96"">-0.700301</td>
<td class=""data row15 col97"" id=""T_ed112_row15_col97"">-1.540662</td>
<td class=""data row15 col98"" id=""T_ed112_row15_col98"">0.159837</td>
<td class=""data row15 col99"" id=""T_ed112_row15_col99"">-0.625415</td>
</tr>
</tbody>
</table></div>
</div>
<p>It is also possible to stick MultiIndexes and even only specific levels.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[66]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">bigdf</span><span class=""o"">.</span><span class=""n"">index</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">MultiIndex</span><span class=""o"">.</span><span class=""n"">from_product</span><span class=""p"">([[</span><span class=""s2"">""A""</span><span class=""p"">,</span><span class=""s2"">""B""</span><span class=""p"">],[</span><span class=""mi"">0</span><span class=""p"">,</span><span class=""mi"">1</span><span class=""p"">],[</span><span class=""mi"">0</span><span class=""p"">,</span><span class=""mi"">1</span><span class=""p"">,</span><span class=""mi"">2</span><span class=""p"">,</span><span class=""mi"">3</span><span class=""p"">]])</span>
<span class=""n"">bigdf</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">set_sticky</span><span class=""p"">(</span><span class=""n"">axis</span><span class=""o"">=</span><span class=""s2"">""index""</span><span class=""p"">,</span> <span class=""n"">pixel_size</span><span class=""o"">=</span><span class=""mi"">18</span><span class=""p"">,</span> <span class=""n"">levels</span><span class=""o"">=</span><span class=""p"">[</span><span class=""mi"">1</span><span class=""p"">,</span><span class=""mi"">2</span><span class=""p"">])</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[66]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_f5094 thead tr th:nth-child(2) {
  position: sticky;
  background-color: inherit;
  left: 0px;
  min-width: 18px;
  max-width: 18px;
  z-index: 3 !important;
}
#T_f5094 tbody tr th.level1 {
  position: sticky;
  background-color: inherit;
  left: 0px;
  min-width: 18px;
  max-width: 18px;
  z-index: 1;
}
#T_f5094 thead tr th:nth-child(3) {
  position: sticky;
  background-color: inherit;
  left: 18px;
  min-width: 18px;
  max-width: 18px;
  z-index: 3 !important;
}
#T_f5094 tbody tr th.level2 {
  position: sticky;
  background-color: inherit;
  left: 18px;
  min-width: 18px;
  max-width: 18px;
  z-index: 1;
}
</style>
<table id=""T_f5094"">
<thead>
<tr>
<th class=""blank""> </th>
<th class=""blank""> </th>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_f5094_level0_col0"">0</th>
<th class=""col_heading level0 col1"" id=""T_f5094_level0_col1"">1</th>
<th class=""col_heading level0 col2"" id=""T_f5094_level0_col2"">2</th>
<th class=""col_heading level0 col3"" id=""T_f5094_level0_col3"">3</th>
<th class=""col_heading level0 col4"" id=""T_f5094_level0_col4"">4</th>
<th class=""col_heading level0 col5"" id=""T_f5094_level0_col5"">5</th>
<th class=""col_heading level0 col6"" id=""T_f5094_level0_col6"">6</th>
<th class=""col_heading level0 col7"" id=""T_f5094_level0_col7"">7</th>
<th class=""col_heading level0 col8"" id=""T_f5094_level0_col8"">8</th>
<th class=""col_heading level0 col9"" id=""T_f5094_level0_col9"">9</th>
<th class=""col_heading level0 col10"" id=""T_f5094_level0_col10"">10</th>
<th class=""col_heading level0 col11"" id=""T_f5094_level0_col11"">11</th>
<th class=""col_heading level0 col12"" id=""T_f5094_level0_col12"">12</th>
<th class=""col_heading level0 col13"" id=""T_f5094_level0_col13"">13</th>
<th class=""col_heading level0 col14"" id=""T_f5094_level0_col14"">14</th>
<th class=""col_heading level0 col15"" id=""T_f5094_level0_col15"">15</th>
<th class=""col_heading level0 col16"" id=""T_f5094_level0_col16"">16</th>
<th class=""col_heading level0 col17"" id=""T_f5094_level0_col17"">17</th>
<th class=""col_heading level0 col18"" id=""T_f5094_level0_col18"">18</th>
<th class=""col_heading level0 col19"" id=""T_f5094_level0_col19"">19</th>
<th class=""col_heading level0 col20"" id=""T_f5094_level0_col20"">20</th>
<th class=""col_heading level0 col21"" id=""T_f5094_level0_col21"">21</th>
<th class=""col_heading level0 col22"" id=""T_f5094_level0_col22"">22</th>
<th class=""col_heading level0 col23"" id=""T_f5094_level0_col23"">23</th>
<th class=""col_heading level0 col24"" id=""T_f5094_level0_col24"">24</th>
<th class=""col_heading level0 col25"" id=""T_f5094_level0_col25"">25</th>
<th class=""col_heading level0 col26"" id=""T_f5094_level0_col26"">26</th>
<th class=""col_heading level0 col27"" id=""T_f5094_level0_col27"">27</th>
<th class=""col_heading level0 col28"" id=""T_f5094_level0_col28"">28</th>
<th class=""col_heading level0 col29"" id=""T_f5094_level0_col29"">29</th>
<th class=""col_heading level0 col30"" id=""T_f5094_level0_col30"">30</th>
<th class=""col_heading level0 col31"" id=""T_f5094_level0_col31"">31</th>
<th class=""col_heading level0 col32"" id=""T_f5094_level0_col32"">32</th>
<th class=""col_heading level0 col33"" id=""T_f5094_level0_col33"">33</th>
<th class=""col_heading level0 col34"" id=""T_f5094_level0_col34"">34</th>
<th class=""col_heading level0 col35"" id=""T_f5094_level0_col35"">35</th>
<th class=""col_heading level0 col36"" id=""T_f5094_level0_col36"">36</th>
<th class=""col_heading level0 col37"" id=""T_f5094_level0_col37"">37</th>
<th class=""col_heading level0 col38"" id=""T_f5094_level0_col38"">38</th>
<th class=""col_heading level0 col39"" id=""T_f5094_level0_col39"">39</th>
<th class=""col_heading level0 col40"" id=""T_f5094_level0_col40"">40</th>
<th class=""col_heading level0 col41"" id=""T_f5094_level0_col41"">41</th>
<th class=""col_heading level0 col42"" id=""T_f5094_level0_col42"">42</th>
<th class=""col_heading level0 col43"" id=""T_f5094_level0_col43"">43</th>
<th class=""col_heading level0 col44"" id=""T_f5094_level0_col44"">44</th>
<th class=""col_heading level0 col45"" id=""T_f5094_level0_col45"">45</th>
<th class=""col_heading level0 col46"" id=""T_f5094_level0_col46"">46</th>
<th class=""col_heading level0 col47"" id=""T_f5094_level0_col47"">47</th>
<th class=""col_heading level0 col48"" id=""T_f5094_level0_col48"">48</th>
<th class=""col_heading level0 col49"" id=""T_f5094_level0_col49"">49</th>
<th class=""col_heading level0 col50"" id=""T_f5094_level0_col50"">50</th>
<th class=""col_heading level0 col51"" id=""T_f5094_level0_col51"">51</th>
<th class=""col_heading level0 col52"" id=""T_f5094_level0_col52"">52</th>
<th class=""col_heading level0 col53"" id=""T_f5094_level0_col53"">53</th>
<th class=""col_heading level0 col54"" id=""T_f5094_level0_col54"">54</th>
<th class=""col_heading level0 col55"" id=""T_f5094_level0_col55"">55</th>
<th class=""col_heading level0 col56"" id=""T_f5094_level0_col56"">56</th>
<th class=""col_heading level0 col57"" id=""T_f5094_level0_col57"">57</th>
<th class=""col_heading level0 col58"" id=""T_f5094_level0_col58"">58</th>
<th class=""col_heading level0 col59"" id=""T_f5094_level0_col59"">59</th>
<th class=""col_heading level0 col60"" id=""T_f5094_level0_col60"">60</th>
<th class=""col_heading level0 col61"" id=""T_f5094_level0_col61"">61</th>
<th class=""col_heading level0 col62"" id=""T_f5094_level0_col62"">62</th>
<th class=""col_heading level0 col63"" id=""T_f5094_level0_col63"">63</th>
<th class=""col_heading level0 col64"" id=""T_f5094_level0_col64"">64</th>
<th class=""col_heading level0 col65"" id=""T_f5094_level0_col65"">65</th>
<th class=""col_heading level0 col66"" id=""T_f5094_level0_col66"">66</th>
<th class=""col_heading level0 col67"" id=""T_f5094_level0_col67"">67</th>
<th class=""col_heading level0 col68"" id=""T_f5094_level0_col68"">68</th>
<th class=""col_heading level0 col69"" id=""T_f5094_level0_col69"">69</th>
<th class=""col_heading level0 col70"" id=""T_f5094_level0_col70"">70</th>
<th class=""col_heading level0 col71"" id=""T_f5094_level0_col71"">71</th>
<th class=""col_heading level0 col72"" id=""T_f5094_level0_col72"">72</th>
<th class=""col_heading level0 col73"" id=""T_f5094_level0_col73"">73</th>
<th class=""col_heading level0 col74"" id=""T_f5094_level0_col74"">74</th>
<th class=""col_heading level0 col75"" id=""T_f5094_level0_col75"">75</th>
<th class=""col_heading level0 col76"" id=""T_f5094_level0_col76"">76</th>
<th class=""col_heading level0 col77"" id=""T_f5094_level0_col77"">77</th>
<th class=""col_heading level0 col78"" id=""T_f5094_level0_col78"">78</th>
<th class=""col_heading level0 col79"" id=""T_f5094_level0_col79"">79</th>
<th class=""col_heading level0 col80"" id=""T_f5094_level0_col80"">80</th>
<th class=""col_heading level0 col81"" id=""T_f5094_level0_col81"">81</th>
<th class=""col_heading level0 col82"" id=""T_f5094_level0_col82"">82</th>
<th class=""col_heading level0 col83"" id=""T_f5094_level0_col83"">83</th>
<th class=""col_heading level0 col84"" id=""T_f5094_level0_col84"">84</th>
<th class=""col_heading level0 col85"" id=""T_f5094_level0_col85"">85</th>
<th class=""col_heading level0 col86"" id=""T_f5094_level0_col86"">86</th>
<th class=""col_heading level0 col87"" id=""T_f5094_level0_col87"">87</th>
<th class=""col_heading level0 col88"" id=""T_f5094_level0_col88"">88</th>
<th class=""col_heading level0 col89"" id=""T_f5094_level0_col89"">89</th>
<th class=""col_heading level0 col90"" id=""T_f5094_level0_col90"">90</th>
<th class=""col_heading level0 col91"" id=""T_f5094_level0_col91"">91</th>
<th class=""col_heading level0 col92"" id=""T_f5094_level0_col92"">92</th>
<th class=""col_heading level0 col93"" id=""T_f5094_level0_col93"">93</th>
<th class=""col_heading level0 col94"" id=""T_f5094_level0_col94"">94</th>
<th class=""col_heading level0 col95"" id=""T_f5094_level0_col95"">95</th>
<th class=""col_heading level0 col96"" id=""T_f5094_level0_col96"">96</th>
<th class=""col_heading level0 col97"" id=""T_f5094_level0_col97"">97</th>
<th class=""col_heading level0 col98"" id=""T_f5094_level0_col98"">98</th>
<th class=""col_heading level0 col99"" id=""T_f5094_level0_col99"">99</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_f5094_level0_row0"" rowspan=""8"">A</th>
<th class=""row_heading level1 row0"" id=""T_f5094_level1_row0"" rowspan=""4"">0</th>
<th class=""row_heading level2 row0"" id=""T_f5094_level2_row0"">0</th>
<td class=""data row0 col0"" id=""T_f5094_row0_col0"">-0.773866</td>
<td class=""data row0 col1"" id=""T_f5094_row0_col1"">-0.240521</td>
<td class=""data row0 col2"" id=""T_f5094_row0_col2"">-0.217165</td>
<td class=""data row0 col3"" id=""T_f5094_row0_col3"">1.173609</td>
<td class=""data row0 col4"" id=""T_f5094_row0_col4"">0.686390</td>
<td class=""data row0 col5"" id=""T_f5094_row0_col5"">0.008358</td>
<td class=""data row0 col6"" id=""T_f5094_row0_col6"">0.696232</td>
<td class=""data row0 col7"" id=""T_f5094_row0_col7"">0.173166</td>
<td class=""data row0 col8"" id=""T_f5094_row0_col8"">0.620498</td>
<td class=""data row0 col9"" id=""T_f5094_row0_col9"">0.504067</td>
<td class=""data row0 col10"" id=""T_f5094_row0_col10"">0.428066</td>
<td class=""data row0 col11"" id=""T_f5094_row0_col11"">-0.051824</td>
<td class=""data row0 col12"" id=""T_f5094_row0_col12"">0.719915</td>
<td class=""data row0 col13"" id=""T_f5094_row0_col13"">0.057165</td>
<td class=""data row0 col14"" id=""T_f5094_row0_col14"">0.562808</td>
<td class=""data row0 col15"" id=""T_f5094_row0_col15"">-0.369536</td>
<td class=""data row0 col16"" id=""T_f5094_row0_col16"">0.483399</td>
<td class=""data row0 col17"" id=""T_f5094_row0_col17"">0.620765</td>
<td class=""data row0 col18"" id=""T_f5094_row0_col18"">-0.354342</td>
<td class=""data row0 col19"" id=""T_f5094_row0_col19"">-1.469471</td>
<td class=""data row0 col20"" id=""T_f5094_row0_col20"">-1.937266</td>
<td class=""data row0 col21"" id=""T_f5094_row0_col21"">0.038031</td>
<td class=""data row0 col22"" id=""T_f5094_row0_col22"">-1.518162</td>
<td class=""data row0 col23"" id=""T_f5094_row0_col23"">-0.417599</td>
<td class=""data row0 col24"" id=""T_f5094_row0_col24"">0.386717</td>
<td class=""data row0 col25"" id=""T_f5094_row0_col25"">0.716193</td>
<td class=""data row0 col26"" id=""T_f5094_row0_col26"">0.489961</td>
<td class=""data row0 col27"" id=""T_f5094_row0_col27"">0.733957</td>
<td class=""data row0 col28"" id=""T_f5094_row0_col28"">0.914415</td>
<td class=""data row0 col29"" id=""T_f5094_row0_col29"">0.679894</td>
<td class=""data row0 col30"" id=""T_f5094_row0_col30"">0.255448</td>
<td class=""data row0 col31"" id=""T_f5094_row0_col31"">-0.508338</td>
<td class=""data row0 col32"" id=""T_f5094_row0_col32"">0.332030</td>
<td class=""data row0 col33"" id=""T_f5094_row0_col33"">-0.111107</td>
<td class=""data row0 col34"" id=""T_f5094_row0_col34"">-0.251983</td>
<td class=""data row0 col35"" id=""T_f5094_row0_col35"">-1.456620</td>
<td class=""data row0 col36"" id=""T_f5094_row0_col36"">0.409630</td>
<td class=""data row0 col37"" id=""T_f5094_row0_col37"">1.062320</td>
<td class=""data row0 col38"" id=""T_f5094_row0_col38"">-0.577115</td>
<td class=""data row0 col39"" id=""T_f5094_row0_col39"">0.718796</td>
<td class=""data row0 col40"" id=""T_f5094_row0_col40"">-0.399260</td>
<td class=""data row0 col41"" id=""T_f5094_row0_col41"">-1.311389</td>
<td class=""data row0 col42"" id=""T_f5094_row0_col42"">0.649122</td>
<td class=""data row0 col43"" id=""T_f5094_row0_col43"">0.091566</td>
<td class=""data row0 col44"" id=""T_f5094_row0_col44"">0.628872</td>
<td class=""data row0 col45"" id=""T_f5094_row0_col45"">0.297894</td>
<td class=""data row0 col46"" id=""T_f5094_row0_col46"">-0.142290</td>
<td class=""data row0 col47"" id=""T_f5094_row0_col47"">-0.542291</td>
<td class=""data row0 col48"" id=""T_f5094_row0_col48"">-0.914290</td>
<td class=""data row0 col49"" id=""T_f5094_row0_col49"">1.144514</td>
<td class=""data row0 col50"" id=""T_f5094_row0_col50"">0.313584</td>
<td class=""data row0 col51"" id=""T_f5094_row0_col51"">1.182635</td>
<td class=""data row0 col52"" id=""T_f5094_row0_col52"">1.214235</td>
<td class=""data row0 col53"" id=""T_f5094_row0_col53"">-0.416446</td>
<td class=""data row0 col54"" id=""T_f5094_row0_col54"">-1.653940</td>
<td class=""data row0 col55"" id=""T_f5094_row0_col55"">-2.550787</td>
<td class=""data row0 col56"" id=""T_f5094_row0_col56"">0.442473</td>
<td class=""data row0 col57"" id=""T_f5094_row0_col57"">0.052127</td>
<td class=""data row0 col58"" id=""T_f5094_row0_col58"">-0.464469</td>
<td class=""data row0 col59"" id=""T_f5094_row0_col59"">-0.523852</td>
<td class=""data row0 col60"" id=""T_f5094_row0_col60"">0.989726</td>
<td class=""data row0 col61"" id=""T_f5094_row0_col61"">-1.325539</td>
<td class=""data row0 col62"" id=""T_f5094_row0_col62"">-0.199687</td>
<td class=""data row0 col63"" id=""T_f5094_row0_col63"">-1.226727</td>
<td class=""data row0 col64"" id=""T_f5094_row0_col64"">0.290018</td>
<td class=""data row0 col65"" id=""T_f5094_row0_col65"">1.164574</td>
<td class=""data row0 col66"" id=""T_f5094_row0_col66"">0.817841</td>
<td class=""data row0 col67"" id=""T_f5094_row0_col67"">-0.309509</td>
<td class=""data row0 col68"" id=""T_f5094_row0_col68"">0.496599</td>
<td class=""data row0 col69"" id=""T_f5094_row0_col69"">0.943536</td>
<td class=""data row0 col70"" id=""T_f5094_row0_col70"">-0.091850</td>
<td class=""data row0 col71"" id=""T_f5094_row0_col71"">-2.802658</td>
<td class=""data row0 col72"" id=""T_f5094_row0_col72"">2.126219</td>
<td class=""data row0 col73"" id=""T_f5094_row0_col73"">-0.521161</td>
<td class=""data row0 col74"" id=""T_f5094_row0_col74"">0.288098</td>
<td class=""data row0 col75"" id=""T_f5094_row0_col75"">-0.454663</td>
<td class=""data row0 col76"" id=""T_f5094_row0_col76"">-1.676143</td>
<td class=""data row0 col77"" id=""T_f5094_row0_col77"">-0.357661</td>
<td class=""data row0 col78"" id=""T_f5094_row0_col78"">-0.788960</td>
<td class=""data row0 col79"" id=""T_f5094_row0_col79"">0.185911</td>
<td class=""data row0 col80"" id=""T_f5094_row0_col80"">-0.017106</td>
<td class=""data row0 col81"" id=""T_f5094_row0_col81"">2.454020</td>
<td class=""data row0 col82"" id=""T_f5094_row0_col82"">1.832706</td>
<td class=""data row0 col83"" id=""T_f5094_row0_col83"">-0.911743</td>
<td class=""data row0 col84"" id=""T_f5094_row0_col84"">-0.655873</td>
<td class=""data row0 col85"" id=""T_f5094_row0_col85"">-0.000514</td>
<td class=""data row0 col86"" id=""T_f5094_row0_col86"">-2.226997</td>
<td class=""data row0 col87"" id=""T_f5094_row0_col87"">0.677285</td>
<td class=""data row0 col88"" id=""T_f5094_row0_col88"">-0.140249</td>
<td class=""data row0 col89"" id=""T_f5094_row0_col89"">-0.408407</td>
<td class=""data row0 col90"" id=""T_f5094_row0_col90"">-0.838665</td>
<td class=""data row0 col91"" id=""T_f5094_row0_col91"">0.482228</td>
<td class=""data row0 col92"" id=""T_f5094_row0_col92"">1.243458</td>
<td class=""data row0 col93"" id=""T_f5094_row0_col93"">-0.477394</td>
<td class=""data row0 col94"" id=""T_f5094_row0_col94"">-0.220343</td>
<td class=""data row0 col95"" id=""T_f5094_row0_col95"">-2.463966</td>
<td class=""data row0 col96"" id=""T_f5094_row0_col96"">0.237325</td>
<td class=""data row0 col97"" id=""T_f5094_row0_col97"">-0.307380</td>
<td class=""data row0 col98"" id=""T_f5094_row0_col98"">1.172478</td>
<td class=""data row0 col99"" id=""T_f5094_row0_col99"">0.819492</td>
</tr>
<tr>
<th class=""row_heading level2 row1"" id=""T_f5094_level2_row1"">1</th>
<td class=""data row1 col0"" id=""T_f5094_row1_col0"">0.405906</td>
<td class=""data row1 col1"" id=""T_f5094_row1_col1"">-0.978919</td>
<td class=""data row1 col2"" id=""T_f5094_row1_col2"">1.267526</td>
<td class=""data row1 col3"" id=""T_f5094_row1_col3"">0.145250</td>
<td class=""data row1 col4"" id=""T_f5094_row1_col4"">-1.066786</td>
<td class=""data row1 col5"" id=""T_f5094_row1_col5"">-2.114192</td>
<td class=""data row1 col6"" id=""T_f5094_row1_col6"">-1.128346</td>
<td class=""data row1 col7"" id=""T_f5094_row1_col7"">-1.082523</td>
<td class=""data row1 col8"" id=""T_f5094_row1_col8"">0.372216</td>
<td class=""data row1 col9"" id=""T_f5094_row1_col9"">0.004127</td>
<td class=""data row1 col10"" id=""T_f5094_row1_col10"">-0.211984</td>
<td class=""data row1 col11"" id=""T_f5094_row1_col11"">0.937326</td>
<td class=""data row1 col12"" id=""T_f5094_row1_col12"">-0.935890</td>
<td class=""data row1 col13"" id=""T_f5094_row1_col13"">-1.704118</td>
<td class=""data row1 col14"" id=""T_f5094_row1_col14"">0.611789</td>
<td class=""data row1 col15"" id=""T_f5094_row1_col15"">-1.030015</td>
<td class=""data row1 col16"" id=""T_f5094_row1_col16"">0.636123</td>
<td class=""data row1 col17"" id=""T_f5094_row1_col17"">-1.506193</td>
<td class=""data row1 col18"" id=""T_f5094_row1_col18"">1.736609</td>
<td class=""data row1 col19"" id=""T_f5094_row1_col19"">1.392958</td>
<td class=""data row1 col20"" id=""T_f5094_row1_col20"">1.009424</td>
<td class=""data row1 col21"" id=""T_f5094_row1_col21"">0.353266</td>
<td class=""data row1 col22"" id=""T_f5094_row1_col22"">0.697339</td>
<td class=""data row1 col23"" id=""T_f5094_row1_col23"">-0.297424</td>
<td class=""data row1 col24"" id=""T_f5094_row1_col24"">0.428702</td>
<td class=""data row1 col25"" id=""T_f5094_row1_col25"">-0.145346</td>
<td class=""data row1 col26"" id=""T_f5094_row1_col26"">-0.333553</td>
<td class=""data row1 col27"" id=""T_f5094_row1_col27"">-0.974699</td>
<td class=""data row1 col28"" id=""T_f5094_row1_col28"">0.665314</td>
<td class=""data row1 col29"" id=""T_f5094_row1_col29"">0.971944</td>
<td class=""data row1 col30"" id=""T_f5094_row1_col30"">0.121950</td>
<td class=""data row1 col31"" id=""T_f5094_row1_col31"">-1.439668</td>
<td class=""data row1 col32"" id=""T_f5094_row1_col32"">1.018808</td>
<td class=""data row1 col33"" id=""T_f5094_row1_col33"">1.442399</td>
<td class=""data row1 col34"" id=""T_f5094_row1_col34"">-0.199585</td>
<td class=""data row1 col35"" id=""T_f5094_row1_col35"">-1.165916</td>
<td class=""data row1 col36"" id=""T_f5094_row1_col36"">0.645656</td>
<td class=""data row1 col37"" id=""T_f5094_row1_col37"">1.436466</td>
<td class=""data row1 col38"" id=""T_f5094_row1_col38"">-0.921215</td>
<td class=""data row1 col39"" id=""T_f5094_row1_col39"">1.293906</td>
<td class=""data row1 col40"" id=""T_f5094_row1_col40"">-2.706443</td>
<td class=""data row1 col41"" id=""T_f5094_row1_col41"">1.460928</td>
<td class=""data row1 col42"" id=""T_f5094_row1_col42"">-0.823197</td>
<td class=""data row1 col43"" id=""T_f5094_row1_col43"">0.292952</td>
<td class=""data row1 col44"" id=""T_f5094_row1_col44"">-1.448992</td>
<td class=""data row1 col45"" id=""T_f5094_row1_col45"">0.026692</td>
<td class=""data row1 col46"" id=""T_f5094_row1_col46"">-0.975883</td>
<td class=""data row1 col47"" id=""T_f5094_row1_col47"">0.392823</td>
<td class=""data row1 col48"" id=""T_f5094_row1_col48"">0.442166</td>
<td class=""data row1 col49"" id=""T_f5094_row1_col49"">0.745741</td>
<td class=""data row1 col50"" id=""T_f5094_row1_col50"">1.187982</td>
<td class=""data row1 col51"" id=""T_f5094_row1_col51"">-0.218570</td>
<td class=""data row1 col52"" id=""T_f5094_row1_col52"">0.305288</td>
<td class=""data row1 col53"" id=""T_f5094_row1_col53"">0.054932</td>
<td class=""data row1 col54"" id=""T_f5094_row1_col54"">-1.476953</td>
<td class=""data row1 col55"" id=""T_f5094_row1_col55"">-0.114434</td>
<td class=""data row1 col56"" id=""T_f5094_row1_col56"">0.014103</td>
<td class=""data row1 col57"" id=""T_f5094_row1_col57"">0.825394</td>
<td class=""data row1 col58"" id=""T_f5094_row1_col58"">-0.060654</td>
<td class=""data row1 col59"" id=""T_f5094_row1_col59"">-0.413688</td>
<td class=""data row1 col60"" id=""T_f5094_row1_col60"">0.974836</td>
<td class=""data row1 col61"" id=""T_f5094_row1_col61"">1.339210</td>
<td class=""data row1 col62"" id=""T_f5094_row1_col62"">1.034838</td>
<td class=""data row1 col63"" id=""T_f5094_row1_col63"">0.040775</td>
<td class=""data row1 col64"" id=""T_f5094_row1_col64"">0.705001</td>
<td class=""data row1 col65"" id=""T_f5094_row1_col65"">0.017796</td>
<td class=""data row1 col66"" id=""T_f5094_row1_col66"">1.867681</td>
<td class=""data row1 col67"" id=""T_f5094_row1_col67"">-0.390173</td>
<td class=""data row1 col68"" id=""T_f5094_row1_col68"">2.285277</td>
<td class=""data row1 col69"" id=""T_f5094_row1_col69"">2.311464</td>
<td class=""data row1 col70"" id=""T_f5094_row1_col70"">-0.085070</td>
<td class=""data row1 col71"" id=""T_f5094_row1_col71"">-0.648115</td>
<td class=""data row1 col72"" id=""T_f5094_row1_col72"">0.576300</td>
<td class=""data row1 col73"" id=""T_f5094_row1_col73"">-0.790087</td>
<td class=""data row1 col74"" id=""T_f5094_row1_col74"">-1.183798</td>
<td class=""data row1 col75"" id=""T_f5094_row1_col75"">-1.334558</td>
<td class=""data row1 col76"" id=""T_f5094_row1_col76"">-0.454118</td>
<td class=""data row1 col77"" id=""T_f5094_row1_col77"">0.319302</td>
<td class=""data row1 col78"" id=""T_f5094_row1_col78"">1.706488</td>
<td class=""data row1 col79"" id=""T_f5094_row1_col79"">0.830429</td>
<td class=""data row1 col80"" id=""T_f5094_row1_col80"">0.502476</td>
<td class=""data row1 col81"" id=""T_f5094_row1_col81"">-0.079631</td>
<td class=""data row1 col82"" id=""T_f5094_row1_col82"">0.414635</td>
<td class=""data row1 col83"" id=""T_f5094_row1_col83"">0.332511</td>
<td class=""data row1 col84"" id=""T_f5094_row1_col84"">0.042935</td>
<td class=""data row1 col85"" id=""T_f5094_row1_col85"">-0.160910</td>
<td class=""data row1 col86"" id=""T_f5094_row1_col86"">0.918553</td>
<td class=""data row1 col87"" id=""T_f5094_row1_col87"">-0.292697</td>
<td class=""data row1 col88"" id=""T_f5094_row1_col88"">-1.303834</td>
<td class=""data row1 col89"" id=""T_f5094_row1_col89"">-0.199604</td>
<td class=""data row1 col90"" id=""T_f5094_row1_col90"">0.871023</td>
<td class=""data row1 col91"" id=""T_f5094_row1_col91"">-1.370681</td>
<td class=""data row1 col92"" id=""T_f5094_row1_col92"">-0.205701</td>
<td class=""data row1 col93"" id=""T_f5094_row1_col93"">-0.492973</td>
<td class=""data row1 col94"" id=""T_f5094_row1_col94"">1.123083</td>
<td class=""data row1 col95"" id=""T_f5094_row1_col95"">-0.081842</td>
<td class=""data row1 col96"" id=""T_f5094_row1_col96"">-0.118527</td>
<td class=""data row1 col97"" id=""T_f5094_row1_col97"">0.245838</td>
<td class=""data row1 col98"" id=""T_f5094_row1_col98"">-0.315742</td>
<td class=""data row1 col99"" id=""T_f5094_row1_col99"">-0.511806</td>
</tr>
<tr>
<th class=""row_heading level2 row2"" id=""T_f5094_level2_row2"">2</th>
<td class=""data row2 col0"" id=""T_f5094_row2_col0"">0.011470</td>
<td class=""data row2 col1"" id=""T_f5094_row2_col1"">-0.036104</td>
<td class=""data row2 col2"" id=""T_f5094_row2_col2"">1.399603</td>
<td class=""data row2 col3"" id=""T_f5094_row2_col3"">-0.418176</td>
<td class=""data row2 col4"" id=""T_f5094_row2_col4"">-0.412229</td>
<td class=""data row2 col5"" id=""T_f5094_row2_col5"">-1.234783</td>
<td class=""data row2 col6"" id=""T_f5094_row2_col6"">-1.121500</td>
<td class=""data row2 col7"" id=""T_f5094_row2_col7"">1.196478</td>
<td class=""data row2 col8"" id=""T_f5094_row2_col8"">-0.569522</td>
<td class=""data row2 col9"" id=""T_f5094_row2_col9"">0.422022</td>
<td class=""data row2 col10"" id=""T_f5094_row2_col10"">-0.220484</td>
<td class=""data row2 col11"" id=""T_f5094_row2_col11"">0.804338</td>
<td class=""data row2 col12"" id=""T_f5094_row2_col12"">2.892667</td>
<td class=""data row2 col13"" id=""T_f5094_row2_col13"">-0.511055</td>
<td class=""data row2 col14"" id=""T_f5094_row2_col14"">-0.168722</td>
<td class=""data row2 col15"" id=""T_f5094_row2_col15"">-1.477996</td>
<td class=""data row2 col16"" id=""T_f5094_row2_col16"">-1.969917</td>
<td class=""data row2 col17"" id=""T_f5094_row2_col17"">0.471354</td>
<td class=""data row2 col18"" id=""T_f5094_row2_col18"">1.698548</td>
<td class=""data row2 col19"" id=""T_f5094_row2_col19"">0.137105</td>
<td class=""data row2 col20"" id=""T_f5094_row2_col20"">-0.762052</td>
<td class=""data row2 col21"" id=""T_f5094_row2_col21"">0.199379</td>
<td class=""data row2 col22"" id=""T_f5094_row2_col22"">-0.964346</td>
<td class=""data row2 col23"" id=""T_f5094_row2_col23"">-0.256692</td>
<td class=""data row2 col24"" id=""T_f5094_row2_col24"">1.265275</td>
<td class=""data row2 col25"" id=""T_f5094_row2_col25"">0.848762</td>
<td class=""data row2 col26"" id=""T_f5094_row2_col26"">-0.784161</td>
<td class=""data row2 col27"" id=""T_f5094_row2_col27"">1.863776</td>
<td class=""data row2 col28"" id=""T_f5094_row2_col28"">-0.355569</td>
<td class=""data row2 col29"" id=""T_f5094_row2_col29"">0.854552</td>
<td class=""data row2 col30"" id=""T_f5094_row2_col30"">0.768061</td>
<td class=""data row2 col31"" id=""T_f5094_row2_col31"">-2.075718</td>
<td class=""data row2 col32"" id=""T_f5094_row2_col32"">-2.501069</td>
<td class=""data row2 col33"" id=""T_f5094_row2_col33"">1.109868</td>
<td class=""data row2 col34"" id=""T_f5094_row2_col34"">0.957545</td>
<td class=""data row2 col35"" id=""T_f5094_row2_col35"">-0.683276</td>
<td class=""data row2 col36"" id=""T_f5094_row2_col36"">0.307764</td>
<td class=""data row2 col37"" id=""T_f5094_row2_col37"">0.733073</td>
<td class=""data row2 col38"" id=""T_f5094_row2_col38"">1.706250</td>
<td class=""data row2 col39"" id=""T_f5094_row2_col39"">-1.118091</td>
<td class=""data row2 col40"" id=""T_f5094_row2_col40"">0.374961</td>
<td class=""data row2 col41"" id=""T_f5094_row2_col41"">-1.414503</td>
<td class=""data row2 col42"" id=""T_f5094_row2_col42"">-0.524183</td>
<td class=""data row2 col43"" id=""T_f5094_row2_col43"">-1.662696</td>
<td class=""data row2 col44"" id=""T_f5094_row2_col44"">0.687921</td>
<td class=""data row2 col45"" id=""T_f5094_row2_col45"">0.521732</td>
<td class=""data row2 col46"" id=""T_f5094_row2_col46"">1.451396</td>
<td class=""data row2 col47"" id=""T_f5094_row2_col47"">-0.833491</td>
<td class=""data row2 col48"" id=""T_f5094_row2_col48"">-0.362796</td>
<td class=""data row2 col49"" id=""T_f5094_row2_col49"">-1.174444</td>
<td class=""data row2 col50"" id=""T_f5094_row2_col50"">-0.813893</td>
<td class=""data row2 col51"" id=""T_f5094_row2_col51"">-0.893220</td>
<td class=""data row2 col52"" id=""T_f5094_row2_col52"">0.770743</td>
<td class=""data row2 col53"" id=""T_f5094_row2_col53"">1.156647</td>
<td class=""data row2 col54"" id=""T_f5094_row2_col54"">-0.647444</td>
<td class=""data row2 col55"" id=""T_f5094_row2_col55"">0.125929</td>
<td class=""data row2 col56"" id=""T_f5094_row2_col56"">0.513600</td>
<td class=""data row2 col57"" id=""T_f5094_row2_col57"">-0.537874</td>
<td class=""data row2 col58"" id=""T_f5094_row2_col58"">1.992052</td>
<td class=""data row2 col59"" id=""T_f5094_row2_col59"">-1.946584</td>
<td class=""data row2 col60"" id=""T_f5094_row2_col60"">-0.104759</td>
<td class=""data row2 col61"" id=""T_f5094_row2_col61"">0.484779</td>
<td class=""data row2 col62"" id=""T_f5094_row2_col62"">-0.290936</td>
<td class=""data row2 col63"" id=""T_f5094_row2_col63"">-0.441075</td>
<td class=""data row2 col64"" id=""T_f5094_row2_col64"">0.542993</td>
<td class=""data row2 col65"" id=""T_f5094_row2_col65"">-1.050038</td>
<td class=""data row2 col66"" id=""T_f5094_row2_col66"">1.630482</td>
<td class=""data row2 col67"" id=""T_f5094_row2_col67"">0.239771</td>
<td class=""data row2 col68"" id=""T_f5094_row2_col68"">-1.177310</td>
<td class=""data row2 col69"" id=""T_f5094_row2_col69"">0.464804</td>
<td class=""data row2 col70"" id=""T_f5094_row2_col70"">-0.966995</td>
<td class=""data row2 col71"" id=""T_f5094_row2_col71"">0.646086</td>
<td class=""data row2 col72"" id=""T_f5094_row2_col72"">0.486899</td>
<td class=""data row2 col73"" id=""T_f5094_row2_col73"">1.022196</td>
<td class=""data row2 col74"" id=""T_f5094_row2_col74"">-2.267827</td>
<td class=""data row2 col75"" id=""T_f5094_row2_col75"">-1.229616</td>
<td class=""data row2 col76"" id=""T_f5094_row2_col76"">1.313805</td>
<td class=""data row2 col77"" id=""T_f5094_row2_col77"">1.073292</td>
<td class=""data row2 col78"" id=""T_f5094_row2_col78"">2.324940</td>
<td class=""data row2 col79"" id=""T_f5094_row2_col79"">-0.542720</td>
<td class=""data row2 col80"" id=""T_f5094_row2_col80"">-1.504292</td>
<td class=""data row2 col81"" id=""T_f5094_row2_col81"">0.777643</td>
<td class=""data row2 col82"" id=""T_f5094_row2_col82"">-0.618553</td>
<td class=""data row2 col83"" id=""T_f5094_row2_col83"">0.011342</td>
<td class=""data row2 col84"" id=""T_f5094_row2_col84"">1.385062</td>
<td class=""data row2 col85"" id=""T_f5094_row2_col85"">1.363552</td>
<td class=""data row2 col86"" id=""T_f5094_row2_col86"">-0.549834</td>
<td class=""data row2 col87"" id=""T_f5094_row2_col87"">0.688896</td>
<td class=""data row2 col88"" id=""T_f5094_row2_col88"">1.361288</td>
<td class=""data row2 col89"" id=""T_f5094_row2_col89"">-0.381137</td>
<td class=""data row2 col90"" id=""T_f5094_row2_col90"">0.797812</td>
<td class=""data row2 col91"" id=""T_f5094_row2_col91"">-1.128198</td>
<td class=""data row2 col92"" id=""T_f5094_row2_col92"">0.369208</td>
<td class=""data row2 col93"" id=""T_f5094_row2_col93"">0.540132</td>
<td class=""data row2 col94"" id=""T_f5094_row2_col94"">0.413853</td>
<td class=""data row2 col95"" id=""T_f5094_row2_col95"">-0.200308</td>
<td class=""data row2 col96"" id=""T_f5094_row2_col96"">-0.969126</td>
<td class=""data row2 col97"" id=""T_f5094_row2_col97"">0.981293</td>
<td class=""data row2 col98"" id=""T_f5094_row2_col98"">-0.009783</td>
<td class=""data row2 col99"" id=""T_f5094_row2_col99"">-0.320020</td>
</tr>
<tr>
<th class=""row_heading level2 row3"" id=""T_f5094_level2_row3"">3</th>
<td class=""data row3 col0"" id=""T_f5094_row3_col0"">-0.574816</td>
<td class=""data row3 col1"" id=""T_f5094_row3_col1"">1.419977</td>
<td class=""data row3 col2"" id=""T_f5094_row3_col2"">0.434813</td>
<td class=""data row3 col3"" id=""T_f5094_row3_col3"">-1.101217</td>
<td class=""data row3 col4"" id=""T_f5094_row3_col4"">-1.586275</td>
<td class=""data row3 col5"" id=""T_f5094_row3_col5"">1.979573</td>
<td class=""data row3 col6"" id=""T_f5094_row3_col6"">0.378298</td>
<td class=""data row3 col7"" id=""T_f5094_row3_col7"">0.782326</td>
<td class=""data row3 col8"" id=""T_f5094_row3_col8"">2.178987</td>
<td class=""data row3 col9"" id=""T_f5094_row3_col9"">0.657564</td>
<td class=""data row3 col10"" id=""T_f5094_row3_col10"">0.683774</td>
<td class=""data row3 col11"" id=""T_f5094_row3_col11"">-0.091000</td>
<td class=""data row3 col12"" id=""T_f5094_row3_col12"">-0.059552</td>
<td class=""data row3 col13"" id=""T_f5094_row3_col13"">-0.738908</td>
<td class=""data row3 col14"" id=""T_f5094_row3_col14"">-0.907653</td>
<td class=""data row3 col15"" id=""T_f5094_row3_col15"">-0.701936</td>
<td class=""data row3 col16"" id=""T_f5094_row3_col16"">0.580039</td>
<td class=""data row3 col17"" id=""T_f5094_row3_col17"">-0.618757</td>
<td class=""data row3 col18"" id=""T_f5094_row3_col18"">0.453684</td>
<td class=""data row3 col19"" id=""T_f5094_row3_col19"">1.665382</td>
<td class=""data row3 col20"" id=""T_f5094_row3_col20"">-0.152321</td>
<td class=""data row3 col21"" id=""T_f5094_row3_col21"">0.880077</td>
<td class=""data row3 col22"" id=""T_f5094_row3_col22"">0.571073</td>
<td class=""data row3 col23"" id=""T_f5094_row3_col23"">-0.604736</td>
<td class=""data row3 col24"" id=""T_f5094_row3_col24"">0.532359</td>
<td class=""data row3 col25"" id=""T_f5094_row3_col25"">0.515031</td>
<td class=""data row3 col26"" id=""T_f5094_row3_col26"">-0.959844</td>
<td class=""data row3 col27"" id=""T_f5094_row3_col27"">-0.887184</td>
<td class=""data row3 col28"" id=""T_f5094_row3_col28"">0.435781</td>
<td class=""data row3 col29"" id=""T_f5094_row3_col29"">0.862093</td>
<td class=""data row3 col30"" id=""T_f5094_row3_col30"">-0.956321</td>
<td class=""data row3 col31"" id=""T_f5094_row3_col31"">-0.625909</td>
<td class=""data row3 col32"" id=""T_f5094_row3_col32"">0.194472</td>
<td class=""data row3 col33"" id=""T_f5094_row3_col33"">0.442490</td>
<td class=""data row3 col34"" id=""T_f5094_row3_col34"">0.526503</td>
<td class=""data row3 col35"" id=""T_f5094_row3_col35"">-0.215274</td>
<td class=""data row3 col36"" id=""T_f5094_row3_col36"">0.090711</td>
<td class=""data row3 col37"" id=""T_f5094_row3_col37"">0.932592</td>
<td class=""data row3 col38"" id=""T_f5094_row3_col38"">0.811999</td>
<td class=""data row3 col39"" id=""T_f5094_row3_col39"">-2.497026</td>
<td class=""data row3 col40"" id=""T_f5094_row3_col40"">0.631545</td>
<td class=""data row3 col41"" id=""T_f5094_row3_col41"">0.321418</td>
<td class=""data row3 col42"" id=""T_f5094_row3_col42"">-0.425549</td>
<td class=""data row3 col43"" id=""T_f5094_row3_col43"">-1.078832</td>
<td class=""data row3 col44"" id=""T_f5094_row3_col44"">0.753444</td>
<td class=""data row3 col45"" id=""T_f5094_row3_col45"">0.199790</td>
<td class=""data row3 col46"" id=""T_f5094_row3_col46"">-0.360526</td>
<td class=""data row3 col47"" id=""T_f5094_row3_col47"">-0.013448</td>
<td class=""data row3 col48"" id=""T_f5094_row3_col48"">-0.819476</td>
<td class=""data row3 col49"" id=""T_f5094_row3_col49"">0.814869</td>
<td class=""data row3 col50"" id=""T_f5094_row3_col50"">0.442118</td>
<td class=""data row3 col51"" id=""T_f5094_row3_col51"">-0.972048</td>
<td class=""data row3 col52"" id=""T_f5094_row3_col52"">-0.060603</td>
<td class=""data row3 col53"" id=""T_f5094_row3_col53"">-2.349825</td>
<td class=""data row3 col54"" id=""T_f5094_row3_col54"">1.265445</td>
<td class=""data row3 col55"" id=""T_f5094_row3_col55"">-0.573257</td>
<td class=""data row3 col56"" id=""T_f5094_row3_col56"">0.429124</td>
<td class=""data row3 col57"" id=""T_f5094_row3_col57"">1.049783</td>
<td class=""data row3 col58"" id=""T_f5094_row3_col58"">1.954773</td>
<td class=""data row3 col59"" id=""T_f5094_row3_col59"">0.071883</td>
<td class=""data row3 col60"" id=""T_f5094_row3_col60"">-0.094209</td>
<td class=""data row3 col61"" id=""T_f5094_row3_col61"">0.265616</td>
<td class=""data row3 col62"" id=""T_f5094_row3_col62"">0.948318</td>
<td class=""data row3 col63"" id=""T_f5094_row3_col63"">0.331645</td>
<td class=""data row3 col64"" id=""T_f5094_row3_col64"">1.343401</td>
<td class=""data row3 col65"" id=""T_f5094_row3_col65"">-0.167934</td>
<td class=""data row3 col66"" id=""T_f5094_row3_col66"">-1.105252</td>
<td class=""data row3 col67"" id=""T_f5094_row3_col67"">-0.167077</td>
<td class=""data row3 col68"" id=""T_f5094_row3_col68"">-0.096576</td>
<td class=""data row3 col69"" id=""T_f5094_row3_col69"">-0.838161</td>
<td class=""data row3 col70"" id=""T_f5094_row3_col70"">-0.208564</td>
<td class=""data row3 col71"" id=""T_f5094_row3_col71"">0.394534</td>
<td class=""data row3 col72"" id=""T_f5094_row3_col72"">0.762533</td>
<td class=""data row3 col73"" id=""T_f5094_row3_col73"">1.235357</td>
<td class=""data row3 col74"" id=""T_f5094_row3_col74"">-0.207282</td>
<td class=""data row3 col75"" id=""T_f5094_row3_col75"">-0.202946</td>
<td class=""data row3 col76"" id=""T_f5094_row3_col76"">-0.468025</td>
<td class=""data row3 col77"" id=""T_f5094_row3_col77"">0.256944</td>
<td class=""data row3 col78"" id=""T_f5094_row3_col78"">2.587584</td>
<td class=""data row3 col79"" id=""T_f5094_row3_col79"">1.186697</td>
<td class=""data row3 col80"" id=""T_f5094_row3_col80"">-1.031903</td>
<td class=""data row3 col81"" id=""T_f5094_row3_col81"">1.428316</td>
<td class=""data row3 col82"" id=""T_f5094_row3_col82"">0.658899</td>
<td class=""data row3 col83"" id=""T_f5094_row3_col83"">-0.046582</td>
<td class=""data row3 col84"" id=""T_f5094_row3_col84"">-0.075422</td>
<td class=""data row3 col85"" id=""T_f5094_row3_col85"">1.329359</td>
<td class=""data row3 col86"" id=""T_f5094_row3_col86"">-0.684267</td>
<td class=""data row3 col87"" id=""T_f5094_row3_col87"">-1.524182</td>
<td class=""data row3 col88"" id=""T_f5094_row3_col88"">2.014061</td>
<td class=""data row3 col89"" id=""T_f5094_row3_col89"">3.770933</td>
<td class=""data row3 col90"" id=""T_f5094_row3_col90"">0.647353</td>
<td class=""data row3 col91"" id=""T_f5094_row3_col91"">-1.021377</td>
<td class=""data row3 col92"" id=""T_f5094_row3_col92"">-0.345493</td>
<td class=""data row3 col93"" id=""T_f5094_row3_col93"">0.582811</td>
<td class=""data row3 col94"" id=""T_f5094_row3_col94"">0.797812</td>
<td class=""data row3 col95"" id=""T_f5094_row3_col95"">1.326020</td>
<td class=""data row3 col96"" id=""T_f5094_row3_col96"">1.422857</td>
<td class=""data row3 col97"" id=""T_f5094_row3_col97"">-3.077007</td>
<td class=""data row3 col98"" id=""T_f5094_row3_col98"">0.184083</td>
<td class=""data row3 col99"" id=""T_f5094_row3_col99"">1.478935</td>
</tr>
<tr>
<th class=""row_heading level1 row4"" id=""T_f5094_level1_row4"" rowspan=""4"">1</th>
<th class=""row_heading level2 row4"" id=""T_f5094_level2_row4"">0</th>
<td class=""data row4 col0"" id=""T_f5094_row4_col0"">-0.600142</td>
<td class=""data row4 col1"" id=""T_f5094_row4_col1"">1.929561</td>
<td class=""data row4 col2"" id=""T_f5094_row4_col2"">-2.346771</td>
<td class=""data row4 col3"" id=""T_f5094_row4_col3"">-0.669700</td>
<td class=""data row4 col4"" id=""T_f5094_row4_col4"">-1.165258</td>
<td class=""data row4 col5"" id=""T_f5094_row4_col5"">0.814788</td>
<td class=""data row4 col6"" id=""T_f5094_row4_col6"">0.444449</td>
<td class=""data row4 col7"" id=""T_f5094_row4_col7"">-0.576758</td>
<td class=""data row4 col8"" id=""T_f5094_row4_col8"">0.353091</td>
<td class=""data row4 col9"" id=""T_f5094_row4_col9"">0.408893</td>
<td class=""data row4 col10"" id=""T_f5094_row4_col10"">0.091391</td>
<td class=""data row4 col11"" id=""T_f5094_row4_col11"">-2.294389</td>
<td class=""data row4 col12"" id=""T_f5094_row4_col12"">0.485506</td>
<td class=""data row4 col13"" id=""T_f5094_row4_col13"">-0.081304</td>
<td class=""data row4 col14"" id=""T_f5094_row4_col14"">-0.716272</td>
<td class=""data row4 col15"" id=""T_f5094_row4_col15"">-1.648010</td>
<td class=""data row4 col16"" id=""T_f5094_row4_col16"">1.005361</td>
<td class=""data row4 col17"" id=""T_f5094_row4_col17"">-1.489603</td>
<td class=""data row4 col18"" id=""T_f5094_row4_col18"">0.363098</td>
<td class=""data row4 col19"" id=""T_f5094_row4_col19"">0.758602</td>
<td class=""data row4 col20"" id=""T_f5094_row4_col20"">-1.373847</td>
<td class=""data row4 col21"" id=""T_f5094_row4_col21"">-0.972057</td>
<td class=""data row4 col22"" id=""T_f5094_row4_col22"">1.988537</td>
<td class=""data row4 col23"" id=""T_f5094_row4_col23"">0.319829</td>
<td class=""data row4 col24"" id=""T_f5094_row4_col24"">1.169060</td>
<td class=""data row4 col25"" id=""T_f5094_row4_col25"">0.146585</td>
<td class=""data row4 col26"" id=""T_f5094_row4_col26"">1.030388</td>
<td class=""data row4 col27"" id=""T_f5094_row4_col27"">1.165984</td>
<td class=""data row4 col28"" id=""T_f5094_row4_col28"">1.369563</td>
<td class=""data row4 col29"" id=""T_f5094_row4_col29"">0.730984</td>
<td class=""data row4 col30"" id=""T_f5094_row4_col30"">-1.383696</td>
<td class=""data row4 col31"" id=""T_f5094_row4_col31"">-0.515189</td>
<td class=""data row4 col32"" id=""T_f5094_row4_col32"">-0.808927</td>
<td class=""data row4 col33"" id=""T_f5094_row4_col33"">-1.174651</td>
<td class=""data row4 col34"" id=""T_f5094_row4_col34"">-1.631502</td>
<td class=""data row4 col35"" id=""T_f5094_row4_col35"">-1.123414</td>
<td class=""data row4 col36"" id=""T_f5094_row4_col36"">-0.478155</td>
<td class=""data row4 col37"" id=""T_f5094_row4_col37"">-1.583067</td>
<td class=""data row4 col38"" id=""T_f5094_row4_col38"">1.419074</td>
<td class=""data row4 col39"" id=""T_f5094_row4_col39"">1.668777</td>
<td class=""data row4 col40"" id=""T_f5094_row4_col40"">1.567517</td>
<td class=""data row4 col41"" id=""T_f5094_row4_col41"">0.222103</td>
<td class=""data row4 col42"" id=""T_f5094_row4_col42"">-0.336040</td>
<td class=""data row4 col43"" id=""T_f5094_row4_col43"">-1.352064</td>
<td class=""data row4 col44"" id=""T_f5094_row4_col44"">0.251032</td>
<td class=""data row4 col45"" id=""T_f5094_row4_col45"">-0.401695</td>
<td class=""data row4 col46"" id=""T_f5094_row4_col46"">0.268413</td>
<td class=""data row4 col47"" id=""T_f5094_row4_col47"">-0.012299</td>
<td class=""data row4 col48"" id=""T_f5094_row4_col48"">-0.918953</td>
<td class=""data row4 col49"" id=""T_f5094_row4_col49"">2.921208</td>
<td class=""data row4 col50"" id=""T_f5094_row4_col50"">-0.581588</td>
<td class=""data row4 col51"" id=""T_f5094_row4_col51"">0.672848</td>
<td class=""data row4 col52"" id=""T_f5094_row4_col52"">1.251136</td>
<td class=""data row4 col53"" id=""T_f5094_row4_col53"">1.382263</td>
<td class=""data row4 col54"" id=""T_f5094_row4_col54"">1.429897</td>
<td class=""data row4 col55"" id=""T_f5094_row4_col55"">1.290990</td>
<td class=""data row4 col56"" id=""T_f5094_row4_col56"">-1.272673</td>
<td class=""data row4 col57"" id=""T_f5094_row4_col57"">-0.308611</td>
<td class=""data row4 col58"" id=""T_f5094_row4_col58"">-0.422988</td>
<td class=""data row4 col59"" id=""T_f5094_row4_col59"">-0.675642</td>
<td class=""data row4 col60"" id=""T_f5094_row4_col60"">0.874441</td>
<td class=""data row4 col61"" id=""T_f5094_row4_col61"">1.305736</td>
<td class=""data row4 col62"" id=""T_f5094_row4_col62"">-0.262585</td>
<td class=""data row4 col63"" id=""T_f5094_row4_col63"">-1.099395</td>
<td class=""data row4 col64"" id=""T_f5094_row4_col64"">-0.667101</td>
<td class=""data row4 col65"" id=""T_f5094_row4_col65"">-0.646737</td>
<td class=""data row4 col66"" id=""T_f5094_row4_col66"">-0.556338</td>
<td class=""data row4 col67"" id=""T_f5094_row4_col67"">-0.196591</td>
<td class=""data row4 col68"" id=""T_f5094_row4_col68"">0.119306</td>
<td class=""data row4 col69"" id=""T_f5094_row4_col69"">-0.266455</td>
<td class=""data row4 col70"" id=""T_f5094_row4_col70"">-0.524267</td>
<td class=""data row4 col71"" id=""T_f5094_row4_col71"">2.650951</td>
<td class=""data row4 col72"" id=""T_f5094_row4_col72"">0.097318</td>
<td class=""data row4 col73"" id=""T_f5094_row4_col73"">-0.974697</td>
<td class=""data row4 col74"" id=""T_f5094_row4_col74"">0.189964</td>
<td class=""data row4 col75"" id=""T_f5094_row4_col75"">1.141155</td>
<td class=""data row4 col76"" id=""T_f5094_row4_col76"">-0.064434</td>
<td class=""data row4 col77"" id=""T_f5094_row4_col77"">1.104971</td>
<td class=""data row4 col78"" id=""T_f5094_row4_col78"">-1.508908</td>
<td class=""data row4 col79"" id=""T_f5094_row4_col79"">-0.031833</td>
<td class=""data row4 col80"" id=""T_f5094_row4_col80"">0.803919</td>
<td class=""data row4 col81"" id=""T_f5094_row4_col81"">-0.659221</td>
<td class=""data row4 col82"" id=""T_f5094_row4_col82"">0.939145</td>
<td class=""data row4 col83"" id=""T_f5094_row4_col83"">0.214041</td>
<td class=""data row4 col84"" id=""T_f5094_row4_col84"">-0.531805</td>
<td class=""data row4 col85"" id=""T_f5094_row4_col85"">0.956060</td>
<td class=""data row4 col86"" id=""T_f5094_row4_col86"">0.249328</td>
<td class=""data row4 col87"" id=""T_f5094_row4_col87"">0.637903</td>
<td class=""data row4 col88"" id=""T_f5094_row4_col88"">-0.510158</td>
<td class=""data row4 col89"" id=""T_f5094_row4_col89"">1.850287</td>
<td class=""data row4 col90"" id=""T_f5094_row4_col90"">-0.348407</td>
<td class=""data row4 col91"" id=""T_f5094_row4_col91"">2.001376</td>
<td class=""data row4 col92"" id=""T_f5094_row4_col92"">-0.389643</td>
<td class=""data row4 col93"" id=""T_f5094_row4_col93"">-0.024786</td>
<td class=""data row4 col94"" id=""T_f5094_row4_col94"">-0.470973</td>
<td class=""data row4 col95"" id=""T_f5094_row4_col95"">0.869339</td>
<td class=""data row4 col96"" id=""T_f5094_row4_col96"">0.170667</td>
<td class=""data row4 col97"" id=""T_f5094_row4_col97"">0.598062</td>
<td class=""data row4 col98"" id=""T_f5094_row4_col98"">1.217262</td>
<td class=""data row4 col99"" id=""T_f5094_row4_col99"">1.274013</td>
</tr>
<tr>
<th class=""row_heading level2 row5"" id=""T_f5094_level2_row5"">1</th>
<td class=""data row5 col0"" id=""T_f5094_row5_col0"">-0.389981</td>
<td class=""data row5 col1"" id=""T_f5094_row5_col1"">-0.752441</td>
<td class=""data row5 col2"" id=""T_f5094_row5_col2"">-0.734871</td>
<td class=""data row5 col3"" id=""T_f5094_row5_col3"">3.517318</td>
<td class=""data row5 col4"" id=""T_f5094_row5_col4"">-1.173559</td>
<td class=""data row5 col5"" id=""T_f5094_row5_col5"">-0.004956</td>
<td class=""data row5 col6"" id=""T_f5094_row5_col6"">0.145419</td>
<td class=""data row5 col7"" id=""T_f5094_row5_col7"">2.151368</td>
<td class=""data row5 col8"" id=""T_f5094_row5_col8"">-3.086037</td>
<td class=""data row5 col9"" id=""T_f5094_row5_col9"">-1.569139</td>
<td class=""data row5 col10"" id=""T_f5094_row5_col10"">1.449784</td>
<td class=""data row5 col11"" id=""T_f5094_row5_col11"">-0.868951</td>
<td class=""data row5 col12"" id=""T_f5094_row5_col12"">-1.687716</td>
<td class=""data row5 col13"" id=""T_f5094_row5_col13"">-0.994401</td>
<td class=""data row5 col14"" id=""T_f5094_row5_col14"">1.153266</td>
<td class=""data row5 col15"" id=""T_f5094_row5_col15"">1.803045</td>
<td class=""data row5 col16"" id=""T_f5094_row5_col16"">-0.819059</td>
<td class=""data row5 col17"" id=""T_f5094_row5_col17"">0.847970</td>
<td class=""data row5 col18"" id=""T_f5094_row5_col18"">0.227102</td>
<td class=""data row5 col19"" id=""T_f5094_row5_col19"">-0.500762</td>
<td class=""data row5 col20"" id=""T_f5094_row5_col20"">0.868210</td>
<td class=""data row5 col21"" id=""T_f5094_row5_col21"">1.823540</td>
<td class=""data row5 col22"" id=""T_f5094_row5_col22"">1.161007</td>
<td class=""data row5 col23"" id=""T_f5094_row5_col23"">-0.307606</td>
<td class=""data row5 col24"" id=""T_f5094_row5_col24"">-0.713416</td>
<td class=""data row5 col25"" id=""T_f5094_row5_col25"">0.363560</td>
<td class=""data row5 col26"" id=""T_f5094_row5_col26"">-0.822162</td>
<td class=""data row5 col27"" id=""T_f5094_row5_col27"">2.427681</td>
<td class=""data row5 col28"" id=""T_f5094_row5_col28"">-0.129537</td>
<td class=""data row5 col29"" id=""T_f5094_row5_col29"">-0.078716</td>
<td class=""data row5 col30"" id=""T_f5094_row5_col30"">1.345644</td>
<td class=""data row5 col31"" id=""T_f5094_row5_col31"">-1.286094</td>
<td class=""data row5 col32"" id=""T_f5094_row5_col32"">0.237242</td>
<td class=""data row5 col33"" id=""T_f5094_row5_col33"">-0.136056</td>
<td class=""data row5 col34"" id=""T_f5094_row5_col34"">0.596664</td>
<td class=""data row5 col35"" id=""T_f5094_row5_col35"">-1.412381</td>
<td class=""data row5 col36"" id=""T_f5094_row5_col36"">1.206341</td>
<td class=""data row5 col37"" id=""T_f5094_row5_col37"">0.299860</td>
<td class=""data row5 col38"" id=""T_f5094_row5_col38"">0.705238</td>
<td class=""data row5 col39"" id=""T_f5094_row5_col39"">0.142412</td>
<td class=""data row5 col40"" id=""T_f5094_row5_col40"">-1.059382</td>
<td class=""data row5 col41"" id=""T_f5094_row5_col41"">0.833468</td>
<td class=""data row5 col42"" id=""T_f5094_row5_col42"">1.060015</td>
<td class=""data row5 col43"" id=""T_f5094_row5_col43"">-0.527045</td>
<td class=""data row5 col44"" id=""T_f5094_row5_col44"">-1.135732</td>
<td class=""data row5 col45"" id=""T_f5094_row5_col45"">-1.140983</td>
<td class=""data row5 col46"" id=""T_f5094_row5_col46"">-0.779540</td>
<td class=""data row5 col47"" id=""T_f5094_row5_col47"">-0.640875</td>
<td class=""data row5 col48"" id=""T_f5094_row5_col48"">-1.217196</td>
<td class=""data row5 col49"" id=""T_f5094_row5_col49"">-1.675663</td>
<td class=""data row5 col50"" id=""T_f5094_row5_col50"">0.241263</td>
<td class=""data row5 col51"" id=""T_f5094_row5_col51"">-0.273322</td>
<td class=""data row5 col52"" id=""T_f5094_row5_col52"">-1.697936</td>
<td class=""data row5 col53"" id=""T_f5094_row5_col53"">-0.594943</td>
<td class=""data row5 col54"" id=""T_f5094_row5_col54"">0.101154</td>
<td class=""data row5 col55"" id=""T_f5094_row5_col55"">1.391735</td>
<td class=""data row5 col56"" id=""T_f5094_row5_col56"">-0.426953</td>
<td class=""data row5 col57"" id=""T_f5094_row5_col57"">1.008344</td>
<td class=""data row5 col58"" id=""T_f5094_row5_col58"">-0.818577</td>
<td class=""data row5 col59"" id=""T_f5094_row5_col59"">1.924570</td>
<td class=""data row5 col60"" id=""T_f5094_row5_col60"">-0.578900</td>
<td class=""data row5 col61"" id=""T_f5094_row5_col61"">-0.457395</td>
<td class=""data row5 col62"" id=""T_f5094_row5_col62"">-1.096705</td>
<td class=""data row5 col63"" id=""T_f5094_row5_col63"">0.418522</td>
<td class=""data row5 col64"" id=""T_f5094_row5_col64"">-0.155623</td>
<td class=""data row5 col65"" id=""T_f5094_row5_col65"">0.169706</td>
<td class=""data row5 col66"" id=""T_f5094_row5_col66"">-2.533706</td>
<td class=""data row5 col67"" id=""T_f5094_row5_col67"">0.018904</td>
<td class=""data row5 col68"" id=""T_f5094_row5_col68"">1.434160</td>
<td class=""data row5 col69"" id=""T_f5094_row5_col69"">0.744095</td>
<td class=""data row5 col70"" id=""T_f5094_row5_col70"">0.647626</td>
<td class=""data row5 col71"" id=""T_f5094_row5_col71"">-0.770309</td>
<td class=""data row5 col72"" id=""T_f5094_row5_col72"">2.329141</td>
<td class=""data row5 col73"" id=""T_f5094_row5_col73"">-0.141547</td>
<td class=""data row5 col74"" id=""T_f5094_row5_col74"">-1.761594</td>
<td class=""data row5 col75"" id=""T_f5094_row5_col75"">0.702091</td>
<td class=""data row5 col76"" id=""T_f5094_row5_col76"">-1.531450</td>
<td class=""data row5 col77"" id=""T_f5094_row5_col77"">-0.788427</td>
<td class=""data row5 col78"" id=""T_f5094_row5_col78"">-0.184622</td>
<td class=""data row5 col79"" id=""T_f5094_row5_col79"">-1.942321</td>
<td class=""data row5 col80"" id=""T_f5094_row5_col80"">1.530113</td>
<td class=""data row5 col81"" id=""T_f5094_row5_col81"">0.503406</td>
<td class=""data row5 col82"" id=""T_f5094_row5_col82"">1.105845</td>
<td class=""data row5 col83"" id=""T_f5094_row5_col83"">-0.935120</td>
<td class=""data row5 col84"" id=""T_f5094_row5_col84"">-1.115483</td>
<td class=""data row5 col85"" id=""T_f5094_row5_col85"">-2.249762</td>
<td class=""data row5 col86"" id=""T_f5094_row5_col86"">1.307135</td>
<td class=""data row5 col87"" id=""T_f5094_row5_col87"">0.788412</td>
<td class=""data row5 col88"" id=""T_f5094_row5_col88"">-0.441091</td>
<td class=""data row5 col89"" id=""T_f5094_row5_col89"">0.073561</td>
<td class=""data row5 col90"" id=""T_f5094_row5_col90"">0.812101</td>
<td class=""data row5 col91"" id=""T_f5094_row5_col91"">-0.916146</td>
<td class=""data row5 col92"" id=""T_f5094_row5_col92"">1.573714</td>
<td class=""data row5 col93"" id=""T_f5094_row5_col93"">-0.309508</td>
<td class=""data row5 col94"" id=""T_f5094_row5_col94"">0.499987</td>
<td class=""data row5 col95"" id=""T_f5094_row5_col95"">0.187594</td>
<td class=""data row5 col96"" id=""T_f5094_row5_col96"">0.558913</td>
<td class=""data row5 col97"" id=""T_f5094_row5_col97"">0.903246</td>
<td class=""data row5 col98"" id=""T_f5094_row5_col98"">0.317901</td>
<td class=""data row5 col99"" id=""T_f5094_row5_col99"">-0.809797</td>
</tr>
<tr>
<th class=""row_heading level2 row6"" id=""T_f5094_level2_row6"">2</th>
<td class=""data row6 col0"" id=""T_f5094_row6_col0"">1.128248</td>
<td class=""data row6 col1"" id=""T_f5094_row6_col1"">1.516826</td>
<td class=""data row6 col2"" id=""T_f5094_row6_col2"">-0.186735</td>
<td class=""data row6 col3"" id=""T_f5094_row6_col3"">-0.668157</td>
<td class=""data row6 col4"" id=""T_f5094_row6_col4"">1.132259</td>
<td class=""data row6 col5"" id=""T_f5094_row6_col5"">-0.246648</td>
<td class=""data row6 col6"" id=""T_f5094_row6_col6"">-0.855167</td>
<td class=""data row6 col7"" id=""T_f5094_row6_col7"">0.732283</td>
<td class=""data row6 col8"" id=""T_f5094_row6_col8"">0.931802</td>
<td class=""data row6 col9"" id=""T_f5094_row6_col9"">1.318684</td>
<td class=""data row6 col10"" id=""T_f5094_row6_col10"">-1.198418</td>
<td class=""data row6 col11"" id=""T_f5094_row6_col11"">-1.149318</td>
<td class=""data row6 col12"" id=""T_f5094_row6_col12"">0.586321</td>
<td class=""data row6 col13"" id=""T_f5094_row6_col13"">-1.171937</td>
<td class=""data row6 col14"" id=""T_f5094_row6_col14"">-0.607731</td>
<td class=""data row6 col15"" id=""T_f5094_row6_col15"">2.753747</td>
<td class=""data row6 col16"" id=""T_f5094_row6_col16"">1.479287</td>
<td class=""data row6 col17"" id=""T_f5094_row6_col17"">-1.136365</td>
<td class=""data row6 col18"" id=""T_f5094_row6_col18"">-0.020485</td>
<td class=""data row6 col19"" id=""T_f5094_row6_col19"">0.320444</td>
<td class=""data row6 col20"" id=""T_f5094_row6_col20"">-1.955755</td>
<td class=""data row6 col21"" id=""T_f5094_row6_col21"">0.660402</td>
<td class=""data row6 col22"" id=""T_f5094_row6_col22"">-1.545371</td>
<td class=""data row6 col23"" id=""T_f5094_row6_col23"">0.200519</td>
<td class=""data row6 col24"" id=""T_f5094_row6_col24"">-0.017263</td>
<td class=""data row6 col25"" id=""T_f5094_row6_col25"">1.634686</td>
<td class=""data row6 col26"" id=""T_f5094_row6_col26"">0.599246</td>
<td class=""data row6 col27"" id=""T_f5094_row6_col27"">0.462989</td>
<td class=""data row6 col28"" id=""T_f5094_row6_col28"">0.023721</td>
<td class=""data row6 col29"" id=""T_f5094_row6_col29"">0.225546</td>
<td class=""data row6 col30"" id=""T_f5094_row6_col30"">0.170972</td>
<td class=""data row6 col31"" id=""T_f5094_row6_col31"">-0.027496</td>
<td class=""data row6 col32"" id=""T_f5094_row6_col32"">-0.061233</td>
<td class=""data row6 col33"" id=""T_f5094_row6_col33"">-0.566411</td>
<td class=""data row6 col34"" id=""T_f5094_row6_col34"">-0.669567</td>
<td class=""data row6 col35"" id=""T_f5094_row6_col35"">0.601618</td>
<td class=""data row6 col36"" id=""T_f5094_row6_col36"">0.503656</td>
<td class=""data row6 col37"" id=""T_f5094_row6_col37"">-0.678253</td>
<td class=""data row6 col38"" id=""T_f5094_row6_col38"">-2.907108</td>
<td class=""data row6 col39"" id=""T_f5094_row6_col39"">-1.717123</td>
<td class=""data row6 col40"" id=""T_f5094_row6_col40"">0.397631</td>
<td class=""data row6 col41"" id=""T_f5094_row6_col41"">1.300108</td>
<td class=""data row6 col42"" id=""T_f5094_row6_col42"">0.215821</td>
<td class=""data row6 col43"" id=""T_f5094_row6_col43"">-0.593075</td>
<td class=""data row6 col44"" id=""T_f5094_row6_col44"">-0.225944</td>
<td class=""data row6 col45"" id=""T_f5094_row6_col45"">-0.946057</td>
<td class=""data row6 col46"" id=""T_f5094_row6_col46"">1.000308</td>
<td class=""data row6 col47"" id=""T_f5094_row6_col47"">0.393160</td>
<td class=""data row6 col48"" id=""T_f5094_row6_col48"">1.342074</td>
<td class=""data row6 col49"" id=""T_f5094_row6_col49"">-0.370687</td>
<td class=""data row6 col50"" id=""T_f5094_row6_col50"">-0.166413</td>
<td class=""data row6 col51"" id=""T_f5094_row6_col51"">-0.419814</td>
<td class=""data row6 col52"" id=""T_f5094_row6_col52"">-0.255931</td>
<td class=""data row6 col53"" id=""T_f5094_row6_col53"">1.789478</td>
<td class=""data row6 col54"" id=""T_f5094_row6_col54"">0.282378</td>
<td class=""data row6 col55"" id=""T_f5094_row6_col55"">0.742260</td>
<td class=""data row6 col56"" id=""T_f5094_row6_col56"">-0.050498</td>
<td class=""data row6 col57"" id=""T_f5094_row6_col57"">1.415309</td>
<td class=""data row6 col58"" id=""T_f5094_row6_col58"">0.838166</td>
<td class=""data row6 col59"" id=""T_f5094_row6_col59"">-1.400292</td>
<td class=""data row6 col60"" id=""T_f5094_row6_col60"">-0.937976</td>
<td class=""data row6 col61"" id=""T_f5094_row6_col61"">-1.499148</td>
<td class=""data row6 col62"" id=""T_f5094_row6_col62"">0.801859</td>
<td class=""data row6 col63"" id=""T_f5094_row6_col63"">0.224824</td>
<td class=""data row6 col64"" id=""T_f5094_row6_col64"">0.283572</td>
<td class=""data row6 col65"" id=""T_f5094_row6_col65"">0.643703</td>
<td class=""data row6 col66"" id=""T_f5094_row6_col66"">-1.198465</td>
<td class=""data row6 col67"" id=""T_f5094_row6_col67"">0.527206</td>
<td class=""data row6 col68"" id=""T_f5094_row6_col68"">0.215202</td>
<td class=""data row6 col69"" id=""T_f5094_row6_col69"">0.437048</td>
<td class=""data row6 col70"" id=""T_f5094_row6_col70"">1.312868</td>
<td class=""data row6 col71"" id=""T_f5094_row6_col71"">0.741243</td>
<td class=""data row6 col72"" id=""T_f5094_row6_col72"">0.077988</td>
<td class=""data row6 col73"" id=""T_f5094_row6_col73"">0.006123</td>
<td class=""data row6 col74"" id=""T_f5094_row6_col74"">0.190370</td>
<td class=""data row6 col75"" id=""T_f5094_row6_col75"">0.018007</td>
<td class=""data row6 col76"" id=""T_f5094_row6_col76"">-1.026036</td>
<td class=""data row6 col77"" id=""T_f5094_row6_col77"">-2.378430</td>
<td class=""data row6 col78"" id=""T_f5094_row6_col78"">-1.069949</td>
<td class=""data row6 col79"" id=""T_f5094_row6_col79"">0.843822</td>
<td class=""data row6 col80"" id=""T_f5094_row6_col80"">1.289216</td>
<td class=""data row6 col81"" id=""T_f5094_row6_col81"">-1.423369</td>
<td class=""data row6 col82"" id=""T_f5094_row6_col82"">-0.462887</td>
<td class=""data row6 col83"" id=""T_f5094_row6_col83"">0.197330</td>
<td class=""data row6 col84"" id=""T_f5094_row6_col84"">-0.935076</td>
<td class=""data row6 col85"" id=""T_f5094_row6_col85"">0.441271</td>
<td class=""data row6 col86"" id=""T_f5094_row6_col86"">0.414643</td>
<td class=""data row6 col87"" id=""T_f5094_row6_col87"">-0.377887</td>
<td class=""data row6 col88"" id=""T_f5094_row6_col88"">-0.530515</td>
<td class=""data row6 col89"" id=""T_f5094_row6_col89"">0.621592</td>
<td class=""data row6 col90"" id=""T_f5094_row6_col90"">1.009572</td>
<td class=""data row6 col91"" id=""T_f5094_row6_col91"">0.569718</td>
<td class=""data row6 col92"" id=""T_f5094_row6_col92"">0.175291</td>
<td class=""data row6 col93"" id=""T_f5094_row6_col93"">-0.656279</td>
<td class=""data row6 col94"" id=""T_f5094_row6_col94"">-0.112273</td>
<td class=""data row6 col95"" id=""T_f5094_row6_col95"">-0.392137</td>
<td class=""data row6 col96"" id=""T_f5094_row6_col96"">-1.043558</td>
<td class=""data row6 col97"" id=""T_f5094_row6_col97"">-0.467318</td>
<td class=""data row6 col98"" id=""T_f5094_row6_col98"">-0.384329</td>
<td class=""data row6 col99"" id=""T_f5094_row6_col99"">-2.009207</td>
</tr>
<tr>
<th class=""row_heading level2 row7"" id=""T_f5094_level2_row7"">3</th>
<td class=""data row7 col0"" id=""T_f5094_row7_col0"">0.658598</td>
<td class=""data row7 col1"" id=""T_f5094_row7_col1"">0.101830</td>
<td class=""data row7 col2"" id=""T_f5094_row7_col2"">-0.682781</td>
<td class=""data row7 col3"" id=""T_f5094_row7_col3"">0.229349</td>
<td class=""data row7 col4"" id=""T_f5094_row7_col4"">-0.305657</td>
<td class=""data row7 col5"" id=""T_f5094_row7_col5"">0.404877</td>
<td class=""data row7 col6"" id=""T_f5094_row7_col6"">0.252244</td>
<td class=""data row7 col7"" id=""T_f5094_row7_col7"">-0.837784</td>
<td class=""data row7 col8"" id=""T_f5094_row7_col8"">-0.039624</td>
<td class=""data row7 col9"" id=""T_f5094_row7_col9"">0.329457</td>
<td class=""data row7 col10"" id=""T_f5094_row7_col10"">0.751694</td>
<td class=""data row7 col11"" id=""T_f5094_row7_col11"">1.469070</td>
<td class=""data row7 col12"" id=""T_f5094_row7_col12"">-0.157199</td>
<td class=""data row7 col13"" id=""T_f5094_row7_col13"">1.032628</td>
<td class=""data row7 col14"" id=""T_f5094_row7_col14"">-0.584639</td>
<td class=""data row7 col15"" id=""T_f5094_row7_col15"">-0.925544</td>
<td class=""data row7 col16"" id=""T_f5094_row7_col16"">0.342474</td>
<td class=""data row7 col17"" id=""T_f5094_row7_col17"">-0.969363</td>
<td class=""data row7 col18"" id=""T_f5094_row7_col18"">0.133480</td>
<td class=""data row7 col19"" id=""T_f5094_row7_col19"">-0.385974</td>
<td class=""data row7 col20"" id=""T_f5094_row7_col20"">-0.600278</td>
<td class=""data row7 col21"" id=""T_f5094_row7_col21"">0.281939</td>
<td class=""data row7 col22"" id=""T_f5094_row7_col22"">0.868579</td>
<td class=""data row7 col23"" id=""T_f5094_row7_col23"">1.129803</td>
<td class=""data row7 col24"" id=""T_f5094_row7_col24"">-0.041898</td>
<td class=""data row7 col25"" id=""T_f5094_row7_col25"">0.961193</td>
<td class=""data row7 col26"" id=""T_f5094_row7_col26"">0.131521</td>
<td class=""data row7 col27"" id=""T_f5094_row7_col27"">-0.792889</td>
<td class=""data row7 col28"" id=""T_f5094_row7_col28"">-1.285737</td>
<td class=""data row7 col29"" id=""T_f5094_row7_col29"">0.073934</td>
<td class=""data row7 col30"" id=""T_f5094_row7_col30"">-1.333315</td>
<td class=""data row7 col31"" id=""T_f5094_row7_col31"">-1.044125</td>
<td class=""data row7 col32"" id=""T_f5094_row7_col32"">1.277338</td>
<td class=""data row7 col33"" id=""T_f5094_row7_col33"">1.492257</td>
<td class=""data row7 col34"" id=""T_f5094_row7_col34"">0.411379</td>
<td class=""data row7 col35"" id=""T_f5094_row7_col35"">1.771805</td>
<td class=""data row7 col36"" id=""T_f5094_row7_col36"">-1.111128</td>
<td class=""data row7 col37"" id=""T_f5094_row7_col37"">1.123233</td>
<td class=""data row7 col38"" id=""T_f5094_row7_col38"">-1.019449</td>
<td class=""data row7 col39"" id=""T_f5094_row7_col39"">1.738357</td>
<td class=""data row7 col40"" id=""T_f5094_row7_col40"">-0.690764</td>
<td class=""data row7 col41"" id=""T_f5094_row7_col41"">-0.120710</td>
<td class=""data row7 col42"" id=""T_f5094_row7_col42"">-0.421359</td>
<td class=""data row7 col43"" id=""T_f5094_row7_col43"">-0.727294</td>
<td class=""data row7 col44"" id=""T_f5094_row7_col44"">-0.857759</td>
<td class=""data row7 col45"" id=""T_f5094_row7_col45"">-0.069436</td>
<td class=""data row7 col46"" id=""T_f5094_row7_col46"">-0.328334</td>
<td class=""data row7 col47"" id=""T_f5094_row7_col47"">-0.558180</td>
<td class=""data row7 col48"" id=""T_f5094_row7_col48"">1.063474</td>
<td class=""data row7 col49"" id=""T_f5094_row7_col49"">-0.519133</td>
<td class=""data row7 col50"" id=""T_f5094_row7_col50"">-0.496902</td>
<td class=""data row7 col51"" id=""T_f5094_row7_col51"">1.089589</td>
<td class=""data row7 col52"" id=""T_f5094_row7_col52"">-1.615801</td>
<td class=""data row7 col53"" id=""T_f5094_row7_col53"">0.080174</td>
<td class=""data row7 col54"" id=""T_f5094_row7_col54"">-0.229938</td>
<td class=""data row7 col55"" id=""T_f5094_row7_col55"">-0.498420</td>
<td class=""data row7 col56"" id=""T_f5094_row7_col56"">-0.624615</td>
<td class=""data row7 col57"" id=""T_f5094_row7_col57"">0.059481</td>
<td class=""data row7 col58"" id=""T_f5094_row7_col58"">-0.093158</td>
<td class=""data row7 col59"" id=""T_f5094_row7_col59"">-1.784549</td>
<td class=""data row7 col60"" id=""T_f5094_row7_col60"">-0.503789</td>
<td class=""data row7 col61"" id=""T_f5094_row7_col61"">-0.140528</td>
<td class=""data row7 col62"" id=""T_f5094_row7_col62"">0.002653</td>
<td class=""data row7 col63"" id=""T_f5094_row7_col63"">-0.484930</td>
<td class=""data row7 col64"" id=""T_f5094_row7_col64"">0.055914</td>
<td class=""data row7 col65"" id=""T_f5094_row7_col65"">-0.680948</td>
<td class=""data row7 col66"" id=""T_f5094_row7_col66"">-0.994271</td>
<td class=""data row7 col67"" id=""T_f5094_row7_col67"">1.277052</td>
<td class=""data row7 col68"" id=""T_f5094_row7_col68"">0.037651</td>
<td class=""data row7 col69"" id=""T_f5094_row7_col69"">2.155421</td>
<td class=""data row7 col70"" id=""T_f5094_row7_col70"">-0.437589</td>
<td class=""data row7 col71"" id=""T_f5094_row7_col71"">0.696404</td>
<td class=""data row7 col72"" id=""T_f5094_row7_col72"">0.417752</td>
<td class=""data row7 col73"" id=""T_f5094_row7_col73"">-0.544785</td>
<td class=""data row7 col74"" id=""T_f5094_row7_col74"">1.190690</td>
<td class=""data row7 col75"" id=""T_f5094_row7_col75"">0.978262</td>
<td class=""data row7 col76"" id=""T_f5094_row7_col76"">0.752102</td>
<td class=""data row7 col77"" id=""T_f5094_row7_col77"">0.504472</td>
<td class=""data row7 col78"" id=""T_f5094_row7_col78"">0.139853</td>
<td class=""data row7 col79"" id=""T_f5094_row7_col79"">-0.505089</td>
<td class=""data row7 col80"" id=""T_f5094_row7_col80"">-0.264975</td>
<td class=""data row7 col81"" id=""T_f5094_row7_col81"">-1.603194</td>
<td class=""data row7 col82"" id=""T_f5094_row7_col82"">0.731847</td>
<td class=""data row7 col83"" id=""T_f5094_row7_col83"">0.010903</td>
<td class=""data row7 col84"" id=""T_f5094_row7_col84"">-1.165346</td>
<td class=""data row7 col85"" id=""T_f5094_row7_col85"">-0.125195</td>
<td class=""data row7 col86"" id=""T_f5094_row7_col86"">-1.032685</td>
<td class=""data row7 col87"" id=""T_f5094_row7_col87"">-0.465520</td>
<td class=""data row7 col88"" id=""T_f5094_row7_col88"">1.514808</td>
<td class=""data row7 col89"" id=""T_f5094_row7_col89"">0.304762</td>
<td class=""data row7 col90"" id=""T_f5094_row7_col90"">0.793414</td>
<td class=""data row7 col91"" id=""T_f5094_row7_col91"">0.314635</td>
<td class=""data row7 col92"" id=""T_f5094_row7_col92"">-1.638279</td>
<td class=""data row7 col93"" id=""T_f5094_row7_col93"">0.111737</td>
<td class=""data row7 col94"" id=""T_f5094_row7_col94"">-0.777037</td>
<td class=""data row7 col95"" id=""T_f5094_row7_col95"">0.251783</td>
<td class=""data row7 col96"" id=""T_f5094_row7_col96"">1.126303</td>
<td class=""data row7 col97"" id=""T_f5094_row7_col97"">-0.808798</td>
<td class=""data row7 col98"" id=""T_f5094_row7_col98"">0.422064</td>
<td class=""data row7 col99"" id=""T_f5094_row7_col99"">-0.349264</td>
</tr>
<tr>
<th class=""row_heading level0 row8"" id=""T_f5094_level0_row8"" rowspan=""8"">B</th>
<th class=""row_heading level1 row8"" id=""T_f5094_level1_row8"" rowspan=""4"">0</th>
<th class=""row_heading level2 row8"" id=""T_f5094_level2_row8"">0</th>
<td class=""data row8 col0"" id=""T_f5094_row8_col0"">-0.356362</td>
<td class=""data row8 col1"" id=""T_f5094_row8_col1"">-0.089227</td>
<td class=""data row8 col2"" id=""T_f5094_row8_col2"">0.609373</td>
<td class=""data row8 col3"" id=""T_f5094_row8_col3"">0.542382</td>
<td class=""data row8 col4"" id=""T_f5094_row8_col4"">-0.768681</td>
<td class=""data row8 col5"" id=""T_f5094_row8_col5"">-0.048074</td>
<td class=""data row8 col6"" id=""T_f5094_row8_col6"">2.015458</td>
<td class=""data row8 col7"" id=""T_f5094_row8_col7"">-1.552351</td>
<td class=""data row8 col8"" id=""T_f5094_row8_col8"">0.251552</td>
<td class=""data row8 col9"" id=""T_f5094_row8_col9"">1.459635</td>
<td class=""data row8 col10"" id=""T_f5094_row8_col10"">0.949707</td>
<td class=""data row8 col11"" id=""T_f5094_row8_col11"">0.339465</td>
<td class=""data row8 col12"" id=""T_f5094_row8_col12"">-0.001372</td>
<td class=""data row8 col13"" id=""T_f5094_row8_col13"">1.798589</td>
<td class=""data row8 col14"" id=""T_f5094_row8_col14"">1.559163</td>
<td class=""data row8 col15"" id=""T_f5094_row8_col15"">0.231783</td>
<td class=""data row8 col16"" id=""T_f5094_row8_col16"">0.423141</td>
<td class=""data row8 col17"" id=""T_f5094_row8_col17"">-0.310530</td>
<td class=""data row8 col18"" id=""T_f5094_row8_col18"">0.353795</td>
<td class=""data row8 col19"" id=""T_f5094_row8_col19"">2.173336</td>
<td class=""data row8 col20"" id=""T_f5094_row8_col20"">-0.196247</td>
<td class=""data row8 col21"" id=""T_f5094_row8_col21"">-0.375636</td>
<td class=""data row8 col22"" id=""T_f5094_row8_col22"">-0.858221</td>
<td class=""data row8 col23"" id=""T_f5094_row8_col23"">0.258410</td>
<td class=""data row8 col24"" id=""T_f5094_row8_col24"">0.656430</td>
<td class=""data row8 col25"" id=""T_f5094_row8_col25"">0.960819</td>
<td class=""data row8 col26"" id=""T_f5094_row8_col26"">1.137893</td>
<td class=""data row8 col27"" id=""T_f5094_row8_col27"">1.553405</td>
<td class=""data row8 col28"" id=""T_f5094_row8_col28"">0.038981</td>
<td class=""data row8 col29"" id=""T_f5094_row8_col29"">-0.632038</td>
<td class=""data row8 col30"" id=""T_f5094_row8_col30"">-0.132009</td>
<td class=""data row8 col31"" id=""T_f5094_row8_col31"">-1.834997</td>
<td class=""data row8 col32"" id=""T_f5094_row8_col32"">-0.242576</td>
<td class=""data row8 col33"" id=""T_f5094_row8_col33"">-0.297879</td>
<td class=""data row8 col34"" id=""T_f5094_row8_col34"">-0.441559</td>
<td class=""data row8 col35"" id=""T_f5094_row8_col35"">-0.769691</td>
<td class=""data row8 col36"" id=""T_f5094_row8_col36"">0.224077</td>
<td class=""data row8 col37"" id=""T_f5094_row8_col37"">-0.153009</td>
<td class=""data row8 col38"" id=""T_f5094_row8_col38"">0.519526</td>
<td class=""data row8 col39"" id=""T_f5094_row8_col39"">-0.680188</td>
<td class=""data row8 col40"" id=""T_f5094_row8_col40"">0.535851</td>
<td class=""data row8 col41"" id=""T_f5094_row8_col41"">0.671496</td>
<td class=""data row8 col42"" id=""T_f5094_row8_col42"">-0.183064</td>
<td class=""data row8 col43"" id=""T_f5094_row8_col43"">0.301234</td>
<td class=""data row8 col44"" id=""T_f5094_row8_col44"">1.288256</td>
<td class=""data row8 col45"" id=""T_f5094_row8_col45"">-2.478240</td>
<td class=""data row8 col46"" id=""T_f5094_row8_col46"">-0.360403</td>
<td class=""data row8 col47"" id=""T_f5094_row8_col47"">0.424067</td>
<td class=""data row8 col48"" id=""T_f5094_row8_col48"">-0.834659</td>
<td class=""data row8 col49"" id=""T_f5094_row8_col49"">-0.128464</td>
<td class=""data row8 col50"" id=""T_f5094_row8_col50"">-0.489013</td>
<td class=""data row8 col51"" id=""T_f5094_row8_col51"">-0.014888</td>
<td class=""data row8 col52"" id=""T_f5094_row8_col52"">-1.461230</td>
<td class=""data row8 col53"" id=""T_f5094_row8_col53"">-1.435223</td>
<td class=""data row8 col54"" id=""T_f5094_row8_col54"">-1.319802</td>
<td class=""data row8 col55"" id=""T_f5094_row8_col55"">1.083675</td>
<td class=""data row8 col56"" id=""T_f5094_row8_col56"">0.979140</td>
<td class=""data row8 col57"" id=""T_f5094_row8_col57"">-0.375291</td>
<td class=""data row8 col58"" id=""T_f5094_row8_col58"">1.110189</td>
<td class=""data row8 col59"" id=""T_f5094_row8_col59"">-1.011351</td>
<td class=""data row8 col60"" id=""T_f5094_row8_col60"">0.587886</td>
<td class=""data row8 col61"" id=""T_f5094_row8_col61"">-0.822775</td>
<td class=""data row8 col62"" id=""T_f5094_row8_col62"">-1.183865</td>
<td class=""data row8 col63"" id=""T_f5094_row8_col63"">1.455173</td>
<td class=""data row8 col64"" id=""T_f5094_row8_col64"">1.134328</td>
<td class=""data row8 col65"" id=""T_f5094_row8_col65"">0.239403</td>
<td class=""data row8 col66"" id=""T_f5094_row8_col66"">-0.837991</td>
<td class=""data row8 col67"" id=""T_f5094_row8_col67"">-1.130932</td>
<td class=""data row8 col68"" id=""T_f5094_row8_col68"">0.783168</td>
<td class=""data row8 col69"" id=""T_f5094_row8_col69"">1.845520</td>
<td class=""data row8 col70"" id=""T_f5094_row8_col70"">1.437072</td>
<td class=""data row8 col71"" id=""T_f5094_row8_col71"">-1.198443</td>
<td class=""data row8 col72"" id=""T_f5094_row8_col72"">1.379098</td>
<td class=""data row8 col73"" id=""T_f5094_row8_col73"">2.129113</td>
<td class=""data row8 col74"" id=""T_f5094_row8_col74"">0.260096</td>
<td class=""data row8 col75"" id=""T_f5094_row8_col75"">-0.011975</td>
<td class=""data row8 col76"" id=""T_f5094_row8_col76"">0.043302</td>
<td class=""data row8 col77"" id=""T_f5094_row8_col77"">0.722941</td>
<td class=""data row8 col78"" id=""T_f5094_row8_col78"">1.028152</td>
<td class=""data row8 col79"" id=""T_f5094_row8_col79"">-0.235806</td>
<td class=""data row8 col80"" id=""T_f5094_row8_col80"">1.145245</td>
<td class=""data row8 col81"" id=""T_f5094_row8_col81"">-1.359598</td>
<td class=""data row8 col82"" id=""T_f5094_row8_col82"">0.232189</td>
<td class=""data row8 col83"" id=""T_f5094_row8_col83"">0.503712</td>
<td class=""data row8 col84"" id=""T_f5094_row8_col84"">-0.614264</td>
<td class=""data row8 col85"" id=""T_f5094_row8_col85"">-0.530606</td>
<td class=""data row8 col86"" id=""T_f5094_row8_col86"">-2.435803</td>
<td class=""data row8 col87"" id=""T_f5094_row8_col87"">-0.255238</td>
<td class=""data row8 col88"" id=""T_f5094_row8_col88"">-0.064423</td>
<td class=""data row8 col89"" id=""T_f5094_row8_col89"">0.784643</td>
<td class=""data row8 col90"" id=""T_f5094_row8_col90"">0.256346</td>
<td class=""data row8 col91"" id=""T_f5094_row8_col91"">0.128023</td>
<td class=""data row8 col92"" id=""T_f5094_row8_col92"">1.414103</td>
<td class=""data row8 col93"" id=""T_f5094_row8_col93"">-1.118659</td>
<td class=""data row8 col94"" id=""T_f5094_row8_col94"">0.877353</td>
<td class=""data row8 col95"" id=""T_f5094_row8_col95"">0.500561</td>
<td class=""data row8 col96"" id=""T_f5094_row8_col96"">0.463651</td>
<td class=""data row8 col97"" id=""T_f5094_row8_col97"">-2.034512</td>
<td class=""data row8 col98"" id=""T_f5094_row8_col98"">-0.981683</td>
<td class=""data row8 col99"" id=""T_f5094_row8_col99"">-0.691944</td>
</tr>
<tr>
<th class=""row_heading level2 row9"" id=""T_f5094_level2_row9"">1</th>
<td class=""data row9 col0"" id=""T_f5094_row9_col0"">-1.113376</td>
<td class=""data row9 col1"" id=""T_f5094_row9_col1"">-1.169402</td>
<td class=""data row9 col2"" id=""T_f5094_row9_col2"">0.680539</td>
<td class=""data row9 col3"" id=""T_f5094_row9_col3"">-1.534212</td>
<td class=""data row9 col4"" id=""T_f5094_row9_col4"">1.653817</td>
<td class=""data row9 col5"" id=""T_f5094_row9_col5"">-1.295181</td>
<td class=""data row9 col6"" id=""T_f5094_row9_col6"">-0.566826</td>
<td class=""data row9 col7"" id=""T_f5094_row9_col7"">0.477014</td>
<td class=""data row9 col8"" id=""T_f5094_row9_col8"">1.413371</td>
<td class=""data row9 col9"" id=""T_f5094_row9_col9"">0.517105</td>
<td class=""data row9 col10"" id=""T_f5094_row9_col10"">1.401153</td>
<td class=""data row9 col11"" id=""T_f5094_row9_col11"">-0.872685</td>
<td class=""data row9 col12"" id=""T_f5094_row9_col12"">0.830957</td>
<td class=""data row9 col13"" id=""T_f5094_row9_col13"">0.181507</td>
<td class=""data row9 col14"" id=""T_f5094_row9_col14"">-0.145616</td>
<td class=""data row9 col15"" id=""T_f5094_row9_col15"">0.694592</td>
<td class=""data row9 col16"" id=""T_f5094_row9_col16"">-0.751208</td>
<td class=""data row9 col17"" id=""T_f5094_row9_col17"">0.324444</td>
<td class=""data row9 col18"" id=""T_f5094_row9_col18"">0.681973</td>
<td class=""data row9 col19"" id=""T_f5094_row9_col19"">-0.054972</td>
<td class=""data row9 col20"" id=""T_f5094_row9_col20"">0.917776</td>
<td class=""data row9 col21"" id=""T_f5094_row9_col21"">-1.024810</td>
<td class=""data row9 col22"" id=""T_f5094_row9_col22"">-0.206446</td>
<td class=""data row9 col23"" id=""T_f5094_row9_col23"">-0.600113</td>
<td class=""data row9 col24"" id=""T_f5094_row9_col24"">0.852805</td>
<td class=""data row9 col25"" id=""T_f5094_row9_col25"">1.455109</td>
<td class=""data row9 col26"" id=""T_f5094_row9_col26"">-0.079769</td>
<td class=""data row9 col27"" id=""T_f5094_row9_col27"">0.076076</td>
<td class=""data row9 col28"" id=""T_f5094_row9_col28"">0.207699</td>
<td class=""data row9 col29"" id=""T_f5094_row9_col29"">-1.850458</td>
<td class=""data row9 col30"" id=""T_f5094_row9_col30"">-0.124124</td>
<td class=""data row9 col31"" id=""T_f5094_row9_col31"">-0.610871</td>
<td class=""data row9 col32"" id=""T_f5094_row9_col32"">-0.883362</td>
<td class=""data row9 col33"" id=""T_f5094_row9_col33"">0.219049</td>
<td class=""data row9 col34"" id=""T_f5094_row9_col34"">-0.685094</td>
<td class=""data row9 col35"" id=""T_f5094_row9_col35"">-0.645330</td>
<td class=""data row9 col36"" id=""T_f5094_row9_col36"">-0.242805</td>
<td class=""data row9 col37"" id=""T_f5094_row9_col37"">-0.775602</td>
<td class=""data row9 col38"" id=""T_f5094_row9_col38"">0.233070</td>
<td class=""data row9 col39"" id=""T_f5094_row9_col39"">2.422642</td>
<td class=""data row9 col40"" id=""T_f5094_row9_col40"">-1.423040</td>
<td class=""data row9 col41"" id=""T_f5094_row9_col41"">-0.582421</td>
<td class=""data row9 col42"" id=""T_f5094_row9_col42"">0.968304</td>
<td class=""data row9 col43"" id=""T_f5094_row9_col43"">-0.701025</td>
<td class=""data row9 col44"" id=""T_f5094_row9_col44"">-0.167850</td>
<td class=""data row9 col45"" id=""T_f5094_row9_col45"">0.277264</td>
<td class=""data row9 col46"" id=""T_f5094_row9_col46"">1.301231</td>
<td class=""data row9 col47"" id=""T_f5094_row9_col47"">0.301205</td>
<td class=""data row9 col48"" id=""T_f5094_row9_col48"">-3.081249</td>
<td class=""data row9 col49"" id=""T_f5094_row9_col49"">-0.562868</td>
<td class=""data row9 col50"" id=""T_f5094_row9_col50"">0.192944</td>
<td class=""data row9 col51"" id=""T_f5094_row9_col51"">-0.664592</td>
<td class=""data row9 col52"" id=""T_f5094_row9_col52"">0.565686</td>
<td class=""data row9 col53"" id=""T_f5094_row9_col53"">0.190913</td>
<td class=""data row9 col54"" id=""T_f5094_row9_col54"">-0.841858</td>
<td class=""data row9 col55"" id=""T_f5094_row9_col55"">-1.856545</td>
<td class=""data row9 col56"" id=""T_f5094_row9_col56"">-1.022777</td>
<td class=""data row9 col57"" id=""T_f5094_row9_col57"">1.295968</td>
<td class=""data row9 col58"" id=""T_f5094_row9_col58"">0.451921</td>
<td class=""data row9 col59"" id=""T_f5094_row9_col59"">0.659955</td>
<td class=""data row9 col60"" id=""T_f5094_row9_col60"">0.065818</td>
<td class=""data row9 col61"" id=""T_f5094_row9_col61"">-0.319586</td>
<td class=""data row9 col62"" id=""T_f5094_row9_col62"">0.253495</td>
<td class=""data row9 col63"" id=""T_f5094_row9_col63"">-1.144646</td>
<td class=""data row9 col64"" id=""T_f5094_row9_col64"">-0.483404</td>
<td class=""data row9 col65"" id=""T_f5094_row9_col65"">0.555902</td>
<td class=""data row9 col66"" id=""T_f5094_row9_col66"">0.807069</td>
<td class=""data row9 col67"" id=""T_f5094_row9_col67"">0.714196</td>
<td class=""data row9 col68"" id=""T_f5094_row9_col68"">0.661196</td>
<td class=""data row9 col69"" id=""T_f5094_row9_col69"">0.053667</td>
<td class=""data row9 col70"" id=""T_f5094_row9_col70"">0.346833</td>
<td class=""data row9 col71"" id=""T_f5094_row9_col71"">-1.288977</td>
<td class=""data row9 col72"" id=""T_f5094_row9_col72"">-0.386734</td>
<td class=""data row9 col73"" id=""T_f5094_row9_col73"">-1.262127</td>
<td class=""data row9 col74"" id=""T_f5094_row9_col74"">0.477495</td>
<td class=""data row9 col75"" id=""T_f5094_row9_col75"">-0.494034</td>
<td class=""data row9 col76"" id=""T_f5094_row9_col76"">-0.911414</td>
<td class=""data row9 col77"" id=""T_f5094_row9_col77"">1.152963</td>
<td class=""data row9 col78"" id=""T_f5094_row9_col78"">-0.342365</td>
<td class=""data row9 col79"" id=""T_f5094_row9_col79"">-0.160187</td>
<td class=""data row9 col80"" id=""T_f5094_row9_col80"">0.470054</td>
<td class=""data row9 col81"" id=""T_f5094_row9_col81"">-0.853063</td>
<td class=""data row9 col82"" id=""T_f5094_row9_col82"">-1.387949</td>
<td class=""data row9 col83"" id=""T_f5094_row9_col83"">-0.257257</td>
<td class=""data row9 col84"" id=""T_f5094_row9_col84"">-1.030690</td>
<td class=""data row9 col85"" id=""T_f5094_row9_col85"">-0.110210</td>
<td class=""data row9 col86"" id=""T_f5094_row9_col86"">0.328911</td>
<td class=""data row9 col87"" id=""T_f5094_row9_col87"">-0.555923</td>
<td class=""data row9 col88"" id=""T_f5094_row9_col88"">0.987713</td>
<td class=""data row9 col89"" id=""T_f5094_row9_col89"">-0.501957</td>
<td class=""data row9 col90"" id=""T_f5094_row9_col90"">2.069887</td>
<td class=""data row9 col91"" id=""T_f5094_row9_col91"">-0.067503</td>
<td class=""data row9 col92"" id=""T_f5094_row9_col92"">0.316029</td>
<td class=""data row9 col93"" id=""T_f5094_row9_col93"">-1.506232</td>
<td class=""data row9 col94"" id=""T_f5094_row9_col94"">2.201621</td>
<td class=""data row9 col95"" id=""T_f5094_row9_col95"">0.492097</td>
<td class=""data row9 col96"" id=""T_f5094_row9_col96"">-0.085193</td>
<td class=""data row9 col97"" id=""T_f5094_row9_col97"">-0.977822</td>
<td class=""data row9 col98"" id=""T_f5094_row9_col98"">1.039147</td>
<td class=""data row9 col99"" id=""T_f5094_row9_col99"">-0.653932</td>
</tr>
<tr>
<th class=""row_heading level2 row10"" id=""T_f5094_level2_row10"">2</th>
<td class=""data row10 col0"" id=""T_f5094_row10_col0"">-0.405638</td>
<td class=""data row10 col1"" id=""T_f5094_row10_col1"">-1.402027</td>
<td class=""data row10 col2"" id=""T_f5094_row10_col2"">-1.166242</td>
<td class=""data row10 col3"" id=""T_f5094_row10_col3"">1.306184</td>
<td class=""data row10 col4"" id=""T_f5094_row10_col4"">0.856283</td>
<td class=""data row10 col5"" id=""T_f5094_row10_col5"">-1.236170</td>
<td class=""data row10 col6"" id=""T_f5094_row10_col6"">-0.646721</td>
<td class=""data row10 col7"" id=""T_f5094_row10_col7"">-1.474064</td>
<td class=""data row10 col8"" id=""T_f5094_row10_col8"">0.082960</td>
<td class=""data row10 col9"" id=""T_f5094_row10_col9"">0.090310</td>
<td class=""data row10 col10"" id=""T_f5094_row10_col10"">-0.169977</td>
<td class=""data row10 col11"" id=""T_f5094_row10_col11"">0.406345</td>
<td class=""data row10 col12"" id=""T_f5094_row10_col12"">0.915427</td>
<td class=""data row10 col13"" id=""T_f5094_row10_col13"">-0.974503</td>
<td class=""data row10 col14"" id=""T_f5094_row10_col14"">0.271637</td>
<td class=""data row10 col15"" id=""T_f5094_row10_col15"">1.539184</td>
<td class=""data row10 col16"" id=""T_f5094_row10_col16"">-0.098866</td>
<td class=""data row10 col17"" id=""T_f5094_row10_col17"">-0.525149</td>
<td class=""data row10 col18"" id=""T_f5094_row10_col18"">1.063933</td>
<td class=""data row10 col19"" id=""T_f5094_row10_col19"">0.085827</td>
<td class=""data row10 col20"" id=""T_f5094_row10_col20"">-0.129622</td>
<td class=""data row10 col21"" id=""T_f5094_row10_col21"">0.947959</td>
<td class=""data row10 col22"" id=""T_f5094_row10_col22"">-0.072496</td>
<td class=""data row10 col23"" id=""T_f5094_row10_col23"">-0.237592</td>
<td class=""data row10 col24"" id=""T_f5094_row10_col24"">0.012549</td>
<td class=""data row10 col25"" id=""T_f5094_row10_col25"">1.065761</td>
<td class=""data row10 col26"" id=""T_f5094_row10_col26"">0.996596</td>
<td class=""data row10 col27"" id=""T_f5094_row10_col27"">-0.172481</td>
<td class=""data row10 col28"" id=""T_f5094_row10_col28"">2.583139</td>
<td class=""data row10 col29"" id=""T_f5094_row10_col29"">-0.028578</td>
<td class=""data row10 col30"" id=""T_f5094_row10_col30"">-0.254856</td>
<td class=""data row10 col31"" id=""T_f5094_row10_col31"">1.328794</td>
<td class=""data row10 col32"" id=""T_f5094_row10_col32"">-1.592951</td>
<td class=""data row10 col33"" id=""T_f5094_row10_col33"">2.434350</td>
<td class=""data row10 col34"" id=""T_f5094_row10_col34"">-0.341500</td>
<td class=""data row10 col35"" id=""T_f5094_row10_col35"">-0.307719</td>
<td class=""data row10 col36"" id=""T_f5094_row10_col36"">-1.333273</td>
<td class=""data row10 col37"" id=""T_f5094_row10_col37"">-1.100845</td>
<td class=""data row10 col38"" id=""T_f5094_row10_col38"">0.209097</td>
<td class=""data row10 col39"" id=""T_f5094_row10_col39"">1.734777</td>
<td class=""data row10 col40"" id=""T_f5094_row10_col40"">0.639632</td>
<td class=""data row10 col41"" id=""T_f5094_row10_col41"">0.424779</td>
<td class=""data row10 col42"" id=""T_f5094_row10_col42"">-0.129327</td>
<td class=""data row10 col43"" id=""T_f5094_row10_col43"">0.905029</td>
<td class=""data row10 col44"" id=""T_f5094_row10_col44"">-0.482909</td>
<td class=""data row10 col45"" id=""T_f5094_row10_col45"">1.731628</td>
<td class=""data row10 col46"" id=""T_f5094_row10_col46"">-2.783425</td>
<td class=""data row10 col47"" id=""T_f5094_row10_col47"">-0.333677</td>
<td class=""data row10 col48"" id=""T_f5094_row10_col48"">-0.110895</td>
<td class=""data row10 col49"" id=""T_f5094_row10_col49"">1.212636</td>
<td class=""data row10 col50"" id=""T_f5094_row10_col50"">-0.208412</td>
<td class=""data row10 col51"" id=""T_f5094_row10_col51"">0.427117</td>
<td class=""data row10 col52"" id=""T_f5094_row10_col52"">1.348563</td>
<td class=""data row10 col53"" id=""T_f5094_row10_col53"">0.043859</td>
<td class=""data row10 col54"" id=""T_f5094_row10_col54"">1.772519</td>
<td class=""data row10 col55"" id=""T_f5094_row10_col55"">-1.416106</td>
<td class=""data row10 col56"" id=""T_f5094_row10_col56"">0.401155</td>
<td class=""data row10 col57"" id=""T_f5094_row10_col57"">0.807157</td>
<td class=""data row10 col58"" id=""T_f5094_row10_col58"">0.303427</td>
<td class=""data row10 col59"" id=""T_f5094_row10_col59"">-1.246288</td>
<td class=""data row10 col60"" id=""T_f5094_row10_col60"">0.178774</td>
<td class=""data row10 col61"" id=""T_f5094_row10_col61"">-0.066126</td>
<td class=""data row10 col62"" id=""T_f5094_row10_col62"">-1.862288</td>
<td class=""data row10 col63"" id=""T_f5094_row10_col63"">1.241295</td>
<td class=""data row10 col64"" id=""T_f5094_row10_col64"">0.377021</td>
<td class=""data row10 col65"" id=""T_f5094_row10_col65"">-0.822320</td>
<td class=""data row10 col66"" id=""T_f5094_row10_col66"">-0.749014</td>
<td class=""data row10 col67"" id=""T_f5094_row10_col67"">1.463652</td>
<td class=""data row10 col68"" id=""T_f5094_row10_col68"">1.602268</td>
<td class=""data row10 col69"" id=""T_f5094_row10_col69"">-1.043877</td>
<td class=""data row10 col70"" id=""T_f5094_row10_col70"">1.185290</td>
<td class=""data row10 col71"" id=""T_f5094_row10_col71"">-0.565783</td>
<td class=""data row10 col72"" id=""T_f5094_row10_col72"">-1.076879</td>
<td class=""data row10 col73"" id=""T_f5094_row10_col73"">1.360241</td>
<td class=""data row10 col74"" id=""T_f5094_row10_col74"">-0.121991</td>
<td class=""data row10 col75"" id=""T_f5094_row10_col75"">0.991043</td>
<td class=""data row10 col76"" id=""T_f5094_row10_col76"">1.007952</td>
<td class=""data row10 col77"" id=""T_f5094_row10_col77"">0.450185</td>
<td class=""data row10 col78"" id=""T_f5094_row10_col78"">-0.744376</td>
<td class=""data row10 col79"" id=""T_f5094_row10_col79"">1.388876</td>
<td class=""data row10 col80"" id=""T_f5094_row10_col80"">-0.316847</td>
<td class=""data row10 col81"" id=""T_f5094_row10_col81"">-0.841655</td>
<td class=""data row10 col82"" id=""T_f5094_row10_col82"">-1.056842</td>
<td class=""data row10 col83"" id=""T_f5094_row10_col83"">-0.500226</td>
<td class=""data row10 col84"" id=""T_f5094_row10_col84"">0.096959</td>
<td class=""data row10 col85"" id=""T_f5094_row10_col85"">1.176896</td>
<td class=""data row10 col86"" id=""T_f5094_row10_col86"">-2.939652</td>
<td class=""data row10 col87"" id=""T_f5094_row10_col87"">1.792213</td>
<td class=""data row10 col88"" id=""T_f5094_row10_col88"">0.316340</td>
<td class=""data row10 col89"" id=""T_f5094_row10_col89"">0.303218</td>
<td class=""data row10 col90"" id=""T_f5094_row10_col90"">1.024967</td>
<td class=""data row10 col91"" id=""T_f5094_row10_col91"">-0.590871</td>
<td class=""data row10 col92"" id=""T_f5094_row10_col92"">-0.453326</td>
<td class=""data row10 col93"" id=""T_f5094_row10_col93"">-0.795981</td>
<td class=""data row10 col94"" id=""T_f5094_row10_col94"">-0.393301</td>
<td class=""data row10 col95"" id=""T_f5094_row10_col95"">-0.374372</td>
<td class=""data row10 col96"" id=""T_f5094_row10_col96"">-1.270199</td>
<td class=""data row10 col97"" id=""T_f5094_row10_col97"">1.618372</td>
<td class=""data row10 col98"" id=""T_f5094_row10_col98"">1.197727</td>
<td class=""data row10 col99"" id=""T_f5094_row10_col99"">-0.914863</td>
</tr>
<tr>
<th class=""row_heading level2 row11"" id=""T_f5094_level2_row11"">3</th>
<td class=""data row11 col0"" id=""T_f5094_row11_col0"">-0.625210</td>
<td class=""data row11 col1"" id=""T_f5094_row11_col1"">0.288911</td>
<td class=""data row11 col2"" id=""T_f5094_row11_col2"">0.288374</td>
<td class=""data row11 col3"" id=""T_f5094_row11_col3"">-1.372667</td>
<td class=""data row11 col4"" id=""T_f5094_row11_col4"">-0.591395</td>
<td class=""data row11 col5"" id=""T_f5094_row11_col5"">-0.478942</td>
<td class=""data row11 col6"" id=""T_f5094_row11_col6"">1.335664</td>
<td class=""data row11 col7"" id=""T_f5094_row11_col7"">-0.459855</td>
<td class=""data row11 col8"" id=""T_f5094_row11_col8"">-1.615975</td>
<td class=""data row11 col9"" id=""T_f5094_row11_col9"">-1.189676</td>
<td class=""data row11 col10"" id=""T_f5094_row11_col10"">0.374767</td>
<td class=""data row11 col11"" id=""T_f5094_row11_col11"">-2.488733</td>
<td class=""data row11 col12"" id=""T_f5094_row11_col12"">0.586656</td>
<td class=""data row11 col13"" id=""T_f5094_row11_col13"">-1.422008</td>
<td class=""data row11 col14"" id=""T_f5094_row11_col14"">0.496030</td>
<td class=""data row11 col15"" id=""T_f5094_row11_col15"">1.911128</td>
<td class=""data row11 col16"" id=""T_f5094_row11_col16"">-0.560660</td>
<td class=""data row11 col17"" id=""T_f5094_row11_col17"">-0.499614</td>
<td class=""data row11 col18"" id=""T_f5094_row11_col18"">-0.372171</td>
<td class=""data row11 col19"" id=""T_f5094_row11_col19"">-1.833069</td>
<td class=""data row11 col20"" id=""T_f5094_row11_col20"">0.237124</td>
<td class=""data row11 col21"" id=""T_f5094_row11_col21"">-0.944446</td>
<td class=""data row11 col22"" id=""T_f5094_row11_col22"">0.912140</td>
<td class=""data row11 col23"" id=""T_f5094_row11_col23"">0.359790</td>
<td class=""data row11 col24"" id=""T_f5094_row11_col24"">-1.359235</td>
<td class=""data row11 col25"" id=""T_f5094_row11_col25"">0.166966</td>
<td class=""data row11 col26"" id=""T_f5094_row11_col26"">-0.047107</td>
<td class=""data row11 col27"" id=""T_f5094_row11_col27"">-0.279789</td>
<td class=""data row11 col28"" id=""T_f5094_row11_col28"">-0.594454</td>
<td class=""data row11 col29"" id=""T_f5094_row11_col29"">-0.739013</td>
<td class=""data row11 col30"" id=""T_f5094_row11_col30"">-1.527645</td>
<td class=""data row11 col31"" id=""T_f5094_row11_col31"">0.401668</td>
<td class=""data row11 col32"" id=""T_f5094_row11_col32"">1.791252</td>
<td class=""data row11 col33"" id=""T_f5094_row11_col33"">-2.774848</td>
<td class=""data row11 col34"" id=""T_f5094_row11_col34"">0.523873</td>
<td class=""data row11 col35"" id=""T_f5094_row11_col35"">2.207585</td>
<td class=""data row11 col36"" id=""T_f5094_row11_col36"">0.488999</td>
<td class=""data row11 col37"" id=""T_f5094_row11_col37"">-0.339283</td>
<td class=""data row11 col38"" id=""T_f5094_row11_col38"">0.131711</td>
<td class=""data row11 col39"" id=""T_f5094_row11_col39"">0.018409</td>
<td class=""data row11 col40"" id=""T_f5094_row11_col40"">1.186551</td>
<td class=""data row11 col41"" id=""T_f5094_row11_col41"">-0.424318</td>
<td class=""data row11 col42"" id=""T_f5094_row11_col42"">1.554994</td>
<td class=""data row11 col43"" id=""T_f5094_row11_col43"">-0.205917</td>
<td class=""data row11 col44"" id=""T_f5094_row11_col44"">-0.934975</td>
<td class=""data row11 col45"" id=""T_f5094_row11_col45"">0.654102</td>
<td class=""data row11 col46"" id=""T_f5094_row11_col46"">-1.227761</td>
<td class=""data row11 col47"" id=""T_f5094_row11_col47"">-0.461025</td>
<td class=""data row11 col48"" id=""T_f5094_row11_col48"">-0.421201</td>
<td class=""data row11 col49"" id=""T_f5094_row11_col49"">-0.058615</td>
<td class=""data row11 col50"" id=""T_f5094_row11_col50"">-0.584563</td>
<td class=""data row11 col51"" id=""T_f5094_row11_col51"">0.336913</td>
<td class=""data row11 col52"" id=""T_f5094_row11_col52"">-0.477102</td>
<td class=""data row11 col53"" id=""T_f5094_row11_col53"">-1.381463</td>
<td class=""data row11 col54"" id=""T_f5094_row11_col54"">0.757745</td>
<td class=""data row11 col55"" id=""T_f5094_row11_col55"">-0.268968</td>
<td class=""data row11 col56"" id=""T_f5094_row11_col56"">0.034870</td>
<td class=""data row11 col57"" id=""T_f5094_row11_col57"">1.231686</td>
<td class=""data row11 col58"" id=""T_f5094_row11_col58"">0.236600</td>
<td class=""data row11 col59"" id=""T_f5094_row11_col59"">1.234720</td>
<td class=""data row11 col60"" id=""T_f5094_row11_col60"">-0.040247</td>
<td class=""data row11 col61"" id=""T_f5094_row11_col61"">0.029582</td>
<td class=""data row11 col62"" id=""T_f5094_row11_col62"">1.034905</td>
<td class=""data row11 col63"" id=""T_f5094_row11_col63"">0.380204</td>
<td class=""data row11 col64"" id=""T_f5094_row11_col64"">-0.012108</td>
<td class=""data row11 col65"" id=""T_f5094_row11_col65"">-0.859511</td>
<td class=""data row11 col66"" id=""T_f5094_row11_col66"">-0.990340</td>
<td class=""data row11 col67"" id=""T_f5094_row11_col67"">-1.205172</td>
<td class=""data row11 col68"" id=""T_f5094_row11_col68"">-1.030178</td>
<td class=""data row11 col69"" id=""T_f5094_row11_col69"">0.426676</td>
<td class=""data row11 col70"" id=""T_f5094_row11_col70"">0.497796</td>
<td class=""data row11 col71"" id=""T_f5094_row11_col71"">-0.876808</td>
<td class=""data row11 col72"" id=""T_f5094_row11_col72"">0.957963</td>
<td class=""data row11 col73"" id=""T_f5094_row11_col73"">0.173016</td>
<td class=""data row11 col74"" id=""T_f5094_row11_col74"">0.131612</td>
<td class=""data row11 col75"" id=""T_f5094_row11_col75"">-1.003556</td>
<td class=""data row11 col76"" id=""T_f5094_row11_col76"">-1.069908</td>
<td class=""data row11 col77"" id=""T_f5094_row11_col77"">-1.799207</td>
<td class=""data row11 col78"" id=""T_f5094_row11_col78"">1.429598</td>
<td class=""data row11 col79"" id=""T_f5094_row11_col79"">-0.116015</td>
<td class=""data row11 col80"" id=""T_f5094_row11_col80"">-1.454980</td>
<td class=""data row11 col81"" id=""T_f5094_row11_col81"">0.261917</td>
<td class=""data row11 col82"" id=""T_f5094_row11_col82"">0.444412</td>
<td class=""data row11 col83"" id=""T_f5094_row11_col83"">0.273290</td>
<td class=""data row11 col84"" id=""T_f5094_row11_col84"">0.844115</td>
<td class=""data row11 col85"" id=""T_f5094_row11_col85"">0.218745</td>
<td class=""data row11 col86"" id=""T_f5094_row11_col86"">-1.033350</td>
<td class=""data row11 col87"" id=""T_f5094_row11_col87"">-1.188295</td>
<td class=""data row11 col88"" id=""T_f5094_row11_col88"">0.058373</td>
<td class=""data row11 col89"" id=""T_f5094_row11_col89"">0.800523</td>
<td class=""data row11 col90"" id=""T_f5094_row11_col90"">-1.627068</td>
<td class=""data row11 col91"" id=""T_f5094_row11_col91"">0.861651</td>
<td class=""data row11 col92"" id=""T_f5094_row11_col92"">0.871018</td>
<td class=""data row11 col93"" id=""T_f5094_row11_col93"">-0.003733</td>
<td class=""data row11 col94"" id=""T_f5094_row11_col94"">-0.243354</td>
<td class=""data row11 col95"" id=""T_f5094_row11_col95"">0.947296</td>
<td class=""data row11 col96"" id=""T_f5094_row11_col96"">0.509406</td>
<td class=""data row11 col97"" id=""T_f5094_row11_col97"">0.044546</td>
<td class=""data row11 col98"" id=""T_f5094_row11_col98"">0.266896</td>
<td class=""data row11 col99"" id=""T_f5094_row11_col99"">1.337165</td>
</tr>
<tr>
<th class=""row_heading level1 row12"" id=""T_f5094_level1_row12"" rowspan=""4"">1</th>
<th class=""row_heading level2 row12"" id=""T_f5094_level2_row12"">0</th>
<td class=""data row12 col0"" id=""T_f5094_row12_col0"">0.699142</td>
<td class=""data row12 col1"" id=""T_f5094_row12_col1"">-1.928033</td>
<td class=""data row12 col2"" id=""T_f5094_row12_col2"">0.105363</td>
<td class=""data row12 col3"" id=""T_f5094_row12_col3"">1.042322</td>
<td class=""data row12 col4"" id=""T_f5094_row12_col4"">0.715206</td>
<td class=""data row12 col5"" id=""T_f5094_row12_col5"">-0.763783</td>
<td class=""data row12 col6"" id=""T_f5094_row12_col6"">0.098798</td>
<td class=""data row12 col7"" id=""T_f5094_row12_col7"">-1.157898</td>
<td class=""data row12 col8"" id=""T_f5094_row12_col8"">0.134105</td>
<td class=""data row12 col9"" id=""T_f5094_row12_col9"">0.042041</td>
<td class=""data row12 col10"" id=""T_f5094_row12_col10"">0.674826</td>
<td class=""data row12 col11"" id=""T_f5094_row12_col11"">0.165649</td>
<td class=""data row12 col12"" id=""T_f5094_row12_col12"">-1.622970</td>
<td class=""data row12 col13"" id=""T_f5094_row12_col13"">-3.131274</td>
<td class=""data row12 col14"" id=""T_f5094_row12_col14"">0.597649</td>
<td class=""data row12 col15"" id=""T_f5094_row12_col15"">-1.880331</td>
<td class=""data row12 col16"" id=""T_f5094_row12_col16"">0.663980</td>
<td class=""data row12 col17"" id=""T_f5094_row12_col17"">-0.256033</td>
<td class=""data row12 col18"" id=""T_f5094_row12_col18"">-1.524058</td>
<td class=""data row12 col19"" id=""T_f5094_row12_col19"">0.492799</td>
<td class=""data row12 col20"" id=""T_f5094_row12_col20"">0.221163</td>
<td class=""data row12 col21"" id=""T_f5094_row12_col21"">0.429622</td>
<td class=""data row12 col22"" id=""T_f5094_row12_col22"">-0.659584</td>
<td class=""data row12 col23"" id=""T_f5094_row12_col23"">1.264506</td>
<td class=""data row12 col24"" id=""T_f5094_row12_col24"">-0.032131</td>
<td class=""data row12 col25"" id=""T_f5094_row12_col25"">-2.114907</td>
<td class=""data row12 col26"" id=""T_f5094_row12_col26"">-0.264043</td>
<td class=""data row12 col27"" id=""T_f5094_row12_col27"">0.457835</td>
<td class=""data row12 col28"" id=""T_f5094_row12_col28"">-0.676837</td>
<td class=""data row12 col29"" id=""T_f5094_row12_col29"">-0.629003</td>
<td class=""data row12 col30"" id=""T_f5094_row12_col30"">0.489145</td>
<td class=""data row12 col31"" id=""T_f5094_row12_col31"">-0.551686</td>
<td class=""data row12 col32"" id=""T_f5094_row12_col32"">0.942622</td>
<td class=""data row12 col33"" id=""T_f5094_row12_col33"">-0.512043</td>
<td class=""data row12 col34"" id=""T_f5094_row12_col34"">-0.455893</td>
<td class=""data row12 col35"" id=""T_f5094_row12_col35"">0.021244</td>
<td class=""data row12 col36"" id=""T_f5094_row12_col36"">-0.178035</td>
<td class=""data row12 col37"" id=""T_f5094_row12_col37"">-2.498073</td>
<td class=""data row12 col38"" id=""T_f5094_row12_col38"">-0.171292</td>
<td class=""data row12 col39"" id=""T_f5094_row12_col39"">0.323510</td>
<td class=""data row12 col40"" id=""T_f5094_row12_col40"">-0.545163</td>
<td class=""data row12 col41"" id=""T_f5094_row12_col41"">-0.668909</td>
<td class=""data row12 col42"" id=""T_f5094_row12_col42"">-0.150031</td>
<td class=""data row12 col43"" id=""T_f5094_row12_col43"">0.521620</td>
<td class=""data row12 col44"" id=""T_f5094_row12_col44"">-0.428980</td>
<td class=""data row12 col45"" id=""T_f5094_row12_col45"">0.676463</td>
<td class=""data row12 col46"" id=""T_f5094_row12_col46"">0.369081</td>
<td class=""data row12 col47"" id=""T_f5094_row12_col47"">-0.724832</td>
<td class=""data row12 col48"" id=""T_f5094_row12_col48"">0.793542</td>
<td class=""data row12 col49"" id=""T_f5094_row12_col49"">1.237422</td>
<td class=""data row12 col50"" id=""T_f5094_row12_col50"">0.401275</td>
<td class=""data row12 col51"" id=""T_f5094_row12_col51"">2.141523</td>
<td class=""data row12 col52"" id=""T_f5094_row12_col52"">0.249012</td>
<td class=""data row12 col53"" id=""T_f5094_row12_col53"">0.486755</td>
<td class=""data row12 col54"" id=""T_f5094_row12_col54"">-0.163274</td>
<td class=""data row12 col55"" id=""T_f5094_row12_col55"">0.592222</td>
<td class=""data row12 col56"" id=""T_f5094_row12_col56"">-0.292600</td>
<td class=""data row12 col57"" id=""T_f5094_row12_col57"">-0.547168</td>
<td class=""data row12 col58"" id=""T_f5094_row12_col58"">0.619104</td>
<td class=""data row12 col59"" id=""T_f5094_row12_col59"">-0.013605</td>
<td class=""data row12 col60"" id=""T_f5094_row12_col60"">0.776734</td>
<td class=""data row12 col61"" id=""T_f5094_row12_col61"">0.131424</td>
<td class=""data row12 col62"" id=""T_f5094_row12_col62"">1.189480</td>
<td class=""data row12 col63"" id=""T_f5094_row12_col63"">-0.666317</td>
<td class=""data row12 col64"" id=""T_f5094_row12_col64"">-0.939036</td>
<td class=""data row12 col65"" id=""T_f5094_row12_col65"">1.105515</td>
<td class=""data row12 col66"" id=""T_f5094_row12_col66"">0.621452</td>
<td class=""data row12 col67"" id=""T_f5094_row12_col67"">1.586605</td>
<td class=""data row12 col68"" id=""T_f5094_row12_col68"">-0.760970</td>
<td class=""data row12 col69"" id=""T_f5094_row12_col69"">1.649646</td>
<td class=""data row12 col70"" id=""T_f5094_row12_col70"">0.283199</td>
<td class=""data row12 col71"" id=""T_f5094_row12_col71"">1.275812</td>
<td class=""data row12 col72"" id=""T_f5094_row12_col72"">-0.452012</td>
<td class=""data row12 col73"" id=""T_f5094_row12_col73"">0.301361</td>
<td class=""data row12 col74"" id=""T_f5094_row12_col74"">-0.976951</td>
<td class=""data row12 col75"" id=""T_f5094_row12_col75"">-0.268106</td>
<td class=""data row12 col76"" id=""T_f5094_row12_col76"">-0.079255</td>
<td class=""data row12 col77"" id=""T_f5094_row12_col77"">-1.258332</td>
<td class=""data row12 col78"" id=""T_f5094_row12_col78"">2.216658</td>
<td class=""data row12 col79"" id=""T_f5094_row12_col79"">-1.175988</td>
<td class=""data row12 col80"" id=""T_f5094_row12_col80"">-0.863497</td>
<td class=""data row12 col81"" id=""T_f5094_row12_col81"">-1.653022</td>
<td class=""data row12 col82"" id=""T_f5094_row12_col82"">-0.561514</td>
<td class=""data row12 col83"" id=""T_f5094_row12_col83"">0.450753</td>
<td class=""data row12 col84"" id=""T_f5094_row12_col84"">0.417200</td>
<td class=""data row12 col85"" id=""T_f5094_row12_col85"">0.094676</td>
<td class=""data row12 col86"" id=""T_f5094_row12_col86"">-2.231054</td>
<td class=""data row12 col87"" id=""T_f5094_row12_col87"">1.316862</td>
<td class=""data row12 col88"" id=""T_f5094_row12_col88"">-0.477441</td>
<td class=""data row12 col89"" id=""T_f5094_row12_col89"">0.646654</td>
<td class=""data row12 col90"" id=""T_f5094_row12_col90"">-0.200252</td>
<td class=""data row12 col91"" id=""T_f5094_row12_col91"">1.074354</td>
<td class=""data row12 col92"" id=""T_f5094_row12_col92"">-0.058176</td>
<td class=""data row12 col93"" id=""T_f5094_row12_col93"">0.120990</td>
<td class=""data row12 col94"" id=""T_f5094_row12_col94"">0.222522</td>
<td class=""data row12 col95"" id=""T_f5094_row12_col95"">-0.179507</td>
<td class=""data row12 col96"" id=""T_f5094_row12_col96"">0.421655</td>
<td class=""data row12 col97"" id=""T_f5094_row12_col97"">-0.914341</td>
<td class=""data row12 col98"" id=""T_f5094_row12_col98"">-0.234178</td>
<td class=""data row12 col99"" id=""T_f5094_row12_col99"">0.741524</td>
</tr>
<tr>
<th class=""row_heading level2 row13"" id=""T_f5094_level2_row13"">1</th>
<td class=""data row13 col0"" id=""T_f5094_row13_col0"">0.932714</td>
<td class=""data row13 col1"" id=""T_f5094_row13_col1"">1.423761</td>
<td class=""data row13 col2"" id=""T_f5094_row13_col2"">-1.280835</td>
<td class=""data row13 col3"" id=""T_f5094_row13_col3"">0.347882</td>
<td class=""data row13 col4"" id=""T_f5094_row13_col4"">-0.863171</td>
<td class=""data row13 col5"" id=""T_f5094_row13_col5"">-0.852580</td>
<td class=""data row13 col6"" id=""T_f5094_row13_col6"">1.044933</td>
<td class=""data row13 col7"" id=""T_f5094_row13_col7"">2.094536</td>
<td class=""data row13 col8"" id=""T_f5094_row13_col8"">0.806206</td>
<td class=""data row13 col9"" id=""T_f5094_row13_col9"">0.416201</td>
<td class=""data row13 col10"" id=""T_f5094_row13_col10"">-1.109503</td>
<td class=""data row13 col11"" id=""T_f5094_row13_col11"">0.145302</td>
<td class=""data row13 col12"" id=""T_f5094_row13_col12"">-0.996871</td>
<td class=""data row13 col13"" id=""T_f5094_row13_col13"">0.325456</td>
<td class=""data row13 col14"" id=""T_f5094_row13_col14"">-0.605081</td>
<td class=""data row13 col15"" id=""T_f5094_row13_col15"">1.175326</td>
<td class=""data row13 col16"" id=""T_f5094_row13_col16"">1.645054</td>
<td class=""data row13 col17"" id=""T_f5094_row13_col17"">0.293432</td>
<td class=""data row13 col18"" id=""T_f5094_row13_col18"">-2.766822</td>
<td class=""data row13 col19"" id=""T_f5094_row13_col19"">1.032849</td>
<td class=""data row13 col20"" id=""T_f5094_row13_col20"">0.079115</td>
<td class=""data row13 col21"" id=""T_f5094_row13_col21"">-1.414132</td>
<td class=""data row13 col22"" id=""T_f5094_row13_col22"">1.463376</td>
<td class=""data row13 col23"" id=""T_f5094_row13_col23"">2.335486</td>
<td class=""data row13 col24"" id=""T_f5094_row13_col24"">0.411951</td>
<td class=""data row13 col25"" id=""T_f5094_row13_col25"">-0.048543</td>
<td class=""data row13 col26"" id=""T_f5094_row13_col26"">0.159284</td>
<td class=""data row13 col27"" id=""T_f5094_row13_col27"">-0.651554</td>
<td class=""data row13 col28"" id=""T_f5094_row13_col28"">-1.093128</td>
<td class=""data row13 col29"" id=""T_f5094_row13_col29"">1.568390</td>
<td class=""data row13 col30"" id=""T_f5094_row13_col30"">-0.077807</td>
<td class=""data row13 col31"" id=""T_f5094_row13_col31"">-2.390779</td>
<td class=""data row13 col32"" id=""T_f5094_row13_col32"">-0.842346</td>
<td class=""data row13 col33"" id=""T_f5094_row13_col33"">-0.229675</td>
<td class=""data row13 col34"" id=""T_f5094_row13_col34"">-0.999072</td>
<td class=""data row13 col35"" id=""T_f5094_row13_col35"">-1.367219</td>
<td class=""data row13 col36"" id=""T_f5094_row13_col36"">-0.792042</td>
<td class=""data row13 col37"" id=""T_f5094_row13_col37"">-1.878575</td>
<td class=""data row13 col38"" id=""T_f5094_row13_col38"">1.451452</td>
<td class=""data row13 col39"" id=""T_f5094_row13_col39"">1.266250</td>
<td class=""data row13 col40"" id=""T_f5094_row13_col40"">-0.734315</td>
<td class=""data row13 col41"" id=""T_f5094_row13_col41"">0.266152</td>
<td class=""data row13 col42"" id=""T_f5094_row13_col42"">0.735523</td>
<td class=""data row13 col43"" id=""T_f5094_row13_col43"">-0.430860</td>
<td class=""data row13 col44"" id=""T_f5094_row13_col44"">0.229864</td>
<td class=""data row13 col45"" id=""T_f5094_row13_col45"">0.850083</td>
<td class=""data row13 col46"" id=""T_f5094_row13_col46"">-2.241241</td>
<td class=""data row13 col47"" id=""T_f5094_row13_col47"">1.063850</td>
<td class=""data row13 col48"" id=""T_f5094_row13_col48"">0.289409</td>
<td class=""data row13 col49"" id=""T_f5094_row13_col49"">-0.354360</td>
<td class=""data row13 col50"" id=""T_f5094_row13_col50"">0.113063</td>
<td class=""data row13 col51"" id=""T_f5094_row13_col51"">-0.173006</td>
<td class=""data row13 col52"" id=""T_f5094_row13_col52"">1.386998</td>
<td class=""data row13 col53"" id=""T_f5094_row13_col53"">1.886236</td>
<td class=""data row13 col54"" id=""T_f5094_row13_col54"">0.587119</td>
<td class=""data row13 col55"" id=""T_f5094_row13_col55"">-0.961133</td>
<td class=""data row13 col56"" id=""T_f5094_row13_col56"">0.399295</td>
<td class=""data row13 col57"" id=""T_f5094_row13_col57"">1.461560</td>
<td class=""data row13 col58"" id=""T_f5094_row13_col58"">0.310823</td>
<td class=""data row13 col59"" id=""T_f5094_row13_col59"">0.280220</td>
<td class=""data row13 col60"" id=""T_f5094_row13_col60"">-0.879103</td>
<td class=""data row13 col61"" id=""T_f5094_row13_col61"">-1.326348</td>
<td class=""data row13 col62"" id=""T_f5094_row13_col62"">0.003337</td>
<td class=""data row13 col63"" id=""T_f5094_row13_col63"">-1.085908</td>
<td class=""data row13 col64"" id=""T_f5094_row13_col64"">-0.436723</td>
<td class=""data row13 col65"" id=""T_f5094_row13_col65"">2.111926</td>
<td class=""data row13 col66"" id=""T_f5094_row13_col66"">0.106068</td>
<td class=""data row13 col67"" id=""T_f5094_row13_col67"">0.615597</td>
<td class=""data row13 col68"" id=""T_f5094_row13_col68"">2.152996</td>
<td class=""data row13 col69"" id=""T_f5094_row13_col69"">-0.196155</td>
<td class=""data row13 col70"" id=""T_f5094_row13_col70"">0.025747</td>
<td class=""data row13 col71"" id=""T_f5094_row13_col71"">-0.039061</td>
<td class=""data row13 col72"" id=""T_f5094_row13_col72"">0.656823</td>
<td class=""data row13 col73"" id=""T_f5094_row13_col73"">-0.347105</td>
<td class=""data row13 col74"" id=""T_f5094_row13_col74"">2.513979</td>
<td class=""data row13 col75"" id=""T_f5094_row13_col75"">1.758070</td>
<td class=""data row13 col76"" id=""T_f5094_row13_col76"">1.288473</td>
<td class=""data row13 col77"" id=""T_f5094_row13_col77"">-0.739185</td>
<td class=""data row13 col78"" id=""T_f5094_row13_col78"">-0.691592</td>
<td class=""data row13 col79"" id=""T_f5094_row13_col79"">-0.098728</td>
<td class=""data row13 col80"" id=""T_f5094_row13_col80"">-0.276386</td>
<td class=""data row13 col81"" id=""T_f5094_row13_col81"">0.489981</td>
<td class=""data row13 col82"" id=""T_f5094_row13_col82"">0.516278</td>
<td class=""data row13 col83"" id=""T_f5094_row13_col83"">-0.838258</td>
<td class=""data row13 col84"" id=""T_f5094_row13_col84"">0.596673</td>
<td class=""data row13 col85"" id=""T_f5094_row13_col85"">-0.331053</td>
<td class=""data row13 col86"" id=""T_f5094_row13_col86"">0.521174</td>
<td class=""data row13 col87"" id=""T_f5094_row13_col87"">-0.145023</td>
<td class=""data row13 col88"" id=""T_f5094_row13_col88"">0.836693</td>
<td class=""data row13 col89"" id=""T_f5094_row13_col89"">-1.092166</td>
<td class=""data row13 col90"" id=""T_f5094_row13_col90"">0.361733</td>
<td class=""data row13 col91"" id=""T_f5094_row13_col91"">-1.169981</td>
<td class=""data row13 col92"" id=""T_f5094_row13_col92"">0.046731</td>
<td class=""data row13 col93"" id=""T_f5094_row13_col93"">0.655377</td>
<td class=""data row13 col94"" id=""T_f5094_row13_col94"">-0.756852</td>
<td class=""data row13 col95"" id=""T_f5094_row13_col95"">1.285805</td>
<td class=""data row13 col96"" id=""T_f5094_row13_col96"">-0.095019</td>
<td class=""data row13 col97"" id=""T_f5094_row13_col97"">0.360253</td>
<td class=""data row13 col98"" id=""T_f5094_row13_col98"">1.370621</td>
<td class=""data row13 col99"" id=""T_f5094_row13_col99"">0.083010</td>
</tr>
<tr>
<th class=""row_heading level2 row14"" id=""T_f5094_level2_row14"">2</th>
<td class=""data row14 col0"" id=""T_f5094_row14_col0"">0.888893</td>
<td class=""data row14 col1"" id=""T_f5094_row14_col1"">2.288725</td>
<td class=""data row14 col2"" id=""T_f5094_row14_col2"">-1.032332</td>
<td class=""data row14 col3"" id=""T_f5094_row14_col3"">0.212273</td>
<td class=""data row14 col4"" id=""T_f5094_row14_col4"">-1.091826</td>
<td class=""data row14 col5"" id=""T_f5094_row14_col5"">1.692498</td>
<td class=""data row14 col6"" id=""T_f5094_row14_col6"">1.025367</td>
<td class=""data row14 col7"" id=""T_f5094_row14_col7"">0.550854</td>
<td class=""data row14 col8"" id=""T_f5094_row14_col8"">0.679430</td>
<td class=""data row14 col9"" id=""T_f5094_row14_col9"">-1.335712</td>
<td class=""data row14 col10"" id=""T_f5094_row14_col10"">-0.798341</td>
<td class=""data row14 col11"" id=""T_f5094_row14_col11"">2.265351</td>
<td class=""data row14 col12"" id=""T_f5094_row14_col12"">-1.006938</td>
<td class=""data row14 col13"" id=""T_f5094_row14_col13"">2.059761</td>
<td class=""data row14 col14"" id=""T_f5094_row14_col14"">0.420266</td>
<td class=""data row14 col15"" id=""T_f5094_row14_col15"">-1.189657</td>
<td class=""data row14 col16"" id=""T_f5094_row14_col16"">0.506674</td>
<td class=""data row14 col17"" id=""T_f5094_row14_col17"">0.260847</td>
<td class=""data row14 col18"" id=""T_f5094_row14_col18"">-0.533145</td>
<td class=""data row14 col19"" id=""T_f5094_row14_col19"">0.727267</td>
<td class=""data row14 col20"" id=""T_f5094_row14_col20"">1.412276</td>
<td class=""data row14 col21"" id=""T_f5094_row14_col21"">1.482106</td>
<td class=""data row14 col22"" id=""T_f5094_row14_col22"">-0.996258</td>
<td class=""data row14 col23"" id=""T_f5094_row14_col23"">0.588641</td>
<td class=""data row14 col24"" id=""T_f5094_row14_col24"">-0.412642</td>
<td class=""data row14 col25"" id=""T_f5094_row14_col25"">-0.920733</td>
<td class=""data row14 col26"" id=""T_f5094_row14_col26"">-0.874691</td>
<td class=""data row14 col27"" id=""T_f5094_row14_col27"">0.839002</td>
<td class=""data row14 col28"" id=""T_f5094_row14_col28"">0.501668</td>
<td class=""data row14 col29"" id=""T_f5094_row14_col29"">-0.342493</td>
<td class=""data row14 col30"" id=""T_f5094_row14_col30"">-0.533806</td>
<td class=""data row14 col31"" id=""T_f5094_row14_col31"">-2.146352</td>
<td class=""data row14 col32"" id=""T_f5094_row14_col32"">-0.597339</td>
<td class=""data row14 col33"" id=""T_f5094_row14_col33"">0.115726</td>
<td class=""data row14 col34"" id=""T_f5094_row14_col34"">0.850683</td>
<td class=""data row14 col35"" id=""T_f5094_row14_col35"">-0.752239</td>
<td class=""data row14 col36"" id=""T_f5094_row14_col36"">0.377263</td>
<td class=""data row14 col37"" id=""T_f5094_row14_col37"">-0.561982</td>
<td class=""data row14 col38"" id=""T_f5094_row14_col38"">0.262783</td>
<td class=""data row14 col39"" id=""T_f5094_row14_col39"">-0.356676</td>
<td class=""data row14 col40"" id=""T_f5094_row14_col40"">-0.367462</td>
<td class=""data row14 col41"" id=""T_f5094_row14_col41"">0.753611</td>
<td class=""data row14 col42"" id=""T_f5094_row14_col42"">-1.267414</td>
<td class=""data row14 col43"" id=""T_f5094_row14_col43"">-1.330698</td>
<td class=""data row14 col44"" id=""T_f5094_row14_col44"">-0.536453</td>
<td class=""data row14 col45"" id=""T_f5094_row14_col45"">0.840938</td>
<td class=""data row14 col46"" id=""T_f5094_row14_col46"">-0.763108</td>
<td class=""data row14 col47"" id=""T_f5094_row14_col47"">-0.268100</td>
<td class=""data row14 col48"" id=""T_f5094_row14_col48"">-0.677424</td>
<td class=""data row14 col49"" id=""T_f5094_row14_col49"">1.606831</td>
<td class=""data row14 col50"" id=""T_f5094_row14_col50"">0.151732</td>
<td class=""data row14 col51"" id=""T_f5094_row14_col51"">-2.085701</td>
<td class=""data row14 col52"" id=""T_f5094_row14_col52"">1.219296</td>
<td class=""data row14 col53"" id=""T_f5094_row14_col53"">0.400863</td>
<td class=""data row14 col54"" id=""T_f5094_row14_col54"">0.591165</td>
<td class=""data row14 col55"" id=""T_f5094_row14_col55"">-1.485213</td>
<td class=""data row14 col56"" id=""T_f5094_row14_col56"">1.501979</td>
<td class=""data row14 col57"" id=""T_f5094_row14_col57"">1.196569</td>
<td class=""data row14 col58"" id=""T_f5094_row14_col58"">-0.214154</td>
<td class=""data row14 col59"" id=""T_f5094_row14_col59"">0.339554</td>
<td class=""data row14 col60"" id=""T_f5094_row14_col60"">-0.034446</td>
<td class=""data row14 col61"" id=""T_f5094_row14_col61"">1.176452</td>
<td class=""data row14 col62"" id=""T_f5094_row14_col62"">0.546340</td>
<td class=""data row14 col63"" id=""T_f5094_row14_col63"">-1.255630</td>
<td class=""data row14 col64"" id=""T_f5094_row14_col64"">-1.309210</td>
<td class=""data row14 col65"" id=""T_f5094_row14_col65"">-0.445437</td>
<td class=""data row14 col66"" id=""T_f5094_row14_col66"">0.189437</td>
<td class=""data row14 col67"" id=""T_f5094_row14_col67"">-0.737463</td>
<td class=""data row14 col68"" id=""T_f5094_row14_col68"">0.843767</td>
<td class=""data row14 col69"" id=""T_f5094_row14_col69"">-0.605632</td>
<td class=""data row14 col70"" id=""T_f5094_row14_col70"">-0.060777</td>
<td class=""data row14 col71"" id=""T_f5094_row14_col71"">0.409310</td>
<td class=""data row14 col72"" id=""T_f5094_row14_col72"">1.285569</td>
<td class=""data row14 col73"" id=""T_f5094_row14_col73"">-0.622638</td>
<td class=""data row14 col74"" id=""T_f5094_row14_col74"">1.018193</td>
<td class=""data row14 col75"" id=""T_f5094_row14_col75"">0.880680</td>
<td class=""data row14 col76"" id=""T_f5094_row14_col76"">0.046805</td>
<td class=""data row14 col77"" id=""T_f5094_row14_col77"">-1.818058</td>
<td class=""data row14 col78"" id=""T_f5094_row14_col78"">-0.809829</td>
<td class=""data row14 col79"" id=""T_f5094_row14_col79"">0.875224</td>
<td class=""data row14 col80"" id=""T_f5094_row14_col80"">0.409569</td>
<td class=""data row14 col81"" id=""T_f5094_row14_col81"">-0.116621</td>
<td class=""data row14 col82"" id=""T_f5094_row14_col82"">-1.238919</td>
<td class=""data row14 col83"" id=""T_f5094_row14_col83"">3.305724</td>
<td class=""data row14 col84"" id=""T_f5094_row14_col84"">-0.024121</td>
<td class=""data row14 col85"" id=""T_f5094_row14_col85"">-1.756500</td>
<td class=""data row14 col86"" id=""T_f5094_row14_col86"">1.328958</td>
<td class=""data row14 col87"" id=""T_f5094_row14_col87"">0.507593</td>
<td class=""data row14 col88"" id=""T_f5094_row14_col88"">-0.866554</td>
<td class=""data row14 col89"" id=""T_f5094_row14_col89"">-2.240848</td>
<td class=""data row14 col90"" id=""T_f5094_row14_col90"">-0.661376</td>
<td class=""data row14 col91"" id=""T_f5094_row14_col91"">-0.671824</td>
<td class=""data row14 col92"" id=""T_f5094_row14_col92"">0.215720</td>
<td class=""data row14 col93"" id=""T_f5094_row14_col93"">-0.296326</td>
<td class=""data row14 col94"" id=""T_f5094_row14_col94"">0.481402</td>
<td class=""data row14 col95"" id=""T_f5094_row14_col95"">0.829645</td>
<td class=""data row14 col96"" id=""T_f5094_row14_col96"">-0.721025</td>
<td class=""data row14 col97"" id=""T_f5094_row14_col97"">1.263914</td>
<td class=""data row14 col98"" id=""T_f5094_row14_col98"">0.549047</td>
<td class=""data row14 col99"" id=""T_f5094_row14_col99"">-1.234945</td>
</tr>
<tr>
<th class=""row_heading level2 row15"" id=""T_f5094_level2_row15"">3</th>
<td class=""data row15 col0"" id=""T_f5094_row15_col0"">-1.978838</td>
<td class=""data row15 col1"" id=""T_f5094_row15_col1"">0.721823</td>
<td class=""data row15 col2"" id=""T_f5094_row15_col2"">-0.559067</td>
<td class=""data row15 col3"" id=""T_f5094_row15_col3"">-1.235243</td>
<td class=""data row15 col4"" id=""T_f5094_row15_col4"">0.420716</td>
<td class=""data row15 col5"" id=""T_f5094_row15_col5"">-0.598845</td>
<td class=""data row15 col6"" id=""T_f5094_row15_col6"">0.359576</td>
<td class=""data row15 col7"" id=""T_f5094_row15_col7"">-0.619366</td>
<td class=""data row15 col8"" id=""T_f5094_row15_col8"">-1.757772</td>
<td class=""data row15 col9"" id=""T_f5094_row15_col9"">-1.156251</td>
<td class=""data row15 col10"" id=""T_f5094_row15_col10"">0.705212</td>
<td class=""data row15 col11"" id=""T_f5094_row15_col11"">0.875071</td>
<td class=""data row15 col12"" id=""T_f5094_row15_col12"">-1.020376</td>
<td class=""data row15 col13"" id=""T_f5094_row15_col13"">0.394760</td>
<td class=""data row15 col14"" id=""T_f5094_row15_col14"">-0.147970</td>
<td class=""data row15 col15"" id=""T_f5094_row15_col15"">0.230249</td>
<td class=""data row15 col16"" id=""T_f5094_row15_col16"">1.355203</td>
<td class=""data row15 col17"" id=""T_f5094_row15_col17"">1.794488</td>
<td class=""data row15 col18"" id=""T_f5094_row15_col18"">2.678058</td>
<td class=""data row15 col19"" id=""T_f5094_row15_col19"">-0.153565</td>
<td class=""data row15 col20"" id=""T_f5094_row15_col20"">-0.460959</td>
<td class=""data row15 col21"" id=""T_f5094_row15_col21"">-0.098108</td>
<td class=""data row15 col22"" id=""T_f5094_row15_col22"">-1.407930</td>
<td class=""data row15 col23"" id=""T_f5094_row15_col23"">-2.487702</td>
<td class=""data row15 col24"" id=""T_f5094_row15_col24"">1.823014</td>
<td class=""data row15 col25"" id=""T_f5094_row15_col25"">0.099873</td>
<td class=""data row15 col26"" id=""T_f5094_row15_col26"">-0.517603</td>
<td class=""data row15 col27"" id=""T_f5094_row15_col27"">-0.509311</td>
<td class=""data row15 col28"" id=""T_f5094_row15_col28"">-1.833175</td>
<td class=""data row15 col29"" id=""T_f5094_row15_col29"">-0.900906</td>
<td class=""data row15 col30"" id=""T_f5094_row15_col30"">0.459493</td>
<td class=""data row15 col31"" id=""T_f5094_row15_col31"">-0.655440</td>
<td class=""data row15 col32"" id=""T_f5094_row15_col32"">1.466122</td>
<td class=""data row15 col33"" id=""T_f5094_row15_col33"">-1.531389</td>
<td class=""data row15 col34"" id=""T_f5094_row15_col34"">-0.422106</td>
<td class=""data row15 col35"" id=""T_f5094_row15_col35"">0.421422</td>
<td class=""data row15 col36"" id=""T_f5094_row15_col36"">0.578615</td>
<td class=""data row15 col37"" id=""T_f5094_row15_col37"">0.259795</td>
<td class=""data row15 col38"" id=""T_f5094_row15_col38"">0.018941</td>
<td class=""data row15 col39"" id=""T_f5094_row15_col39"">-0.168726</td>
<td class=""data row15 col40"" id=""T_f5094_row15_col40"">1.611107</td>
<td class=""data row15 col41"" id=""T_f5094_row15_col41"">-1.586550</td>
<td class=""data row15 col42"" id=""T_f5094_row15_col42"">-1.384941</td>
<td class=""data row15 col43"" id=""T_f5094_row15_col43"">0.858377</td>
<td class=""data row15 col44"" id=""T_f5094_row15_col44"">1.033242</td>
<td class=""data row15 col45"" id=""T_f5094_row15_col45"">1.701343</td>
<td class=""data row15 col46"" id=""T_f5094_row15_col46"">1.748344</td>
<td class=""data row15 col47"" id=""T_f5094_row15_col47"">-0.371182</td>
<td class=""data row15 col48"" id=""T_f5094_row15_col48"">-0.843575</td>
<td class=""data row15 col49"" id=""T_f5094_row15_col49"">2.089641</td>
<td class=""data row15 col50"" id=""T_f5094_row15_col50"">-0.345430</td>
<td class=""data row15 col51"" id=""T_f5094_row15_col51"">-1.740556</td>
<td class=""data row15 col52"" id=""T_f5094_row15_col52"">0.141915</td>
<td class=""data row15 col53"" id=""T_f5094_row15_col53"">-2.197138</td>
<td class=""data row15 col54"" id=""T_f5094_row15_col54"">0.689569</td>
<td class=""data row15 col55"" id=""T_f5094_row15_col55"">-0.150025</td>
<td class=""data row15 col56"" id=""T_f5094_row15_col56"">0.287456</td>
<td class=""data row15 col57"" id=""T_f5094_row15_col57"">0.654016</td>
<td class=""data row15 col58"" id=""T_f5094_row15_col58"">-1.521919</td>
<td class=""data row15 col59"" id=""T_f5094_row15_col59"">-0.918008</td>
<td class=""data row15 col60"" id=""T_f5094_row15_col60"">-0.587528</td>
<td class=""data row15 col61"" id=""T_f5094_row15_col61"">0.230636</td>
<td class=""data row15 col62"" id=""T_f5094_row15_col62"">0.262637</td>
<td class=""data row15 col63"" id=""T_f5094_row15_col63"">0.615674</td>
<td class=""data row15 col64"" id=""T_f5094_row15_col64"">0.600044</td>
<td class=""data row15 col65"" id=""T_f5094_row15_col65"">-0.494699</td>
<td class=""data row15 col66"" id=""T_f5094_row15_col66"">-0.743089</td>
<td class=""data row15 col67"" id=""T_f5094_row15_col67"">0.220026</td>
<td class=""data row15 col68"" id=""T_f5094_row15_col68"">-0.242207</td>
<td class=""data row15 col69"" id=""T_f5094_row15_col69"">0.528216</td>
<td class=""data row15 col70"" id=""T_f5094_row15_col70"">-0.328174</td>
<td class=""data row15 col71"" id=""T_f5094_row15_col71"">-1.536517</td>
<td class=""data row15 col72"" id=""T_f5094_row15_col72"">-1.476640</td>
<td class=""data row15 col73"" id=""T_f5094_row15_col73"">-1.162114</td>
<td class=""data row15 col74"" id=""T_f5094_row15_col74"">-1.260222</td>
<td class=""data row15 col75"" id=""T_f5094_row15_col75"">1.106252</td>
<td class=""data row15 col76"" id=""T_f5094_row15_col76"">-1.467408</td>
<td class=""data row15 col77"" id=""T_f5094_row15_col77"">-0.349341</td>
<td class=""data row15 col78"" id=""T_f5094_row15_col78"">-1.841217</td>
<td class=""data row15 col79"" id=""T_f5094_row15_col79"">0.031296</td>
<td class=""data row15 col80"" id=""T_f5094_row15_col80"">-0.076475</td>
<td class=""data row15 col81"" id=""T_f5094_row15_col81"">-0.353383</td>
<td class=""data row15 col82"" id=""T_f5094_row15_col82"">0.807545</td>
<td class=""data row15 col83"" id=""T_f5094_row15_col83"">0.779064</td>
<td class=""data row15 col84"" id=""T_f5094_row15_col84"">-2.398417</td>
<td class=""data row15 col85"" id=""T_f5094_row15_col85"">-0.267828</td>
<td class=""data row15 col86"" id=""T_f5094_row15_col86"">1.549734</td>
<td class=""data row15 col87"" id=""T_f5094_row15_col87"">0.814397</td>
<td class=""data row15 col88"" id=""T_f5094_row15_col88"">0.284770</td>
<td class=""data row15 col89"" id=""T_f5094_row15_col89"">-0.659369</td>
<td class=""data row15 col90"" id=""T_f5094_row15_col90"">0.761040</td>
<td class=""data row15 col91"" id=""T_f5094_row15_col91"">-0.722067</td>
<td class=""data row15 col92"" id=""T_f5094_row15_col92"">0.810332</td>
<td class=""data row15 col93"" id=""T_f5094_row15_col93"">1.501295</td>
<td class=""data row15 col94"" id=""T_f5094_row15_col94"">1.440865</td>
<td class=""data row15 col95"" id=""T_f5094_row15_col95"">-1.367459</td>
<td class=""data row15 col96"" id=""T_f5094_row15_col96"">-0.700301</td>
<td class=""data row15 col97"" id=""T_f5094_row15_col97"">-1.540662</td>
<td class=""data row15 col98"" id=""T_f5094_row15_col98"">0.159837</td>
<td class=""data row15 col99"" id=""T_f5094_row15_col99"">-0.625415</td>
</tr>
</tbody>
</table></div>
</div>
</section>
<section id=""HTML-Escaping"">
<h3>HTML Escaping<a class=""headerlink"" href=""#HTML-Escaping"" title=""Link to this heading"">#</a></h3>
<p>Suppose you have to display HTML within HTML, that can be a bit of pain when the renderer can’t distinguish. You can use the <code class=""docutils literal notranslate""><span class=""pre"">escape</span></code> formatting option to handle this, and even use it within a formatter that contains HTML itself.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[67]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df4</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">([[</span><span class=""s1"">'&lt;div&gt;&lt;/div&gt;'</span><span class=""p"">,</span> <span class=""s1"">'""&amp;other""'</span><span class=""p"">,</span> <span class=""s1"">'&lt;span&gt;&lt;/span&gt;'</span><span class=""p"">]])</span>
<span class=""n"">df4</span><span class=""o"">.</span><span class=""n"">style</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[67]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
</style>
<table id=""T_79df1"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_79df1_level0_col0"">0</th>
<th class=""col_heading level0 col1"" id=""T_79df1_level0_col1"">1</th>
<th class=""col_heading level0 col2"" id=""T_79df1_level0_col2"">2</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_79df1_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_79df1_row0_col0""><div></div></td>
<td class=""data row0 col1"" id=""T_79df1_row0_col1"">""&amp;other""</td>
<td class=""data row0 col2"" id=""T_79df1_row0_col2""><span></span></td>
</tr>
</tbody>
</table></div>
</div>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[68]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df4</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">format</span><span class=""p"">(</span><span class=""n"">escape</span><span class=""o"">=</span><span class=""s2"">""html""</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[68]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
</style>
<table id=""T_65d1d"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_65d1d_level0_col0"">0</th>
<th class=""col_heading level0 col1"" id=""T_65d1d_level0_col1"">1</th>
<th class=""col_heading level0 col2"" id=""T_65d1d_level0_col2"">2</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_65d1d_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_65d1d_row0_col0"">&lt;div&gt;&lt;/div&gt;</td>
<td class=""data row0 col1"" id=""T_65d1d_row0_col1"">""&amp;other""</td>
<td class=""data row0 col2"" id=""T_65d1d_row0_col2"">&lt;span&gt;&lt;/span&gt;</td>
</tr>
</tbody>
</table></div>
</div>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[69]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df4</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">format</span><span class=""p"">(</span><span class=""s1"">'&lt;a href=""https://pandas.pydata.org"" target=""_blank""&gt;</span><span class=""si"">{}</span><span class=""s1"">&lt;/a&gt;'</span><span class=""p"">,</span> <span class=""n"">escape</span><span class=""o"">=</span><span class=""s2"">""html""</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[69]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
</style>
<table id=""T_4eb91"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_4eb91_level0_col0"">0</th>
<th class=""col_heading level0 col1"" id=""T_4eb91_level0_col1"">1</th>
<th class=""col_heading level0 col2"" id=""T_4eb91_level0_col2"">2</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_4eb91_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_4eb91_row0_col0""><a href=""https://pandas.pydata.org"" target=""_blank"">&lt;div&gt;&lt;/div&gt;</a></td>
<td class=""data row0 col1"" id=""T_4eb91_row0_col1""><a href=""https://pandas.pydata.org"" target=""_blank"">""&amp;other""</a></td>
<td class=""data row0 col2"" id=""T_4eb91_row0_col2""><a href=""https://pandas.pydata.org"" target=""_blank"">&lt;span&gt;&lt;/span&gt;</a></td>
</tr>
</tbody>
</table></div>
</div>
</section>
</section>
<section id=""Export-to-Excel"">
<h2>Export to Excel<a class=""headerlink"" href=""#Export-to-Excel"" title=""Link to this heading"">#</a></h2>
<p>Some support (<em>since version 0.20.0</em>) is available for exporting styled <code class=""docutils literal notranslate""><span class=""pre"">DataFrames</span></code> to Excel worksheets using the <code class=""docutils literal notranslate""><span class=""pre"">OpenPyXL</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">XlsxWriter</span></code> engines. CSS2.2 properties handled include:</p>
<ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">background-color</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">border-style</span></code> properties</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">border-width</span></code> properties</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">border-color</span></code> properties</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">color</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">font-family</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">font-style</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">font-weight</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">text-align</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">text-decoration</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">vertical-align</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">white-space:</span> <span class=""pre"">nowrap</span></code></p></li>
<li><p>Shorthand and side-specific border properties are supported (e.g. <code class=""docutils literal notranslate""><span class=""pre"">border-style</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">border-left-style</span></code>) as well as the <code class=""docutils literal notranslate""><span class=""pre"">border</span></code> shorthands for all sides (<code class=""docutils literal notranslate""><span class=""pre"">border:</span> <span class=""pre"">1px</span> <span class=""pre"">solid</span> <span class=""pre"">green</span></code>) or specified sides (<code class=""docutils literal notranslate""><span class=""pre"">border-left:</span> <span class=""pre"">1px</span> <span class=""pre"">solid</span> <span class=""pre"">green</span></code>). Using a <code class=""docutils literal notranslate""><span class=""pre"">border</span></code> shorthand will override any border properties set before it (See <a class=""reference external"" href=""https://drafts.csswg.org/css-backgrounds/#border-shorthands"">CSS Working Group</a> for more details)</p></li>
<li><p>Only CSS2 named colors and hex colors of the form <code class=""docutils literal notranslate""><span class=""pre"">#rgb</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">#rrggbb</span></code> are currently supported.</p></li>
<li><p>The following pseudo CSS properties are also available to set Excel specific style properties:</p>
<ul>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">number-format</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">border-style</span></code> (for Excel-specific styles: “hair”, “mediumDashDot”, “dashDotDot”, “mediumDashDotDot”, “dashDot”, “slantDashDot”, or “mediumDashed”)</p></li>
</ul>
</li>
</ul>
<p>Table level styles, and data cell CSS-classes are not included in the export to Excel: individual cells must have their properties mapped by the <code class=""docutils literal notranslate""><span class=""pre"">Styler.apply</span></code> and/or <code class=""docutils literal notranslate""><span class=""pre"">Styler.map</span></code> methods.</p>
<div class=""nbinput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[70]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df2</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span>\
    <span class=""nb"">map</span><span class=""p"">(</span><span class=""n"">style_negative</span><span class=""p"">,</span> <span class=""n"">props</span><span class=""o"">=</span><span class=""s1"">'color:red;'</span><span class=""p"">)</span><span class=""o"">.</span>\
    <span class=""n"">highlight_max</span><span class=""p"">(</span><span class=""n"">axis</span><span class=""o"">=</span><span class=""mi"">0</span><span class=""p"">)</span><span class=""o"">.</span>\
    <span class=""n"">to_excel</span><span class=""p"">(</span><span class=""s1"">'styled.xlsx'</span><span class=""p"">,</span> <span class=""n"">engine</span><span class=""o"">=</span><span class=""s1"">'openpyxl'</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<p>A screenshot of the output:</p>
<p><img alt=""Excel spreadsheet with styled DataFrame"" src=""../_images/style-excel.png""/></p>
</section>
<section id=""Export-to-LaTeX"">
<h2>Export to LaTeX<a class=""headerlink"" href=""#Export-to-LaTeX"" title=""Link to this heading"">#</a></h2>
<p>There is support (<em>since version 1.3.0</em>) to export <code class=""docutils literal notranslate""><span class=""pre"">Styler</span></code> to LaTeX. The documentation for the <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.to_latex.html""><span class=""doc"">.to_latex</span></a> method gives further detail and numerous examples.</p>
</section>
<section id=""More-About-CSS-and-HTML"">
<h2>More About CSS and HTML<a class=""headerlink"" href=""#More-About-CSS-and-HTML"" title=""Link to this heading"">#</a></h2>
<p>Cascading Style Sheet (CSS) language, which is designed to influence how a browser renders HTML elements, has its own peculiarities. It never reports errors: it just silently ignores them and doesn’t render your objects how you intend so can sometimes be frustrating. Here is a very brief primer on how <code class=""docutils literal notranslate""><span class=""pre"">Styler</span></code> creates HTML and interacts with CSS, with advice on common pitfalls to avoid.</p>
<section id=""CSS-Classes-and-Ids"">
<h3>CSS Classes and Ids<a class=""headerlink"" href=""#CSS-Classes-and-Ids"" title=""Link to this heading"">#</a></h3>
<p>The precise structure of the CSS <code class=""docutils literal notranslate""><span class=""pre"">class</span></code> attached to each cell is as follows.</p>
<ul class=""simple"">
<li><p>Cells with Index and Column names include <code class=""docutils literal notranslate""><span class=""pre"">index_name</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">level&lt;k&gt;</span></code> where <code class=""docutils literal notranslate""><span class=""pre"">k</span></code> is its level in a MultiIndex</p></li>
<li><p>Index label cells include</p>
<ul>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">row_heading</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">level&lt;k&gt;</span></code> where <code class=""docutils literal notranslate""><span class=""pre"">k</span></code> is the level in a MultiIndex</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">row&lt;m&gt;</span></code> where <code class=""docutils literal notranslate""><span class=""pre"">m</span></code> is the numeric position of the row</p></li>
</ul>
</li>
<li><p>Column label cells include</p>
<ul>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">col_heading</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">level&lt;k&gt;</span></code> where <code class=""docutils literal notranslate""><span class=""pre"">k</span></code> is the level in a MultiIndex</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">col&lt;n&gt;</span></code> where <code class=""docutils literal notranslate""><span class=""pre"">n</span></code> is the numeric position of the column</p></li>
</ul>
</li>
<li><p>Data cells include</p>
<ul>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">data</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">row&lt;m&gt;</span></code>, where <code class=""docutils literal notranslate""><span class=""pre"">m</span></code> is the numeric position of the cell.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">col&lt;n&gt;</span></code>, where <code class=""docutils literal notranslate""><span class=""pre"">n</span></code> is the numeric position of the cell.</p></li>
</ul>
</li>
<li><p>Blank cells include <code class=""docutils literal notranslate""><span class=""pre"">blank</span></code></p></li>
<li><p>Trimmed cells include <code class=""docutils literal notranslate""><span class=""pre"">col_trim</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">row_trim</span></code></p></li>
</ul>
<p>The structure of the <code class=""docutils literal notranslate""><span class=""pre"">id</span></code> is <code class=""docutils literal notranslate""><span class=""pre"">T_uuid_level&lt;k&gt;_row&lt;m&gt;_col&lt;n&gt;</span></code> where <code class=""docutils literal notranslate""><span class=""pre"">level&lt;k&gt;</span></code> is used only on headings, and headings will only have either <code class=""docutils literal notranslate""><span class=""pre"">row&lt;m&gt;</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">col&lt;n&gt;</span></code> whichever is needed. By default we’ve also prepended each row/column identifier with a UUID unique to each DataFrame so that the style from one doesn’t collide with the styling from another within the same notebook or page. You can read more about the use of UUIDs in <a class=""reference internal"" href=""#Optimization""><span class=""std std-ref"">Optimization</span></a>.</p>
<p>We can see example of the HTML by calling the <a class=""reference internal"" href=""../reference/api/pandas.io.formats.style.Styler.to_html.html""><span class=""doc"">.to_html()</span></a> method.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[71]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">([[</span><span class=""mi"">1</span><span class=""p"">,</span><span class=""mi"">2</span><span class=""p"">],[</span><span class=""mi"">3</span><span class=""p"">,</span><span class=""mi"">4</span><span class=""p"">]],</span> <span class=""n"">index</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s1"">'i1'</span><span class=""p"">,</span> <span class=""s1"">'i2'</span><span class=""p"">],</span> <span class=""n"">columns</span><span class=""o"">=</span><span class=""p"">[</span><span class=""s1"">'c1'</span><span class=""p"">,</span> <span class=""s1"">'c2'</span><span class=""p"">])</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">to_html</span><span class=""p"">())</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt empty docutils container"">
</div>
<div class=""output_area docutils container"">
<div class=""highlight""><pre>
&lt;style type=""text/css""&gt;
&lt;/style&gt;
&lt;table id=""T_a1de3""&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th class=""blank level0"" &gt;&amp;nbsp;&lt;/th&gt;
      &lt;th id=""T_a1de3_level0_col0"" class=""col_heading level0 col0"" &gt;c1&lt;/th&gt;
      &lt;th id=""T_a1de3_level0_col1"" class=""col_heading level0 col1"" &gt;c2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th id=""T_a1de3_level0_row0"" class=""row_heading level0 row0"" &gt;i1&lt;/th&gt;
      &lt;td id=""T_a1de3_row0_col0"" class=""data row0 col0"" &gt;1&lt;/td&gt;
      &lt;td id=""T_a1de3_row0_col1"" class=""data row0 col1"" &gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th id=""T_a1de3_level0_row1"" class=""row_heading level0 row1"" &gt;i2&lt;/th&gt;
      &lt;td id=""T_a1de3_row1_col0"" class=""data row1 col0"" &gt;3&lt;/td&gt;
      &lt;td id=""T_a1de3_row1_col1"" class=""data row1 col1"" &gt;4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

</pre></div></div>
</div>
</section>
<section id=""CSS-Hierarchies"">
<h3>CSS Hierarchies<a class=""headerlink"" href=""#CSS-Hierarchies"" title=""Link to this heading"">#</a></h3>
<p>The examples have shown that when CSS styles overlap, the one that comes last in the HTML render, takes precedence. So the following yield different results:</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[72]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df4</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">([[</span><span class=""s1"">'text'</span><span class=""p"">]])</span>
<span class=""n"">df4</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">map</span><span class=""p"">(</span><span class=""k"">lambda</span> <span class=""n"">x</span><span class=""p"">:</span> <span class=""s1"">'color:green;'</span><span class=""p"">)</span>\
         <span class=""o"">.</span><span class=""n"">map</span><span class=""p"">(</span><span class=""k"">lambda</span> <span class=""n"">x</span><span class=""p"">:</span> <span class=""s1"">'color:red;'</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[72]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_098ea_row0_col0 {
  color: green;
  color: red;
}
</style>
<table id=""T_098ea"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_098ea_level0_col0"">0</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_098ea_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_098ea_row0_col0"">text</td>
</tr>
</tbody>
</table></div>
</div>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[73]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df4</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">map</span><span class=""p"">(</span><span class=""k"">lambda</span> <span class=""n"">x</span><span class=""p"">:</span> <span class=""s1"">'color:red;'</span><span class=""p"">)</span>\
         <span class=""o"">.</span><span class=""n"">map</span><span class=""p"">(</span><span class=""k"">lambda</span> <span class=""n"">x</span><span class=""p"">:</span> <span class=""s1"">'color:green;'</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[73]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_71979_row0_col0 {
  color: red;
  color: green;
}
</style>
<table id=""T_71979"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_71979_level0_col0"">0</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_71979_level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_71979_row0_col0"">text</td>
</tr>
</tbody>
</table></div>
</div>
<p>This is only true for CSS rules that are equivalent in hierarchy, or importance. You can read more about <a class=""reference external"" href=""https://www.w3schools.com/css/css_specificity.asp"">CSS specificity here</a> but for our purposes it suffices to summarize the key points:</p>
<p>A CSS importance score for each HTML element is derived by starting at zero and adding:</p>
<ul class=""simple"">
<li><p>1000 for an inline style attribute</p></li>
<li><p>100 for each ID</p></li>
<li><p>10 for each attribute, class or pseudo-class</p></li>
<li><p>1 for each element name or pseudo-element</p></li>
</ul>
<p>Let’s use this to describe the action of the following configurations</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[74]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df4</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">set_uuid</span><span class=""p"">(</span><span class=""s1"">'a_'</span><span class=""p"">)</span>\
         <span class=""o"">.</span><span class=""n"">set_table_styles</span><span class=""p"">([{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'td'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'color:red;'</span><span class=""p"">}])</span>\
         <span class=""o"">.</span><span class=""n"">map</span><span class=""p"">(</span><span class=""k"">lambda</span> <span class=""n"">x</span><span class=""p"">:</span> <span class=""s1"">'color:green;'</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[74]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_a_ td {
  color: red;
}
#T_a__row0_col0 {
  color: green;
}
</style>
<table id=""T_a_"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_a__level0_col0"">0</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_a__level0_row0"">0</th>
<td class=""data row0 col0"" id=""T_a__row0_col0"">text</td>
</tr>
</tbody>
</table></div>
</div>
<p>This text is red because the generated selector <code class=""docutils literal notranslate""><span class=""pre"">#T_a_</span> <span class=""pre"">td</span></code> is worth 101 (ID plus element), whereas <code class=""docutils literal notranslate""><span class=""pre"">#T_a_row0_col0</span></code> is only worth 100 (ID), so is considered inferior even though in the HTML it comes after the previous.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[75]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df4</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">set_uuid</span><span class=""p"">(</span><span class=""s1"">'b_'</span><span class=""p"">)</span>\
         <span class=""o"">.</span><span class=""n"">set_table_styles</span><span class=""p"">([{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'td'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'color:red;'</span><span class=""p"">},</span>
                            <span class=""p"">{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'.cls-1'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'color:blue;'</span><span class=""p"">}])</span>\
         <span class=""o"">.</span><span class=""n"">map</span><span class=""p"">(</span><span class=""k"">lambda</span> <span class=""n"">x</span><span class=""p"">:</span> <span class=""s1"">'color:green;'</span><span class=""p"">)</span>\
         <span class=""o"">.</span><span class=""n"">set_td_classes</span><span class=""p"">(</span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">([[</span><span class=""s1"">'cls-1'</span><span class=""p"">]]))</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[75]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_b_ td {
  color: red;
}
#T_b_ .cls-1 {
  color: blue;
}
#T_b__row0_col0 {
  color: green;
}
</style>
<table id=""T_b_"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_b__level0_col0"">0</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_b__level0_row0"">0</th>
<td class=""data row0 col0 cls-1"" id=""T_b__row0_col0"">text</td>
</tr>
</tbody>
</table></div>
</div>
<p>In the above case the text is blue because the selector <code class=""docutils literal notranslate""><span class=""pre"">#T_b_</span> <span class=""pre"">.cls-1</span></code> is worth 110 (ID plus class), which takes precedence.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[76]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df4</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">set_uuid</span><span class=""p"">(</span><span class=""s1"">'c_'</span><span class=""p"">)</span>\
         <span class=""o"">.</span><span class=""n"">set_table_styles</span><span class=""p"">([{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'td'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'color:red;'</span><span class=""p"">},</span>
                            <span class=""p"">{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'.cls-1'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'color:blue;'</span><span class=""p"">},</span>
                            <span class=""p"">{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'td.data'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'color:yellow;'</span><span class=""p"">}])</span>\
         <span class=""o"">.</span><span class=""n"">map</span><span class=""p"">(</span><span class=""k"">lambda</span> <span class=""n"">x</span><span class=""p"">:</span> <span class=""s1"">'color:green;'</span><span class=""p"">)</span>\
         <span class=""o"">.</span><span class=""n"">set_td_classes</span><span class=""p"">(</span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">([[</span><span class=""s1"">'cls-1'</span><span class=""p"">]]))</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[76]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_c_ td {
  color: red;
}
#T_c_ .cls-1 {
  color: blue;
}
#T_c_ td.data {
  color: yellow;
}
#T_c__row0_col0 {
  color: green;
}
</style>
<table id=""T_c_"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_c__level0_col0"">0</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_c__level0_row0"">0</th>
<td class=""data row0 col0 cls-1"" id=""T_c__row0_col0"">text</td>
</tr>
</tbody>
</table></div>
</div>
<p>Now we have created another table style this time the selector <code class=""docutils literal notranslate""><span class=""pre"">T_c_</span> <span class=""pre"">td.data</span></code> (ID plus element plus class) gets bumped up to 111.</p>
<p>If your style fails to be applied, and its really frustrating, try the <code class=""docutils literal notranslate""><span class=""pre"">!important</span></code> trump card.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[77]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">df4</span><span class=""o"">.</span><span class=""n"">style</span><span class=""o"">.</span><span class=""n"">set_uuid</span><span class=""p"">(</span><span class=""s1"">'d_'</span><span class=""p"">)</span>\
         <span class=""o"">.</span><span class=""n"">set_table_styles</span><span class=""p"">([{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'td'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'color:red;'</span><span class=""p"">},</span>
                            <span class=""p"">{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'.cls-1'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'color:blue;'</span><span class=""p"">},</span>
                            <span class=""p"">{</span><span class=""s1"">'selector'</span><span class=""p"">:</span> <span class=""s1"">'td.data'</span><span class=""p"">,</span> <span class=""s1"">'props'</span><span class=""p"">:</span> <span class=""s1"">'color:yellow;'</span><span class=""p"">}])</span>\
         <span class=""o"">.</span><span class=""n"">map</span><span class=""p"">(</span><span class=""k"">lambda</span> <span class=""n"">x</span><span class=""p"">:</span> <span class=""s1"">'color:green !important;'</span><span class=""p"">)</span>\
         <span class=""o"">.</span><span class=""n"">set_td_classes</span><span class=""p"">(</span><span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">([[</span><span class=""s1"">'cls-1'</span><span class=""p"">]]))</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[77]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
#T_d_ td {
  color: red;
}
#T_d_ .cls-1 {
  color: blue;
}
#T_d_ td.data {
  color: yellow;
}
#T_d__row0_col0 {
  color: green !important;
}
</style>
<table id=""T_d_"">
<thead>
<tr>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_d__level0_col0"">0</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_d__level0_row0"">0</th>
<td class=""data row0 col0 cls-1"" id=""T_d__row0_col0"">text</td>
</tr>
</tbody>
</table></div>
</div>
<p>Finally got that green text after all!</p>
</section>
</section>
<section id=""Extensibility"">
<h2>Extensibility<a class=""headerlink"" href=""#Extensibility"" title=""Link to this heading"">#</a></h2>
<p>The core of pandas is, and will remain, its “high-performance, easy-to-use data structures”. With that in mind, we hope that <code class=""docutils literal notranslate""><span class=""pre"">DataFrame.style</span></code> accomplishes two goals</p>
<ul class=""simple"">
<li><p>Provide an API that is pleasing to use interactively and is “good enough” for many tasks</p></li>
<li><p>Provide the foundations for dedicated libraries to build on</p></li>
</ul>
<p>If you build a great library on top of this, let us know and we’ll <a class=""reference external"" href=""https://pandas.pydata.org/pandas-docs/stable/ecosystem.html"">link</a> to it.</p>
<section id=""Subclassing"">
<h3>Subclassing<a class=""headerlink"" href=""#Subclassing"" title=""Link to this heading"">#</a></h3>
<p>If the default template doesn’t quite suit your needs, you can subclass Styler and extend or override the template. We’ll show an example of extending the default template to insert a custom header before each table.</p>
<div class=""nbinput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[78]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""kn"">from</span> <span class=""nn"">jinja2</span> <span class=""kn"">import</span> <span class=""n"">Environment</span><span class=""p"">,</span> <span class=""n"">ChoiceLoader</span><span class=""p"">,</span> <span class=""n"">FileSystemLoader</span>
<span class=""kn"">from</span> <span class=""nn"">IPython.display</span> <span class=""kn"">import</span> <span class=""n"">HTML</span>
<span class=""kn"">from</span> <span class=""nn"">pandas.io.formats.style</span> <span class=""kn"">import</span> <span class=""n"">Styler</span>
</pre></div>
</div>
</div>
<p>We’ll use the following template:</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[79]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""k"">with</span> <span class=""nb"">open</span><span class=""p"">(</span><span class=""s2"">""templates/myhtml.tpl""</span><span class=""p"">)</span> <span class=""k"">as</span> <span class=""n"">f</span><span class=""p"">:</span>
    <span class=""nb"">print</span><span class=""p"">(</span><span class=""n"">f</span><span class=""o"">.</span><span class=""n"">read</span><span class=""p"">())</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt empty docutils container"">
</div>
<div class=""output_area docutils container"">
<div class=""highlight""><pre>
{% extends ""html_table.tpl"" %}
{% block table %}
&lt;h1&gt;{{ table_title|default(""My Table"") }}&lt;/h1&gt;
{{ super() }}
{% endblock table %}

</pre></div></div>
</div>
<p>Now that we’ve created a template, we need to set up a subclass of <code class=""docutils literal notranslate""><span class=""pre"">Styler</span></code> that knows about it.</p>
<div class=""nbinput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[80]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""k"">class</span> <span class=""nc"">MyStyler</span><span class=""p"">(</span><span class=""n"">Styler</span><span class=""p"">):</span>
    <span class=""n"">env</span> <span class=""o"">=</span> <span class=""n"">Environment</span><span class=""p"">(</span>
        <span class=""n"">loader</span><span class=""o"">=</span><span class=""n"">ChoiceLoader</span><span class=""p"">([</span>
            <span class=""n"">FileSystemLoader</span><span class=""p"">(</span><span class=""s2"">""templates""</span><span class=""p"">),</span>  <span class=""c1""># contains ours</span>
            <span class=""n"">Styler</span><span class=""o"">.</span><span class=""n"">loader</span><span class=""p"">,</span>  <span class=""c1""># the default</span>
        <span class=""p"">])</span>
    <span class=""p"">)</span>
    <span class=""n"">template_html_table</span> <span class=""o"">=</span> <span class=""n"">env</span><span class=""o"">.</span><span class=""n"">get_template</span><span class=""p"">(</span><span class=""s2"">""myhtml.tpl""</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<p>Notice that we include the original loader in our environment’s loader. That’s because we extend the original template, so the Jinja environment needs to be able to find it.</p>
<p>Now we can use that custom styler. It’s <code class=""docutils literal notranslate""><span class=""pre"">__init__</span></code> takes a DataFrame.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[81]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">MyStyler</span><span class=""p"">(</span><span class=""n"">df3</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[81]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
</style>
<h1>My Table</h1>
<table id=""T_bcebf"">
<thead>
<tr>
<th class=""blank""> </th>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_bcebf_level0_col0"">c1</th>
<th class=""col_heading level0 col1"" id=""T_bcebf_level0_col1"">c2</th>
<th class=""col_heading level0 col2"" id=""T_bcebf_level0_col2"">c3</th>
<th class=""col_heading level0 col3"" id=""T_bcebf_level0_col3"">c4</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_bcebf_level0_row0"" rowspan=""2"">A</th>
<th class=""row_heading level1 row0"" id=""T_bcebf_level1_row0"">r1</th>
<td class=""data row0 col0"" id=""T_bcebf_row0_col0"">-1.048553</td>
<td class=""data row0 col1"" id=""T_bcebf_row0_col1"">-1.420018</td>
<td class=""data row0 col2"" id=""T_bcebf_row0_col2"">-1.706270</td>
<td class=""data row0 col3"" id=""T_bcebf_row0_col3"">1.950775</td>
</tr>
<tr>
<th class=""row_heading level1 row1"" id=""T_bcebf_level1_row1"">r2</th>
<td class=""data row1 col0"" id=""T_bcebf_row1_col0"">-0.509652</td>
<td class=""data row1 col1"" id=""T_bcebf_row1_col1"">-0.438074</td>
<td class=""data row1 col2"" id=""T_bcebf_row1_col2"">-1.252795</td>
<td class=""data row1 col3"" id=""T_bcebf_row1_col3"">0.777490</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_bcebf_level0_row2"" rowspan=""2"">B</th>
<th class=""row_heading level1 row2"" id=""T_bcebf_level1_row2"">r1</th>
<td class=""data row2 col0"" id=""T_bcebf_row2_col0"">-1.613898</td>
<td class=""data row2 col1"" id=""T_bcebf_row2_col1"">-0.212740</td>
<td class=""data row2 col2"" id=""T_bcebf_row2_col2"">-0.895467</td>
<td class=""data row2 col3"" id=""T_bcebf_row2_col3"">0.386902</td>
</tr>
<tr>
<th class=""row_heading level1 row3"" id=""T_bcebf_level1_row3"">r2</th>
<td class=""data row3 col0"" id=""T_bcebf_row3_col0"">-0.510805</td>
<td class=""data row3 col1"" id=""T_bcebf_row3_col1"">-1.180632</td>
<td class=""data row3 col2"" id=""T_bcebf_row3_col2"">-0.028182</td>
<td class=""data row3 col3"" id=""T_bcebf_row3_col3"">0.428332</td>
</tr>
</tbody>
</table></div>
</div>
<p>Our custom template accepts a <code class=""docutils literal notranslate""><span class=""pre"">table_title</span></code> keyword. We can provide the value in the <code class=""docutils literal notranslate""><span class=""pre"">.to_html</span></code> method.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[82]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">HTML</span><span class=""p"">(</span><span class=""n"">MyStyler</span><span class=""p"">(</span><span class=""n"">df3</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">to_html</span><span class=""p"">(</span><span class=""n"">table_title</span><span class=""o"">=</span><span class=""s2"">""Extending Example""</span><span class=""p"">))</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[82]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
</style>
<h1>Extending Example</h1>
<table id=""T_507de"">
<thead>
<tr>
<th class=""blank""> </th>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_507de_level0_col0"">c1</th>
<th class=""col_heading level0 col1"" id=""T_507de_level0_col1"">c2</th>
<th class=""col_heading level0 col2"" id=""T_507de_level0_col2"">c3</th>
<th class=""col_heading level0 col3"" id=""T_507de_level0_col3"">c4</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_507de_level0_row0"" rowspan=""2"">A</th>
<th class=""row_heading level1 row0"" id=""T_507de_level1_row0"">r1</th>
<td class=""data row0 col0"" id=""T_507de_row0_col0"">-1.048553</td>
<td class=""data row0 col1"" id=""T_507de_row0_col1"">-1.420018</td>
<td class=""data row0 col2"" id=""T_507de_row0_col2"">-1.706270</td>
<td class=""data row0 col3"" id=""T_507de_row0_col3"">1.950775</td>
</tr>
<tr>
<th class=""row_heading level1 row1"" id=""T_507de_level1_row1"">r2</th>
<td class=""data row1 col0"" id=""T_507de_row1_col0"">-0.509652</td>
<td class=""data row1 col1"" id=""T_507de_row1_col1"">-0.438074</td>
<td class=""data row1 col2"" id=""T_507de_row1_col2"">-1.252795</td>
<td class=""data row1 col3"" id=""T_507de_row1_col3"">0.777490</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_507de_level0_row2"" rowspan=""2"">B</th>
<th class=""row_heading level1 row2"" id=""T_507de_level1_row2"">r1</th>
<td class=""data row2 col0"" id=""T_507de_row2_col0"">-1.613898</td>
<td class=""data row2 col1"" id=""T_507de_row2_col1"">-0.212740</td>
<td class=""data row2 col2"" id=""T_507de_row2_col2"">-0.895467</td>
<td class=""data row2 col3"" id=""T_507de_row2_col3"">0.386902</td>
</tr>
<tr>
<th class=""row_heading level1 row3"" id=""T_507de_level1_row3"">r2</th>
<td class=""data row3 col0"" id=""T_507de_row3_col0"">-0.510805</td>
<td class=""data row3 col1"" id=""T_507de_row3_col1"">-1.180632</td>
<td class=""data row3 col2"" id=""T_507de_row3_col2"">-0.028182</td>
<td class=""data row3 col3"" id=""T_507de_row3_col3"">0.428332</td>
</tr>
</tbody>
</table></div>
</div>
<p>For convenience, we provide the <code class=""docutils literal notranslate""><span class=""pre"">Styler.from_custom_template</span></code> method that does the same as the custom subclass.</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[83]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">EasyStyler</span> <span class=""o"">=</span> <span class=""n"">Styler</span><span class=""o"">.</span><span class=""n"">from_custom_template</span><span class=""p"">(</span><span class=""s2"">""templates""</span><span class=""p"">,</span> <span class=""s2"">""myhtml.tpl""</span><span class=""p"">)</span>
<span class=""n"">HTML</span><span class=""p"">(</span><span class=""n"">EasyStyler</span><span class=""p"">(</span><span class=""n"">df3</span><span class=""p"">)</span><span class=""o"">.</span><span class=""n"">to_html</span><span class=""p"">(</span><span class=""n"">table_title</span><span class=""o"">=</span><span class=""s2"">""Another Title""</span><span class=""p"">))</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[83]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
</style>
<h1>Another Title</h1>
<table id=""T_ce111"">
<thead>
<tr>
<th class=""blank""> </th>
<th class=""blank level0""> </th>
<th class=""col_heading level0 col0"" id=""T_ce111_level0_col0"">c1</th>
<th class=""col_heading level0 col1"" id=""T_ce111_level0_col1"">c2</th>
<th class=""col_heading level0 col2"" id=""T_ce111_level0_col2"">c3</th>
<th class=""col_heading level0 col3"" id=""T_ce111_level0_col3"">c4</th>
</tr>
</thead>
<tbody>
<tr>
<th class=""row_heading level0 row0"" id=""T_ce111_level0_row0"" rowspan=""2"">A</th>
<th class=""row_heading level1 row0"" id=""T_ce111_level1_row0"">r1</th>
<td class=""data row0 col0"" id=""T_ce111_row0_col0"">-1.048553</td>
<td class=""data row0 col1"" id=""T_ce111_row0_col1"">-1.420018</td>
<td class=""data row0 col2"" id=""T_ce111_row0_col2"">-1.706270</td>
<td class=""data row0 col3"" id=""T_ce111_row0_col3"">1.950775</td>
</tr>
<tr>
<th class=""row_heading level1 row1"" id=""T_ce111_level1_row1"">r2</th>
<td class=""data row1 col0"" id=""T_ce111_row1_col0"">-0.509652</td>
<td class=""data row1 col1"" id=""T_ce111_row1_col1"">-0.438074</td>
<td class=""data row1 col2"" id=""T_ce111_row1_col2"">-1.252795</td>
<td class=""data row1 col3"" id=""T_ce111_row1_col3"">0.777490</td>
</tr>
<tr>
<th class=""row_heading level0 row2"" id=""T_ce111_level0_row2"" rowspan=""2"">B</th>
<th class=""row_heading level1 row2"" id=""T_ce111_level1_row2"">r1</th>
<td class=""data row2 col0"" id=""T_ce111_row2_col0"">-1.613898</td>
<td class=""data row2 col1"" id=""T_ce111_row2_col1"">-0.212740</td>
<td class=""data row2 col2"" id=""T_ce111_row2_col2"">-0.895467</td>
<td class=""data row2 col3"" id=""T_ce111_row2_col3"">0.386902</td>
</tr>
<tr>
<th class=""row_heading level1 row3"" id=""T_ce111_level1_row3"">r2</th>
<td class=""data row3 col0"" id=""T_ce111_row3_col0"">-0.510805</td>
<td class=""data row3 col1"" id=""T_ce111_row3_col1"">-1.180632</td>
<td class=""data row3 col2"" id=""T_ce111_row3_col2"">-0.028182</td>
<td class=""data row3 col3"" id=""T_ce111_row3_col3"">0.428332</td>
</tr>
</tbody>
</table></div>
</div>
<section id=""Template-Structure"">
<h4>Template Structure<a class=""headerlink"" href=""#Template-Structure"" title=""Link to this heading"">#</a></h4>
<p>Here’s the template structure for the both the style generation template and the table generation template:</p>
<p>Style template:</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[85]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">HTML</span><span class=""p"">(</span><span class=""n"">style_structure</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[85]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
    /* Overrides of notebook CSS for static HTML export */
    .template_block {
        background-color: hsla(120, 60%, 70%, 0.2);
        margin: 10px;
        padding: 5px;
        border: 1px solid hsla(120, 60%, 70%, 0.5);
        border-left: 2px solid black;
    }
    .template_block pre {
        background: transparent;
        padding: 0;
    }
    .big_vertical_ellipsis {
        font-size: 24pt;
    }
</style>
<div class=""template_block"">before_style</div>
<div class=""template_block"">style
<pre>&lt;style type=""text/css""&gt;</pre>
<div class=""template_block"">table_styles</div>
<div class=""template_block"">before_cellstyle</div>
<div class=""template_block"">cellstyle</div>
<pre>&lt;/style&gt;</pre>
</div></div>
</div>
<p>Table template:</p>
<div class=""nbinput docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[87]:
</pre></div>
</div>
<div class=""input_area highlight-ipython3 notranslate""><div class=""highlight""><pre><span></span><span class=""n"">HTML</span><span class=""p"">(</span><span class=""n"">table_structure</span><span class=""p"">)</span>
</pre></div>
</div>
</div>
<div class=""nboutput nblast docutils container"">
<div class=""prompt highlight-none notranslate""><div class=""highlight""><pre><span></span>[87]:
</pre></div>
</div>
<div class=""output_area rendered_html docutils container"">
<style type=""text/css"">
    /* Overrides of notebook CSS for static HTML export */
    .template_block {
        background-color: hsla(120, 60%, 70%, 0.2);
        margin: 10px;
        padding: 5px;
        border: 1px solid hsla(120, 60%, 70%, 0.5);
        border-left: 2px solid black;
    }
    .template_block pre {
        background: transparent;
        padding: 0;
    }
    .big_vertical_ellipsis {
        font-size: 24pt;
    }
</style>
<div class=""template_block"">before_table</div>
<div class=""template_block"">table
<pre>&lt;table ...&gt;</pre>
<div class=""template_block"">caption</div>
<div class=""template_block"">thead
<div class=""template_block"">before_head_rows</div>
<div class=""template_block"">head_tr (loop over headers)</div>
<div class=""template_block"">after_head_rows</div>
</div>
<div class=""template_block"">tbody
<div class=""template_block"">before_rows</div>
<div class=""template_block"">tr (loop over data rows)</div>
<div class=""template_block"">after_rows</div>
</div>
<pre>&lt;/table&gt;</pre>
</div>
<div class=""template_block"">after_table</div></div>
</div>
<p>See the template in the <a class=""reference external"" href=""https://github.com/pandas-dev/pandas"">GitHub repo</a> for more details.</p>
<script type=""application/vnd.jupyter.widget-state+json"">
{""state"": {""8387df507fb64f17986fb30b4300d99c"": {""model_name"": ""LayoutModel"", ""model_module"": ""@jupyter-widgets/base"", ""model_module_version"": ""2.0.0"", ""state"": {""_model_module"": ""@jupyter-widgets/base"", ""_model_module_version"": ""2.0.0"", ""_model_name"": ""LayoutModel"", ""_view_count"": null, ""_view_module"": ""@jupyter-widgets/base"", ""_view_module_version"": ""2.0.0"", ""_view_name"": ""LayoutView"", ""align_content"": null, ""align_items"": null, ""align_self"": null, ""border_bottom"": null, ""border_left"": null, ""border_right"": null, ""border_top"": null, ""bottom"": null, ""display"": null, ""flex"": null, ""flex_flow"": null, ""grid_area"": null, ""grid_auto_columns"": null, ""grid_auto_flow"": null, ""grid_auto_rows"": null, ""grid_column"": null, ""grid_gap"": null, ""grid_row"": null, ""grid_template_areas"": null, ""grid_template_columns"": null, ""grid_template_rows"": null, ""height"": null, ""justify_content"": null, ""justify_items"": null, ""left"": null, ""margin"": null, ""max_height"": null, ""max_width"": null, ""min_height"": null, ""min_width"": null, ""object_fit"": null, ""object_position"": null, ""order"": null, ""overflow"": null, ""padding"": null, ""right"": null, ""top"": null, ""visibility"": null, ""width"": null}}, ""bf83a63a5f8245b58351a5875ea55836"": {""model_name"": ""VBoxModel"", ""model_module"": ""@jupyter-widgets/controls"", ""model_module_version"": ""2.0.0"", ""state"": {""_dom_classes"": [""widget-interact""], ""_model_module"": ""@jupyter-widgets/controls"", ""_model_module_version"": ""2.0.0"", ""_model_name"": ""VBoxModel"", ""_view_count"": null, ""_view_module"": ""@jupyter-widgets/controls"", ""_view_module_version"": ""2.0.0"", ""_view_name"": ""VBoxView"", ""box_style"": """", ""children"": [""IPY_MODEL_f429bf2240d74a1798c344ce19c8aab8"", ""IPY_MODEL_c1ca86df06f04a6c83d85f93798d2ceb"", ""IPY_MODEL_31a11e4df5a04db7a58eea964eadb7fe"", ""IPY_MODEL_4c3b5acbea5c4f8fbee8c03898586b5b"", ""IPY_MODEL_b028f5170f024388a3eb85255f0ac0c7""], ""layout"": ""IPY_MODEL_8387df507fb64f17986fb30b4300d99c"", ""tabbable"": null, ""tooltip"": null}}, ""71ab57a8f7d2421b9b89518dd4fbeae3"": {""model_name"": ""LayoutModel"", ""model_module"": ""@jupyter-widgets/base"", ""model_module_version"": ""2.0.0"", ""state"": {""_model_module"": ""@jupyter-widgets/base"", ""_model_module_version"": ""2.0.0"", ""_model_name"": ""LayoutModel"", ""_view_count"": null, ""_view_module"": ""@jupyter-widgets/base"", ""_view_module_version"": ""2.0.0"", ""_view_name"": ""LayoutView"", ""align_content"": null, ""align_items"": null, ""align_self"": null, ""border_bottom"": null, ""border_left"": null, ""border_right"": null, ""border_top"": null, ""bottom"": null, ""display"": null, ""flex"": null, ""flex_flow"": null, ""grid_area"": null, ""grid_auto_columns"": null, ""grid_auto_flow"": null, ""grid_auto_rows"": null, ""grid_column"": null, ""grid_gap"": null, ""grid_row"": null, ""grid_template_areas"": null, ""grid_template_columns"": null, ""grid_template_rows"": null, ""height"": null, ""justify_content"": null, ""justify_items"": null, ""left"": null, ""margin"": null, ""max_height"": null, ""max_width"": null, ""min_height"": null, ""min_width"": null, ""object_fit"": null, ""object_position"": null, ""order"": null, ""overflow"": null, ""padding"": null, ""right"": null, ""top"": null, ""visibility"": null, ""width"": null}}, ""09ac9f7f46fb4f63b9240c3dbd8d5c6f"": {""model_name"": ""SliderStyleModel"", ""model_module"": ""@jupyter-widgets/controls"", ""model_module_version"": ""2.0.0"", ""state"": {""_model_module"": ""@jupyter-widgets/controls"", ""_model_module_version"": ""2.0.0"", ""_model_name"": ""SliderStyleModel"", ""_view_count"": null, ""_view_module"": ""@jupyter-widgets/base"", ""_view_module_version"": ""2.0.0"", ""_view_name"": ""StyleView"", ""description_width"": """", ""handle_color"": null}}, ""f429bf2240d74a1798c344ce19c8aab8"": {""model_name"": ""IntSliderModel"", ""model_module"": ""@jupyter-widgets/controls"", ""model_module_version"": ""2.0.0"", ""state"": {""_dom_classes"": [], ""_model_module"": ""@jupyter-widgets/controls"", ""_model_module_version"": ""2.0.0"", ""_model_name"": ""IntSliderModel"", ""_view_count"": null, ""_view_module"": ""@jupyter-widgets/controls"", ""_view_module_version"": ""2.0.0"", ""_view_name"": ""IntSliderView"", ""behavior"": ""drag-tap"", ""continuous_update"": true, ""description"": ""h_neg"", ""description_allow_html"": false, ""disabled"": false, ""layout"": ""IPY_MODEL_71ab57a8f7d2421b9b89518dd4fbeae3"", ""max"": 359, ""min"": 0, ""orientation"": ""horizontal"", ""readout"": true, ""readout_format"": ""d"", ""step"": 1, ""style"": ""IPY_MODEL_09ac9f7f46fb4f63b9240c3dbd8d5c6f"", ""tabbable"": null, ""tooltip"": null, ""value"": 179}}, ""31b765c62dd44cf3aabea4996e36ddab"": {""model_name"": ""LayoutModel"", ""model_module"": ""@jupyter-widgets/base"", ""model_module_version"": ""2.0.0"", ""state"": {""_model_module"": ""@jupyter-widgets/base"", ""_model_module_version"": ""2.0.0"", ""_model_name"": ""LayoutModel"", ""_view_count"": null, ""_view_module"": ""@jupyter-widgets/base"", ""_view_module_version"": ""2.0.0"", ""_view_name"": ""LayoutView"", ""align_content"": null, ""align_items"": null, ""align_self"": null, ""border_bottom"": null, ""border_left"": null, ""border_right"": null, ""border_top"": null, ""bottom"": null, ""display"": null, ""flex"": null, ""flex_flow"": null, ""grid_area"": null, ""grid_auto_columns"": null, ""grid_auto_flow"": null, ""grid_auto_rows"": null, ""grid_column"": null, ""grid_gap"": null, ""grid_row"": null, ""grid_template_areas"": null, ""grid_template_columns"": null, ""grid_template_rows"": null, ""height"": null, ""justify_content"": null, ""justify_items"": null, ""left"": null, ""margin"": null, ""max_height"": null, ""max_width"": null, ""min_height"": null, ""min_width"": null, ""object_fit"": null, ""object_position"": null, ""order"": null, ""overflow"": null, ""padding"": null, ""right"": null, ""top"": null, ""visibility"": null, ""width"": null}}, ""f955c194afde4cc892e66b20ac85c9dd"": {""model_name"": ""SliderStyleModel"", ""model_module"": ""@jupyter-widgets/controls"", ""model_module_version"": ""2.0.0"", ""state"": {""_model_module"": ""@jupyter-widgets/controls"", ""_model_module_version"": ""2.0.0"", ""_model_name"": ""SliderStyleModel"", ""_view_count"": null, ""_view_module"": ""@jupyter-widgets/base"", ""_view_module_version"": ""2.0.0"", ""_view_name"": ""StyleView"", ""description_width"": """", ""handle_color"": null}}, ""c1ca86df06f04a6c83d85f93798d2ceb"": {""model_name"": ""IntSliderModel"", ""model_module"": ""@jupyter-widgets/controls"", ""model_module_version"": ""2.0.0"", ""state"": {""_dom_classes"": [], ""_model_module"": ""@jupyter-widgets/controls"", ""_model_module_version"": ""2.0.0"", ""_model_name"": ""IntSliderModel"", ""_view_count"": null, ""_view_module"": ""@jupyter-widgets/controls"", ""_view_module_version"": ""2.0.0"", ""_view_name"": ""IntSliderView"", ""behavior"": ""drag-tap"", ""continuous_update"": true, ""description"": ""h_pos"", ""description_allow_html"": false, ""disabled"": false, ""layout"": ""IPY_MODEL_31b765c62dd44cf3aabea4996e36ddab"", ""max"": 359, ""min"": 0, ""orientation"": ""horizontal"", ""readout"": true, ""readout_format"": ""d"", ""step"": 1, ""style"": ""IPY_MODEL_f955c194afde4cc892e66b20ac85c9dd"", ""tabbable"": null, ""tooltip"": null, ""value"": 179}}, ""61e5ff198a5642118edb5c16e7463ba5"": {""model_name"": ""LayoutModel"", ""model_module"": ""@jupyter-widgets/base"", ""model_module_version"": ""2.0.0"", ""state"": {""_model_module"": ""@jupyter-widgets/base"", ""_model_module_version"": ""2.0.0"", ""_model_name"": ""LayoutModel"", ""_view_count"": null, ""_view_module"": ""@jupyter-widgets/base"", ""_view_module_version"": ""2.0.0"", ""_view_name"": ""LayoutView"", ""align_content"": null, ""align_items"": null, ""align_self"": null, ""border_bottom"": null, ""border_left"": null, ""border_right"": null, ""border_top"": null, ""bottom"": null, ""display"": null, ""flex"": null, ""flex_flow"": null, ""grid_area"": null, ""grid_auto_columns"": null, ""grid_auto_flow"": null, ""grid_auto_rows"": null, ""grid_column"": null, ""grid_gap"": null, ""grid_row"": null, ""grid_template_areas"": null, ""grid_template_columns"": null, ""grid_template_rows"": null, ""height"": null, ""justify_content"": null, ""justify_items"": null, ""left"": null, ""margin"": null, ""max_height"": null, ""max_width"": null, ""min_height"": null, ""min_width"": null, ""object_fit"": null, ""object_position"": null, ""order"": null, ""overflow"": null, ""padding"": null, ""right"": null, ""top"": null, ""visibility"": null, ""width"": null}}, ""f0fbab8e267646209eb0c4cb0734fc1f"": {""model_name"": ""SliderStyleModel"", ""model_module"": ""@jupyter-widgets/controls"", ""model_module_version"": ""2.0.0"", ""state"": {""_model_module"": ""@jupyter-widgets/controls"", ""_model_module_version"": ""2.0.0"", ""_model_name"": ""SliderStyleModel"", ""_view_count"": null, ""_view_module"": ""@jupyter-widgets/base"", ""_view_module_version"": ""2.0.0"", ""_view_name"": ""StyleView"", ""description_width"": """", ""handle_color"": null}}, ""31a11e4df5a04db7a58eea964eadb7fe"": {""model_name"": ""FloatSliderModel"", ""model_module"": ""@jupyter-widgets/controls"", ""model_module_version"": ""2.0.0"", ""state"": {""_dom_classes"": [], ""_model_module"": ""@jupyter-widgets/controls"", ""_model_module_version"": ""2.0.0"", ""_model_name"": ""FloatSliderModel"", ""_view_count"": null, ""_view_module"": ""@jupyter-widgets/controls"", ""_view_module_version"": ""2.0.0"", ""_view_name"": ""FloatSliderView"", ""behavior"": ""drag-tap"", ""continuous_update"": true, ""description"": ""s"", ""description_allow_html"": false, ""disabled"": false, ""layout"": ""IPY_MODEL_61e5ff198a5642118edb5c16e7463ba5"", ""max"": 99.9, ""min"": 0.0, ""orientation"": ""horizontal"", ""readout"": true, ""readout_format"": "".2f"", ""step"": 0.1, ""style"": ""IPY_MODEL_f0fbab8e267646209eb0c4cb0734fc1f"", ""tabbable"": null, ""tooltip"": null, ""value"": 49.95}}, ""7b2bb15f3d59433cbaafe1e07625574f"": {""model_name"": ""LayoutModel"", ""model_module"": ""@jupyter-widgets/base"", ""model_module_version"": ""2.0.0"", ""state"": {""_model_module"": ""@jupyter-widgets/base"", ""_model_module_version"": ""2.0.0"", ""_model_name"": ""LayoutModel"", ""_view_count"": null, ""_view_module"": ""@jupyter-widgets/base"", ""_view_module_version"": ""2.0.0"", ""_view_name"": ""LayoutView"", ""align_content"": null, ""align_items"": null, ""align_self"": null, ""border_bottom"": null, ""border_left"": null, ""border_right"": null, ""border_top"": null, ""bottom"": null, ""display"": null, ""flex"": null, ""flex_flow"": null, ""grid_area"": null, ""grid_auto_columns"": null, ""grid_auto_flow"": null, ""grid_auto_rows"": null, ""grid_column"": null, ""grid_gap"": null, ""grid_row"": null, ""grid_template_areas"": null, ""grid_template_columns"": null, ""grid_template_rows"": null, ""height"": null, ""justify_content"": null, ""justify_items"": null, ""left"": null, ""margin"": null, ""max_height"": null, ""max_width"": null, ""min_height"": null, ""min_width"": null, ""object_fit"": null, ""object_position"": null, ""order"": null, ""overflow"": null, ""padding"": null, ""right"": null, ""top"": null, ""visibility"": null, ""width"": null}}, ""7aa46291003d4d31999e1ff5cfa8ee19"": {""model_name"": ""SliderStyleModel"", ""model_module"": ""@jupyter-widgets/controls"", ""model_module_version"": ""2.0.0"", ""state"": {""_model_module"": ""@jupyter-widgets/controls"", ""_model_module_version"": ""2.0.0"", ""_model_name"": ""SliderStyleModel"", ""_view_count"": null, ""_view_module"": ""@jupyter-widgets/base"", ""_view_module_version"": ""2.0.0"", ""_view_name"": ""StyleView"", ""description_width"": """", ""handle_color"": null}}, ""4c3b5acbea5c4f8fbee8c03898586b5b"": {""model_name"": ""FloatSliderModel"", ""model_module"": ""@jupyter-widgets/controls"", ""model_module_version"": ""2.0.0"", ""state"": {""_dom_classes"": [], ""_model_module"": ""@jupyter-widgets/controls"", ""_model_module_version"": ""2.0.0"", ""_model_name"": ""FloatSliderModel"", ""_view_count"": null, ""_view_module"": ""@jupyter-widgets/controls"", ""_view_module_version"": ""2.0.0"", ""_view_name"": ""FloatSliderView"", ""behavior"": ""drag-tap"", ""continuous_update"": true, ""description"": ""l"", ""description_allow_html"": false, ""disabled"": false, ""layout"": ""IPY_MODEL_7b2bb15f3d59433cbaafe1e07625574f"", ""max"": 99.9, ""min"": 0.0, ""orientation"": ""horizontal"", ""readout"": true, ""readout_format"": "".2f"", ""step"": 0.1, ""style"": ""IPY_MODEL_7aa46291003d4d31999e1ff5cfa8ee19"", ""tabbable"": null, ""tooltip"": null, ""value"": 49.95}}, ""18114b0064d54124a745452e966c7e09"": {""model_name"": ""LayoutModel"", ""model_module"": ""@jupyter-widgets/base"", ""model_module_version"": ""2.0.0"", ""state"": {""_model_module"": ""@jupyter-widgets/base"", ""_model_module_version"": ""2.0.0"", ""_model_name"": ""LayoutModel"", ""_view_count"": null, ""_view_module"": ""@jupyter-widgets/base"", ""_view_module_version"": ""2.0.0"", ""_view_name"": ""LayoutView"", ""align_content"": null, ""align_items"": null, ""align_self"": null, ""border_bottom"": null, ""border_left"": null, ""border_right"": null, ""border_top"": null, ""bottom"": null, ""display"": null, ""flex"": null, ""flex_flow"": null, ""grid_area"": null, ""grid_auto_columns"": null, ""grid_auto_flow"": null, ""grid_auto_rows"": null, ""grid_column"": null, ""grid_gap"": null, ""grid_row"": null, ""grid_template_areas"": null, ""grid_template_columns"": null, ""grid_template_rows"": null, ""height"": null, ""justify_content"": null, ""justify_items"": null, ""left"": null, ""margin"": null, ""max_height"": null, ""max_width"": null, ""min_height"": null, ""min_width"": null, ""object_fit"": null, ""object_position"": null, ""order"": null, ""overflow"": null, ""padding"": null, ""right"": null, ""top"": null, ""visibility"": null, ""width"": null}}, ""b028f5170f024388a3eb85255f0ac0c7"": {""model_name"": ""OutputModel"", ""model_module"": ""@jupyter-widgets/output"", ""model_module_version"": ""1.0.0"", ""state"": {""_dom_classes"": [], ""_model_module"": ""@jupyter-widgets/output"", ""_model_module_version"": ""1.0.0"", ""_model_name"": ""OutputModel"", ""_view_count"": null, ""_view_module"": ""@jupyter-widgets/output"", ""_view_module_version"": ""1.0.0"", ""_view_name"": ""OutputView"", ""layout"": ""IPY_MODEL_18114b0064d54124a745452e966c7e09"", ""msg_id"": """", ""outputs"": [{""output_type"": ""display_data"", ""metadata"": {}, ""data"": {""text/plain"": ""<pandas.io.formats.style.Styler at 0x7f4eeb6ea350>"", ""text/html"": ""<style type=\""text/css\"">\n#T_fc233_row0_col0 {\n  background-color: #749691;\n  color: #f1f1f1;\n}\n#T_fc233_row0_col1 {\n  background-color: #b4c7c4;\n  color: #000000;\n}\n#T_fc233_row0_col2, #T_fc233_row4_col3 {\n  background-color: #000000;\n  color: #f1f1f1;\n}\n#T_fc233_row0_col3, #T_fc233_row1_col2, #T_fc233_row5_col0, #T_fc233_row5_col3, #T_fc233_row6_col0, #T_fc233_row7_col1, #T_fc233_row8_col1, #T_fc233_row9_col2 {\n  background-color: #557e79;\n  color: #f1f1f1;\n}\n#T_fc233_row1_col0 {\n  background-color: #6e928d;\n  color: #f1f1f1;\n}\n#T_fc233_row1_col1 {\n  background-color: #aec2bf;\n  color: #000000;\n}\n#T_fc233_row1_col3 {\n  background-color: #91aca8;\n  color: #f1f1f1;\n}\n#T_fc233_row2_col0 {\n  background-color: #ebf0ef;\n  color: #000000;\n}\n#T_fc233_row2_col1 {\n  background-color: #b3c6c3;\n  color: #000000;\n}\n#T_fc233_row2_col2 {\n  background-color: #cedbd9;\n  color: #000000;\n}\n#T_fc233_row2_col3 {\n  background-color: #a6bcb9;\n  color: #000000;\n}\n#T_fc233_row3_col0 {\n  background-color: #b5c8c5;\n  color: #000000;\n}\n#T_fc233_row3_col1 {\n  background-color: #ccd9d7;\n  color: #000000;\n}\n#T_fc233_row3_col2, #T_fc233_row7_col3 {\n  background-color: #c8d6d4;\n  color: #000000;\n}\n#T_fc233_row3_col3 {\n  background-color: #c4d2d0;\n  color: #000000;\n}\n#T_fc233_row4_col0 {\n  background-color: #86a4a0;\n  color: #f1f1f1;\n}\n#T_fc233_row4_col1 {\n  background-color: #eaefee;\n  color: #000000;\n}\n#T_fc233_row4_col2 {\n  background-color: #e6edec;\n  color: #000000;\n}\n#T_fc233_row5_col1 {\n  background-color: #9db5b1;\n  color: #000000;\n}\n#T_fc233_row5_col2 {\n  background-color: #698d88;\n  color: #f1f1f1;\n}\n#T_fc233_row6_col1, #T_fc233_row7_col0 {\n  background-color: #84a29e;\n  color: #f1f1f1;\n}\n#T_fc233_row6_col2 {\n  background-color: #b8c9c7;\n  color: #000000;\n}\n#T_fc233_row6_col3 {\n  background-color: #8da9a5;\n  color: #f1f1f1;\n}\n#T_fc233_row7_col2 {\n  background-color: #d1dcdb;\n  color: #000000;\n}\n#T_fc233_row8_col0 {\n  background-color: #bfcfcc;\n  color: #000000;\n}\n#T_fc233_row8_col2 {\n  background-color: #5e857f;\n  color: #f1f1f1;\n}\n#T_fc233_row8_col3 {\n  background-color: #b2c5c2;\n  color: #000000;\n}\n#T_fc233_row9_col0 {\n  background-color: #97b0ad;\n  color: #f1f1f1;\n}\n#T_fc233_row9_col1 {\n  background-color: #6c908b;\n  color: #f1f1f1;\n}\n#T_fc233_row9_col3 {\n  background-color: #82a09c;\n  color: #f1f1f1;\n}\n</style>\n<table id=\""T_fc233\"">\n  <thead>\n    <tr>\n      <th class=\""blank level0\"" >&nbsp;</th>\n      <th id=\""T_fc233_level0_col0\"" class=\""col_heading level0 col0\"" >A</th>\n      <th id=\""T_fc233_level0_col1\"" class=\""col_heading level0 col1\"" >B</th>\n      <th id=\""T_fc233_level0_col2\"" class=\""col_heading level0 col2\"" >C</th>\n      <th id=\""T_fc233_level0_col3\"" class=\""col_heading level0 col3\"" >D</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\""T_fc233_level0_row0\"" class=\""row_heading level0 row0\"" >0</th>\n      <td id=\""T_fc233_row0_col0\"" class=\""data row0 col0\"" >1.764052</td>\n      <td id=\""T_fc233_row0_col1\"" class=\""data row0 col1\"" >0.400157</td>\n      <td id=\""T_fc233_row0_col2\"" class=\""data row0 col2\"" >nan</td>\n      <td id=\""T_fc233_row0_col3\"" class=\""data row0 col3\"" >2.240893</td>\n    </tr>\n    <tr>\n      <th id=\""T_fc233_level0_row1\"" class=\""row_heading level0 row1\"" >1</th>\n      <td id=\""T_fc233_row1_col0\"" class=\""data row1 col0\"" >1.867558</td>\n      <td id=\""T_fc233_row1_col1\"" class=\""data row1 col1\"" >-0.977278</td>\n      <td id=\""T_fc233_row1_col2\"" class=\""data row1 col2\"" >0.950088</td>\n      <td id=\""T_fc233_row1_col3\"" class=\""data row1 col3\"" >-0.151357</td>\n    </tr>\n    <tr>\n      <th id=\""T_fc233_level0_row2\"" class=\""row_heading level0 row2\"" >2</th>\n      <td id=\""T_fc233_row2_col0\"" class=\""data row2 col0\"" >-0.103219</td>\n      <td id=\""T_fc233_row2_col1\"" class=\""data row2 col1\"" >0.410599</td>\n      <td id=\""T_fc233_row2_col2\"" class=\""data row2 col2\"" >0.144044</td>\n      <td id=\""T_fc233_row2_col3\"" class=\""data row2 col3\"" >1.454274</td>\n    </tr>\n    <tr>\n      <th id=\""T_fc233_level0_row3\"" class=\""row_heading level0 row3\"" >3</th>\n      <td id=\""T_fc233_row3_col0\"" class=\""data row3 col0\"" >0.761038</td>\n      <td id=\""T_fc233_row3_col1\"" class=\""data row3 col1\"" >0.121675</td>\n      <td id=\""T_fc233_row3_col2\"" class=\""data row3 col2\"" >0.443863</td>\n      <td id=\""T_fc233_row3_col3\"" class=\""data row3 col3\"" >0.333674</td>\n    </tr>\n    <tr>\n      <th id=\""T_fc233_level0_row4\"" class=\""row_heading level0 row4\"" >4</th>\n      <td id=\""T_fc233_row4_col0\"" class=\""data row4 col0\"" >1.494079</td>\n      <td id=\""T_fc233_row4_col1\"" class=\""data row4 col1\"" >-0.205158</td>\n      <td id=\""T_fc233_row4_col2\"" class=\""data row4 col2\"" >0.313068</td>\n      <td id=\""T_fc233_row4_col3\"" class=\""data row4 col3\"" >nan</td>\n    </tr>\n    <tr>\n      <th id=\""T_fc233_level0_row5\"" class=\""row_heading level0 row5\"" >5</th>\n      <td id=\""T_fc233_row5_col0\"" class=\""data row5 col0\"" >-2.552990</td>\n      <td id=\""T_fc233_row5_col1\"" class=\""data row5 col1\"" >0.653619</td>\n      <td id=\""T_fc233_row5_col2\"" class=\""data row5 col2\"" >0.864436</td>\n      <td id=\""T_fc233_row5_col3\"" class=\""data row5 col3\"" >-0.742165</td>\n    </tr>\n    <tr>\n      <th id=\""T_fc233_level0_row6\"" class=\""row_heading level0 row6\"" >6</th>\n      <td id=\""T_fc233_row6_col0\"" class=\""data row6 col0\"" >2.269755</td>\n      <td id=\""T_fc233_row6_col1\"" class=\""data row6 col1\"" >-1.454366</td>\n      <td id=\""T_fc233_row6_col2\"" class=\""data row6 col2\"" >0.045759</td>\n      <td id=\""T_fc233_row6_col3\"" class=\""data row6 col3\"" >-0.187184</td>\n    </tr>\n    <tr>\n      <th id=\""T_fc233_level0_row7\"" class=\""row_heading level0 row7\"" >7</th>\n      <td id=\""T_fc233_row7_col0\"" class=\""data row7 col0\"" >1.532779</td>\n      <td id=\""T_fc233_row7_col1\"" class=\""data row7 col1\"" >1.469359</td>\n      <td id=\""T_fc233_row7_col2\"" class=\""data row7 col2\"" >0.154947</td>\n      <td id=\""T_fc233_row7_col3\"" class=\""data row7 col3\"" >0.378163</td>\n    </tr>\n    <tr>\n      <th id=\""T_fc233_level0_row8\"" class=\""row_heading level0 row8\"" >8</th>\n      <td id=\""T_fc233_row8_col0\"" class=\""data row8 col0\"" >-0.887786</td>\n      <td id=\""T_fc233_row8_col1\"" class=\""data row8 col1\"" >-1.980796</td>\n      <td id=\""T_fc233_row8_col2\"" class=\""data row8 col2\"" >-0.347912</td>\n      <td id=\""T_fc233_row8_col3\"" class=\""data row8 col3\"" >0.156349</td>\n    </tr>\n    <tr>\n      <th id=\""T_fc233_level0_row9\"" class=\""row_heading level0 row9\"" >9</th>\n      <td id=\""T_fc233_row9_col0\"" class=\""data row9 col0\"" >1.230291</td>\n      <td id=\""T_fc233_row9_col1\"" class=\""data row9 col1\"" >1.202380</td>\n      <td id=\""T_fc233_row9_col2\"" class=\""data row9 col2\"" >-0.387327</td>\n      <td id=\""T_fc233_row9_col3\"" class=\""data row9 col3\"" >-0.302303</td>\n    </tr>\n  </tbody>\n</table>\n""}}], ""tabbable"": null, ""tooltip"": null}}}, ""version_major"": 2, ""version_minor"": 0}
</script></section>
</section>
</section>
</section>
</article>","Table Visualization # This section demonstrates visualization of tabular data using the Styler class. For information on visualization with charting please see Chart Visualization . This document is written as a Jupyter Notebook, and can be viewed or downloaded here . Styler Object and Customising the Display # Styling and output display customisation should be performed after the data in a DataFrame has been processed. The Styler is not dynamically updated if further changes to the DataFrame are made. The DataFrame.style attribute is a property that returns a Styler object. It has a _repr_html_ method defined on it so it is rendered automatically in Jupyter Notebook. The Styler, which can be used for large data but is primarily designed for small data, currently has the ability to output to these formats: HTML LaTeX String (and CSV by extension) Excel (JSON is not currently available) The first three of these have display customisation methods designed to format and customise the output. These include: Formatting values, the index and columns headers, using .format() and .format_index() , Renaming the index or column header labels, using .relabel_index() Hiding certain columns, the index and/or column headers, or index names, using .hide() Concatenating similar DataFrames, using .concat() Formatting the Display # Formatting Values # The Styler distinguishes the display value from the actual value, in both data values and index or columns headers. To control the display value, the text is printed in each cell as a string, and we can use the .format() and .format_index() methods to manipulate this according to a format spec string or a callable that takes a single value and returns a string. It is possible to define this for the whole table, or index, or for individual columns, or MultiIndex levels. We can also overwrite index names. Additionally, the format function has a precision argument to specifically help format floats, as well as decimal and thousands separators to support other locales, an na_rep argument to display missing data, and an escape and hyperlinks arguments to help displaying safe-HTML or safe-LaTeX. The default formatter is configured to adopt pandas’ global options such as styler.format.precision option, controllable using with pd.option_context('format.precision', 2): [2]: import pandas as pd import numpy as np import matplotlib as mpl df = pd . DataFrame ({ ""strings"" : [ ""Adam"" , ""Mike"" ], ""ints"" : [ 1 , 3 ], ""floats"" : [ 1.123 , 1000.23 ] }) df . style \ . format ( precision = 3 , thousands = ""."" , decimal = "","" ) \ . format_index ( str . upper , axis = 1 ) \ . relabel_index ([ ""row 1"" , ""row 2"" ], axis = 0 ) [2]: STRINGS INTS FLOATS row 1 Adam 1 1,123 row 2 Mike 3 1.000,230 Using Styler to manipulate the display is a useful feature because maintaining the indexing and data values for other purposes gives greater control. You do not have to overwrite your DataFrame to display it how you like. Here is a more comprehensive example of using the formatting functions whilst still relying on the underlying data for indexing and calculations. [3]: weather_df = pd . DataFrame ( np . random . rand ( 10 , 2 ) * 5 , index = pd . date_range ( start = ""2021-01-01"" , periods = 10 ), columns = [ ""Tokyo"" , ""Beijing"" ]) def rain_condition ( v ): if v < 1.75 : return ""Dry"" elif v < 2.75 : return ""Rain"" return ""Heavy Rain"" def make_pretty ( styler ): styler . set_caption ( ""Weather Conditions"" ) styler . format ( rain_condition ) styler . format_index ( lambda v : v . strftime ( ""%A"" )) styler . background_gradient ( axis = None , vmin = 1 , vmax = 5 , cmap = ""YlGnBu"" ) return styler weather_df [3]: Tokyo Beijing 2021-01-01 2.552517 1.976602 2021-01-02 1.665753 3.757927 2021-01-03 4.679882 2.242228 2021-01-04 1.268592 0.915911 2021-01-05 0.258386 4.647607 2021-01-06 1.279295 4.642458 2021-01-07 0.560487 3.670073 2021-01-08 0.980423 1.026641 2021-01-09 1.471664 1.384219 2021-01-10 4.617766 4.251794 [4]: weather_df . loc [ ""2021-01-04"" : ""2021-01-08"" ] . style . pipe ( make_pretty ) [4]: Weather Conditions Tokyo Beijing Monday Dry Dry Tuesday Dry Heavy Rain Wednesday Dry Heavy Rain Thursday Dry Heavy Rain Friday Dry Dry Hiding Data # The index and column headers can be completely hidden, as well subselecting rows or columns that one wishes to exclude. Both these options are performed using the same methods. The index can be hidden from rendering by calling .hide() without any arguments, which might be useful if your index is integer based. Similarly column headers can be hidden by calling .hide(axis=”columns”) without any further arguments. Specific rows or columns can be hidden from rendering by calling the same .hide() method and passing in a row/column label, a list-like or a slice of row/column labels to for the subset argument. Hiding does not change the integer arrangement of CSS classes, e.g. hiding the first two columns of a DataFrame means the column class indexing will still start at col2 , since col0 and col1 are simply ignored. [5]: df = pd . DataFrame ( np . random . randn ( 5 , 5 )) df . style \ . hide ( subset = [ 0 , 2 , 4 ], axis = 0 ) \ . hide ( subset = [ 0 , 2 , 4 ], axis = 1 ) [5]: 1 3 1 0.561440 -0.858225 3 0.176255 0.876609 To invert the function to a show functionality it is best practice to compose a list of hidden items. [6]: show = [ 0 , 2 , 4 ] df . style \ . hide ([ row for row in df . index if row not in show ], axis = 0 ) \ . hide ([ col for col in df . columns if col not in show ], axis = 1 ) [6]: 0 2 4 0 -0.056334 -1.188982 0.482870 2 -0.718731 -0.499113 -1.350023 4 -0.720169 1.225336 -0.512159 Concatenating DataFrame Outputs # Two or more Stylers can be concatenated together provided they share the same columns. This is very useful for showing summary statistics for a DataFrame, and is often used in combination with DataFrame.agg. Since the objects concatenated are Stylers they can independently be styled as will be shown below and their concatenation preserves those styles. [7]: summary_styler = df . agg ([ ""sum"" , ""mean"" ]) . style \ . format ( precision = 3 ) \ . relabel_index ([ ""Sum"" , ""Average"" ]) df . style . format ( precision = 1 ) . concat ( summary_styler ) [7]: 0 1 2 3 4 0 -0.1 0.8 -1.2 0.3 0.5 1 0.5 0.6 0.1 -0.9 0.9 2 -0.7 -0.8 -0.5 0.2 -1.4 3 2.2 0.2 0.9 0.9 0.1 4 -0.7 -1.0 1.2 -0.5 -0.5 Sum 1.179 -0.213 0.506 -0.082 -0.430 Average 0.236 -0.043 0.101 -0.016 -0.086 Styler Object and HTML # The Styler was originally constructed to support the wide array of HTML formatting options. Its HTML output creates an HTML <table> and leverages CSS styling language to manipulate many parameters including colors, fonts, borders, background, etc. See here for more information on styling HTML tables. This allows a lot of flexibility out of the box, and even enables web developers to integrate DataFrames into their exiting user interface designs. Below we demonstrate the default output, which looks very similar to the standard DataFrame HTML representation. But the HTML here has already attached some CSS classes to each cell, even if we haven’t yet created any styles. We can view these by calling the .to_html() method, which returns the raw HTML as string, which is useful for further processing or adding to a file - read on in More about CSS and HTML . This section will also provide a walkthrough for how to convert this default output to represent a DataFrame output that is more communicative. For example how we can build s : [8]: df = pd . DataFrame ([[ 38.0 , 2.0 , 18.0 , 22.0 , 21 , np . nan ],[ 19 , 439 , 6 , 452 , 226 , 232 ]], index = pd . Index ([ 'Tumour (Positive)' , 'Non-Tumour (Negative)' ], name = 'Actual Label:' ), columns = pd . MultiIndex . from_product ([[ 'Decision Tree' , 'Regression' , 'Random' ],[ 'Tumour' , 'Non-Tumour' ]], names = [ 'Model:' , 'Predicted:' ])) df . style [8]: Model: Decision Tree Regression Random Predicted: Tumour Non-Tumour Tumour Non-Tumour Tumour Non-Tumour Actual Label: Tumour (Positive) 38.000000 2.000000 18.000000 22.000000 21 nan Non-Tumour (Negative) 19.000000 439.000000 6.000000 452.000000 226 232.000000 [10]: s [10]: Confusion matrix for multiple cancer prediction models. Model: Decision Tree Regression Predicted: Tumour Non-Tumour Tumour Non-Tumour Actual Label: Tumour (Positive) 38 2 18 22 Non-Tumour (Negative) 19 439 6 452 The first step we have taken is the create the Styler object from the DataFrame and then select the range of interest by hiding unwanted columns with .hide() . [11]: s = df . style . format ( ' {:.0f} ' ) . hide ([( 'Random' , 'Tumour' ), ( 'Random' , 'Non-Tumour' )], axis = ""columns"" ) s [11]: Model: Decision Tree Regression Predicted: Tumour Non-Tumour Tumour Non-Tumour Actual Label: Tumour (Positive) 38 2 18 22 Non-Tumour (Negative) 19 439 6 452 Methods to Add Styles # There are 3 primary methods of adding custom CSS styles to Styler : Using .set_table_styles() to control broader areas of the table with specified internal CSS. Although table styles allow the flexibility to add CSS selectors and properties controlling all individual parts of the table, they are unwieldy for individual cell specifications. Also, note that table styles cannot be exported to Excel. Using .set_td_classes() to directly link either external CSS classes to your data cells or link the internal CSS classes created by .set_table_styles() . See here . These cannot be used on column header rows or indexes, and also won’t export to Excel. Using the .apply() and .map() functions to add direct internal CSS to specific data cells. See here . As of v1.4.0 there are also methods that work directly on column header rows or indexes; .apply_index() and .map_index() . Note that only these methods add styles that will export to Excel. These methods work in a similar way to DataFrame.apply() and DataFrame.map() . Table Styles # Table styles are flexible enough to control all individual parts of the table, including column headers and indexes. However, they can be unwieldy to type for individual data cells or for any kind of conditional formatting, so we recommend that table styles are used for broad styling, such as entire rows or columns at a time. Table styles are also used to control features which can apply to the whole table at once such as creating a generic hover functionality. The :hover pseudo-selector, as well as other pseudo-selectors, can only be used this way. To replicate the normal format of CSS selectors and properties (attribute value pairs), e.g. tr:hover {   background-color: #ffff99; } the necessary format to pass styles to .set_table_styles() is as a list of dicts, each with a CSS-selector tag and CSS-properties. Properties can either be a list of 2-tuples, or a regular CSS-string, for example: [13]: cell_hover = { # for row hover use <tr> instead of <td> 'selector' : 'td:hover' , 'props' : [( 'background-color' , '#ffffb3' )] } index_names = { 'selector' : '.index_name' , 'props' : 'font-style: italic; color: darkgrey; font-weight:normal;' } headers = { 'selector' : 'th:not(.index_name)' , 'props' : 'background-color: #000066; color: white;' } s . set_table_styles ([ cell_hover , index_names , headers ]) [13]: Model: Decision Tree Regression Predicted: Tumour Non-Tumour Tumour Non-Tumour Actual Label: Tumour (Positive) 38 2 18 22 Non-Tumour (Negative) 19 439 6 452 Next we just add a couple more styling artifacts targeting specific parts of the table. Be careful here, since we are chaining methods we need to explicitly instruct the method not to overwrite the existing styles. [15]: s . set_table_styles ([ { 'selector' : 'th.col_heading' , 'props' : 'text-align: center;' }, { 'selector' : 'th.col_heading.level0' , 'props' : 'font-size: 1.5em;' }, { 'selector' : 'td' , 'props' : 'text-align: center; font-weight: bold;' }, ], overwrite = False ) [15]: Model: Decision Tree Regression Predicted: Tumour Non-Tumour Tumour Non-Tumour Actual Label: Tumour (Positive) 38 2 18 22 Non-Tumour (Negative) 19 439 6 452 As a convenience method ( since version 1.2.0 ) we can also pass a dict to .set_table_styles() which contains row or column keys. Behind the scenes Styler just indexes the keys and adds relevant .col<m> or .row<n> classes as necessary to the given CSS selectors. [17]: s . set_table_styles ({ ( 'Regression' , 'Tumour' ): [{ 'selector' : 'th' , 'props' : 'border-left: 1px solid white' }, { 'selector' : 'td' , 'props' : 'border-left: 1px solid #000066' }] }, overwrite = False , axis = 0 ) [17]: Model: Decision Tree Regression Predicted: Tumour Non-Tumour Tumour Non-Tumour Actual Label: Tumour (Positive) 38 2 18 22 Non-Tumour (Negative) 19 439 6 452 Setting Classes and Linking to External CSS # If you have designed a website then it is likely you will already have an external CSS file that controls the styling of table and cell objects within it. You may want to use these native files rather than duplicate all the CSS in python (and duplicate any maintenance work). Table Attributes # It is very easy to add a class to the main <table> using .set_table_attributes() . This method can also attach inline styles - read more in CSS Hierarchies . [19]: out = s . set_table_attributes ( 'class=""my-table-cls""' ) . to_html () print ( out [ out . find ( '<table' ):][: 109 ]) <table id=""T_xyz01"" class=""my-table-cls"">   <thead>     <tr>       <th class=""index_name level0"" >Model:</th> Data Cell CSS Classes # New in version 1.2.0 The .set_td_classes() method accepts a DataFrame with matching indices and columns to the underlying Styler ’s DataFrame. That DataFrame will contain strings as css-classes to add to individual data cells: the <td> elements of the <table> . Rather than use external CSS we will create our classes internally and add them to table style. We will save adding the borders until the section on tooltips . [20]: s . set_table_styles ([ # create internal CSS classes { 'selector' : '.true' , 'props' : 'background-color: #e6ffe6;' }, { 'selector' : '.false' , 'props' : 'background-color: #ffe6e6;' }, ], overwrite = False ) cell_color = pd . DataFrame ([[ 'true ' , 'false ' , 'true ' , 'false ' ], [ 'false ' , 'true ' , 'false ' , 'true ' ]], index = df . index , columns = df . columns [: 4 ]) s . set_td_classes ( cell_color ) [20]: Model: Decision Tree Regression Predicted: Tumour Non-Tumour Tumour Non-Tumour Actual Label: Tumour (Positive) 38 2 18 22 Non-Tumour (Negative) 19 439 6 452 Styler Functions # Acting on Data # We use the following methods to pass your style functions. Both of those methods take a function (and some other keyword arguments) and apply it to the DataFrame in a certain way, rendering CSS styles. .map() (elementwise): accepts a function that takes a single value and returns a string with the CSS attribute-value pair. .apply() (column-/row-/table-wise): accepts a function that takes a Series or DataFrame and returns a Series, DataFrame, or numpy array with an identical shape where each element is a string with a CSS attribute-value pair. This method passes each column or row of your DataFrame one-at-a-time or the entire table at once, depending on the axis keyword argument. For columnwise use axis=0 , rowwise use axis=1 , and for the entire table at once use axis=None . This method is powerful for applying multiple, complex logic to data cells. We create a new DataFrame to demonstrate this. [22]: np . random . seed ( 0 ) df2 = pd . DataFrame ( np . random . randn ( 10 , 4 ), columns = [ 'A' , 'B' , 'C' , 'D' ]) df2 . style [22]: A B C D 0 1.764052 0.400157 0.978738 2.240893 1 1.867558 -0.977278 0.950088 -0.151357 2 -0.103219 0.410599 0.144044 1.454274 3 0.761038 0.121675 0.443863 0.333674 4 1.494079 -0.205158 0.313068 -0.854096 5 -2.552990 0.653619 0.864436 -0.742165 6 2.269755 -1.454366 0.045759 -0.187184 7 1.532779 1.469359 0.154947 0.378163 8 -0.887786 -1.980796 -0.347912 0.156349 9 1.230291 1.202380 -0.387327 -0.302303 For example we can build a function that colors text if it is negative, and chain this with a function that partially fades cells of negligible value. Since this looks at each element in turn we use map . [23]: def style_negative ( v , props = '' ): return props if v < 0 else None s2 = df2 . style . map ( style_negative , props = 'color:red;' ) \ . map ( lambda v : 'opacity: 20%;' if ( v < 0.3 ) and ( v > - 0.3 ) else None ) s2 [23]: A B C D 0 1.764052 0.400157 0.978738 2.240893 1 1.867558 -0.977278 0.950088 -0.151357 2 -0.103219 0.410599 0.144044 1.454274 3 0.761038 0.121675 0.443863 0.333674 4 1.494079 -0.205158 0.313068 -0.854096 5 -2.552990 0.653619 0.864436 -0.742165 6 2.269755 -1.454366 0.045759 -0.187184 7 1.532779 1.469359 0.154947 0.378163 8 -0.887786 -1.980796 -0.347912 0.156349 9 1.230291 1.202380 -0.387327 -0.302303 We can also build a function that highlights the maximum value across rows, cols, and the DataFrame all at once. In this case we use apply . Below we highlight the maximum in a column. [25]: def highlight_max ( s , props = '' ): return np . where ( s == np . nanmax ( s . values ), props , '' ) s2 . apply ( highlight_max , props = 'color:white;background-color:darkblue' , axis = 0 ) [25]: A B C D 0 1.764052 0.400157 0.978738 2.240893 1 1.867558 -0.977278 0.950088 -0.151357 2 -0.103219 0.410599 0.144044 1.454274 3 0.761038 0.121675 0.443863 0.333674 4 1.494079 -0.205158 0.313068 -0.854096 5 -2.552990 0.653619 0.864436 -0.742165 6 2.269755 -1.454366 0.045759 -0.187184 7 1.532779 1.469359 0.154947 0.378163 8 -0.887786 -1.980796 -0.347912 0.156349 9 1.230291 1.202380 -0.387327 -0.302303 We can use the same function across the different axes, highlighting here the DataFrame maximum in purple, and row maximums in pink. [27]: s2 . apply ( highlight_max , props = 'color:white;background-color:pink;' , axis = 1 ) \ . apply ( highlight_max , props = 'color:white;background-color:purple' , axis = None ) [27]: A B C D 0 1.764052 0.400157 0.978738 2.240893 1 1.867558 -0.977278 0.950088 -0.151357 2 -0.103219 0.410599 0.144044 1.454274 3 0.761038 0.121675 0.443863 0.333674 4 1.494079 -0.205158 0.313068 -0.854096 5 -2.552990 0.653619 0.864436 -0.742165 6 2.269755 -1.454366 0.045759 -0.187184 7 1.532779 1.469359 0.154947 0.378163 8 -0.887786 -1.980796 -0.347912 0.156349 9 1.230291 1.202380 -0.387327 -0.302303 This last example shows how some styles have been overwritten by others. In general the most recent style applied is active but you can read more in the section on CSS hierarchies . You can also apply these styles to more granular parts of the DataFrame - read more in section on subset slicing . It is possible to replicate some of this functionality using just classes but it can be more cumbersome. See item 3) of Optimization Debugging Tip : If you’re having trouble writing your style function, try just passing it into DataFrame.apply . Internally, Styler.apply uses DataFrame.apply so the result should be the same, and with DataFrame.apply you will be able to inspect the CSS string output of your intended function in each cell. Acting on the Index and Column Headers # Similar application is achieved for headers by using: .map_index() (elementwise): accepts a function that takes a single value and returns a string with the CSS attribute-value pair. .apply_index() (level-wise): accepts a function that takes a Series and returns a Series, or numpy array with an identical shape where each element is a string with a CSS attribute-value pair. This method passes each level of your Index one-at-a-time. To style the index use axis=0 and to style the column headers use axis=1 . You can select a level of a MultiIndex but currently no similar subset application is available for these methods. [29]: s2 . map_index ( lambda v : ""color:pink;"" if v > 4 else ""color:darkblue;"" , axis = 0 ) s2 . apply_index ( lambda s : np . where ( s . isin ([ ""A"" , ""B"" ]), ""color:pink;"" , ""color:darkblue;"" ), axis = 1 ) [29]: A B C D 0 1.764052 0.400157 0.978738 2.240893 1 1.867558 -0.977278 0.950088 -0.151357 2 -0.103219 0.410599 0.144044 1.454274 3 0.761038 0.121675 0.443863 0.333674 4 1.494079 -0.205158 0.313068 -0.854096 5 -2.552990 0.653619 0.864436 -0.742165 6 2.269755 -1.454366 0.045759 -0.187184 7 1.532779 1.469359 0.154947 0.378163 8 -0.887786 -1.980796 -0.347912 0.156349 9 1.230291 1.202380 -0.387327 -0.302303 Tooltips and Captions # Table captions can be added with the .set_caption() method. You can use table styles to control the CSS relevant to the caption. [30]: s . set_caption ( ""Confusion matrix for multiple cancer prediction models."" ) \ . set_table_styles ([{ 'selector' : 'caption' , 'props' : 'caption-side: bottom; font-size:1.25em;' }], overwrite = False ) [30]: Confusion matrix for multiple cancer prediction models. Model: Decision Tree Regression Predicted: Tumour Non-Tumour Tumour Non-Tumour Actual Label: Tumour (Positive) 38 2 18 22 Non-Tumour (Negative) 19 439 6 452 Adding tooltips ( since version 1.3.0 ) can be done using the .set_tooltips() method in the same way you can add CSS classes to data cells by providing a string based DataFrame with intersecting indices and columns. You don’t have to specify a css_class name or any css props for the tooltips, since there are standard defaults, but the option is there if you want more visual control. [32]: tt = pd . DataFrame ([[ 'This model has a very strong true positive rate' , ""This model's total number of false negatives is too high"" ]], index = [ 'Tumour (Positive)' ], columns = df . columns [[ 0 , 3 ]]) s . set_tooltips ( tt , props = 'visibility: hidden; position: absolute; z-index: 1; border: 1px solid #000066;' 'background-color: white; color: #000066; font-size: 0.8em;' 'transform: translate(0px, -24px); padding: 0.6em; border-radius: 0.5em;' ) [32]: Confusion matrix for multiple cancer prediction models. Model: Decision Tree Regression Predicted: Tumour Non-Tumour Tumour Non-Tumour Actual Label: Tumour (Positive) 38 2 18 22 Non-Tumour (Negative) 19 439 6 452 The only thing left to do for our table is to add the highlighting borders to draw the audience attention to the tooltips. We will create internal CSS classes as before using table styles. Setting classes always overwrites so we need to make sure we add the previous classes. [34]: s . set_table_styles ([ # create internal CSS classes { 'selector' : '.border-red' , 'props' : 'border: 2px dashed red;' }, { 'selector' : '.border-green' , 'props' : 'border: 2px dashed green;' }, ], overwrite = False ) cell_border = pd . DataFrame ([[ 'border-green ' , ' ' , ' ' , 'border-red ' ], [ ' ' , ' ' , ' ' , ' ' ]], index = df . index , columns = df . columns [: 4 ]) s . set_td_classes ( cell_color + cell_border ) [34]: Confusion matrix for multiple cancer prediction models. Model: Decision Tree Regression Predicted: Tumour Non-Tumour Tumour Non-Tumour Actual Label: Tumour (Positive) 38 2 18 22 Non-Tumour (Negative) 19 439 6 452 Finer Control with Slicing # The examples we have shown so far for the Styler.apply and Styler.map functions have not demonstrated the use of the subset argument. This is a useful argument which permits a lot of flexibility: it allows you to apply styles to specific rows or columns, without having to code that logic into your style function. The value passed to subset behaves similar to slicing a DataFrame; A scalar is treated as a column label A list (or Series or NumPy array) is treated as multiple column labels A tuple is treated as (row_indexer, column_indexer) Consider using pd.IndexSlice to construct the tuple for the last one. We will create a MultiIndexed DataFrame to demonstrate the functionality. [36]: df3 = pd . DataFrame ( np . random . randn ( 4 , 4 ), pd . MultiIndex . from_product ([[ 'A' , 'B' ], [ 'r1' , 'r2' ]]), columns = [ 'c1' , 'c2' , 'c3' , 'c4' ]) df3 [36]: c1 c2 c3 c4 A r1 -1.048553 -1.420018 -1.706270 1.950775 r2 -0.509652 -0.438074 -1.252795 0.777490 B r1 -1.613898 -0.212740 -0.895467 0.386902 r2 -0.510805 -1.180632 -0.028182 0.428332 We will use subset to highlight the maximum in the third and fourth columns with red text. We will highlight the subset sliced region in yellow. [37]: slice_ = [ 'c3' , 'c4' ] df3 . style . apply ( highlight_max , props = 'color:red;' , axis = 0 , subset = slice_ ) \ . set_properties ( ** { 'background-color' : '#ffffb3' }, subset = slice_ ) [37]: c1 c2 c3 c4 A r1 -1.048553 -1.420018 -1.706270 1.950775 r2 -0.509652 -0.438074 -1.252795 0.777490 B r1 -1.613898 -0.212740 -0.895467 0.386902 r2 -0.510805 -1.180632 -0.028182 0.428332 If combined with the IndexSlice as suggested then it can index across both dimensions with greater flexibility. [38]: idx = pd . IndexSlice slice_ = idx [ idx [:, 'r1' ], idx [ 'c2' : 'c4' ]] df3 . style . apply ( highlight_max , props = 'color:red;' , axis = 0 , subset = slice_ ) \ . set_properties ( ** { 'background-color' : '#ffffb3' }, subset = slice_ ) [38]: c1 c2 c3 c4 A r1 -1.048553 -1.420018 -1.706270 1.950775 r2 -0.509652 -0.438074 -1.252795 0.777490 B r1 -1.613898 -0.212740 -0.895467 0.386902 r2 -0.510805 -1.180632 -0.028182 0.428332 This also provides the flexibility to sub select rows when used with the axis=1 . [39]: slice_ = idx [ idx [:, 'r2' ], :] df3 . style . apply ( highlight_max , props = 'color:red;' , axis = 1 , subset = slice_ ) \ . set_properties ( ** { 'background-color' : '#ffffb3' }, subset = slice_ ) [39]: c1 c2 c3 c4 A r1 -1.048553 -1.420018 -1.706270 1.950775 r2 -0.509652 -0.438074 -1.252795 0.777490 B r1 -1.613898 -0.212740 -0.895467 0.386902 r2 -0.510805 -1.180632 -0.028182 0.428332 There is also scope to provide conditional filtering . Suppose we want to highlight the maximum across columns 2 and 4 only in the case that the sum of columns 1 and 3 is less than -2.0 (essentially excluding rows (:,'r2') ) . [40]: slice_ = idx [ idx [( df3 [ 'c1' ] + df3 [ 'c3' ]) < - 2.0 ], [ 'c2' , 'c4' ]] df3 . style . apply ( highlight_max , props = 'color:red;' , axis = 1 , subset = slice_ ) \ . set_properties ( ** { 'background-color' : '#ffffb3' }, subset = slice_ ) [40]: c1 c2 c3 c4 A r1 -1.048553 -1.420018 -1.706270 1.950775 r2 -0.509652 -0.438074 -1.252795 0.777490 B r1 -1.613898 -0.212740 -0.895467 0.386902 r2 -0.510805 -1.180632 -0.028182 0.428332 Only label-based slicing is supported right now, not positional, and not callables. If your style function uses a subset or axis keyword argument, consider wrapping your function in a functools.partial , partialing out that keyword. my_func2 = functools . partial ( my_func , subset = 42 ) Optimization # Generally, for smaller tables and most cases, the rendered HTML does not need to be optimized, and we don’t really recommend it. There are two cases where it is worth considering: If you are rendering and styling a very large HTML table, certain browsers have performance issues. If you are using Styler to dynamically create part of online user interfaces and want to improve network performance. Here we recommend the following steps to implement: 1. Remove UUID and cell_ids # Ignore the uuid and set cell_ids to False . This will prevent unnecessary HTML. This is sub-optimal: [41]: df4 = pd . DataFrame ([[ 1 , 2 ],[ 3 , 4 ]]) s4 = df4 . style This is better: [42]: from pandas.io.formats.style import Styler s4 = Styler ( df4 , uuid_len = 0 , cell_ids = False ) 2. Use table styles # Use table styles where possible (e.g. for all cells or rows or columns at a time) since the CSS is nearly always more efficient than other formats. This is sub-optimal: [43]: props = 'font-family: ""Times New Roman"", Times, serif; color: #e83e8c; font-size:1.3em;' df4 . style . map ( lambda x : props , subset = [ 1 ]) [43]: 0 1 0 1 2 1 3 4 This is better: [44]: df4 . style . set_table_styles ([{ 'selector' : 'td.col1' , 'props' : props }]) [44]: 0 1 0 1 2 1 3 4 3. Set classes instead of using Styler functions # For large DataFrames where the same style is applied to many cells it can be more efficient to declare the styles as classes and then apply those classes to data cells, rather than directly applying styles to cells. It is, however, probably still easier to use the Styler function api when you are not concerned about optimization. This is sub-optimal: [45]: df2 . style . apply ( highlight_max , props = 'color:white;background-color:darkblue;' , axis = 0 ) \ . apply ( highlight_max , props = 'color:white;background-color:pink;' , axis = 1 ) \ . apply ( highlight_max , props = 'color:white;background-color:purple' , axis = None ) [45]: A B C D 0 1.764052 0.400157 0.978738 2.240893 1 1.867558 -0.977278 0.950088 -0.151357 2 -0.103219 0.410599 0.144044 1.454274 3 0.761038 0.121675 0.443863 0.333674 4 1.494079 -0.205158 0.313068 -0.854096 5 -2.552990 0.653619 0.864436 -0.742165 6 2.269755 -1.454366 0.045759 -0.187184 7 1.532779 1.469359 0.154947 0.378163 8 -0.887786 -1.980796 -0.347912 0.156349 9 1.230291 1.202380 -0.387327 -0.302303 This is better: [46]: build = lambda x : pd . DataFrame ( x , index = df2 . index , columns = df2 . columns ) cls1 = build ( df2 . apply ( highlight_max , props = 'cls-1 ' , axis = 0 )) cls2 = build ( df2 . apply ( highlight_max , props = 'cls-2 ' , axis = 1 , result_type = 'expand' ) . values ) cls3 = build ( highlight_max ( df2 , props = 'cls-3 ' )) df2 . style . set_table_styles ([ { 'selector' : '.cls-1' , 'props' : 'color:white;background-color:darkblue;' }, { 'selector' : '.cls-2' , 'props' : 'color:white;background-color:pink;' }, { 'selector' : '.cls-3' , 'props' : 'color:white;background-color:purple;' } ]) . set_td_classes ( cls1 + cls2 + cls3 ) [46]: A B C D 0 1.764052 0.400157 0.978738 2.240893 1 1.867558 -0.977278 0.950088 -0.151357 2 -0.103219 0.410599 0.144044 1.454274 3 0.761038 0.121675 0.443863 0.333674 4 1.494079 -0.205158 0.313068 -0.854096 5 -2.552990 0.653619 0.864436 -0.742165 6 2.269755 -1.454366 0.045759 -0.187184 7 1.532779 1.469359 0.154947 0.378163 8 -0.887786 -1.980796 -0.347912 0.156349 9 1.230291 1.202380 -0.387327 -0.302303 4. Don’t use tooltips # Tooltips require cell_ids to work and they generate extra HTML elements for every data cell. 5. If every byte counts use string replacement # You can remove unnecessary HTML, or shorten the default class names by replacing the default css dict. You can read a little more about CSS below . [47]: my_css = { ""row_heading"" : """" , ""col_heading"" : """" , ""index_name"" : """" , ""col"" : ""c"" , ""row"" : ""r"" , ""col_trim"" : """" , ""row_trim"" : """" , ""level"" : ""l"" , ""data"" : """" , ""blank"" : """" , } html = Styler ( df4 , uuid_len = 0 , cell_ids = False ) html . set_table_styles ([{ 'selector' : 'td' , 'props' : props }, { 'selector' : '.c1' , 'props' : 'color:green;' }, { 'selector' : '.l0' , 'props' : 'color:blue;' }], css_class_names = my_css ) print ( html . to_html ()) <style type=""text/css""> #T_ td {   font-family: ""Times New Roman"", Times, serif;   color: #e83e8c;   font-size: 1.3em; } #T_ .c1 {   color: green; } #T_ .l0 {   color: blue; } </style> <table id=""T_"">   <thead>     <tr>       <th class="" l0"" >&nbsp;</th>       <th class="" l0 c0"" >0</th>       <th class="" l0 c1"" >1</th>     </tr>   </thead>   <tbody>     <tr>       <th class="" l0 r0"" >0</th>       <td class="" r0 c0"" >1</td>       <td class="" r0 c1"" >2</td>     </tr>     <tr>       <th class="" l0 r1"" >1</th>       <td class="" r1 c0"" >3</td>       <td class="" r1 c1"" >4</td>     </tr>   </tbody> </table> [48]: html [48]: 0 1 0 1 2 1 3 4 Builtin Styles # Some styling functions are common enough that we’ve “built them in” to the Styler , so you don’t have to write them and apply them yourself. The current list of such functions is: .highlight_null : for use with identifying missing data. .highlight_min and .highlight_max : for use with identifying extremeties in data. .highlight_between and .highlight_quantile : for use with identifying classes within data. .background_gradient : a flexible method for highlighting cells based on their, or other, values on a numeric scale. .text_gradient : similar method for highlighting text based on their, or other, values on a numeric scale. .bar : to display mini-charts within cell backgrounds. The individual documentation on each function often gives more examples of their arguments. Highlight Null # [49]: df2 . iloc [ 0 , 2 ] = np . nan df2 . iloc [ 4 , 3 ] = np . nan df2 . loc [: 4 ] . style . highlight_null ( color = 'yellow' ) [49]: A B C D 0 1.764052 0.400157 nan 2.240893 1 1.867558 -0.977278 0.950088 -0.151357 2 -0.103219 0.410599 0.144044 1.454274 3 0.761038 0.121675 0.443863 0.333674 4 1.494079 -0.205158 0.313068 nan Highlight Min or Max # [50]: df2 . loc [: 4 ] . style . highlight_max ( axis = 1 , props = 'color:white; font-weight:bold; background-color:darkblue;' ) [50]: A B C D 0 1.764052 0.400157 nan 2.240893 1 1.867558 -0.977278 0.950088 -0.151357 2 -0.103219 0.410599 0.144044 1.454274 3 0.761038 0.121675 0.443863 0.333674 4 1.494079 -0.205158 0.313068 nan Highlight Between # This method accepts ranges as float, or NumPy arrays or Series provided the indexes match. [51]: left = pd . Series ([ 1.0 , 0.0 , 1.0 ], index = [ ""A"" , ""B"" , ""D"" ]) df2 . loc [: 4 ] . style . highlight_between ( left = left , right = 1.5 , axis = 1 , props = 'color:white; background-color:purple;' ) [51]: A B C D 0 1.764052 0.400157 nan 2.240893 1 1.867558 -0.977278 0.950088 -0.151357 2 -0.103219 0.410599 0.144044 1.454274 3 0.761038 0.121675 0.443863 0.333674 4 1.494079 -0.205158 0.313068 nan Highlight Quantile # Useful for detecting the highest or lowest percentile values [52]: df2 . loc [: 4 ] . style . highlight_quantile ( q_left = 0.85 , axis = None , color = 'yellow' ) [52]: A B C D 0 1.764052 0.400157 nan 2.240893 1 1.867558 -0.977278 0.950088 -0.151357 2 -0.103219 0.410599 0.144044 1.454274 3 0.761038 0.121675 0.443863 0.333674 4 1.494079 -0.205158 0.313068 nan Background Gradient and Text Gradient # You can create “heatmaps” with the background_gradient and text_gradient methods. These require matplotlib, and we’ll use Seaborn to get a nice colormap. [53]: import seaborn as sns cm = sns . light_palette ( ""green"" , as_cmap = True ) df2 . style . background_gradient ( cmap = cm ) [53]: A B C D 0 1.764052 0.400157 nan 2.240893 1 1.867558 -0.977278 0.950088 -0.151357 2 -0.103219 0.410599 0.144044 1.454274 3 0.761038 0.121675 0.443863 0.333674 4 1.494079 -0.205158 0.313068 nan 5 -2.552990 0.653619 0.864436 -0.742165 6 2.269755 -1.454366 0.045759 -0.187184 7 1.532779 1.469359 0.154947 0.378163 8 -0.887786 -1.980796 -0.347912 0.156349 9 1.230291 1.202380 -0.387327 -0.302303 [54]: df2 . style . text_gradient ( cmap = cm ) [54]: A B C D 0 1.764052 0.400157 nan 2.240893 1 1.867558 -0.977278 0.950088 -0.151357 2 -0.103219 0.410599 0.144044 1.454274 3 0.761038 0.121675 0.443863 0.333674 4 1.494079 -0.205158 0.313068 nan 5 -2.552990 0.653619 0.864436 -0.742165 6 2.269755 -1.454366 0.045759 -0.187184 7 1.532779 1.469359 0.154947 0.378163 8 -0.887786 -1.980796 -0.347912 0.156349 9 1.230291 1.202380 -0.387327 -0.302303 .background_gradient and .text_gradient have a number of keyword arguments to customise the gradients and colors. See the documentation. Set properties # Use Styler.set_properties when the style doesn’t actually depend on the values. This is just a simple wrapper for .map where the function returns the same properties for all cells. [55]: df2 . loc [: 4 ] . style . set_properties ( ** { 'background-color' : 'black' , 'color' : 'lawngreen' , 'border-color' : 'white' }) [55]: A B C D 0 1.764052 0.400157 nan 2.240893 1 1.867558 -0.977278 0.950088 -0.151357 2 -0.103219 0.410599 0.144044 1.454274 3 0.761038 0.121675 0.443863 0.333674 4 1.494079 -0.205158 0.313068 nan Bar charts # You can include “bar charts” in your DataFrame. [56]: df2 . style . bar ( subset = [ 'A' , 'B' ], color = '#d65f5f' ) [56]: A B C D 0 1.764052 0.400157 nan 2.240893 1 1.867558 -0.977278 0.950088 -0.151357 2 -0.103219 0.410599 0.144044 1.454274 3 0.761038 0.121675 0.443863 0.333674 4 1.494079 -0.205158 0.313068 nan 5 -2.552990 0.653619 0.864436 -0.742165 6 2.269755 -1.454366 0.045759 -0.187184 7 1.532779 1.469359 0.154947 0.378163 8 -0.887786 -1.980796 -0.347912 0.156349 9 1.230291 1.202380 -0.387327 -0.302303 Additional keyword arguments give more control on centering and positioning, and you can pass a list of [color_negative, color_positive] to highlight lower and higher values or a matplotlib colormap. To showcase an example here’s how you can change the above with the new align option, combined with setting vmin and vmax limits, the width of the figure, and underlying css props of cells, leaving space to display the text and the bars. We also use text_gradient to color the text the same as the bars using a matplotlib colormap (although in this case the visualization is probably better without this additional effect). [57]: df2 . style . format ( ' {:.3f} ' , na_rep = """" ) \ . bar ( align = 0 , vmin =- 2.5 , vmax = 2.5 , cmap = ""bwr"" , height = 50 , width = 60 , props = ""width: 120px; border-right: 1px solid black;"" ) \ . text_gradient ( cmap = ""bwr"" , vmin =- 2.5 , vmax = 2.5 ) [57]: A B C D 0 1.764 0.400 2.241 1 1.868 -0.977 0.950 -0.151 2 -0.103 0.411 0.144 1.454 3 0.761 0.122 0.444 0.334 4 1.494 -0.205 0.313 5 -2.553 0.654 0.864 -0.742 6 2.270 -1.454 0.046 -0.187 7 1.533 1.469 0.155 0.378 8 -0.888 -1.981 -0.348 0.156 9 1.230 1.202 -0.387 -0.302 The following example aims to give a highlight of the behavior of the new align options: [59]: HTML ( head ) [59]: Align All Negative Both Neg and Pos All Positive Large Positive left -100 -60 -30 -20 -10 -5 0 90 10 20 50 100 100 103 101 102 right -100 -60 -30 -20 -10 -5 0 90 10 20 50 100 100 103 101 102 zero -100 -60 -30 -20 -10 -5 0 90 10 20 50 100 100 103 101 102 mid -100 -60 -30 -20 -10 -5 0 90 10 20 50 100 100 103 101 102 mean -100 -60 -30 -20 -10 -5 0 90 10 20 50 100 100 103 101 102 99 -100 -60 -30 -20 -10 -5 0 90 10 20 50 100 100 103 101 102 Sharing styles # Say you have a lovely style built up for a DataFrame, and now you want to apply the same style to a second DataFrame. Export the style with df1.style.export , and import it on the second DataFrame with df1.style.set [60]: style1 = df2 . style \ . map ( style_negative , props = 'color:red;' ) \ . map ( lambda v : 'opacity: 20%;' if ( v < 0.3 ) and ( v > - 0.3 ) else None ) \ . set_table_styles ([{ ""selector"" : ""th"" , ""props"" : ""color: blue;"" }]) \ . hide ( axis = ""index"" ) style1 [60]: A B C D 1.764052 0.400157 nan 2.240893 1.867558 -0.977278 0.950088 -0.151357 -0.103219 0.410599 0.144044 1.454274 0.761038 0.121675 0.443863 0.333674 1.494079 -0.205158 0.313068 nan -2.552990 0.653619 0.864436 -0.742165 2.269755 -1.454366 0.045759 -0.187184 1.532779 1.469359 0.154947 0.378163 -0.887786 -1.980796 -0.347912 0.156349 1.230291 1.202380 -0.387327 -0.302303 [61]: style2 = df3 . style style2 . use ( style1 . export ()) style2 [61]: c1 c2 c3 c4 -1.048553 -1.420018 -1.706270 1.950775 -0.509652 -0.438074 -1.252795 0.777490 -1.613898 -0.212740 -0.895467 0.386902 -0.510805 -1.180632 -0.028182 0.428332 Notice that you’re able to share the styles even though they’re data aware. The styles are re-evaluated on the new DataFrame they’ve been use d upon. Limitations # DataFrame only (use Series.to_frame().style ) The index and columns do not need to be unique, but certain styling functions can only work with unique indexes. No large repr, and construction performance isn’t great; although we have some HTML optimizations You can only apply styles, you can’t insert new HTML entities, except via subclassing. Other Fun and Useful Stuff # Here are a few interesting examples. Widgets # Styler interacts pretty well with widgets. If you’re viewing this online instead of running the notebook yourself, you’re missing out on interactively adjusting the color palette. [62]: from ipywidgets import widgets @widgets . interact def f ( h_neg = ( 0 , 359 , 1 ), h_pos = ( 0 , 359 ), s = ( 0. , 99.9 ), l = ( 0. , 99.9 )): return df2 . style . background_gradient ( cmap = sns . palettes . diverging_palette ( h_neg = h_neg , h_pos = h_pos , s = s , l = l , as_cmap = True ) ) Magnify # [63]: def magnify (): return [ dict ( selector = ""th"" , props = [( ""font-size"" , ""4pt"" )]), dict ( selector = ""td"" , props = [( 'padding' , ""0em 0em"" )]), dict ( selector = ""th:hover"" , props = [( ""font-size"" , ""12pt"" )]), dict ( selector = ""tr:hover td:hover"" , props = [( 'max-width' , '200px' ), ( 'font-size' , '12pt' )]) ] [64]: np . random . seed ( 25 ) cmap = cmap = sns . diverging_palette ( 5 , 250 , as_cmap = True ) bigdf = pd . DataFrame ( np . random . randn ( 20 , 25 )) . cumsum () bigdf . style . background_gradient ( cmap , axis = 1 ) \ . set_properties ( ** { 'max-width' : '80px' , 'font-size' : '1pt' }) \ . set_caption ( ""Hover to magnify"" ) \ . format ( precision = 2 ) \ . set_table_styles ( magnify ()) [64]: Hover to magnify 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 0 0.23 1.03 -0.84 -0.59 -0.96 -0.22 -0.62 1.84 -2.05 0.87 -0.92 -0.23 2.15 -1.33 0.08 -1.25 1.20 -1.05 1.06 -0.42 2.29 -2.59 2.82 0.68 -1.58 1 -1.75 1.56 -1.13 -1.10 1.03 0.00 -2.46 3.45 -1.66 1.27 -0.52 -0.02 1.52 -1.09 -1.86 -1.13 -0.68 -0.81 0.35 -0.06 1.79 -2.82 2.26 0.78 0.44 2 -0.65 3.22 -1.76 0.52 2.20 -0.37 -3.00 3.73 -1.87 2.46 0.21 -0.24 -0.10 -0.78 -3.02 -0.82 -0.21 -0.23 0.86 -0.68 1.45 -4.89 3.03 1.91 0.61 3 -1.62 3.71 -2.31 0.43 4.17 -0.43 -3.86 4.16 -2.15 1.08 0.12 0.60 -0.89 0.27 -3.67 -2.71 -0.31 -1.59 1.35 -1.83 0.91 -5.80 2.81 2.11 0.28 4 -3.35 4.48 -1.86 -1.70 5.19 -1.02 -3.81 4.72 -0.72 1.08 -0.18 0.83 -0.22 -1.08 -4.27 -2.88 -0.97 -1.78 1.53 -1.80 2.21 -6.34 3.34 2.49 2.09 5 -0.84 4.23 -1.65 -2.00 5.34 -0.99 -4.13 3.94 -1.06 -0.94 1.24 0.09 -1.78 -0.11 -4.45 -0.85 -2.06 -1.35 0.80 -1.63 1.54 -6.51 2.80 2.14 3.77 6 -0.74 5.35 -2.11 -1.13 4.20 -1.85 -3.20 3.76 -3.22 -1.23 0.34 0.57 -1.82 0.54 -4.43 -1.83 -4.03 -2.62 -0.20 -4.68 1.93 -8.46 3.34 2.52 5.81 7 -0.44 4.69 -2.30 -0.21 5.93 -2.63 -1.83 5.46 -4.50 -3.16 -1.73 0.18 0.11 0.04 -5.99 -0.45 -6.20 -3.89 0.71 -3.95 0.67 -7.26 2.97 3.39 6.66 8 0.92 5.80 -3.33 -0.65 5.99 -3.19 -1.83 5.63 -3.53 -1.30 -1.61 0.82 -2.45 -0.40 -6.06 -0.52 -6.60 -3.48 -0.04 -4.60 0.51 -5.85 3.23 2.40 5.08 9 0.38 5.54 -4.49 -0.80 7.05 -2.64 -0.44 5.35 -1.96 -0.33 -0.80 0.26 -3.37 -0.82 -6.05 -2.61 -8.45 -4.45 0.41 -4.71 1.89 -6.93 2.14 3.00 5.16 10 2.06 5.84 -3.90 -0.98 7.78 -2.49 -0.59 5.59 -2.22 -0.71 -0.46 1.80 -2.79 0.48 -5.97 -3.44 -7.77 -5.49 -0.70 -4.61 -0.52 -7.72 1.54 5.02 5.81 11 1.86 4.47 -2.17 -1.38 5.90 -0.49 0.02 5.78 -1.04 -0.60 0.49 1.96 -1.47 1.88 -5.92 -4.55 -8.15 -3.42 -2.24 -4.33 -1.17 -7.90 1.36 5.31 5.83 12 3.19 4.22 -3.06 -2.27 5.93 -2.64 0.33 6.72 -2.84 -0.20 1.89 2.63 -1.53 0.75 -5.27 -4.53 -7.57 -2.85 -2.17 -4.78 -1.13 -8.99 2.11 6.42 5.60 13 2.31 4.45 -3.87 -2.05 6.76 -3.25 -2.17 7.99 -2.56 -0.80 0.71 2.33 -0.16 -0.46 -5.10 -3.79 -7.58 -4.00 0.33 -3.67 -1.05 -8.71 2.47 5.87 6.71 14 3.78 4.33 -3.88 -1.58 6.22 -3.23 -1.46 5.57 -2.93 -0.33 -0.97 1.72 3.61 0.29 -4.21 -4.10 -6.68 -4.50 -2.19 -2.43 -1.64 -9.36 3.36 6.11 7.53 15 5.64 5.31 -3.98 -2.26 5.91 -3.30 -1.03 5.68 -3.06 -0.33 -1.16 2.19 4.20 1.01 -3.22 -4.31 -5.74 -4.44 -2.30 -1.36 -1.20 -11.27 2.59 6.69 5.91 16 4.08 4.34 -2.44 -3.30 6.04 -2.52 -0.47 5.28 -4.84 1.58 0.23 0.10 5.79 1.80 -3.13 -3.85 -5.53 -2.97 -2.13 -1.15 -0.56 -13.13 2.07 6.16 4.94 17 5.64 4.57 -3.53 -3.76 6.58 -2.58 -0.75 6.58 -4.78 3.63 -0.29 0.56 5.76 2.05 -2.27 -2.31 -4.95 -3.16 -3.06 -2.43 0.84 -12.57 3.56 7.36 4.70 18 5.99 5.82 -2.85 -4.15 7.12 -3.32 -1.21 7.93 -4.85 1.44 -0.63 0.35 7.47 0.87 -1.52 -2.09 -4.23 -2.55 -2.46 -2.89 1.90 -9.74 3.43 7.07 4.39 19 4.03 6.23 -4.10 -4.11 7.19 -4.10 -1.52 6.53 -5.21 -0.24 0.01 1.16 6.43 -1.97 -2.64 -1.66 -5.20 -3.25 -2.87 -1.65 1.64 -10.66 2.83 7.48 3.94 Sticky Headers # If you display a large matrix or DataFrame in a notebook, but you want to always see the column and row headers you can use the .set_sticky method which manipulates the table styles CSS. [65]: bigdf = pd . DataFrame ( np . random . randn ( 16 , 100 )) bigdf . style . set_sticky ( axis = ""index"" ) [65]: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 0 -0.773866 -0.240521 -0.217165 1.173609 0.686390 0.008358 0.696232 0.173166 0.620498 0.504067 0.428066 -0.051824 0.719915 0.057165 0.562808 -0.369536 0.483399 0.620765 -0.354342 -1.469471 -1.937266 0.038031 -1.518162 -0.417599 0.386717 0.716193 0.489961 0.733957 0.914415 0.679894 0.255448 -0.508338 0.332030 -0.111107 -0.251983 -1.456620 0.409630 1.062320 -0.577115 0.718796 -0.399260 -1.311389 0.649122 0.091566 0.628872 0.297894 -0.142290 -0.542291 -0.914290 1.144514 0.313584 1.182635 1.214235 -0.416446 -1.653940 -2.550787 0.442473 0.052127 -0.464469 -0.523852 0.989726 -1.325539 -0.199687 -1.226727 0.290018 1.164574 0.817841 -0.309509 0.496599 0.943536 -0.091850 -2.802658 2.126219 -0.521161 0.288098 -0.454663 -1.676143 -0.357661 -0.788960 0.185911 -0.017106 2.454020 1.832706 -0.911743 -0.655873 -0.000514 -2.226997 0.677285 -0.140249 -0.408407 -0.838665 0.482228 1.243458 -0.477394 -0.220343 -2.463966 0.237325 -0.307380 1.172478 0.819492 1 0.405906 -0.978919 1.267526 0.145250 -1.066786 -2.114192 -1.128346 -1.082523 0.372216 0.004127 -0.211984 0.937326 -0.935890 -1.704118 0.611789 -1.030015 0.636123 -1.506193 1.736609 1.392958 1.009424 0.353266 0.697339 -0.297424 0.428702 -0.145346 -0.333553 -0.974699 0.665314 0.971944 0.121950 -1.439668 1.018808 1.442399 -0.199585 -1.165916 0.645656 1.436466 -0.921215 1.293906 -2.706443 1.460928 -0.823197 0.292952 -1.448992 0.026692 -0.975883 0.392823 0.442166 0.745741 1.187982 -0.218570 0.305288 0.054932 -1.476953 -0.114434 0.014103 0.825394 -0.060654 -0.413688 0.974836 1.339210 1.034838 0.040775 0.705001 0.017796 1.867681 -0.390173 2.285277 2.311464 -0.085070 -0.648115 0.576300 -0.790087 -1.183798 -1.334558 -0.454118 0.319302 1.706488 0.830429 0.502476 -0.079631 0.414635 0.332511 0.042935 -0.160910 0.918553 -0.292697 -1.303834 -0.199604 0.871023 -1.370681 -0.205701 -0.492973 1.123083 -0.081842 -0.118527 0.245838 -0.315742 -0.511806 2 0.011470 -0.036104 1.399603 -0.418176 -0.412229 -1.234783 -1.121500 1.196478 -0.569522 0.422022 -0.220484 0.804338 2.892667 -0.511055 -0.168722 -1.477996 -1.969917 0.471354 1.698548 0.137105 -0.762052 0.199379 -0.964346 -0.256692 1.265275 0.848762 -0.784161 1.863776 -0.355569 0.854552 0.768061 -2.075718 -2.501069 1.109868 0.957545 -0.683276 0.307764 0.733073 1.706250 -1.118091 0.374961 -1.414503 -0.524183 -1.662696 0.687921 0.521732 1.451396 -0.833491 -0.362796 -1.174444 -0.813893 -0.893220 0.770743 1.156647 -0.647444 0.125929 0.513600 -0.537874 1.992052 -1.946584 -0.104759 0.484779 -0.290936 -0.441075 0.542993 -1.050038 1.630482 0.239771 -1.177310 0.464804 -0.966995 0.646086 0.486899 1.022196 -2.267827 -1.229616 1.313805 1.073292 2.324940 -0.542720 -1.504292 0.777643 -0.618553 0.011342 1.385062 1.363552 -0.549834 0.688896 1.361288 -0.381137 0.797812 -1.128198 0.369208 0.540132 0.413853 -0.200308 -0.969126 0.981293 -0.009783 -0.320020 3 -0.574816 1.419977 0.434813 -1.101217 -1.586275 1.979573 0.378298 0.782326 2.178987 0.657564 0.683774 -0.091000 -0.059552 -0.738908 -0.907653 -0.701936 0.580039 -0.618757 0.453684 1.665382 -0.152321 0.880077 0.571073 -0.604736 0.532359 0.515031 -0.959844 -0.887184 0.435781 0.862093 -0.956321 -0.625909 0.194472 0.442490 0.526503 -0.215274 0.090711 0.932592 0.811999 -2.497026 0.631545 0.321418 -0.425549 -1.078832 0.753444 0.199790 -0.360526 -0.013448 -0.819476 0.814869 0.442118 -0.972048 -0.060603 -2.349825 1.265445 -0.573257 0.429124 1.049783 1.954773 0.071883 -0.094209 0.265616 0.948318 0.331645 1.343401 -0.167934 -1.105252 -0.167077 -0.096576 -0.838161 -0.208564 0.394534 0.762533 1.235357 -0.207282 -0.202946 -0.468025 0.256944 2.587584 1.186697 -1.031903 1.428316 0.658899 -0.046582 -0.075422 1.329359 -0.684267 -1.524182 2.014061 3.770933 0.647353 -1.021377 -0.345493 0.582811 0.797812 1.326020 1.422857 -3.077007 0.184083 1.478935 4 -0.600142 1.929561 -2.346771 -0.669700 -1.165258 0.814788 0.444449 -0.576758 0.353091 0.408893 0.091391 -2.294389 0.485506 -0.081304 -0.716272 -1.648010 1.005361 -1.489603 0.363098 0.758602 -1.373847 -0.972057 1.988537 0.319829 1.169060 0.146585 1.030388 1.165984 1.369563 0.730984 -1.383696 -0.515189 -0.808927 -1.174651 -1.631502 -1.123414 -0.478155 -1.583067 1.419074 1.668777 1.567517 0.222103 -0.336040 -1.352064 0.251032 -0.401695 0.268413 -0.012299 -0.918953 2.921208 -0.581588 0.672848 1.251136 1.382263 1.429897 1.290990 -1.272673 -0.308611 -0.422988 -0.675642 0.874441 1.305736 -0.262585 -1.099395 -0.667101 -0.646737 -0.556338 -0.196591 0.119306 -0.266455 -0.524267 2.650951 0.097318 -0.974697 0.189964 1.141155 -0.064434 1.104971 -1.508908 -0.031833 0.803919 -0.659221 0.939145 0.214041 -0.531805 0.956060 0.249328 0.637903 -0.510158 1.850287 -0.348407 2.001376 -0.389643 -0.024786 -0.470973 0.869339 0.170667 0.598062 1.217262 1.274013 5 -0.389981 -0.752441 -0.734871 3.517318 -1.173559 -0.004956 0.145419 2.151368 -3.086037 -1.569139 1.449784 -0.868951 -1.687716 -0.994401 1.153266 1.803045 -0.819059 0.847970 0.227102 -0.500762 0.868210 1.823540 1.161007 -0.307606 -0.713416 0.363560 -0.822162 2.427681 -0.129537 -0.078716 1.345644 -1.286094 0.237242 -0.136056 0.596664 -1.412381 1.206341 0.299860 0.705238 0.142412 -1.059382 0.833468 1.060015 -0.527045 -1.135732 -1.140983 -0.779540 -0.640875 -1.217196 -1.675663 0.241263 -0.273322 -1.697936 -0.594943 0.101154 1.391735 -0.426953 1.008344 -0.818577 1.924570 -0.578900 -0.457395 -1.096705 0.418522 -0.155623 0.169706 -2.533706 0.018904 1.434160 0.744095 0.647626 -0.770309 2.329141 -0.141547 -1.761594 0.702091 -1.531450 -0.788427 -0.184622 -1.942321 1.530113 0.503406 1.105845 -0.935120 -1.115483 -2.249762 1.307135 0.788412 -0.441091 0.073561 0.812101 -0.916146 1.573714 -0.309508 0.499987 0.187594 0.558913 0.903246 0.317901 -0.809797 6 1.128248 1.516826 -0.186735 -0.668157 1.132259 -0.246648 -0.855167 0.732283 0.931802 1.318684 -1.198418 -1.149318 0.586321 -1.171937 -0.607731 2.753747 1.479287 -1.136365 -0.020485 0.320444 -1.955755 0.660402 -1.545371 0.200519 -0.017263 1.634686 0.599246 0.462989 0.023721 0.225546 0.170972 -0.027496 -0.061233 -0.566411 -0.669567 0.601618 0.503656 -0.678253 -2.907108 -1.717123 0.397631 1.300108 0.215821 -0.593075 -0.225944 -0.946057 1.000308 0.393160 1.342074 -0.370687 -0.166413 -0.419814 -0.255931 1.789478 0.282378 0.742260 -0.050498 1.415309 0.838166 -1.400292 -0.937976 -1.499148 0.801859 0.224824 0.283572 0.643703 -1.198465 0.527206 0.215202 0.437048 1.312868 0.741243 0.077988 0.006123 0.190370 0.018007 -1.026036 -2.378430 -1.069949 0.843822 1.289216 -1.423369 -0.462887 0.197330 -0.935076 0.441271 0.414643 -0.377887 -0.530515 0.621592 1.009572 0.569718 0.175291 -0.656279 -0.112273 -0.392137 -1.043558 -0.467318 -0.384329 -2.009207 7 0.658598 0.101830 -0.682781 0.229349 -0.305657 0.404877 0.252244 -0.837784 -0.039624 0.329457 0.751694 1.469070 -0.157199 1.032628 -0.584639 -0.925544 0.342474 -0.969363 0.133480 -0.385974 -0.600278 0.281939 0.868579 1.129803 -0.041898 0.961193 0.131521 -0.792889 -1.285737 0.073934 -1.333315 -1.044125 1.277338 1.492257 0.411379 1.771805 -1.111128 1.123233 -1.019449 1.738357 -0.690764 -0.120710 -0.421359 -0.727294 -0.857759 -0.069436 -0.328334 -0.558180 1.063474 -0.519133 -0.496902 1.089589 -1.615801 0.080174 -0.229938 -0.498420 -0.624615 0.059481 -0.093158 -1.784549 -0.503789 -0.140528 0.002653 -0.484930 0.055914 -0.680948 -0.994271 1.277052 0.037651 2.155421 -0.437589 0.696404 0.417752 -0.544785 1.190690 0.978262 0.752102 0.504472 0.139853 -0.505089 -0.264975 -1.603194 0.731847 0.010903 -1.165346 -0.125195 -1.032685 -0.465520 1.514808 0.304762 0.793414 0.314635 -1.638279 0.111737 -0.777037 0.251783 1.126303 -0.808798 0.422064 -0.349264 8 -0.356362 -0.089227 0.609373 0.542382 -0.768681 -0.048074 2.015458 -1.552351 0.251552 1.459635 0.949707 0.339465 -0.001372 1.798589 1.559163 0.231783 0.423141 -0.310530 0.353795 2.173336 -0.196247 -0.375636 -0.858221 0.258410 0.656430 0.960819 1.137893 1.553405 0.038981 -0.632038 -0.132009 -1.834997 -0.242576 -0.297879 -0.441559 -0.769691 0.224077 -0.153009 0.519526 -0.680188 0.535851 0.671496 -0.183064 0.301234 1.288256 -2.478240 -0.360403 0.424067 -0.834659 -0.128464 -0.489013 -0.014888 -1.461230 -1.435223 -1.319802 1.083675 0.979140 -0.375291 1.110189 -1.011351 0.587886 -0.822775 -1.183865 1.455173 1.134328 0.239403 -0.837991 -1.130932 0.783168 1.845520 1.437072 -1.198443 1.379098 2.129113 0.260096 -0.011975 0.043302 0.722941 1.028152 -0.235806 1.145245 -1.359598 0.232189 0.503712 -0.614264 -0.530606 -2.435803 -0.255238 -0.064423 0.784643 0.256346 0.128023 1.414103 -1.118659 0.877353 0.500561 0.463651 -2.034512 -0.981683 -0.691944 9 -1.113376 -1.169402 0.680539 -1.534212 1.653817 -1.295181 -0.566826 0.477014 1.413371 0.517105 1.401153 -0.872685 0.830957 0.181507 -0.145616 0.694592 -0.751208 0.324444 0.681973 -0.054972 0.917776 -1.024810 -0.206446 -0.600113 0.852805 1.455109 -0.079769 0.076076 0.207699 -1.850458 -0.124124 -0.610871 -0.883362 0.219049 -0.685094 -0.645330 -0.242805 -0.775602 0.233070 2.422642 -1.423040 -0.582421 0.968304 -0.701025 -0.167850 0.277264 1.301231 0.301205 -3.081249 -0.562868 0.192944 -0.664592 0.565686 0.190913 -0.841858 -1.856545 -1.022777 1.295968 0.451921 0.659955 0.065818 -0.319586 0.253495 -1.144646 -0.483404 0.555902 0.807069 0.714196 0.661196 0.053667 0.346833 -1.288977 -0.386734 -1.262127 0.477495 -0.494034 -0.911414 1.152963 -0.342365 -0.160187 0.470054 -0.853063 -1.387949 -0.257257 -1.030690 -0.110210 0.328911 -0.555923 0.987713 -0.501957 2.069887 -0.067503 0.316029 -1.506232 2.201621 0.492097 -0.085193 -0.977822 1.039147 -0.653932 10 -0.405638 -1.402027 -1.166242 1.306184 0.856283 -1.236170 -0.646721 -1.474064 0.082960 0.090310 -0.169977 0.406345 0.915427 -0.974503 0.271637 1.539184 -0.098866 -0.525149 1.063933 0.085827 -0.129622 0.947959 -0.072496 -0.237592 0.012549 1.065761 0.996596 -0.172481 2.583139 -0.028578 -0.254856 1.328794 -1.592951 2.434350 -0.341500 -0.307719 -1.333273 -1.100845 0.209097 1.734777 0.639632 0.424779 -0.129327 0.905029 -0.482909 1.731628 -2.783425 -0.333677 -0.110895 1.212636 -0.208412 0.427117 1.348563 0.043859 1.772519 -1.416106 0.401155 0.807157 0.303427 -1.246288 0.178774 -0.066126 -1.862288 1.241295 0.377021 -0.822320 -0.749014 1.463652 1.602268 -1.043877 1.185290 -0.565783 -1.076879 1.360241 -0.121991 0.991043 1.007952 0.450185 -0.744376 1.388876 -0.316847 -0.841655 -1.056842 -0.500226 0.096959 1.176896 -2.939652 1.792213 0.316340 0.303218 1.024967 -0.590871 -0.453326 -0.795981 -0.393301 -0.374372 -1.270199 1.618372 1.197727 -0.914863 11 -0.625210 0.288911 0.288374 -1.372667 -0.591395 -0.478942 1.335664 -0.459855 -1.615975 -1.189676 0.374767 -2.488733 0.586656 -1.422008 0.496030 1.911128 -0.560660 -0.499614 -0.372171 -1.833069 0.237124 -0.944446 0.912140 0.359790 -1.359235 0.166966 -0.047107 -0.279789 -0.594454 -0.739013 -1.527645 0.401668 1.791252 -2.774848 0.523873 2.207585 0.488999 -0.339283 0.131711 0.018409 1.186551 -0.424318 1.554994 -0.205917 -0.934975 0.654102 -1.227761 -0.461025 -0.421201 -0.058615 -0.584563 0.336913 -0.477102 -1.381463 0.757745 -0.268968 0.034870 1.231686 0.236600 1.234720 -0.040247 0.029582 1.034905 0.380204 -0.012108 -0.859511 -0.990340 -1.205172 -1.030178 0.426676 0.497796 -0.876808 0.957963 0.173016 0.131612 -1.003556 -1.069908 -1.799207 1.429598 -0.116015 -1.454980 0.261917 0.444412 0.273290 0.844115 0.218745 -1.033350 -1.188295 0.058373 0.800523 -1.627068 0.861651 0.871018 -0.003733 -0.243354 0.947296 0.509406 0.044546 0.266896 1.337165 12 0.699142 -1.928033 0.105363 1.042322 0.715206 -0.763783 0.098798 -1.157898 0.134105 0.042041 0.674826 0.165649 -1.622970 -3.131274 0.597649 -1.880331 0.663980 -0.256033 -1.524058 0.492799 0.221163 0.429622 -0.659584 1.264506 -0.032131 -2.114907 -0.264043 0.457835 -0.676837 -0.629003 0.489145 -0.551686 0.942622 -0.512043 -0.455893 0.021244 -0.178035 -2.498073 -0.171292 0.323510 -0.545163 -0.668909 -0.150031 0.521620 -0.428980 0.676463 0.369081 -0.724832 0.793542 1.237422 0.401275 2.141523 0.249012 0.486755 -0.163274 0.592222 -0.292600 -0.547168 0.619104 -0.013605 0.776734 0.131424 1.189480 -0.666317 -0.939036 1.105515 0.621452 1.586605 -0.760970 1.649646 0.283199 1.275812 -0.452012 0.301361 -0.976951 -0.268106 -0.079255 -1.258332 2.216658 -1.175988 -0.863497 -1.653022 -0.561514 0.450753 0.417200 0.094676 -2.231054 1.316862 -0.477441 0.646654 -0.200252 1.074354 -0.058176 0.120990 0.222522 -0.179507 0.421655 -0.914341 -0.234178 0.741524 13 0.932714 1.423761 -1.280835 0.347882 -0.863171 -0.852580 1.044933 2.094536 0.806206 0.416201 -1.109503 0.145302 -0.996871 0.325456 -0.605081 1.175326 1.645054 0.293432 -2.766822 1.032849 0.079115 -1.414132 1.463376 2.335486 0.411951 -0.048543 0.159284 -0.651554 -1.093128 1.568390 -0.077807 -2.390779 -0.842346 -0.229675 -0.999072 -1.367219 -0.792042 -1.878575 1.451452 1.266250 -0.734315 0.266152 0.735523 -0.430860 0.229864 0.850083 -2.241241 1.063850 0.289409 -0.354360 0.113063 -0.173006 1.386998 1.886236 0.587119 -0.961133 0.399295 1.461560 0.310823 0.280220 -0.879103 -1.326348 0.003337 -1.085908 -0.436723 2.111926 0.106068 0.615597 2.152996 -0.196155 0.025747 -0.039061 0.656823 -0.347105 2.513979 1.758070 1.288473 -0.739185 -0.691592 -0.098728 -0.276386 0.489981 0.516278 -0.838258 0.596673 -0.331053 0.521174 -0.145023 0.836693 -1.092166 0.361733 -1.169981 0.046731 0.655377 -0.756852 1.285805 -0.095019 0.360253 1.370621 0.083010 14 0.888893 2.288725 -1.032332 0.212273 -1.091826 1.692498 1.025367 0.550854 0.679430 -1.335712 -0.798341 2.265351 -1.006938 2.059761 0.420266 -1.189657 0.506674 0.260847 -0.533145 0.727267 1.412276 1.482106 -0.996258 0.588641 -0.412642 -0.920733 -0.874691 0.839002 0.501668 -0.342493 -0.533806 -2.146352 -0.597339 0.115726 0.850683 -0.752239 0.377263 -0.561982 0.262783 -0.356676 -0.367462 0.753611 -1.267414 -1.330698 -0.536453 0.840938 -0.763108 -0.268100 -0.677424 1.606831 0.151732 -2.085701 1.219296 0.400863 0.591165 -1.485213 1.501979 1.196569 -0.214154 0.339554 -0.034446 1.176452 0.546340 -1.255630 -1.309210 -0.445437 0.189437 -0.737463 0.843767 -0.605632 -0.060777 0.409310 1.285569 -0.622638 1.018193 0.880680 0.046805 -1.818058 -0.809829 0.875224 0.409569 -0.116621 -1.238919 3.305724 -0.024121 -1.756500 1.328958 0.507593 -0.866554 -2.240848 -0.661376 -0.671824 0.215720 -0.296326 0.481402 0.829645 -0.721025 1.263914 0.549047 -1.234945 15 -1.978838 0.721823 -0.559067 -1.235243 0.420716 -0.598845 0.359576 -0.619366 -1.757772 -1.156251 0.705212 0.875071 -1.020376 0.394760 -0.147970 0.230249 1.355203 1.794488 2.678058 -0.153565 -0.460959 -0.098108 -1.407930 -2.487702 1.823014 0.099873 -0.517603 -0.509311 -1.833175 -0.900906 0.459493 -0.655440 1.466122 -1.531389 -0.422106 0.421422 0.578615 0.259795 0.018941 -0.168726 1.611107 -1.586550 -1.384941 0.858377 1.033242 1.701343 1.748344 -0.371182 -0.843575 2.089641 -0.345430 -1.740556 0.141915 -2.197138 0.689569 -0.150025 0.287456 0.654016 -1.521919 -0.918008 -0.587528 0.230636 0.262637 0.615674 0.600044 -0.494699 -0.743089 0.220026 -0.242207 0.528216 -0.328174 -1.536517 -1.476640 -1.162114 -1.260222 1.106252 -1.467408 -0.349341 -1.841217 0.031296 -0.076475 -0.353383 0.807545 0.779064 -2.398417 -0.267828 1.549734 0.814397 0.284770 -0.659369 0.761040 -0.722067 0.810332 1.501295 1.440865 -1.367459 -0.700301 -1.540662 0.159837 -0.625415 It is also possible to stick MultiIndexes and even only specific levels. [66]: bigdf . index = pd . MultiIndex . from_product ([[ ""A"" , ""B"" ],[ 0 , 1 ],[ 0 , 1 , 2 , 3 ]]) bigdf . style . set_sticky ( axis = ""index"" , pixel_size = 18 , levels = [ 1 , 2 ]) [66]: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 A 0 0 -0.773866 -0.240521 -0.217165 1.173609 0.686390 0.008358 0.696232 0.173166 0.620498 0.504067 0.428066 -0.051824 0.719915 0.057165 0.562808 -0.369536 0.483399 0.620765 -0.354342 -1.469471 -1.937266 0.038031 -1.518162 -0.417599 0.386717 0.716193 0.489961 0.733957 0.914415 0.679894 0.255448 -0.508338 0.332030 -0.111107 -0.251983 -1.456620 0.409630 1.062320 -0.577115 0.718796 -0.399260 -1.311389 0.649122 0.091566 0.628872 0.297894 -0.142290 -0.542291 -0.914290 1.144514 0.313584 1.182635 1.214235 -0.416446 -1.653940 -2.550787 0.442473 0.052127 -0.464469 -0.523852 0.989726 -1.325539 -0.199687 -1.226727 0.290018 1.164574 0.817841 -0.309509 0.496599 0.943536 -0.091850 -2.802658 2.126219 -0.521161 0.288098 -0.454663 -1.676143 -0.357661 -0.788960 0.185911 -0.017106 2.454020 1.832706 -0.911743 -0.655873 -0.000514 -2.226997 0.677285 -0.140249 -0.408407 -0.838665 0.482228 1.243458 -0.477394 -0.220343 -2.463966 0.237325 -0.307380 1.172478 0.819492 1 0.405906 -0.978919 1.267526 0.145250 -1.066786 -2.114192 -1.128346 -1.082523 0.372216 0.004127 -0.211984 0.937326 -0.935890 -1.704118 0.611789 -1.030015 0.636123 -1.506193 1.736609 1.392958 1.009424 0.353266 0.697339 -0.297424 0.428702 -0.145346 -0.333553 -0.974699 0.665314 0.971944 0.121950 -1.439668 1.018808 1.442399 -0.199585 -1.165916 0.645656 1.436466 -0.921215 1.293906 -2.706443 1.460928 -0.823197 0.292952 -1.448992 0.026692 -0.975883 0.392823 0.442166 0.745741 1.187982 -0.218570 0.305288 0.054932 -1.476953 -0.114434 0.014103 0.825394 -0.060654 -0.413688 0.974836 1.339210 1.034838 0.040775 0.705001 0.017796 1.867681 -0.390173 2.285277 2.311464 -0.085070 -0.648115 0.576300 -0.790087 -1.183798 -1.334558 -0.454118 0.319302 1.706488 0.830429 0.502476 -0.079631 0.414635 0.332511 0.042935 -0.160910 0.918553 -0.292697 -1.303834 -0.199604 0.871023 -1.370681 -0.205701 -0.492973 1.123083 -0.081842 -0.118527 0.245838 -0.315742 -0.511806 2 0.011470 -0.036104 1.399603 -0.418176 -0.412229 -1.234783 -1.121500 1.196478 -0.569522 0.422022 -0.220484 0.804338 2.892667 -0.511055 -0.168722 -1.477996 -1.969917 0.471354 1.698548 0.137105 -0.762052 0.199379 -0.964346 -0.256692 1.265275 0.848762 -0.784161 1.863776 -0.355569 0.854552 0.768061 -2.075718 -2.501069 1.109868 0.957545 -0.683276 0.307764 0.733073 1.706250 -1.118091 0.374961 -1.414503 -0.524183 -1.662696 0.687921 0.521732 1.451396 -0.833491 -0.362796 -1.174444 -0.813893 -0.893220 0.770743 1.156647 -0.647444 0.125929 0.513600 -0.537874 1.992052 -1.946584 -0.104759 0.484779 -0.290936 -0.441075 0.542993 -1.050038 1.630482 0.239771 -1.177310 0.464804 -0.966995 0.646086 0.486899 1.022196 -2.267827 -1.229616 1.313805 1.073292 2.324940 -0.542720 -1.504292 0.777643 -0.618553 0.011342 1.385062 1.363552 -0.549834 0.688896 1.361288 -0.381137 0.797812 -1.128198 0.369208 0.540132 0.413853 -0.200308 -0.969126 0.981293 -0.009783 -0.320020 3 -0.574816 1.419977 0.434813 -1.101217 -1.586275 1.979573 0.378298 0.782326 2.178987 0.657564 0.683774 -0.091000 -0.059552 -0.738908 -0.907653 -0.701936 0.580039 -0.618757 0.453684 1.665382 -0.152321 0.880077 0.571073 -0.604736 0.532359 0.515031 -0.959844 -0.887184 0.435781 0.862093 -0.956321 -0.625909 0.194472 0.442490 0.526503 -0.215274 0.090711 0.932592 0.811999 -2.497026 0.631545 0.321418 -0.425549 -1.078832 0.753444 0.199790 -0.360526 -0.013448 -0.819476 0.814869 0.442118 -0.972048 -0.060603 -2.349825 1.265445 -0.573257 0.429124 1.049783 1.954773 0.071883 -0.094209 0.265616 0.948318 0.331645 1.343401 -0.167934 -1.105252 -0.167077 -0.096576 -0.838161 -0.208564 0.394534 0.762533 1.235357 -0.207282 -0.202946 -0.468025 0.256944 2.587584 1.186697 -1.031903 1.428316 0.658899 -0.046582 -0.075422 1.329359 -0.684267 -1.524182 2.014061 3.770933 0.647353 -1.021377 -0.345493 0.582811 0.797812 1.326020 1.422857 -3.077007 0.184083 1.478935 1 0 -0.600142 1.929561 -2.346771 -0.669700 -1.165258 0.814788 0.444449 -0.576758 0.353091 0.408893 0.091391 -2.294389 0.485506 -0.081304 -0.716272 -1.648010 1.005361 -1.489603 0.363098 0.758602 -1.373847 -0.972057 1.988537 0.319829 1.169060 0.146585 1.030388 1.165984 1.369563 0.730984 -1.383696 -0.515189 -0.808927 -1.174651 -1.631502 -1.123414 -0.478155 -1.583067 1.419074 1.668777 1.567517 0.222103 -0.336040 -1.352064 0.251032 -0.401695 0.268413 -0.012299 -0.918953 2.921208 -0.581588 0.672848 1.251136 1.382263 1.429897 1.290990 -1.272673 -0.308611 -0.422988 -0.675642 0.874441 1.305736 -0.262585 -1.099395 -0.667101 -0.646737 -0.556338 -0.196591 0.119306 -0.266455 -0.524267 2.650951 0.097318 -0.974697 0.189964 1.141155 -0.064434 1.104971 -1.508908 -0.031833 0.803919 -0.659221 0.939145 0.214041 -0.531805 0.956060 0.249328 0.637903 -0.510158 1.850287 -0.348407 2.001376 -0.389643 -0.024786 -0.470973 0.869339 0.170667 0.598062 1.217262 1.274013 1 -0.389981 -0.752441 -0.734871 3.517318 -1.173559 -0.004956 0.145419 2.151368 -3.086037 -1.569139 1.449784 -0.868951 -1.687716 -0.994401 1.153266 1.803045 -0.819059 0.847970 0.227102 -0.500762 0.868210 1.823540 1.161007 -0.307606 -0.713416 0.363560 -0.822162 2.427681 -0.129537 -0.078716 1.345644 -1.286094 0.237242 -0.136056 0.596664 -1.412381 1.206341 0.299860 0.705238 0.142412 -1.059382 0.833468 1.060015 -0.527045 -1.135732 -1.140983 -0.779540 -0.640875 -1.217196 -1.675663 0.241263 -0.273322 -1.697936 -0.594943 0.101154 1.391735 -0.426953 1.008344 -0.818577 1.924570 -0.578900 -0.457395 -1.096705 0.418522 -0.155623 0.169706 -2.533706 0.018904 1.434160 0.744095 0.647626 -0.770309 2.329141 -0.141547 -1.761594 0.702091 -1.531450 -0.788427 -0.184622 -1.942321 1.530113 0.503406 1.105845 -0.935120 -1.115483 -2.249762 1.307135 0.788412 -0.441091 0.073561 0.812101 -0.916146 1.573714 -0.309508 0.499987 0.187594 0.558913 0.903246 0.317901 -0.809797 2 1.128248 1.516826 -0.186735 -0.668157 1.132259 -0.246648 -0.855167 0.732283 0.931802 1.318684 -1.198418 -1.149318 0.586321 -1.171937 -0.607731 2.753747 1.479287 -1.136365 -0.020485 0.320444 -1.955755 0.660402 -1.545371 0.200519 -0.017263 1.634686 0.599246 0.462989 0.023721 0.225546 0.170972 -0.027496 -0.061233 -0.566411 -0.669567 0.601618 0.503656 -0.678253 -2.907108 -1.717123 0.397631 1.300108 0.215821 -0.593075 -0.225944 -0.946057 1.000308 0.393160 1.342074 -0.370687 -0.166413 -0.419814 -0.255931 1.789478 0.282378 0.742260 -0.050498 1.415309 0.838166 -1.400292 -0.937976 -1.499148 0.801859 0.224824 0.283572 0.643703 -1.198465 0.527206 0.215202 0.437048 1.312868 0.741243 0.077988 0.006123 0.190370 0.018007 -1.026036 -2.378430 -1.069949 0.843822 1.289216 -1.423369 -0.462887 0.197330 -0.935076 0.441271 0.414643 -0.377887 -0.530515 0.621592 1.009572 0.569718 0.175291 -0.656279 -0.112273 -0.392137 -1.043558 -0.467318 -0.384329 -2.009207 3 0.658598 0.101830 -0.682781 0.229349 -0.305657 0.404877 0.252244 -0.837784 -0.039624 0.329457 0.751694 1.469070 -0.157199 1.032628 -0.584639 -0.925544 0.342474 -0.969363 0.133480 -0.385974 -0.600278 0.281939 0.868579 1.129803 -0.041898 0.961193 0.131521 -0.792889 -1.285737 0.073934 -1.333315 -1.044125 1.277338 1.492257 0.411379 1.771805 -1.111128 1.123233 -1.019449 1.738357 -0.690764 -0.120710 -0.421359 -0.727294 -0.857759 -0.069436 -0.328334 -0.558180 1.063474 -0.519133 -0.496902 1.089589 -1.615801 0.080174 -0.229938 -0.498420 -0.624615 0.059481 -0.093158 -1.784549 -0.503789 -0.140528 0.002653 -0.484930 0.055914 -0.680948 -0.994271 1.277052 0.037651 2.155421 -0.437589 0.696404 0.417752 -0.544785 1.190690 0.978262 0.752102 0.504472 0.139853 -0.505089 -0.264975 -1.603194 0.731847 0.010903 -1.165346 -0.125195 -1.032685 -0.465520 1.514808 0.304762 0.793414 0.314635 -1.638279 0.111737 -0.777037 0.251783 1.126303 -0.808798 0.422064 -0.349264 B 0 0 -0.356362 -0.089227 0.609373 0.542382 -0.768681 -0.048074 2.015458 -1.552351 0.251552 1.459635 0.949707 0.339465 -0.001372 1.798589 1.559163 0.231783 0.423141 -0.310530 0.353795 2.173336 -0.196247 -0.375636 -0.858221 0.258410 0.656430 0.960819 1.137893 1.553405 0.038981 -0.632038 -0.132009 -1.834997 -0.242576 -0.297879 -0.441559 -0.769691 0.224077 -0.153009 0.519526 -0.680188 0.535851 0.671496 -0.183064 0.301234 1.288256 -2.478240 -0.360403 0.424067 -0.834659 -0.128464 -0.489013 -0.014888 -1.461230 -1.435223 -1.319802 1.083675 0.979140 -0.375291 1.110189 -1.011351 0.587886 -0.822775 -1.183865 1.455173 1.134328 0.239403 -0.837991 -1.130932 0.783168 1.845520 1.437072 -1.198443 1.379098 2.129113 0.260096 -0.011975 0.043302 0.722941 1.028152 -0.235806 1.145245 -1.359598 0.232189 0.503712 -0.614264 -0.530606 -2.435803 -0.255238 -0.064423 0.784643 0.256346 0.128023 1.414103 -1.118659 0.877353 0.500561 0.463651 -2.034512 -0.981683 -0.691944 1 -1.113376 -1.169402 0.680539 -1.534212 1.653817 -1.295181 -0.566826 0.477014 1.413371 0.517105 1.401153 -0.872685 0.830957 0.181507 -0.145616 0.694592 -0.751208 0.324444 0.681973 -0.054972 0.917776 -1.024810 -0.206446 -0.600113 0.852805 1.455109 -0.079769 0.076076 0.207699 -1.850458 -0.124124 -0.610871 -0.883362 0.219049 -0.685094 -0.645330 -0.242805 -0.775602 0.233070 2.422642 -1.423040 -0.582421 0.968304 -0.701025 -0.167850 0.277264 1.301231 0.301205 -3.081249 -0.562868 0.192944 -0.664592 0.565686 0.190913 -0.841858 -1.856545 -1.022777 1.295968 0.451921 0.659955 0.065818 -0.319586 0.253495 -1.144646 -0.483404 0.555902 0.807069 0.714196 0.661196 0.053667 0.346833 -1.288977 -0.386734 -1.262127 0.477495 -0.494034 -0.911414 1.152963 -0.342365 -0.160187 0.470054 -0.853063 -1.387949 -0.257257 -1.030690 -0.110210 0.328911 -0.555923 0.987713 -0.501957 2.069887 -0.067503 0.316029 -1.506232 2.201621 0.492097 -0.085193 -0.977822 1.039147 -0.653932 2 -0.405638 -1.402027 -1.166242 1.306184 0.856283 -1.236170 -0.646721 -1.474064 0.082960 0.090310 -0.169977 0.406345 0.915427 -0.974503 0.271637 1.539184 -0.098866 -0.525149 1.063933 0.085827 -0.129622 0.947959 -0.072496 -0.237592 0.012549 1.065761 0.996596 -0.172481 2.583139 -0.028578 -0.254856 1.328794 -1.592951 2.434350 -0.341500 -0.307719 -1.333273 -1.100845 0.209097 1.734777 0.639632 0.424779 -0.129327 0.905029 -0.482909 1.731628 -2.783425 -0.333677 -0.110895 1.212636 -0.208412 0.427117 1.348563 0.043859 1.772519 -1.416106 0.401155 0.807157 0.303427 -1.246288 0.178774 -0.066126 -1.862288 1.241295 0.377021 -0.822320 -0.749014 1.463652 1.602268 -1.043877 1.185290 -0.565783 -1.076879 1.360241 -0.121991 0.991043 1.007952 0.450185 -0.744376 1.388876 -0.316847 -0.841655 -1.056842 -0.500226 0.096959 1.176896 -2.939652 1.792213 0.316340 0.303218 1.024967 -0.590871 -0.453326 -0.795981 -0.393301 -0.374372 -1.270199 1.618372 1.197727 -0.914863 3 -0.625210 0.288911 0.288374 -1.372667 -0.591395 -0.478942 1.335664 -0.459855 -1.615975 -1.189676 0.374767 -2.488733 0.586656 -1.422008 0.496030 1.911128 -0.560660 -0.499614 -0.372171 -1.833069 0.237124 -0.944446 0.912140 0.359790 -1.359235 0.166966 -0.047107 -0.279789 -0.594454 -0.739013 -1.527645 0.401668 1.791252 -2.774848 0.523873 2.207585 0.488999 -0.339283 0.131711 0.018409 1.186551 -0.424318 1.554994 -0.205917 -0.934975 0.654102 -1.227761 -0.461025 -0.421201 -0.058615 -0.584563 0.336913 -0.477102 -1.381463 0.757745 -0.268968 0.034870 1.231686 0.236600 1.234720 -0.040247 0.029582 1.034905 0.380204 -0.012108 -0.859511 -0.990340 -1.205172 -1.030178 0.426676 0.497796 -0.876808 0.957963 0.173016 0.131612 -1.003556 -1.069908 -1.799207 1.429598 -0.116015 -1.454980 0.261917 0.444412 0.273290 0.844115 0.218745 -1.033350 -1.188295 0.058373 0.800523 -1.627068 0.861651 0.871018 -0.003733 -0.243354 0.947296 0.509406 0.044546 0.266896 1.337165 1 0 0.699142 -1.928033 0.105363 1.042322 0.715206 -0.763783 0.098798 -1.157898 0.134105 0.042041 0.674826 0.165649 -1.622970 -3.131274 0.597649 -1.880331 0.663980 -0.256033 -1.524058 0.492799 0.221163 0.429622 -0.659584 1.264506 -0.032131 -2.114907 -0.264043 0.457835 -0.676837 -0.629003 0.489145 -0.551686 0.942622 -0.512043 -0.455893 0.021244 -0.178035 -2.498073 -0.171292 0.323510 -0.545163 -0.668909 -0.150031 0.521620 -0.428980 0.676463 0.369081 -0.724832 0.793542 1.237422 0.401275 2.141523 0.249012 0.486755 -0.163274 0.592222 -0.292600 -0.547168 0.619104 -0.013605 0.776734 0.131424 1.189480 -0.666317 -0.939036 1.105515 0.621452 1.586605 -0.760970 1.649646 0.283199 1.275812 -0.452012 0.301361 -0.976951 -0.268106 -0.079255 -1.258332 2.216658 -1.175988 -0.863497 -1.653022 -0.561514 0.450753 0.417200 0.094676 -2.231054 1.316862 -0.477441 0.646654 -0.200252 1.074354 -0.058176 0.120990 0.222522 -0.179507 0.421655 -0.914341 -0.234178 0.741524 1 0.932714 1.423761 -1.280835 0.347882 -0.863171 -0.852580 1.044933 2.094536 0.806206 0.416201 -1.109503 0.145302 -0.996871 0.325456 -0.605081 1.175326 1.645054 0.293432 -2.766822 1.032849 0.079115 -1.414132 1.463376 2.335486 0.411951 -0.048543 0.159284 -0.651554 -1.093128 1.568390 -0.077807 -2.390779 -0.842346 -0.229675 -0.999072 -1.367219 -0.792042 -1.878575 1.451452 1.266250 -0.734315 0.266152 0.735523 -0.430860 0.229864 0.850083 -2.241241 1.063850 0.289409 -0.354360 0.113063 -0.173006 1.386998 1.886236 0.587119 -0.961133 0.399295 1.461560 0.310823 0.280220 -0.879103 -1.326348 0.003337 -1.085908 -0.436723 2.111926 0.106068 0.615597 2.152996 -0.196155 0.025747 -0.039061 0.656823 -0.347105 2.513979 1.758070 1.288473 -0.739185 -0.691592 -0.098728 -0.276386 0.489981 0.516278 -0.838258 0.596673 -0.331053 0.521174 -0.145023 0.836693 -1.092166 0.361733 -1.169981 0.046731 0.655377 -0.756852 1.285805 -0.095019 0.360253 1.370621 0.083010 2 0.888893 2.288725 -1.032332 0.212273 -1.091826 1.692498 1.025367 0.550854 0.679430 -1.335712 -0.798341 2.265351 -1.006938 2.059761 0.420266 -1.189657 0.506674 0.260847 -0.533145 0.727267 1.412276 1.482106 -0.996258 0.588641 -0.412642 -0.920733 -0.874691 0.839002 0.501668 -0.342493 -0.533806 -2.146352 -0.597339 0.115726 0.850683 -0.752239 0.377263 -0.561982 0.262783 -0.356676 -0.367462 0.753611 -1.267414 -1.330698 -0.536453 0.840938 -0.763108 -0.268100 -0.677424 1.606831 0.151732 -2.085701 1.219296 0.400863 0.591165 -1.485213 1.501979 1.196569 -0.214154 0.339554 -0.034446 1.176452 0.546340 -1.255630 -1.309210 -0.445437 0.189437 -0.737463 0.843767 -0.605632 -0.060777 0.409310 1.285569 -0.622638 1.018193 0.880680 0.046805 -1.818058 -0.809829 0.875224 0.409569 -0.116621 -1.238919 3.305724 -0.024121 -1.756500 1.328958 0.507593 -0.866554 -2.240848 -0.661376 -0.671824 0.215720 -0.296326 0.481402 0.829645 -0.721025 1.263914 0.549047 -1.234945 3 -1.978838 0.721823 -0.559067 -1.235243 0.420716 -0.598845 0.359576 -0.619366 -1.757772 -1.156251 0.705212 0.875071 -1.020376 0.394760 -0.147970 0.230249 1.355203 1.794488 2.678058 -0.153565 -0.460959 -0.098108 -1.407930 -2.487702 1.823014 0.099873 -0.517603 -0.509311 -1.833175 -0.900906 0.459493 -0.655440 1.466122 -1.531389 -0.422106 0.421422 0.578615 0.259795 0.018941 -0.168726 1.611107 -1.586550 -1.384941 0.858377 1.033242 1.701343 1.748344 -0.371182 -0.843575 2.089641 -0.345430 -1.740556 0.141915 -2.197138 0.689569 -0.150025 0.287456 0.654016 -1.521919 -0.918008 -0.587528 0.230636 0.262637 0.615674 0.600044 -0.494699 -0.743089 0.220026 -0.242207 0.528216 -0.328174 -1.536517 -1.476640 -1.162114 -1.260222 1.106252 -1.467408 -0.349341 -1.841217 0.031296 -0.076475 -0.353383 0.807545 0.779064 -2.398417 -0.267828 1.549734 0.814397 0.284770 -0.659369 0.761040 -0.722067 0.810332 1.501295 1.440865 -1.367459 -0.700301 -1.540662 0.159837 -0.625415 HTML Escaping # Suppose you have to display HTML within HTML, that can be a bit of pain when the renderer can’t distinguish. You can use the escape formatting option to handle this, and even use it within a formatter that contains HTML itself. [67]: df4 = pd . DataFrame ([[ '<div></div>' , '""&other""' , '<span></span>' ]]) df4 . style [67]: 0 1 2 0 ""&other"" [68]: df4 . style . format ( escape = ""html"" ) [68]: 0 1 2 0 <div></div> ""&other"" <span></span> [69]: df4 . style . format ( '<a href=""https://pandas.pydata.org"" target=""_blank""> {} </a>' , escape = ""html"" ) [69]: 0 1 2 0 <div></div> ""&other"" <span></span> Export to Excel # Some support ( since version 0.20.0 ) is available for exporting styled DataFrames to Excel worksheets using the OpenPyXL or XlsxWriter engines. CSS2.2 properties handled include: background-color border-style properties border-width properties border-color properties color font-family font-style font-weight text-align text-decoration vertical-align white-space: nowrap Shorthand and side-specific border properties are supported (e.g. border-style and border-left-style ) as well as the border shorthands for all sides ( border: 1px solid green ) or specified sides ( border-left: 1px solid green ). Using a border shorthand will override any border properties set before it (See CSS Working Group for more details) Only CSS2 named colors and hex colors of the form #rgb or #rrggbb are currently supported. The following pseudo CSS properties are also available to set Excel specific style properties: number-format border-style (for Excel-specific styles: “hair”, “mediumDashDot”, “dashDotDot”, “mediumDashDotDot”, “dashDot”, “slantDashDot”, or “mediumDashed”) Table level styles, and data cell CSS-classes are not included in the export to Excel: individual cells must have their properties mapped by the Styler.apply and/or Styler.map methods. [70]: df2 . style . \ map ( style_negative , props = 'color:red;' ) . \ highlight_max ( axis = 0 ) . \ to_excel ( 'styled.xlsx' , engine = 'openpyxl' ) A screenshot of the output: Export to LaTeX # There is support ( since version 1.3.0 ) to export Styler to LaTeX. The documentation for the .to_latex method gives further detail and numerous examples. More About CSS and HTML # Cascading Style Sheet (CSS) language, which is designed to influence how a browser renders HTML elements, has its own peculiarities. It never reports errors: it just silently ignores them and doesn’t render your objects how you intend so can sometimes be frustrating. Here is a very brief primer on how Styler creates HTML and interacts with CSS, with advice on common pitfalls to avoid. CSS Classes and Ids # The precise structure of the CSS class attached to each cell is as follows. Cells with Index and Column names include index_name and level<k> where k is its level in a MultiIndex Index label cells include row_heading level<k> where k is the level in a MultiIndex row<m> where m is the numeric position of the row Column label cells include col_heading level<k> where k is the level in a MultiIndex col<n> where n is the numeric position of the column Data cells include data row<m> , where m is the numeric position of the cell. col<n> , where n is the numeric position of the cell. Blank cells include blank Trimmed cells include col_trim or row_trim The structure of the id is T_uuid_level<k>_row<m>_col<n> where level<k> is used only on headings, and headings will only have either row<m> or col<n> whichever is needed. By default we’ve also prepended each row/column identifier with a UUID unique to each DataFrame so that the style from one doesn’t collide with the styling from another within the same notebook or page. You can read more about the use of UUIDs in Optimization . We can see example of the HTML by calling the .to_html() method. [71]: print ( pd . DataFrame ([[ 1 , 2 ],[ 3 , 4 ]], index = [ 'i1' , 'i2' ], columns = [ 'c1' , 'c2' ]) . style . to_html ()) <style type=""text/css""> </style> <table id=""T_a1de3"">   <thead>     <tr>       <th class=""blank level0"" >&nbsp;</th>       <th id=""T_a1de3_level0_col0"" class=""col_heading level0 col0"" >c1</th>       <th id=""T_a1de3_level0_col1"" class=""col_heading level0 col1"" >c2</th>     </tr>   </thead>   <tbody>     <tr>       <th id=""T_a1de3_level0_row0"" class=""row_heading level0 row0"" >i1</th>       <td id=""T_a1de3_row0_col0"" class=""data row0 col0"" >1</td>       <td id=""T_a1de3_row0_col1"" class=""data row0 col1"" >2</td>     </tr>     <tr>       <th id=""T_a1de3_level0_row1"" class=""row_heading level0 row1"" >i2</th>       <td id=""T_a1de3_row1_col0"" class=""data row1 col0"" >3</td>       <td id=""T_a1de3_row1_col1"" class=""data row1 col1"" >4</td>     </tr>   </tbody> </table> CSS Hierarchies # The examples have shown that when CSS styles overlap, the one that comes last in the HTML render, takes precedence. So the following yield different results: [72]: df4 = pd . DataFrame ([[ 'text' ]]) df4 . style . map ( lambda x : 'color:green;' ) \ . map ( lambda x : 'color:red;' ) [72]: 0 0 text [73]: df4 . style . map ( lambda x : 'color:red;' ) \ . map ( lambda x : 'color:green;' ) [73]: 0 0 text This is only true for CSS rules that are equivalent in hierarchy, or importance. You can read more about CSS specificity here but for our purposes it suffices to summarize the key points: A CSS importance score for each HTML element is derived by starting at zero and adding: 1000 for an inline style attribute 100 for each ID 10 for each attribute, class or pseudo-class 1 for each element name or pseudo-element Let’s use this to describe the action of the following configurations [74]: df4 . style . set_uuid ( 'a_' ) \ . set_table_styles ([{ 'selector' : 'td' , 'props' : 'color:red;' }]) \ . map ( lambda x : 'color:green;' ) [74]: 0 0 text This text is red because the generated selector #T_a_ td is worth 101 (ID plus element), whereas #T_a_row0_col0 is only worth 100 (ID), so is considered inferior even though in the HTML it comes after the previous. [75]: df4 . style . set_uuid ( 'b_' ) \ . set_table_styles ([{ 'selector' : 'td' , 'props' : 'color:red;' }, { 'selector' : '.cls-1' , 'props' : 'color:blue;' }]) \ . map ( lambda x : 'color:green;' ) \ . set_td_classes ( pd . DataFrame ([[ 'cls-1' ]])) [75]: 0 0 text In the above case the text is blue because the selector #T_b_ .cls-1 is worth 110 (ID plus class), which takes precedence. [76]: df4 . style . set_uuid ( 'c_' ) \ . set_table_styles ([{ 'selector' : 'td' , 'props' : 'color:red;' }, { 'selector' : '.cls-1' , 'props' : 'color:blue;' }, { 'selector' : 'td.data' , 'props' : 'color:yellow;' }]) \ . map ( lambda x : 'color:green;' ) \ . set_td_classes ( pd . DataFrame ([[ 'cls-1' ]])) [76]: 0 0 text Now we have created another table style this time the selector T_c_ td.data (ID plus element plus class) gets bumped up to 111. If your style fails to be applied, and its really frustrating, try the !important trump card. [77]: df4 . style . set_uuid ( 'd_' ) \ . set_table_styles ([{ 'selector' : 'td' , 'props' : 'color:red;' }, { 'selector' : '.cls-1' , 'props' : 'color:blue;' }, { 'selector' : 'td.data' , 'props' : 'color:yellow;' }]) \ . map ( lambda x : 'color:green !important;' ) \ . set_td_classes ( pd . DataFrame ([[ 'cls-1' ]])) [77]: 0 0 text Finally got that green text after all! Extensibility # The core of pandas is, and will remain, its “high-performance, easy-to-use data structures”. With that in mind, we hope that DataFrame.style accomplishes two goals Provide an API that is pleasing to use interactively and is “good enough” for many tasks Provide the foundations for dedicated libraries to build on If you build a great library on top of this, let us know and we’ll link to it. Subclassing # If the default template doesn’t quite suit your needs, you can subclass Styler and extend or override the template. We’ll show an example of extending the default template to insert a custom header before each table. [78]: from jinja2 import Environment , ChoiceLoader , FileSystemLoader from IPython.display import HTML from pandas.io.formats.style import Styler We’ll use the following template: [79]: with open ( ""templates/myhtml.tpl"" ) as f : print ( f . read ()) {% extends ""html_table.tpl"" %} {% block table %} <h1>{{ table_title|default(""My Table"") }}</h1> {{ super() }} {% endblock table %} Now that we’ve created a template, we need to set up a subclass of Styler that knows about it. [80]: class MyStyler ( Styler ): env = Environment ( loader = ChoiceLoader ([ FileSystemLoader ( ""templates"" ), # contains ours Styler . loader , # the default ]) ) template_html_table = env . get_template ( ""myhtml.tpl"" ) Notice that we include the original loader in our environment’s loader. That’s because we extend the original template, so the Jinja environment needs to be able to find it. Now we can use that custom styler. It’s __init__ takes a DataFrame. [81]: MyStyler ( df3 ) [81]: My Table c1 c2 c3 c4 A r1 -1.048553 -1.420018 -1.706270 1.950775 r2 -0.509652 -0.438074 -1.252795 0.777490 B r1 -1.613898 -0.212740 -0.895467 0.386902 r2 -0.510805 -1.180632 -0.028182 0.428332 Our custom template accepts a table_title keyword. We can provide the value in the .to_html method. [82]: HTML ( MyStyler ( df3 ) . to_html ( table_title = ""Extending Example"" )) [82]: Extending Example c1 c2 c3 c4 A r1 -1.048553 -1.420018 -1.706270 1.950775 r2 -0.509652 -0.438074 -1.252795 0.777490 B r1 -1.613898 -0.212740 -0.895467 0.386902 r2 -0.510805 -1.180632 -0.028182 0.428332 For convenience, we provide the Styler.from_custom_template method that does the same as the custom subclass. [83]: EasyStyler = Styler . from_custom_template ( ""templates"" , ""myhtml.tpl"" ) HTML ( EasyStyler ( df3 ) . to_html ( table_title = ""Another Title"" )) [83]: Another Title c1 c2 c3 c4 A r1 -1.048553 -1.420018 -1.706270 1.950775 r2 -0.509652 -0.438074 -1.252795 0.777490 B r1 -1.613898 -0.212740 -0.895467 0.386902 r2 -0.510805 -1.180632 -0.028182 0.428332 Template Structure # Here’s the template structure for the both the style generation template and the table generation template: Style template: [85]: HTML ( style_structure ) [85]: before_style style <style type=""text/css""> table_styles before_cellstyle cellstyle </style> Table template: [87]: HTML ( table_structure ) [87]: before_table table <table ...> caption thead before_head_rows head_tr (loop over headers) after_head_rows tbody before_rows tr (loop over data rows) after_rows </table> after_table See the template in the GitHub repo for more details."
https://pandas.pydata.org/docs/user_guide/groupby.html,Group by: split-apply-combine,"<article class=""bd-article"" role=""main"">
<section id=""group-by-split-apply-combine"">
<span id=""groupby""></span><h1>Group by: split-apply-combine<a class=""headerlink"" href=""#group-by-split-apply-combine"" title=""Link to this heading"">#</a></h1>
<p>By “group by” we are referring to a process involving one or more of the following
steps:</p>
<ul class=""simple"">
<li><p><strong>Splitting</strong> the data into groups based on some criteria.</p></li>
<li><p><strong>Applying</strong> a function to each group independently.</p></li>
<li><p><strong>Combining</strong> the results into a data structure.</p></li>
</ul>
<p>Out of these, the split step is the most straightforward. In the apply step, we
might wish to do one of the following:</p>
<ul>
<li><p><strong>Aggregation</strong>: compute a summary statistic (or statistics) for each
group. Some examples:</p>
<blockquote>
<div><ul class=""simple"">
<li><p>Compute group sums or means.</p></li>
<li><p>Compute group sizes / counts.</p></li>
</ul>
</div></blockquote>
</li>
<li><p><strong>Transformation</strong>: perform some group-specific computations and return a
like-indexed object. Some examples:</p>
<blockquote>
<div><ul class=""simple"">
<li><p>Standardize data (zscore) within a group.</p></li>
<li><p>Filling NAs within groups with a value derived from each group.</p></li>
</ul>
</div></blockquote>
</li>
<li><p><strong>Filtration</strong>: discard some groups, according to a group-wise computation
that evaluates to True or False. Some examples:</p>
<blockquote>
<div><ul class=""simple"">
<li><p>Discard data that belong to groups with only a few members.</p></li>
<li><p>Filter out data based on the group sum or mean.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<p>Many of these operations are defined on GroupBy objects. These operations are similar
to those of the <a class=""reference internal"" href=""basics.html#basics-aggregate""><span class=""std std-ref"">aggregating API</span></a>,
<a class=""reference internal"" href=""window.html#window-overview""><span class=""std std-ref"">window API</span></a>, and <a class=""reference internal"" href=""timeseries.html#timeseries-aggregate""><span class=""std std-ref"">resample API</span></a>.</p>
<p>It is possible that a given operation does not fall into one of these categories or
is some combination of them. In such a case, it may be possible to compute the
operation using GroupBy’s <code class=""docutils literal notranslate""><span class=""pre"">apply</span></code> method. This method will examine the results of the
apply step and try to sensibly combine them into a single result if it doesn’t fit into either
of the above three categories.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>An operation that is split into multiple steps using built-in GroupBy operations
will be more efficient than using the <code class=""docutils literal notranslate""><span class=""pre"">apply</span></code> method with a user-defined Python
function.</p>
</div>
<p>The name GroupBy should be quite familiar to those who have used
a SQL-based tool (or <code class=""docutils literal notranslate""><span class=""pre"">itertools</span></code>), in which you can write code like:</p>
<div class=""highlight-sql notranslate""><div class=""highlight""><pre><span></span><span class=""k"">SELECT</span><span class=""w""> </span><span class=""n"">Column1</span><span class=""p"">,</span><span class=""w""> </span><span class=""n"">Column2</span><span class=""p"">,</span><span class=""w""> </span><span class=""n"">mean</span><span class=""p"">(</span><span class=""n"">Column3</span><span class=""p"">),</span><span class=""w""> </span><span class=""k"">sum</span><span class=""p"">(</span><span class=""n"">Column4</span><span class=""p"">)</span>
<span class=""k"">FROM</span><span class=""w""> </span><span class=""n"">SomeTable</span>
<span class=""k"">GROUP</span><span class=""w""> </span><span class=""k"">BY</span><span class=""w""> </span><span class=""n"">Column1</span><span class=""p"">,</span><span class=""w""> </span><span class=""n"">Column2</span>
</pre></div>
</div>
<p>We aim to make operations like this natural and easy to express using
pandas. We’ll address each area of GroupBy functionality, then provide some
non-trivial examples / use cases.</p>
<p>See the <a class=""reference internal"" href=""cookbook.html#cookbook-grouping""><span class=""std std-ref"">cookbook</span></a> for some advanced strategies.</p>
<section id=""splitting-an-object-into-groups"">
<span id=""groupby-split""></span><h2>Splitting an object into groups<a class=""headerlink"" href=""#splitting-an-object-into-groups"" title=""Link to this heading"">#</a></h2>
<p>The abstract definition of grouping is to provide a mapping of labels to
group names. To create a GroupBy object (more on what the GroupBy object is
later), you may do the following:</p>

<p>The mapping can be specified many different ways:</p>
<ul class=""simple"">
<li><p>A Python function, to be called on each of the index labels.</p></li>
<li><p>A list or NumPy array of the same length as the index.</p></li>
<li><p>A dict or <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>, providing a <code class=""docutils literal notranslate""><span class=""pre"">label</span> <span class=""pre"">-&gt;</span> <span class=""pre"">group</span> <span class=""pre"">name</span></code> mapping.</p></li>
<li><p>For <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> objects, a string indicating either a column name or
an index level name to be used to group.</p></li>
<li><p>A list of any of the above things.</p></li>
</ul>
<p>Collectively we refer to the grouping objects as the <strong>keys</strong>. For example,
consider the following <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>:</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>A string passed to <code class=""docutils literal notranslate""><span class=""pre"">groupby</span></code> may refer to either a column or an index level.
If a string matches both a column name and an index level name, a
<code class=""docutils literal notranslate""><span class=""pre"">ValueError</span></code> will be raised.</p>
</div>

<p>On a DataFrame, we obtain a GroupBy object by calling <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.groupby.html#pandas.DataFrame.groupby"" title=""pandas.DataFrame.groupby""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">groupby()</span></code></a>.
This method returns a <code class=""docutils literal notranslate""><span class=""pre"">pandas.api.typing.DataFrameGroupBy</span></code> instance.
We could naturally group by either the <code class=""docutils literal notranslate""><span class=""pre"">A</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">B</span></code> columns, or both:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">df.groupby('A')</span></code> is just syntactic sugar for <code class=""docutils literal notranslate""><span class=""pre"">df.groupby(df['A'])</span></code>.</p>
</div>
<p>If we also have a MultiIndex on columns <code class=""docutils literal notranslate""><span class=""pre"">A</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">B</span></code>, we can group by all
the columns except the one we specify:</p>

<p>The above GroupBy will split the DataFrame on its index (rows). To split by columns, first do
a transpose:</p>

<p>pandas <a class=""reference internal"" href=""../reference/api/pandas.Index.html#pandas.Index"" title=""pandas.Index""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Index</span></code></a> objects support duplicate values. If a
non-unique index is used as the group key in a groupby operation, all values
for the same index value will be considered to be in one group and thus the
output of aggregation functions will only contain unique index values:</p>

<p>Note that <strong>no splitting occurs</strong> until it’s needed. Creating the GroupBy object
only verifies that you’ve passed a valid mapping.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Many kinds of complicated data manipulations can be expressed in terms of
GroupBy operations (though it can’t be guaranteed to be the most efficient implementation).
You can get quite creative with the label mapping functions.</p>
</div>
<section id=""groupby-sorting"">
<span id=""id1""></span><h3>GroupBy sorting<a class=""headerlink"" href=""#groupby-sorting"" title=""Link to this heading"">#</a></h3>
<p>By default the group keys are sorted during the <code class=""docutils literal notranslate""><span class=""pre"">groupby</span></code> operation. You may however pass <code class=""docutils literal notranslate""><span class=""pre"">sort=False</span></code> for potential speedups. With <code class=""docutils literal notranslate""><span class=""pre"">sort=False</span></code> the order among group-keys follows the order of appearance of the keys in the original dataframe:</p>

<p>Note that <code class=""docutils literal notranslate""><span class=""pre"">groupby</span></code> will preserve the order in which <em>observations</em> are sorted <em>within</em> each group.
For example, the groups created by <code class=""docutils literal notranslate""><span class=""pre"">groupby()</span></code> below are in the order they appeared in the original <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>:</p>

<section id=""groupby-dropna"">
<span id=""id2""></span><h4>GroupBy dropna<a class=""headerlink"" href=""#groupby-dropna"" title=""Link to this heading"">#</a></h4>
<p>By default <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> values are excluded from group keys during the <code class=""docutils literal notranslate""><span class=""pre"">groupby</span></code> operation. However,
in case you want to include <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> values in group keys, you could pass <code class=""docutils literal notranslate""><span class=""pre"">dropna=False</span></code> to achieve it.</p>


<p>The default setting of <code class=""docutils literal notranslate""><span class=""pre"">dropna</span></code> argument is <code class=""docutils literal notranslate""><span class=""pre"">True</span></code> which means <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> are not included in group keys.</p>
</section>
</section>
<section id=""groupby-object-attributes"">
<span id=""groupby-attributes""></span><h3>GroupBy object attributes<a class=""headerlink"" href=""#groupby-object-attributes"" title=""Link to this heading"">#</a></h3>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">groups</span></code> attribute is a dictionary whose keys are the computed unique groups
and corresponding values are the axis labels belonging to each group. In the
above example we have:</p>

<p>Calling the standard Python <code class=""docutils literal notranslate""><span class=""pre"">len</span></code> function on the GroupBy object returns
the number of groups, which is the same as the length of the <code class=""docutils literal notranslate""><span class=""pre"">groups</span></code> dictionary:</p>

<p id=""groupby-tabcompletion""><code class=""docutils literal notranslate""><span class=""pre"">GroupBy</span></code> will tab complete column names, GroupBy operations, and other attributes:</p>


</section>
<section id=""groupby-with-multiindex"">
<span id=""groupby-multiindex""></span><h3>GroupBy with MultiIndex<a class=""headerlink"" href=""#groupby-with-multiindex"" title=""Link to this heading"">#</a></h3>
<p>With <a class=""reference internal"" href=""advanced.html#advanced-hierarchical""><span class=""std std-ref"">hierarchically-indexed data</span></a>, it’s quite
natural to group by one of the levels of the hierarchy.</p>
<p>Let’s create a Series with a two-level <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code>.</p>

<p>We can then group by one of the levels in <code class=""docutils literal notranslate""><span class=""pre"">s</span></code>.</p>

<p>If the MultiIndex has names specified, these can be passed instead of the level
number:</p>

<p>Grouping with multiple levels is supported.</p>

<p>Index level names may be supplied as keys.</p>

<p>More on the <code class=""docutils literal notranslate""><span class=""pre"">sum</span></code> function and aggregation later.</p>
</section>
<section id=""grouping-dataframe-with-index-levels-and-columns"">
<h3>Grouping DataFrame with Index levels and columns<a class=""headerlink"" href=""#grouping-dataframe-with-index-levels-and-columns"" title=""Link to this heading"">#</a></h3>
<p>A DataFrame may be grouped by a combination of columns and index levels. You
can specify both column and index names, or use a <a class=""reference internal"" href=""../reference/api/pandas.Grouper.html#pandas.Grouper"" title=""pandas.Grouper""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Grouper</span></code></a>.</p>
<p>Let’s first create a DataFrame with a MultiIndex:</p>

<p>Then we group <code class=""docutils literal notranslate""><span class=""pre"">df</span></code> by the <code class=""docutils literal notranslate""><span class=""pre"">second</span></code> index level and the <code class=""docutils literal notranslate""><span class=""pre"">A</span></code> column.</p>

<p>Index levels may also be specified by name.</p>

<p>Index level names may be specified as keys directly to <code class=""docutils literal notranslate""><span class=""pre"">groupby</span></code>.</p>

</section>
<section id=""dataframe-column-selection-in-groupby"">
<h3>DataFrame column selection in GroupBy<a class=""headerlink"" href=""#dataframe-column-selection-in-groupby"" title=""Link to this heading"">#</a></h3>
<p>Once you have created the GroupBy object from a DataFrame, you might want to do
something different for each of the columns. Thus, by using <code class=""docutils literal notranslate""><span class=""pre"">[]</span></code> on the GroupBy
object in a similar way as the one used to get a column from a DataFrame, you can do:</p>

<p>This is mainly syntactic sugar for the alternative, which is much more verbose:</p>

<p>Additionally, this method avoids recomputing the internal grouping information
derived from the passed key.</p>
<p>You can also include the grouping columns if you want to operate on them.</p>

</section>
</section>
<section id=""iterating-through-groups"">
<span id=""groupby-iterating-label""></span><h2>Iterating through groups<a class=""headerlink"" href=""#iterating-through-groups"" title=""Link to this heading"">#</a></h2>
<p>With the GroupBy object in hand, iterating through the grouped data is very
natural and functions similarly to <a class=""reference external"" href=""https://docs.python.org/3/library/itertools.html#itertools.groupby"" title=""(in Python v3.12)""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">itertools.groupby()</span></code></a>:</p>

<p>In the case of grouping by multiple keys, the group name will be a tuple:</p>

<p>See <a class=""reference internal"" href=""timeseries.html#timeseries-iterating-label""><span class=""std std-ref"">Iterating through groups</span></a>.</p>
</section>
<section id=""selecting-a-group"">
<h2>Selecting a group<a class=""headerlink"" href=""#selecting-a-group"" title=""Link to this heading"">#</a></h2>
<p>A single group can be selected using
<a class=""reference internal"" href=""../reference/api/pandas.core.groupby.DataFrameGroupBy.get_group.html#pandas.core.groupby.DataFrameGroupBy.get_group"" title=""pandas.core.groupby.DataFrameGroupBy.get_group""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrameGroupBy.get_group()</span></code></a>:</p>

<p>Or for an object grouped on multiple columns:</p>

</section>
<section id=""aggregation"">
<span id=""groupby-aggregate""></span><h2>Aggregation<a class=""headerlink"" href=""#aggregation"" title=""Link to this heading"">#</a></h2>
<p>An aggregation is a GroupBy operation that reduces the dimension of the grouping
object. The result of an aggregation is, or at least is treated as,
a scalar value for each column in a group. For example, producing the sum of each
column in a group of values.</p>

<p>In the result, the keys of the groups appear in the index by default. They can be
instead included in the columns by passing <code class=""docutils literal notranslate""><span class=""pre"">as_index=False</span></code>.</p>

<section id=""built-in-aggregation-methods"">
<span id=""groupby-aggregate-builtin""></span><h3>Built-in aggregation methods<a class=""headerlink"" href=""#built-in-aggregation-methods"" title=""Link to this heading"">#</a></h3>
<p>Many common aggregations are built-in to GroupBy objects as methods. Of the methods
listed below, those with a <code class=""docutils literal notranslate""><span class=""pre"">*</span></code> do <em>not</em> have an efficient, GroupBy-specific, implementation.</p>

<p>Some examples:</p>

<p>Another aggregation example is to compute the size of each group.
This is included in GroupBy as the <code class=""docutils literal notranslate""><span class=""pre"">size</span></code> method. It returns a Series whose
index consists of the group names and the values are the sizes of each group.</p>

<p>While the <a class=""reference internal"" href=""../reference/api/pandas.core.groupby.DataFrameGroupBy.describe.html#pandas.core.groupby.DataFrameGroupBy.describe"" title=""pandas.core.groupby.DataFrameGroupBy.describe""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrameGroupBy.describe()</span></code></a> method is not itself a reducer, it
can be used to conveniently produce a collection of summary statistics about each of
the groups.</p>

<p>Another aggregation example is to compute the number of unique values of each group.
This is similar to the <a class=""reference internal"" href=""../reference/api/pandas.core.groupby.DataFrameGroupBy.value_counts.html#pandas.core.groupby.DataFrameGroupBy.value_counts"" title=""pandas.core.groupby.DataFrameGroupBy.value_counts""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrameGroupBy.value_counts()</span></code></a> function, except that it only counts the
number of unique values.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Aggregation functions <strong>will not</strong> return the groups that you are aggregating over
as named <em>columns</em> when <code class=""docutils literal notranslate""><span class=""pre"">as_index=True</span></code>, the default. The grouped columns will
be the <strong>indices</strong> of the returned object.</p>
<p>Passing <code class=""docutils literal notranslate""><span class=""pre"">as_index=False</span></code> <strong>will</strong> return the groups that you are aggregating over as
named columns, regardless if they are named <strong>indices</strong> or <em>columns</em> in the inputs.</p>
</div>
</section>
<section id=""the-aggregate-method"">
<span id=""groupby-aggregate-agg""></span><h3>The <a class=""reference internal"" href=""../reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html#pandas.core.groupby.DataFrameGroupBy.aggregate"" title=""pandas.core.groupby.DataFrameGroupBy.aggregate""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">aggregate()</span></code></a> method<a class=""headerlink"" href=""#the-aggregate-method"" title=""Link to this heading"">#</a></h3>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The <a class=""reference internal"" href=""../reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html#pandas.core.groupby.DataFrameGroupBy.aggregate"" title=""pandas.core.groupby.DataFrameGroupBy.aggregate""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">aggregate()</span></code></a> method can accept many different types of
inputs. This section details using string aliases for various GroupBy methods; other
inputs are detailed in the sections below.</p>
</div>
<p>Any reduction method that pandas implements can be passed as a string to
<a class=""reference internal"" href=""../reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html#pandas.core.groupby.DataFrameGroupBy.aggregate"" title=""pandas.core.groupby.DataFrameGroupBy.aggregate""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">aggregate()</span></code></a>. Users are encouraged to use the shorthand,
<code class=""docutils literal notranslate""><span class=""pre"">agg</span></code>. It will operate as if the corresponding method was called.</p>

<p>The result of the aggregation will have the group names as the
new index. In the case of multiple keys, the result is a
<a class=""reference internal"" href=""advanced.html#advanced-hierarchical""><span class=""std std-ref"">MultiIndex</span></a> by default. As mentioned above, this can be
changed by using the <code class=""docutils literal notranslate""><span class=""pre"">as_index</span></code> option:</p>

<p>Note that you could use the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.reset_index.html#pandas.DataFrame.reset_index"" title=""pandas.DataFrame.reset_index""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.reset_index()</span></code></a> DataFrame function to achieve
the same result as the column names are stored in the resulting <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code>, although
this will make an extra copy.</p>

</section>
<section id=""aggregation-with-user-defined-functions"">
<span id=""groupby-aggregate-udf""></span><h3>Aggregation with User-Defined Functions<a class=""headerlink"" href=""#aggregation-with-user-defined-functions"" title=""Link to this heading"">#</a></h3>
<p>Users can also provide their own User-Defined Functions (UDFs) for custom aggregations.</p>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>When aggregating with a UDF, the UDF should not mutate the
provided <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>. See <a class=""reference internal"" href=""gotchas.html#gotchas-udf-mutation""><span class=""std std-ref"">Mutating with User Defined Function (UDF) methods</span></a> for more information.</p>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Aggregating with a UDF is often less performant than using
the pandas built-in methods on GroupBy. Consider breaking up a complex operation
into a chain of operations that utilize the built-in methods.</p>
</div>

<p>The resulting dtype will reflect that of the aggregating function. If the results from different groups have
different dtypes, then a common dtype will be determined in the same way as <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> construction.</p>

</section>
<section id=""applying-multiple-functions-at-once"">
<span id=""groupby-aggregate-multifunc""></span><h3>Applying multiple functions at once<a class=""headerlink"" href=""#applying-multiple-functions-at-once"" title=""Link to this heading"">#</a></h3>
<p>On a grouped <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>, you can pass a list or dict of functions to
<code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">SeriesGroupBy.agg()</span></code>, outputting a DataFrame:</p>

<p>On a grouped <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>, you can pass a list of functions to
<code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrameGroupBy.agg()</span></code> to aggregate each
column, which produces an aggregated result with a hierarchical column index:</p>

<p>The resulting aggregations are named after the functions themselves. If you
need to rename, then you can add in a chained operation for a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> like this:</p>

<p>For a grouped <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>, you can rename in a similar manner:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>In general, the output column names should be unique, but pandas will allow
you apply to the same function (or two functions with the same name) to the same
column.</p>

<p>pandas also allows you to provide multiple lambdas. In this case, pandas
will mangle the name of the (nameless) lambda functions, appending <code class=""docutils literal notranslate""><span class=""pre"">_&lt;i&gt;</span></code>
to each subsequent lambda.</p>

</div>
</section>
<section id=""named-aggregation"">
<span id=""groupby-aggregate-named""></span><h3>Named aggregation<a class=""headerlink"" href=""#named-aggregation"" title=""Link to this heading"">#</a></h3>
<p>To support column-specific aggregation <em>with control over the output column names</em>, pandas
accepts the special syntax in <a class=""reference internal"" href=""../reference/api/pandas.core.groupby.DataFrameGroupBy.agg.html#pandas.core.groupby.DataFrameGroupBy.agg"" title=""pandas.core.groupby.DataFrameGroupBy.agg""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrameGroupBy.agg()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.core.groupby.SeriesGroupBy.agg.html#pandas.core.groupby.SeriesGroupBy.agg"" title=""pandas.core.groupby.SeriesGroupBy.agg""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">SeriesGroupBy.agg()</span></code></a>, known as “named aggregation”, where</p>
<ul class=""simple"">
<li><p>The keywords are the <em>output</em> column names</p></li>
<li><p>The values are tuples whose first element is the column to select
and the second element is the aggregation to apply to that column. pandas
provides the <a class=""reference internal"" href=""../reference/api/pandas.NamedAgg.html#pandas.NamedAgg"" title=""pandas.NamedAgg""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NamedAgg</span></code></a> namedtuple with the fields <code class=""docutils literal notranslate""><span class=""pre"">['column',</span> <span class=""pre"">'aggfunc']</span></code>
to make it clearer what the arguments are. As usual, the aggregation can
be a callable or a string alias.</p></li>
</ul>

<p><a class=""reference internal"" href=""../reference/api/pandas.NamedAgg.html#pandas.NamedAgg"" title=""pandas.NamedAgg""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NamedAgg</span></code></a> is just a <code class=""docutils literal notranslate""><span class=""pre"">namedtuple</span></code>. Plain tuples are allowed as well.</p>

<p>If the column names you want are not valid Python keywords, construct a dictionary
and unpack the keyword arguments</p>

<p>When using named aggregation, additional keyword arguments are not passed through
to the aggregation functions; only pairs
of <code class=""docutils literal notranslate""><span class=""pre"">(column,</span> <span class=""pre"">aggfunc)</span></code> should be passed as <code class=""docutils literal notranslate""><span class=""pre"">**kwargs</span></code>. If your aggregation functions
require additional arguments, apply them partially with <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">functools.partial()</span></code>.</p>
<p>Named aggregation is also valid for Series groupby aggregations. In this case there’s
no column selection, so the values are just the functions.</p>

</section>
<section id=""applying-different-functions-to-dataframe-columns"">
<h3>Applying different functions to DataFrame columns<a class=""headerlink"" href=""#applying-different-functions-to-dataframe-columns"" title=""Link to this heading"">#</a></h3>
<p>By passing a dict to <code class=""docutils literal notranslate""><span class=""pre"">aggregate</span></code> you can apply a different aggregation to the
columns of a DataFrame:</p>

<p>The function names can also be strings. In order for a string to be valid it
must be implemented on GroupBy:</p>

</section>
</section>
<section id=""transformation"">
<span id=""groupby-transform""></span><h2>Transformation<a class=""headerlink"" href=""#transformation"" title=""Link to this heading"">#</a></h2>
<p>A transformation is a GroupBy operation whose result is indexed the same
as the one being grouped. Common examples include <a class=""reference internal"" href=""../reference/api/pandas.core.groupby.DataFrameGroupBy.cumsum.html#pandas.core.groupby.DataFrameGroupBy.cumsum"" title=""pandas.core.groupby.DataFrameGroupBy.cumsum""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">cumsum()</span></code></a> and
<a class=""reference internal"" href=""../reference/api/pandas.core.groupby.DataFrameGroupBy.diff.html#pandas.core.groupby.DataFrameGroupBy.diff"" title=""pandas.core.groupby.DataFrameGroupBy.diff""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">diff()</span></code></a>.</p>

<p>Unlike aggregations, the groupings that are used to split
the original object are not included in the result.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Since transformations do not include the groupings that are used to split the result,
the arguments <code class=""docutils literal notranslate""><span class=""pre"">as_index</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">sort</span></code> in <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.groupby.html#pandas.DataFrame.groupby"" title=""pandas.DataFrame.groupby""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.groupby()</span></code></a> and
<a class=""reference internal"" href=""../reference/api/pandas.Series.groupby.html#pandas.Series.groupby"" title=""pandas.Series.groupby""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.groupby()</span></code></a> have no effect.</p>
</div>
<p>A common use of a transformation is to add the result back into the original DataFrame.</p>

<section id=""built-in-transformation-methods"">
<h3>Built-in transformation methods<a class=""headerlink"" href=""#built-in-transformation-methods"" title=""Link to this heading"">#</a></h3>
<p>The following methods on GroupBy act as transformations.</p>

<p>In addition, passing any built-in aggregation method as a string to
<a class=""reference internal"" href=""../reference/api/pandas.core.groupby.DataFrameGroupBy.transform.html#pandas.core.groupby.DataFrameGroupBy.transform"" title=""pandas.core.groupby.DataFrameGroupBy.transform""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">transform()</span></code></a> (see the next section) will broadcast the result
across the group, producing a transformed result. If the aggregation method has an efficient
implementation, this will be performant as well.</p>
</section>
<section id=""the-transform-method"">
<span id=""groupby-transformation-transform""></span><h3>The <a class=""reference internal"" href=""../reference/api/pandas.core.groupby.DataFrameGroupBy.transform.html#pandas.core.groupby.DataFrameGroupBy.transform"" title=""pandas.core.groupby.DataFrameGroupBy.transform""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">transform()</span></code></a> method<a class=""headerlink"" href=""#the-transform-method"" title=""Link to this heading"">#</a></h3>
<p>Similar to the <a class=""reference internal"" href=""#groupby-aggregate-agg""><span class=""std std-ref"">aggregation method</span></a>, the
<a class=""reference internal"" href=""../reference/api/pandas.core.groupby.DataFrameGroupBy.transform.html#pandas.core.groupby.DataFrameGroupBy.transform"" title=""pandas.core.groupby.DataFrameGroupBy.transform""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">transform()</span></code></a> method can accept string aliases to the built-in
transformation methods in the previous section. It can <em>also</em> accept string aliases to
the built-in aggregation methods. When an aggregation method is provided, the result
will be broadcast across the group.</p>

<p>In addition to string aliases, the <a class=""reference internal"" href=""../reference/api/pandas.core.groupby.DataFrameGroupBy.transform.html#pandas.core.groupby.DataFrameGroupBy.transform"" title=""pandas.core.groupby.DataFrameGroupBy.transform""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">transform()</span></code></a> method can
also accept User-Defined Functions (UDFs). The UDF must:</p>
<ul class=""simple"">
<li><p>Return a result that is either the same size as the group chunk or
broadcastable to the size of the group chunk (e.g., a scalar,
<code class=""docutils literal notranslate""><span class=""pre"">grouped.transform(lambda</span> <span class=""pre"">x:</span> <span class=""pre"">x.iloc[-1])</span></code>).</p></li>
<li><p>Operate column-by-column on the group chunk. The transform is applied to
the first group chunk using chunk.apply.</p></li>
<li><p>Not perform in-place operations on the group chunk. Group chunks should
be treated as immutable, and changes to a group chunk may produce unexpected
results. See <a class=""reference internal"" href=""gotchas.html#gotchas-udf-mutation""><span class=""std std-ref"">Mutating with User Defined Function (UDF) methods</span></a> for more information.</p></li>
<li><p>(Optionally) operates on all columns of the entire group chunk at once. If this is
supported, a fast path is used starting from the <em>second</em> chunk.</p></li>
</ul>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Transforming by supplying <code class=""docutils literal notranslate""><span class=""pre"">transform</span></code> with a UDF is
often less performant than using the built-in methods on GroupBy.
Consider breaking up a complex operation into a chain of operations that utilize
the built-in methods.</p>
<p>All of the examples in this section can be made more performant by calling
built-in methods instead of using UDFs.
See <a class=""reference internal"" href=""#groupby-efficient-transforms""><span class=""std std-ref"">below for examples</span></a>.</p>
</div>
<div class=""versionchanged"">
<p><span class=""versionmodified changed"">Changed in version 2.0.0: </span>When using <code class=""docutils literal notranslate""><span class=""pre"">.transform</span></code> on a grouped DataFrame and the transformation function
returns a DataFrame, pandas now aligns the result’s index
with the input’s index. You can call <code class=""docutils literal notranslate""><span class=""pre"">.to_numpy()</span></code> within the transformation
function to avoid alignment.</p>
</div>
<p>Similar to <a class=""reference internal"" href=""#groupby-aggregate-agg""><span class=""std std-ref"">The aggregate() method</span></a>, the resulting dtype will reflect that of the
transformation function. If the results from different groups have different dtypes, then
a common dtype will be determined in the same way as <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> construction.</p>
<p>Suppose we wish to standardize the data within each group:</p>

<p>We would expect the result to now have mean 0 and standard deviation 1 within
each group (up to floating-point error), which we can easily check:</p>

<p>We can also visually compare the original and transformed data sets.</p>

<img alt=""../_images/groupby_transform_plot.png"" src=""../_images/groupby_transform_plot.png""/>
<p>Transformation functions that have lower dimension outputs are broadcast to
match the shape of the input array.</p>

<p>Another common data transform is to replace missing data with the group mean.</p>

<p>We can verify that the group means have not changed in the transformed data,
and that the transformed data contains no NAs.</p>

<p id=""groupby-efficient-transforms"">As mentioned in the note above, each of the examples in this section can be computed
more efficiently using built-in methods. In the code below, the inefficient way
using a UDF is commented out and the faster alternative appears below.</p>

</section>
<section id=""window-and-resample-operations"">
<span id=""groupby-transform-window-resample""></span><h3>Window and resample operations<a class=""headerlink"" href=""#window-and-resample-operations"" title=""Link to this heading"">#</a></h3>
<p>It is possible to use <code class=""docutils literal notranslate""><span class=""pre"">resample()</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">expanding()</span></code> and
<code class=""docutils literal notranslate""><span class=""pre"">rolling()</span></code> as methods on groupbys.</p>
<p>The example below will apply the <code class=""docutils literal notranslate""><span class=""pre"">rolling()</span></code> method on the samples of
the column B, based on the groups of column A.</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">expanding()</span></code> method will accumulate a given operation
(<code class=""docutils literal notranslate""><span class=""pre"">sum()</span></code> in the example) for all the members of each particular
group.</p>

<p>Suppose you want to use the <code class=""docutils literal notranslate""><span class=""pre"">resample()</span></code> method to get a daily
frequency in each group of your dataframe, and wish to complete the
missing values with the <code class=""docutils literal notranslate""><span class=""pre"">ffill()</span></code> method.</p>

</section>
</section>
<section id=""filtration"">
<span id=""groupby-filter""></span><h2>Filtration<a class=""headerlink"" href=""#filtration"" title=""Link to this heading"">#</a></h2>
<p>A filtration is a GroupBy operation that subsets the original grouping object. It
may either filter out entire groups, part of groups, or both. Filtrations return
a filtered version of the calling object, including the grouping columns when provided.
In the following example, <code class=""docutils literal notranslate""><span class=""pre"">class</span></code> is included in the result.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Unlike aggregations, filtrations do not add the group keys to the index of the
result. Because of this, passing <code class=""docutils literal notranslate""><span class=""pre"">as_index=False</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">sort=True</span></code> will not
affect these methods.</p>
</div>
<p>Filtrations will respect subsetting the columns of the GroupBy object.</p>

<section id=""built-in-filtrations"">
<h3>Built-in filtrations<a class=""headerlink"" href=""#built-in-filtrations"" title=""Link to this heading"">#</a></h3>
<p>The following methods on GroupBy act as filtrations. All these methods have an
efficient, GroupBy-specific, implementation.</p>

<p>Users can also use transformations along with Boolean indexing to construct complex
filtrations within groups. For example, suppose we are given groups of products and
their volumes, and we wish to subset the data to only the largest products capturing no
more than 90% of the total volume within each group.</p>

</section>
<section id=""the-filter-method"">
<h3>The <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">filter</span></code> method<a class=""headerlink"" href=""#the-filter-method"" title=""Link to this heading"">#</a></h3>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Filtering by supplying <code class=""docutils literal notranslate""><span class=""pre"">filter</span></code> with a User-Defined Function (UDF) is
often less performant than using the built-in methods on GroupBy.
Consider breaking up a complex operation into a chain of operations that utilize
the built-in methods.</p>
</div>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">filter</span></code> method takes a User-Defined Function (UDF) that, when applied to
an entire group, returns either <code class=""docutils literal notranslate""><span class=""pre"">True</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">False</span></code>. The result of the <code class=""docutils literal notranslate""><span class=""pre"">filter</span></code>
method is then the subset of groups for which the UDF returned <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>.</p>
<p>Suppose we want to take only elements that belong to groups with a group sum greater
than 2.</p>

<p>Another useful operation is filtering out elements that belong to groups
with only a couple members.</p>

<p>Alternatively, instead of dropping the offending groups, we can return a
like-indexed objects where the groups that do not pass the filter are filled
with NaNs.</p>

<p>For DataFrames with multiple columns, filters should explicitly specify a column as the filter criterion.</p>

</section>
</section>
<section id=""flexible-apply"">
<span id=""groupby-apply""></span><h2>Flexible <code class=""docutils literal notranslate""><span class=""pre"">apply</span></code><a class=""headerlink"" href=""#flexible-apply"" title=""Link to this heading"">#</a></h2>
<p>Some operations on the grouped data might not fit into the aggregation,
transformation, or filtration categories. For these, you can use the <code class=""docutils literal notranslate""><span class=""pre"">apply</span></code>
function.</p>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">apply</span></code> has to try to infer from the result whether it should act as a reducer,
transformer, <em>or</em> filter, depending on exactly what is passed to it. Thus the
grouped column(s) may be included in the output or not. While
it tries to intelligently guess how to behave, it can sometimes guess wrong.</p>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>All of the examples in this section can be more reliably, and more efficiently,
computed using other pandas functionality.</p>
</div>

<p>The dimension of the returned result can also change:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">apply</span></code> on a Series can operate on a returned value from the applied function
that is itself a series, and possibly upcast the result to a DataFrame:</p>

<p>Similar to <a class=""reference internal"" href=""#groupby-aggregate-agg""><span class=""std std-ref"">The aggregate() method</span></a>, the resulting dtype will reflect that of the
apply function. If the results from different groups have different dtypes, then
a common dtype will be determined in the same way as <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> construction.</p>
<section id=""control-grouped-column-s-placement-with-group-keys"">
<h3>Control grouped column(s) placement with <code class=""docutils literal notranslate""><span class=""pre"">group_keys</span></code><a class=""headerlink"" href=""#control-grouped-column-s-placement-with-group-keys"" title=""Link to this heading"">#</a></h3>
<p>To control whether the grouped column(s) are included in the indices, you can use
the argument <code class=""docutils literal notranslate""><span class=""pre"">group_keys</span></code> which defaults to <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>. Compare</p>

<p>with</p>

</section>
</section>
<section id=""numba-accelerated-routines"">
<h2>Numba Accelerated Routines<a class=""headerlink"" href=""#numba-accelerated-routines"" title=""Link to this heading"">#</a></h2>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.1.</span></p>
</div>
<p>If <a class=""reference external"" href=""https://numba.pydata.org/"">Numba</a> is installed as an optional dependency, the <code class=""docutils literal notranslate""><span class=""pre"">transform</span></code> and
<code class=""docutils literal notranslate""><span class=""pre"">aggregate</span></code> methods support <code class=""docutils literal notranslate""><span class=""pre"">engine='numba'</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">engine_kwargs</span></code> arguments.
See <a class=""reference internal"" href=""enhancingperf.html#enhancingperf-numba""><span class=""std std-ref"">enhancing performance with Numba</span></a> for general usage of the arguments
and performance considerations.</p>
<p>The function signature must start with <code class=""docutils literal notranslate""><span class=""pre"">values,</span> <span class=""pre"">index</span></code> <strong>exactly</strong> as the data belonging to each group
will be passed into <code class=""docutils literal notranslate""><span class=""pre"">values</span></code>, and the group index will be passed into <code class=""docutils literal notranslate""><span class=""pre"">index</span></code>.</p>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>When using <code class=""docutils literal notranslate""><span class=""pre"">engine='numba'</span></code>, there will be no “fall back” behavior internally. The group
data and group index will be passed as NumPy arrays to the JITed user defined function, and no
alternative execution attempts will be tried.</p>
</div>
</section>
<section id=""other-useful-features"">
<h2>Other useful features<a class=""headerlink"" href=""#other-useful-features"" title=""Link to this heading"">#</a></h2>
<section id=""exclusion-of-non-numeric-columns"">
<h3>Exclusion of non-numeric columns<a class=""headerlink"" href=""#exclusion-of-non-numeric-columns"" title=""Link to this heading"">#</a></h3>
<p>Again consider the example DataFrame we’ve been looking at:</p>

<p>Suppose we wish to compute the standard deviation grouped by the <code class=""docutils literal notranslate""><span class=""pre"">A</span></code>
column. There is a slight problem, namely that we don’t care about the data in
column <code class=""docutils literal notranslate""><span class=""pre"">B</span></code> because it is not numeric. You can avoid non-numeric columns by
specifying <code class=""docutils literal notranslate""><span class=""pre"">numeric_only=True</span></code>:</p>

<p>Note that <code class=""docutils literal notranslate""><span class=""pre"">df.groupby('A').colname.std().</span></code> is more efficient than
<code class=""docutils literal notranslate""><span class=""pre"">df.groupby('A').std().colname</span></code>. So if the result of an aggregation function
is only needed over one column (here <code class=""docutils literal notranslate""><span class=""pre"">colname</span></code>), it may be filtered
<em>before</em> applying the aggregation function.</p>

</section>
<section id=""handling-of-un-observed-categorical-values"">
<span id=""groupby-observed""></span><h3>Handling of (un)observed Categorical values<a class=""headerlink"" href=""#handling-of-un-observed-categorical-values"" title=""Link to this heading"">#</a></h3>
<p>When using a <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> grouper (as a single grouper, or as part of multiple groupers), the <code class=""docutils literal notranslate""><span class=""pre"">observed</span></code> keyword
controls whether to return a cartesian product of all possible groupers values (<code class=""docutils literal notranslate""><span class=""pre"">observed=False</span></code>) or only those
that are observed groupers (<code class=""docutils literal notranslate""><span class=""pre"">observed=True</span></code>).</p>
<p>Show all values:</p>

<p>Show only the observed values:</p>

<p>The returned dtype of the grouped will <em>always</em> include <em>all</em> of the categories that were grouped.</p>

</section>
<section id=""na-group-handling"">
<span id=""groupby-missing""></span><h3>NA group handling<a class=""headerlink"" href=""#na-group-handling"" title=""Link to this heading"">#</a></h3>
<p>By <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code>, we are referring to any <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> values, including
<a class=""reference internal"" href=""../reference/api/pandas.NA.html#pandas.NA"" title=""pandas.NA""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">NA</span></code></a>, <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">NaT</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">None</span></code>. If there are any <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> values in the
grouping key, by default these will be excluded. In other words, any
“<code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> group” will be dropped. You can include NA groups by specifying <code class=""docutils literal notranslate""><span class=""pre"">dropna=False</span></code>.</p>

</section>
<section id=""grouping-with-ordered-factors"">
<h3>Grouping with ordered factors<a class=""headerlink"" href=""#grouping-with-ordered-factors"" title=""Link to this heading"">#</a></h3>
<p>Categorical variables represented as instances of pandas’s <code class=""docutils literal notranslate""><span class=""pre"">Categorical</span></code> class
can be used as group keys. If so, the order of the levels will be preserved. When
<code class=""docutils literal notranslate""><span class=""pre"">observed=False</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">sort=False</span></code>, any unobserved categories will be at the
end of the result in order.</p>

</section>
<section id=""grouping-with-a-grouper-specification"">
<span id=""groupby-specify""></span><h3>Grouping with a grouper specification<a class=""headerlink"" href=""#grouping-with-a-grouper-specification"" title=""Link to this heading"">#</a></h3>
<p>You may need to specify a bit more data to properly group. You can
use the <code class=""docutils literal notranslate""><span class=""pre"">pd.Grouper</span></code> to provide this local control.</p>

<p>Groupby a specific column with the desired frequency. This is like resampling.</p>

<p>When <code class=""docutils literal notranslate""><span class=""pre"">freq</span></code> is specified, the object returned by <code class=""docutils literal notranslate""><span class=""pre"">pd.Grouper</span></code> will be an
instance of <code class=""docutils literal notranslate""><span class=""pre"">pandas.api.typing.TimeGrouper</span></code>. When there is a column and index
with the same name, you can use <code class=""docutils literal notranslate""><span class=""pre"">key</span></code> to group by the column and <code class=""docutils literal notranslate""><span class=""pre"">level</span></code>
to group by the index.</p>

</section>
<section id=""taking-the-first-rows-of-each-group"">
<h3>Taking the first rows of each group<a class=""headerlink"" href=""#taking-the-first-rows-of-each-group"" title=""Link to this heading"">#</a></h3>
<p>Just like for a DataFrame or Series you can call head and tail on a groupby:</p>

<p>This shows the first or last n rows from each group.</p>
</section>
<section id=""taking-the-nth-row-of-each-group"">
<span id=""groupby-nth""></span><h3>Taking the nth row of each group<a class=""headerlink"" href=""#taking-the-nth-row-of-each-group"" title=""Link to this heading"">#</a></h3>
<p>To select the nth item from each group, use <a class=""reference internal"" href=""../reference/api/pandas.core.groupby.DataFrameGroupBy.nth.html#pandas.core.groupby.DataFrameGroupBy.nth"" title=""pandas.core.groupby.DataFrameGroupBy.nth""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrameGroupBy.nth()</span></code></a> or
<a class=""reference internal"" href=""../reference/api/pandas.core.groupby.SeriesGroupBy.nth.html#pandas.core.groupby.SeriesGroupBy.nth"" title=""pandas.core.groupby.SeriesGroupBy.nth""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">SeriesGroupBy.nth()</span></code></a>. Arguments supplied can be any integer, lists of integers,
slices, or lists of slices; see below for examples. When the nth element of a group
does not exist an error is <em>not</em> raised; instead no corresponding rows are returned.</p>
<p>In general this operation acts as a filtration. In certain cases it will also return
one row per group, making it also a reduction. However because in general it can
return zero or multiple rows per group, pandas treats it as a filtration in all cases.</p>

<p>If the nth element of a group does not exist, then no corresponding row is included
in the result. In particular, if the specified <code class=""docutils literal notranslate""><span class=""pre"">n</span></code> is larger than any group, the
result will be an empty DataFrame.</p>

<p>If you want to select the nth not-null item, use the <code class=""docutils literal notranslate""><span class=""pre"">dropna</span></code> kwarg. For a DataFrame this should be either <code class=""docutils literal notranslate""><span class=""pre"">'any'</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">'all'</span></code> just like you would pass to dropna:</p>

<p>You can also select multiple rows from each group by specifying multiple nth values as a list of ints.</p>

<p>You may also use slices or lists of slices.</p>

</section>
<section id=""enumerate-group-items"">
<h3>Enumerate group items<a class=""headerlink"" href=""#enumerate-group-items"" title=""Link to this heading"">#</a></h3>
<p>To see the order in which each row appears within its group, use the
<code class=""docutils literal notranslate""><span class=""pre"">cumcount</span></code> method:</p>

</section>
<section id=""enumerate-groups"">
<span id=""groupby-ngroup""></span><h3>Enumerate groups<a class=""headerlink"" href=""#enumerate-groups"" title=""Link to this heading"">#</a></h3>
<p>To see the ordering of the groups (as opposed to the order of rows
within a group given by <code class=""docutils literal notranslate""><span class=""pre"">cumcount</span></code>) you can use
<a class=""reference internal"" href=""../reference/api/pandas.core.groupby.DataFrameGroupBy.ngroup.html#pandas.core.groupby.DataFrameGroupBy.ngroup"" title=""pandas.core.groupby.DataFrameGroupBy.ngroup""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrameGroupBy.ngroup()</span></code></a>.</p>
<p>Note that the numbers given to the groups match the order in which the
groups would be seen when iterating over the groupby object, not the
order they are first observed.</p>

</section>
<section id=""plotting"">
<h3>Plotting<a class=""headerlink"" href=""#plotting"" title=""Link to this heading"">#</a></h3>
<p>Groupby also works with some plotting methods. In this case, suppose we
suspect that the values in column 1 are 3 times higher on average in group “B”.</p>

<p>We can easily visualize this with a boxplot:</p>

<img alt=""../_images/groupby_boxplot.png"" src=""../_images/groupby_boxplot.png""/>
<p>The result of calling <code class=""docutils literal notranslate""><span class=""pre"">boxplot</span></code> is a dictionary whose keys are the values
of our grouping column <code class=""docutils literal notranslate""><span class=""pre"">g</span></code> (“A” and “B”). The values of the resulting dictionary
can be controlled by the <code class=""docutils literal notranslate""><span class=""pre"">return_type</span></code> keyword of <code class=""docutils literal notranslate""><span class=""pre"">boxplot</span></code>.
See the <a class=""reference internal"" href=""visualization.html#visualization-box""><span class=""std std-ref"">visualization documentation</span></a> for more.</p>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>For historical reasons, <code class=""docutils literal notranslate""><span class=""pre"">df.groupby(""g"").boxplot()</span></code> is not equivalent
to <code class=""docutils literal notranslate""><span class=""pre"">df.boxplot(by=""g"")</span></code>. See <a class=""reference internal"" href=""visualization.html#visualization-box-return""><span class=""std std-ref"">here</span></a> for
an explanation.</p>
</div>
</section>
<section id=""piping-function-calls"">
<span id=""groupby-pipe""></span><h3>Piping function calls<a class=""headerlink"" href=""#piping-function-calls"" title=""Link to this heading"">#</a></h3>
<p>Similar to the functionality provided by <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>, functions
that take <code class=""docutils literal notranslate""><span class=""pre"">GroupBy</span></code> objects can be chained together using a <code class=""docutils literal notranslate""><span class=""pre"">pipe</span></code> method to
allow for a cleaner, more readable syntax. To read about <code class=""docutils literal notranslate""><span class=""pre"">.pipe</span></code> in general terms,
see <a class=""reference internal"" href=""basics.html#basics-pipe""><span class=""std std-ref"">here</span></a>.</p>
<p>Combining <code class=""docutils literal notranslate""><span class=""pre"">.groupby</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">.pipe</span></code> is often useful when you need to reuse
GroupBy objects.</p>
<p>As an example, imagine having a DataFrame with columns for stores, products,
revenue and quantity sold. We’d like to do a groupwise calculation of <em>prices</em>
(i.e. revenue/quantity) per store and per product. We could do this in a
multi-step operation, but expressing it in terms of piping can make the
code more readable. First we set the data:</p>

<p>We now find the prices per store/product.</p>

<p>Piping can also be expressive when you want to deliver a grouped object to some
arbitrary function, for example:</p>

<p>Here <code class=""docutils literal notranslate""><span class=""pre"">mean</span></code> takes a GroupBy object and finds the mean of the Revenue and Quantity
columns respectively for each Store-Product combination. The <code class=""docutils literal notranslate""><span class=""pre"">mean</span></code> function can
be any function that takes in a GroupBy object; the <code class=""docutils literal notranslate""><span class=""pre"">.pipe</span></code> will pass the GroupBy
object as a parameter into the function you specify.</p>
</section>
</section>
<section id=""examples"">
<h2>Examples<a class=""headerlink"" href=""#examples"" title=""Link to this heading"">#</a></h2>
<section id=""multi-column-factorization"">
<span id=""groupby-multicolumn-factorization""></span><h3>Multi-column factorization<a class=""headerlink"" href=""#multi-column-factorization"" title=""Link to this heading"">#</a></h3>
<p>By using <a class=""reference internal"" href=""../reference/api/pandas.core.groupby.DataFrameGroupBy.ngroup.html#pandas.core.groupby.DataFrameGroupBy.ngroup"" title=""pandas.core.groupby.DataFrameGroupBy.ngroup""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrameGroupBy.ngroup()</span></code></a>, we can extract
information about the groups in a way similar to <a class=""reference internal"" href=""../reference/api/pandas.factorize.html#pandas.factorize"" title=""pandas.factorize""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">factorize()</span></code></a> (as described
further in the <a class=""reference internal"" href=""reshaping.html#reshaping-factorize""><span class=""std std-ref"">reshaping API</span></a>) but which applies
naturally to multiple columns of mixed type and different
sources. This can be useful as an intermediate categorical-like step
in processing, when the relationships between the group rows are more
important than their content, or as input to an algorithm which only
accepts the integer encoding. (For more information about support in
pandas for full categorical data, see the <a class=""reference internal"" href=""categorical.html#categorical""><span class=""std std-ref"">Categorical
introduction</span></a> and the
<a class=""reference internal"" href=""../reference/arrays.html#api-arrays-categorical""><span class=""std std-ref"">API documentation</span></a>.)</p>

</section>
<section id=""groupby-by-indexer-to-resample-data"">
<h3>Groupby by indexer to ‘resample’ data<a class=""headerlink"" href=""#groupby-by-indexer-to-resample-data"" title=""Link to this heading"">#</a></h3>
<p>Resampling produces new hypothetical samples (resamples) from already existing observed data or from a model that generates data. These new samples are similar to the pre-existing samples.</p>
<p>In order for resample to work on indices that are non-datetimelike, the following procedure can be utilized.</p>
<p>In the following examples, <strong>df.index // 5</strong> returns an integer array which is used to determine what gets selected for the groupby operation.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The example below shows how we can downsample by consolidation of samples into fewer ones.
Here by using <strong>df.index // 5</strong>, we are aggregating the samples in bins. By applying <strong>std()</strong>
function, we aggregate the information contained in many samples into a small subset of values
which is their standard deviation thereby reducing the number of samples.</p>
</div>

</section>
<section id=""returning-a-series-to-propagate-names"">
<h3>Returning a Series to propagate names<a class=""headerlink"" href=""#returning-a-series-to-propagate-names"" title=""Link to this heading"">#</a></h3>
<p>Group DataFrame columns, compute a set of metrics and return a named Series.
The Series name is used as the name for the column index. This is especially
useful in conjunction with reshaping operations such as stacking, in which the
column index name will be used as the name of the inserted column:</p>

</section>
</section>
</section>
</article>","Group by: split-apply-combine # By “group by” we are referring to a process involving one or more of the following steps: Splitting the data into groups based on some criteria. Applying a function to each group independently. Combining the results into a data structure. Out of these, the split step is the most straightforward. In the apply step, we might wish to do one of the following: Aggregation : compute a summary statistic (or statistics) for each group. Some examples: Compute group sums or means. Compute group sizes / counts. Transformation : perform some group-specific computations and return a like-indexed object. Some examples: Standardize data (zscore) within a group. Filling NAs within groups with a value derived from each group. Filtration : discard some groups, according to a group-wise computation that evaluates to True or False. Some examples: Discard data that belong to groups with only a few members. Filter out data based on the group sum or mean. Many of these operations are defined on GroupBy objects. These operations are similar to those of the aggregating API , window API , and resample API . It is possible that a given operation does not fall into one of these categories or is some combination of them. In such a case, it may be possible to compute the operation using GroupBy’s apply method. This method will examine the results of the apply step and try to sensibly combine them into a single result if it doesn’t fit into either of the above three categories. Note An operation that is split into multiple steps using built-in GroupBy operations will be more efficient than using the apply method with a user-defined Python function. The name GroupBy should be quite familiar to those who have used a SQL-based tool (or itertools ), in which you can write code like: SELECT Column1 , Column2 , mean ( Column3 ), sum ( Column4 ) FROM SomeTable GROUP BY Column1 , Column2 We aim to make operations like this natural and easy to express using pandas. We’ll address each area of GroupBy functionality, then provide some non-trivial examples / use cases. See the cookbook for some advanced strategies. Splitting an object into groups # The abstract definition of grouping is to provide a mapping of labels to group names. To create a GroupBy object (more on what the GroupBy object is later), you may do the following: The mapping can be specified many different ways: A Python function, to be called on each of the index labels. A list or NumPy array of the same length as the index. A dict or Series , providing a label -> group name mapping. For DataFrame objects, a string indicating either a column name or an index level name to be used to group. A list of any of the above things. Collectively we refer to the grouping objects as the keys . For example, consider the following DataFrame : Note A string passed to groupby may refer to either a column or an index level. If a string matches both a column name and an index level name, a ValueError will be raised. On a DataFrame, we obtain a GroupBy object by calling groupby() . This method returns a pandas.api.typing.DataFrameGroupBy instance. We could naturally group by either the A or B columns, or both: Note df.groupby('A') is just syntactic sugar for df.groupby(df['A']) . If we also have a MultiIndex on columns A and B , we can group by all the columns except the one we specify: The above GroupBy will split the DataFrame on its index (rows). To split by columns, first do a transpose: pandas Index objects support duplicate values. If a non-unique index is used as the group key in a groupby operation, all values for the same index value will be considered to be in one group and thus the output of aggregation functions will only contain unique index values: Note that no splitting occurs until it’s needed. Creating the GroupBy object only verifies that you’ve passed a valid mapping. Note Many kinds of complicated data manipulations can be expressed in terms of GroupBy operations (though it can’t be guaranteed to be the most efficient implementation). You can get quite creative with the label mapping functions. GroupBy sorting # By default the group keys are sorted during the groupby operation. You may however pass sort=False for potential speedups. With sort=False the order among group-keys follows the order of appearance of the keys in the original dataframe: Note that groupby will preserve the order in which observations are sorted within each group. For example, the groups created by groupby() below are in the order they appeared in the original DataFrame : GroupBy dropna # By default NA values are excluded from group keys during the groupby operation. However, in case you want to include NA values in group keys, you could pass dropna=False to achieve it. The default setting of dropna argument is True which means NA are not included in group keys. GroupBy object attributes # The groups attribute is a dictionary whose keys are the computed unique groups and corresponding values are the axis labels belonging to each group. In the above example we have: Calling the standard Python len function on the GroupBy object returns the number of groups, which is the same as the length of the groups dictionary: GroupBy will tab complete column names, GroupBy operations, and other attributes: GroupBy with MultiIndex # With hierarchically-indexed data , it’s quite natural to group by one of the levels of the hierarchy. Let’s create a Series with a two-level MultiIndex . We can then group by one of the levels in s . If the MultiIndex has names specified, these can be passed instead of the level number: Grouping with multiple levels is supported. Index level names may be supplied as keys. More on the sum function and aggregation later. Grouping DataFrame with Index levels and columns # A DataFrame may be grouped by a combination of columns and index levels. You can specify both column and index names, or use a Grouper . Let’s first create a DataFrame with a MultiIndex: Then we group df by the second index level and the A column. Index levels may also be specified by name. Index level names may be specified as keys directly to groupby . DataFrame column selection in GroupBy # Once you have created the GroupBy object from a DataFrame, you might want to do something different for each of the columns. Thus, by using [] on the GroupBy object in a similar way as the one used to get a column from a DataFrame, you can do: This is mainly syntactic sugar for the alternative, which is much more verbose: Additionally, this method avoids recomputing the internal grouping information derived from the passed key. You can also include the grouping columns if you want to operate on them. Iterating through groups # With the GroupBy object in hand, iterating through the grouped data is very natural and functions similarly to itertools.groupby() : In the case of grouping by multiple keys, the group name will be a tuple: See Iterating through groups . Selecting a group # A single group can be selected using DataFrameGroupBy.get_group() : Or for an object grouped on multiple columns: Aggregation # An aggregation is a GroupBy operation that reduces the dimension of the grouping object. The result of an aggregation is, or at least is treated as, a scalar value for each column in a group. For example, producing the sum of each column in a group of values. In the result, the keys of the groups appear in the index by default. They can be instead included in the columns by passing as_index=False . Built-in aggregation methods # Many common aggregations are built-in to GroupBy objects as methods. Of the methods listed below, those with a * do not have an efficient, GroupBy-specific, implementation. Some examples: Another aggregation example is to compute the size of each group. This is included in GroupBy as the size method. It returns a Series whose index consists of the group names and the values are the sizes of each group. While the DataFrameGroupBy.describe() method is not itself a reducer, it can be used to conveniently produce a collection of summary statistics about each of the groups. Another aggregation example is to compute the number of unique values of each group. This is similar to the DataFrameGroupBy.value_counts() function, except that it only counts the number of unique values. Note Aggregation functions will not return the groups that you are aggregating over as named columns when as_index=True , the default. The grouped columns will be the indices of the returned object. Passing as_index=False will return the groups that you are aggregating over as named columns, regardless if they are named indices or columns in the inputs. The aggregate() method # Note The aggregate() method can accept many different types of inputs. This section details using string aliases for various GroupBy methods; other inputs are detailed in the sections below. Any reduction method that pandas implements can be passed as a string to aggregate() . Users are encouraged to use the shorthand, agg . It will operate as if the corresponding method was called. The result of the aggregation will have the group names as the new index. In the case of multiple keys, the result is a MultiIndex by default. As mentioned above, this can be changed by using the as_index option: Note that you could use the DataFrame.reset_index() DataFrame function to achieve the same result as the column names are stored in the resulting MultiIndex , although this will make an extra copy. Aggregation with User-Defined Functions # Users can also provide their own User-Defined Functions (UDFs) for custom aggregations. Warning When aggregating with a UDF, the UDF should not mutate the provided Series . See Mutating with User Defined Function (UDF) methods for more information. Note Aggregating with a UDF is often less performant than using the pandas built-in methods on GroupBy. Consider breaking up a complex operation into a chain of operations that utilize the built-in methods. The resulting dtype will reflect that of the aggregating function. If the results from different groups have different dtypes, then a common dtype will be determined in the same way as DataFrame construction. Applying multiple functions at once # On a grouped Series , you can pass a list or dict of functions to SeriesGroupBy.agg() , outputting a DataFrame: On a grouped DataFrame , you can pass a list of functions to DataFrameGroupBy.agg() to aggregate each column, which produces an aggregated result with a hierarchical column index: The resulting aggregations are named after the functions themselves. If you need to rename, then you can add in a chained operation for a Series like this: For a grouped DataFrame , you can rename in a similar manner: Note In general, the output column names should be unique, but pandas will allow you apply to the same function (or two functions with the same name) to the same column. pandas also allows you to provide multiple lambdas. In this case, pandas will mangle the name of the (nameless) lambda functions, appending _<i> to each subsequent lambda. Named aggregation # To support column-specific aggregation with control over the output column names , pandas accepts the special syntax in DataFrameGroupBy.agg() and SeriesGroupBy.agg() , known as “named aggregation”, where The keywords are the output column names The values are tuples whose first element is the column to select and the second element is the aggregation to apply to that column. pandas provides the NamedAgg namedtuple with the fields ['column', 'aggfunc'] to make it clearer what the arguments are. As usual, the aggregation can be a callable or a string alias. NamedAgg is just a namedtuple . Plain tuples are allowed as well. If the column names you want are not valid Python keywords, construct a dictionary and unpack the keyword arguments When using named aggregation, additional keyword arguments are not passed through to the aggregation functions; only pairs of (column, aggfunc) should be passed as **kwargs . If your aggregation functions require additional arguments, apply them partially with functools.partial() . Named aggregation is also valid for Series groupby aggregations. In this case there’s no column selection, so the values are just the functions. Applying different functions to DataFrame columns # By passing a dict to aggregate you can apply a different aggregation to the columns of a DataFrame: The function names can also be strings. In order for a string to be valid it must be implemented on GroupBy: Transformation # A transformation is a GroupBy operation whose result is indexed the same as the one being grouped. Common examples include cumsum() and diff() . Unlike aggregations, the groupings that are used to split the original object are not included in the result. Note Since transformations do not include the groupings that are used to split the result, the arguments as_index and sort in DataFrame.groupby() and Series.groupby() have no effect. A common use of a transformation is to add the result back into the original DataFrame. Built-in transformation methods # The following methods on GroupBy act as transformations. In addition, passing any built-in aggregation method as a string to transform() (see the next section) will broadcast the result across the group, producing a transformed result. If the aggregation method has an efficient implementation, this will be performant as well. The transform() method # Similar to the aggregation method , the transform() method can accept string aliases to the built-in transformation methods in the previous section. It can also accept string aliases to the built-in aggregation methods. When an aggregation method is provided, the result will be broadcast across the group. In addition to string aliases, the transform() method can also accept User-Defined Functions (UDFs). The UDF must: Return a result that is either the same size as the group chunk or broadcastable to the size of the group chunk (e.g., a scalar, grouped.transform(lambda x: x.iloc[-1]) ). Operate column-by-column on the group chunk. The transform is applied to the first group chunk using chunk.apply. Not perform in-place operations on the group chunk. Group chunks should be treated as immutable, and changes to a group chunk may produce unexpected results. See Mutating with User Defined Function (UDF) methods for more information. (Optionally) operates on all columns of the entire group chunk at once. If this is supported, a fast path is used starting from the second chunk. Note Transforming by supplying transform with a UDF is often less performant than using the built-in methods on GroupBy. Consider breaking up a complex operation into a chain of operations that utilize the built-in methods. All of the examples in this section can be made more performant by calling built-in methods instead of using UDFs. See below for examples . Changed in version 2.0.0: When using .transform on a grouped DataFrame and the transformation function returns a DataFrame, pandas now aligns the result’s index with the input’s index. You can call .to_numpy() within the transformation function to avoid alignment. Similar to The aggregate() method , the resulting dtype will reflect that of the transformation function. If the results from different groups have different dtypes, then a common dtype will be determined in the same way as DataFrame construction. Suppose we wish to standardize the data within each group: We would expect the result to now have mean 0 and standard deviation 1 within each group (up to floating-point error), which we can easily check: We can also visually compare the original and transformed data sets. Transformation functions that have lower dimension outputs are broadcast to match the shape of the input array. Another common data transform is to replace missing data with the group mean. We can verify that the group means have not changed in the transformed data, and that the transformed data contains no NAs. As mentioned in the note above, each of the examples in this section can be computed more efficiently using built-in methods. In the code below, the inefficient way using a UDF is commented out and the faster alternative appears below. Window and resample operations # It is possible to use resample() , expanding() and rolling() as methods on groupbys. The example below will apply the rolling() method on the samples of the column B, based on the groups of column A. The expanding() method will accumulate a given operation ( sum() in the example) for all the members of each particular group. Suppose you want to use the resample() method to get a daily frequency in each group of your dataframe, and wish to complete the missing values with the ffill() method. Filtration # A filtration is a GroupBy operation that subsets the original grouping object. It may either filter out entire groups, part of groups, or both. Filtrations return a filtered version of the calling object, including the grouping columns when provided. In the following example, class is included in the result. Note Unlike aggregations, filtrations do not add the group keys to the index of the result. Because of this, passing as_index=False or sort=True will not affect these methods. Filtrations will respect subsetting the columns of the GroupBy object. Built-in filtrations # The following methods on GroupBy act as filtrations. All these methods have an efficient, GroupBy-specific, implementation. Users can also use transformations along with Boolean indexing to construct complex filtrations within groups. For example, suppose we are given groups of products and their volumes, and we wish to subset the data to only the largest products capturing no more than 90% of the total volume within each group. The filter method # Note Filtering by supplying filter with a User-Defined Function (UDF) is often less performant than using the built-in methods on GroupBy. Consider breaking up a complex operation into a chain of operations that utilize the built-in methods. The filter method takes a User-Defined Function (UDF) that, when applied to an entire group, returns either True or False . The result of the filter method is then the subset of groups for which the UDF returned True . Suppose we want to take only elements that belong to groups with a group sum greater than 2. Another useful operation is filtering out elements that belong to groups with only a couple members. Alternatively, instead of dropping the offending groups, we can return a like-indexed objects where the groups that do not pass the filter are filled with NaNs. For DataFrames with multiple columns, filters should explicitly specify a column as the filter criterion. Flexible apply # Some operations on the grouped data might not fit into the aggregation, transformation, or filtration categories. For these, you can use the apply function. Warning apply has to try to infer from the result whether it should act as a reducer, transformer, or filter, depending on exactly what is passed to it. Thus the grouped column(s) may be included in the output or not. While it tries to intelligently guess how to behave, it can sometimes guess wrong. Note All of the examples in this section can be more reliably, and more efficiently, computed using other pandas functionality. The dimension of the returned result can also change: apply on a Series can operate on a returned value from the applied function that is itself a series, and possibly upcast the result to a DataFrame: Similar to The aggregate() method , the resulting dtype will reflect that of the apply function. If the results from different groups have different dtypes, then a common dtype will be determined in the same way as DataFrame construction. Control grouped column(s) placement with group_keys # To control whether the grouped column(s) are included in the indices, you can use the argument group_keys which defaults to True . Compare with Numba Accelerated Routines # New in version 1.1. If Numba is installed as an optional dependency, the transform and aggregate methods support engine='numba' and engine_kwargs arguments. See enhancing performance with Numba for general usage of the arguments and performance considerations. The function signature must start with values, index exactly as the data belonging to each group will be passed into values , and the group index will be passed into index . Warning When using engine='numba' , there will be no “fall back” behavior internally. The group data and group index will be passed as NumPy arrays to the JITed user defined function, and no alternative execution attempts will be tried. Other useful features # Exclusion of non-numeric columns # Again consider the example DataFrame we’ve been looking at: Suppose we wish to compute the standard deviation grouped by the A column. There is a slight problem, namely that we don’t care about the data in column B because it is not numeric. You can avoid non-numeric columns by specifying numeric_only=True : Note that df.groupby('A').colname.std(). is more efficient than df.groupby('A').std().colname . So if the result of an aggregation function is only needed over one column (here colname ), it may be filtered before applying the aggregation function. Handling of (un)observed Categorical values # When using a Categorical grouper (as a single grouper, or as part of multiple groupers), the observed keyword controls whether to return a cartesian product of all possible groupers values ( observed=False ) or only those that are observed groupers ( observed=True ). Show all values: Show only the observed values: The returned dtype of the grouped will always include all of the categories that were grouped. NA group handling # By NA , we are referring to any NA values, including NA , NaN , NaT , and None . If there are any NA values in the grouping key, by default these will be excluded. In other words, any “ NA group” will be dropped. You can include NA groups by specifying dropna=False . Grouping with ordered factors # Categorical variables represented as instances of pandas’s Categorical class can be used as group keys. If so, the order of the levels will be preserved. When observed=False and sort=False , any unobserved categories will be at the end of the result in order. Grouping with a grouper specification # You may need to specify a bit more data to properly group. You can use the pd.Grouper to provide this local control. Groupby a specific column with the desired frequency. This is like resampling. When freq is specified, the object returned by pd.Grouper will be an instance of pandas.api.typing.TimeGrouper . When there is a column and index with the same name, you can use key to group by the column and level to group by the index. Taking the first rows of each group # Just like for a DataFrame or Series you can call head and tail on a groupby: This shows the first or last n rows from each group. Taking the nth row of each group # To select the nth item from each group, use DataFrameGroupBy.nth() or SeriesGroupBy.nth() . Arguments supplied can be any integer, lists of integers, slices, or lists of slices; see below for examples. When the nth element of a group does not exist an error is not raised; instead no corresponding rows are returned. In general this operation acts as a filtration. In certain cases it will also return one row per group, making it also a reduction. However because in general it can return zero or multiple rows per group, pandas treats it as a filtration in all cases. If the nth element of a group does not exist, then no corresponding row is included in the result. In particular, if the specified n is larger than any group, the result will be an empty DataFrame. If you want to select the nth not-null item, use the dropna kwarg. For a DataFrame this should be either 'any' or 'all' just like you would pass to dropna: You can also select multiple rows from each group by specifying multiple nth values as a list of ints. You may also use slices or lists of slices. Enumerate group items # To see the order in which each row appears within its group, use the cumcount method: Enumerate groups # To see the ordering of the groups (as opposed to the order of rows within a group given by cumcount ) you can use DataFrameGroupBy.ngroup() . Note that the numbers given to the groups match the order in which the groups would be seen when iterating over the groupby object, not the order they are first observed. Plotting # Groupby also works with some plotting methods. In this case, suppose we suspect that the values in column 1 are 3 times higher on average in group “B”. We can easily visualize this with a boxplot: The result of calling boxplot is a dictionary whose keys are the values of our grouping column g (“A” and “B”). The values of the resulting dictionary can be controlled by the return_type keyword of boxplot . See the visualization documentation for more. Warning For historical reasons, df.groupby(""g"").boxplot() is not equivalent to df.boxplot(by=""g"") . See here for an explanation. Piping function calls # Similar to the functionality provided by DataFrame and Series , functions that take GroupBy objects can be chained together using a pipe method to allow for a cleaner, more readable syntax. To read about .pipe in general terms, see here . Combining .groupby and .pipe is often useful when you need to reuse GroupBy objects. As an example, imagine having a DataFrame with columns for stores, products, revenue and quantity sold. We’d like to do a groupwise calculation of prices (i.e. revenue/quantity) per store and per product. We could do this in a multi-step operation, but expressing it in terms of piping can make the code more readable. First we set the data: We now find the prices per store/product. Piping can also be expressive when you want to deliver a grouped object to some arbitrary function, for example: Here mean takes a GroupBy object and finds the mean of the Revenue and Quantity columns respectively for each Store-Product combination. The mean function can be any function that takes in a GroupBy object; the .pipe will pass the GroupBy object as a parameter into the function you specify. Examples # Multi-column factorization # By using DataFrameGroupBy.ngroup() , we can extract information about the groups in a way similar to factorize() (as described further in the reshaping API ) but which applies naturally to multiple columns of mixed type and different sources. This can be useful as an intermediate categorical-like step in processing, when the relationships between the group rows are more important than their content, or as input to an algorithm which only accepts the integer encoding. (For more information about support in pandas for full categorical data, see the Categorical introduction and the API documentation .) Groupby by indexer to ‘resample’ data # Resampling produces new hypothetical samples (resamples) from already existing observed data or from a model that generates data. These new samples are similar to the pre-existing samples. In order for resample to work on indices that are non-datetimelike, the following procedure can be utilized. In the following examples, df.index // 5 returns an integer array which is used to determine what gets selected for the groupby operation. Note The example below shows how we can downsample by consolidation of samples into fewer ones. Here by using df.index // 5 , we are aggregating the samples in bins. By applying std() function, we aggregate the information contained in many samples into a small subset of values which is their standard deviation thereby reducing the number of samples. Returning a Series to propagate names # Group DataFrame columns, compute a set of metrics and return a named Series. The Series name is used as the name for the column index. This is especially useful in conjunction with reshaping operations such as stacking, in which the column index name will be used as the name of the inserted column:"
https://pandas.pydata.org/docs/user_guide/window.html,Windowing operations,"<article class=""bd-article"" role=""main"">
<section id=""windowing-operations"">
<span id=""window""></span><h1>Windowing operations<a class=""headerlink"" href=""#windowing-operations"" title=""Link to this heading"">#</a></h1>
<p>pandas contains a compact set of APIs for performing windowing operations - an operation that performs
an aggregation over a sliding partition of values. The API functions similarly to the <code class=""docutils literal notranslate""><span class=""pre"">groupby</span></code> API
in that <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> call the windowing method with
necessary parameters and then subsequently call the aggregation function.</p>

<p>The windows are comprised by looking back the length of the window from the current observation.
The result above can be derived by taking the sum of the following windowed partitions of data:</p>

<section id=""overview"">
<span id=""window-overview""></span><h2>Overview<a class=""headerlink"" href=""#overview"" title=""Link to this heading"">#</a></h2>
<p>pandas supports 4 types of windowing operations:</p>
<ol class=""arabic simple"">
<li><p>Rolling window: Generic fixed or variable sliding window over the values.</p></li>
<li><p>Weighted window: Weighted, non-rectangular window supplied by the <code class=""docutils literal notranslate""><span class=""pre"">scipy.signal</span></code> library.</p></li>
<li><p>Expanding window: Accumulating window over the values.</p></li>
<li><p>Exponentially Weighted window: Accumulating and exponentially weighted window over the values.</p></li>
</ol>

<p>As noted above, some operations support specifying a window based on a time offset:</p>

<p>Additionally, some methods support chaining a <code class=""docutils literal notranslate""><span class=""pre"">groupby</span></code> operation with a windowing operation
which will first group the data by the specified keys and then perform a windowing operation per group.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Windowing operations currently only support numeric data (integer and float)
and will always return <code class=""docutils literal notranslate""><span class=""pre"">float64</span></code> values.</p>
</div>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Some windowing aggregation, <code class=""docutils literal notranslate""><span class=""pre"">mean</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">sum</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">var</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">std</span></code> methods may suffer from numerical
imprecision due to the underlying windowing algorithms accumulating sums. When values differ
with magnitude <span class=""math notranslate nohighlight"">\(1/np.finfo(np.double).eps\)</span> this results in truncation. It must be
noted, that large values may have an impact on windows, which do not include these values. <a class=""reference external"" href=""https://en.wikipedia.org/wiki/Kahan_summation_algorithm"">Kahan summation</a> is used
to compute the rolling sums to preserve accuracy as much as possible.</p>
</div>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.3.0.</span></p>
</div>
<p>Some windowing operations also support the <code class=""docutils literal notranslate""><span class=""pre"">method='table'</span></code> option in the constructor which
performs the windowing operation over an entire <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> instead of a single column or row at a time.
This can provide a useful performance benefit for a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> with many columns or rows
(with the corresponding <code class=""docutils literal notranslate""><span class=""pre"">axis</span></code> argument) or the ability to utilize other columns during the windowing
operation. The <code class=""docutils literal notranslate""><span class=""pre"">method='table'</span></code> option can only be used if <code class=""docutils literal notranslate""><span class=""pre"">engine='numba'</span></code> is specified
in the corresponding method call.</p>
<p>For example, a <a class=""reference external"" href=""https://en.wikipedia.org/wiki/Weighted_arithmetic_mean"">weighted mean</a> calculation can
be calculated with <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">apply()</span></code> by specifying a separate column of weights.</p>

<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.3.</span></p>
</div>
<p>Some windowing operations also support an <code class=""docutils literal notranslate""><span class=""pre"">online</span></code> method after constructing a windowing object
which returns a new object that supports passing in new <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> objects
to continue the windowing calculation with the new values (i.e. online calculations).</p>
<p>The methods on this new windowing objects must call the aggregation method first to “prime” the initial
state of the online calculation. Then, new <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> objects can be passed in
the <code class=""docutils literal notranslate""><span class=""pre"">update</span></code> argument to continue the windowing calculation.</p>


<p>All windowing operations support a <code class=""docutils literal notranslate""><span class=""pre"">min_periods</span></code> argument that dictates the minimum amount of
non-<code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code> values a window must have; otherwise, the resulting value is <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code>.
<code class=""docutils literal notranslate""><span class=""pre"">min_periods</span></code> defaults to 1 for time-based windows and <code class=""docutils literal notranslate""><span class=""pre"">window</span></code> for fixed windows</p>

<p>Additionally, all windowing operations supports the <code class=""docutils literal notranslate""><span class=""pre"">aggregate</span></code> method for returning a result
of multiple aggregations applied to a window.</p>

</section>
<section id=""rolling-window"">
<span id=""window-generic""></span><h2>Rolling window<a class=""headerlink"" href=""#rolling-window"" title=""Link to this heading"">#</a></h2>
<p>Generic rolling windows support specifying windows as a fixed number of observations or variable
number of observations based on an offset. If a time based offset is provided, the corresponding
time based index must be monotonic.</p>

<p>For all supported aggregation functions, see <a class=""reference internal"" href=""../reference/window.html#api-functions-rolling""><span class=""std std-ref"">Rolling window functions</span></a>.</p>
<section id=""centering-windows"">
<span id=""window-center""></span><h3>Centering windows<a class=""headerlink"" href=""#centering-windows"" title=""Link to this heading"">#</a></h3>
<p>By default the labels are set to the right edge of the window, but a
<code class=""docutils literal notranslate""><span class=""pre"">center</span></code> keyword is available so the labels can be set at the center.</p>

<p>This can also be applied to datetime-like indices.</p>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.3.0.</span></p>
</div>

</section>
<section id=""rolling-window-endpoints"">
<span id=""window-endpoints""></span><h3>Rolling window endpoints<a class=""headerlink"" href=""#rolling-window-endpoints"" title=""Link to this heading"">#</a></h3>
<p>The inclusion of the interval endpoints in rolling window calculations can be specified with the <code class=""docutils literal notranslate""><span class=""pre"">closed</span></code>
parameter:</p>

<p>For example, having the right endpoint open is useful in many problems that require that there is no contamination
from present information back to past information. This allows the rolling window to compute statistics
“up to that point in time”, but not including that point in time.</p>

</section>
<section id=""custom-window-rolling"">
<span id=""window-custom-rolling-window""></span><h3>Custom window rolling<a class=""headerlink"" href=""#custom-window-rolling"" title=""Link to this heading"">#</a></h3>
<p>In addition to accepting an integer or offset as a <code class=""docutils literal notranslate""><span class=""pre"">window</span></code> argument, <code class=""docutils literal notranslate""><span class=""pre"">rolling</span></code> also accepts
a <code class=""docutils literal notranslate""><span class=""pre"">BaseIndexer</span></code> subclass that allows a user to define a custom method for calculating window bounds.
The <code class=""docutils literal notranslate""><span class=""pre"">BaseIndexer</span></code> subclass will need to define a <code class=""docutils literal notranslate""><span class=""pre"">get_window_bounds</span></code> method that returns
a tuple of two arrays, the first being the starting indices of the windows and second being the
ending indices of the windows. Additionally, <code class=""docutils literal notranslate""><span class=""pre"">num_values</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">min_periods</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">center</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">closed</span></code>
and <code class=""docutils literal notranslate""><span class=""pre"">step</span></code> will automatically be passed to <code class=""docutils literal notranslate""><span class=""pre"">get_window_bounds</span></code> and the defined method must
always accept these arguments.</p>
<p>For example, if we have the following <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a></p>

<p>and we want to use an expanding window where <code class=""docutils literal notranslate""><span class=""pre"">use_expanding</span></code> is <code class=""docutils literal notranslate""><span class=""pre"">True</span></code> otherwise a window of size
1, we can create the following <code class=""docutils literal notranslate""><span class=""pre"">BaseIndexer</span></code> subclass:</p>

<p>You can view other examples of <code class=""docutils literal notranslate""><span class=""pre"">BaseIndexer</span></code> subclasses <a class=""reference external"" href=""https://github.com/pandas-dev/pandas/blob/main/pandas/core/indexers/objects.py"">here</a></p>
<p>One subclass of note within those examples is the <code class=""docutils literal notranslate""><span class=""pre"">VariableOffsetWindowIndexer</span></code> that allows
rolling operations over a non-fixed offset like a <code class=""docutils literal notranslate""><span class=""pre"">BusinessDay</span></code>.</p>

<p>For some problems knowledge of the future is available for analysis. For example, this occurs when
each data point is a full time series read from an experiment, and the task is to extract underlying
conditions. In these cases it can be useful to perform forward-looking rolling window computations.
<a class=""reference internal"" href=""../reference/api/pandas.api.indexers.FixedForwardWindowIndexer.html#pandas.api.indexers.FixedForwardWindowIndexer"" title=""pandas.api.indexers.FixedForwardWindowIndexer""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">FixedForwardWindowIndexer</span></code></a> class is available for this purpose.
This <a class=""reference internal"" href=""../reference/api/pandas.api.indexers.BaseIndexer.html#pandas.api.indexers.BaseIndexer"" title=""pandas.api.indexers.BaseIndexer""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">BaseIndexer</span></code></a> subclass implements a closed fixed-width
forward-looking rolling window, and we can use it as follows:</p>

<p>We can also achieve this by using slicing, applying rolling aggregation, and then flipping the result as shown in example below:</p>

</section>
<section id=""rolling-apply"">
<span id=""window-rolling-apply""></span><h3>Rolling apply<a class=""headerlink"" href=""#rolling-apply"" title=""Link to this heading"">#</a></h3>
<p>The <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">apply()</span></code> function takes an extra <code class=""docutils literal notranslate""><span class=""pre"">func</span></code> argument and performs
generic rolling computations. The <code class=""docutils literal notranslate""><span class=""pre"">func</span></code> argument should be a single function
that produces a single value from an ndarray input. <code class=""docutils literal notranslate""><span class=""pre"">raw</span></code> specifies whether
the windows are cast as <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> objects (<code class=""docutils literal notranslate""><span class=""pre"">raw=False</span></code>) or ndarray objects (<code class=""docutils literal notranslate""><span class=""pre"">raw=True</span></code>).</p>

</section>
<section id=""numba-engine"">
<span id=""window-numba-engine""></span><h3>Numba engine<a class=""headerlink"" href=""#numba-engine"" title=""Link to this heading"">#</a></h3>
<p>Additionally, <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">apply()</span></code> can leverage <a class=""reference external"" href=""https://numba.pydata.org/"">Numba</a>
if installed as an optional dependency. The apply aggregation can be executed using Numba by specifying
<code class=""docutils literal notranslate""><span class=""pre"">engine='numba'</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">engine_kwargs</span></code> arguments (<code class=""docutils literal notranslate""><span class=""pre"">raw</span></code> must also be set to <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>).
See <a class=""reference internal"" href=""enhancingperf.html#enhancingperf-numba""><span class=""std std-ref"">enhancing performance with Numba</span></a> for general usage of the arguments and performance considerations.</p>
<p>Numba will be applied in potentially two routines:</p>
<ol class=""arabic simple"">
<li><p>If <code class=""docutils literal notranslate""><span class=""pre"">func</span></code> is a standard Python function, the engine will <a class=""reference external"" href=""https://numba.pydata.org/numba-doc/latest/user/overview.html"">JIT</a> the passed function. <code class=""docutils literal notranslate""><span class=""pre"">func</span></code> can also be a JITed function in which case the engine will not JIT the function again.</p></li>
<li><p>The engine will JIT the for loop where the apply function is applied to each window.</p></li>
</ol>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">engine_kwargs</span></code> argument is a dictionary of keyword arguments that will be passed into the
<a class=""reference external"" href=""https://numba.pydata.org/numba-doc/latest/reference/jit-compilation.html#numba.jit"">numba.jit decorator</a>.
These keyword arguments will be applied to <em>both</em> the passed function (if a standard Python function)
and the apply for loop over each window.</p>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.3.0.</span></p>
</div>
<p><code class=""docutils literal notranslate""><span class=""pre"">mean</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">median</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">max</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">min</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">sum</span></code> also support the <code class=""docutils literal notranslate""><span class=""pre"">engine</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">engine_kwargs</span></code> arguments.</p>
</section>
<section id=""binary-window-functions"">
<span id=""window-cov-corr""></span><h3>Binary window functions<a class=""headerlink"" href=""#binary-window-functions"" title=""Link to this heading"">#</a></h3>
<p><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">cov()</span></code> and <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">corr()</span></code> can compute moving window statistics about
two <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or any combination of <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>/<a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>/<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>. Here is the behavior in each case:</p>
<ul class=""simple"">
<li><p>two <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>: compute the statistic for the pairing.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>/<a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>: compute the statistics for each column of the DataFrame
with the passed Series, thus returning a DataFrame.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>/<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>: by default compute the statistic for matching column
names, returning a DataFrame. If the keyword argument <code class=""docutils literal notranslate""><span class=""pre"">pairwise=True</span></code> is
passed then computes the statistic for each pair of columns, returning a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> with a
<a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a> whose values are the dates in question (see <a class=""reference internal"" href=""#window-corr-pairwise""><span class=""std std-ref"">the next section</span></a>).</p></li>
</ul>
<p>For example:</p>

</section>
<section id=""computing-rolling-pairwise-covariances-and-correlations"">
<span id=""window-corr-pairwise""></span><h3>Computing rolling pairwise covariances and correlations<a class=""headerlink"" href=""#computing-rolling-pairwise-covariances-and-correlations"" title=""Link to this heading"">#</a></h3>
<p>In financial data analysis and other fields it’s common to compute covariance
and correlation matrices for a collection of time series. Often one is also
interested in moving-window covariance and correlation matrices. This can be
done by passing the <code class=""docutils literal notranslate""><span class=""pre"">pairwise</span></code> keyword argument, which in the case of
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> inputs will yield a MultiIndexed <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> whose <code class=""docutils literal notranslate""><span class=""pre"">index</span></code> are the dates in
question. In the case of a single DataFrame argument the <code class=""docutils literal notranslate""><span class=""pre"">pairwise</span></code> argument
can even be omitted:</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Missing values are ignored and each entry is computed using the pairwise
complete observations.</p>
<p>Assuming the missing data are missing at random this results in an estimate
for the covariance matrix which is unbiased. However, for many applications
this estimate may not be acceptable because the estimated covariance matrix
is not guaranteed to be positive semi-definite. This could lead to
estimated correlations having absolute values which are greater than one,
and/or a non-invertible covariance matrix. See <a class=""reference external"" href=""https://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_matrices"">Estimation of covariance
matrices</a>
for more details.</p>
</div>

</section>
</section>
<section id=""weighted-window"">
<span id=""window-weighted""></span><h2>Weighted window<a class=""headerlink"" href=""#weighted-window"" title=""Link to this heading"">#</a></h2>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">win_type</span></code> argument in <code class=""docutils literal notranslate""><span class=""pre"">.rolling</span></code> generates a weighted windows that are commonly used in filtering
and spectral estimation. <code class=""docutils literal notranslate""><span class=""pre"">win_type</span></code> must be string that corresponds to a <a class=""reference external"" href=""https://docs.scipy.org/doc/scipy/reference/signal.windows.html#module-scipy.signal.windows"">scipy.signal window function</a>.
Scipy must be installed in order to use these windows, and supplementary arguments
that the Scipy window methods take must be specified in the aggregation function.</p>

<p>For all supported aggregation functions, see <a class=""reference internal"" href=""../reference/window.html#api-functions-window""><span class=""std std-ref"">Weighted window functions</span></a>.</p>
</section>
<section id=""expanding-window"">
<span id=""window-expanding""></span><h2>Expanding window<a class=""headerlink"" href=""#expanding-window"" title=""Link to this heading"">#</a></h2>
<p>An expanding window yields the value of an aggregation statistic with all the data available up to that
point in time. Since these calculations are a special case of rolling statistics,
they are implemented in pandas such that the following two calls are equivalent:</p>

<p>For all supported aggregation functions, see <a class=""reference internal"" href=""../reference/window.html#api-functions-expanding""><span class=""std std-ref"">Expanding window functions</span></a>.</p>
</section>
<section id=""exponentially-weighted-window"">
<span id=""window-exponentially-weighted""></span><h2>Exponentially weighted window<a class=""headerlink"" href=""#exponentially-weighted-window"" title=""Link to this heading"">#</a></h2>
<p>An exponentially weighted window is similar to an expanding window but with each prior point
being exponentially weighted down relative to the current point.</p>
<p>In general, a weighted moving average is calculated as</p>
<div class=""math notranslate nohighlight"">
\[y_t = \frac{\sum_{i=0}^t w_i x_{t-i}}{\sum_{i=0}^t w_i},\]</div>
<p>where <span class=""math notranslate nohighlight"">\(x_t\)</span> is the input, <span class=""math notranslate nohighlight"">\(y_t\)</span> is the result and the <span class=""math notranslate nohighlight"">\(w_i\)</span>
are the weights.</p>
<p>For all supported aggregation functions, see <a class=""reference internal"" href=""../reference/window.html#api-functions-ewm""><span class=""std std-ref"">Exponentially-weighted window functions</span></a>.</p>
<p>The EW functions support two variants of exponential weights.
The default, <code class=""docutils literal notranslate""><span class=""pre"">adjust=True</span></code>, uses the weights <span class=""math notranslate nohighlight"">\(w_i = (1 - \alpha)^i\)</span>
which gives</p>
<div class=""math notranslate nohighlight"">
\[y_t = \frac{x_t + (1 - \alpha)x_{t-1} + (1 - \alpha)^2 x_{t-2} + ...
+ (1 - \alpha)^t x_{0}}{1 + (1 - \alpha) + (1 - \alpha)^2 + ...
+ (1 - \alpha)^t}\]</div>
<p>When <code class=""docutils literal notranslate""><span class=""pre"">adjust=False</span></code> is specified, moving averages are calculated as</p>
<div class=""math notranslate nohighlight"">
\[\begin{split}y_0 &amp;= x_0 \\
y_t &amp;= (1 - \alpha) y_{t-1} + \alpha x_t,\end{split}\]</div>
<p>which is equivalent to using weights</p>
<div class=""math notranslate nohighlight"">
\[\begin{split}w_i = \begin{cases}
\alpha (1 - \alpha)^i &amp; \text{if } i &lt; t \\
(1 - \alpha)^i &amp; \text{if } i = t.
\end{cases}\end{split}\]</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>These equations are sometimes written in terms of <span class=""math notranslate nohighlight"">\(\alpha' = 1 - \alpha\)</span>, e.g.</p>
<div class=""math notranslate nohighlight"">
\[y_t = \alpha' y_{t-1} + (1 - \alpha') x_t.\]</div>
</div>
<p>The difference between the above two variants arises because we are
dealing with series which have finite history. Consider a series of infinite
history, with <code class=""docutils literal notranslate""><span class=""pre"">adjust=True</span></code>:</p>
<div class=""math notranslate nohighlight"">
\[y_t = \frac{x_t + (1 - \alpha)x_{t-1} + (1 - \alpha)^2 x_{t-2} + ...}
{1 + (1 - \alpha) + (1 - \alpha)^2 + ...}\]</div>
<p>Noting that the denominator is a geometric series with initial term equal to 1
and a ratio of <span class=""math notranslate nohighlight"">\(1 - \alpha\)</span> we have</p>
<div class=""math notranslate nohighlight"">
\[\begin{split}y_t &amp;= \frac{x_t + (1 - \alpha)x_{t-1} + (1 - \alpha)^2 x_{t-2} + ...}
{\frac{1}{1 - (1 - \alpha)}}\\
&amp;= [x_t + (1 - \alpha)x_{t-1} + (1 - \alpha)^2 x_{t-2} + ...] \alpha \\
&amp;= \alpha x_t + [(1-\alpha)x_{t-1} + (1 - \alpha)^2 x_{t-2} + ...]\alpha \\
&amp;= \alpha x_t + (1 - \alpha)[x_{t-1} + (1 - \alpha) x_{t-2} + ...]\alpha\\
&amp;= \alpha x_t + (1 - \alpha) y_{t-1}\end{split}\]</div>
<p>which is the same expression as <code class=""docutils literal notranslate""><span class=""pre"">adjust=False</span></code> above and therefore
shows the equivalence of the two variants for infinite series.
When <code class=""docutils literal notranslate""><span class=""pre"">adjust=False</span></code>, we have <span class=""math notranslate nohighlight"">\(y_0 = x_0\)</span> and
<span class=""math notranslate nohighlight"">\(y_t = \alpha x_t + (1 - \alpha) y_{t-1}\)</span>.
Therefore, there is an assumption that <span class=""math notranslate nohighlight"">\(x_0\)</span> is not an ordinary value
but rather an exponentially weighted moment of the infinite series up to that
point.</p>
<p>One must have <span class=""math notranslate nohighlight"">\(0 &lt; \alpha \leq 1\)</span>, and while it is possible to pass
<span class=""math notranslate nohighlight"">\(\alpha\)</span> directly, it’s often easier to think about either the
<strong>span</strong>, <strong>center of mass (com)</strong> or <strong>half-life</strong> of an EW moment:</p>
<div class=""math notranslate nohighlight"">
\[\begin{split}\alpha =
\begin{cases}
\frac{2}{s + 1}, &amp; \text{for span}\ s \geq 1\\
\frac{1}{1 + c}, &amp; \text{for center of mass}\ c \geq 0\\
1 - \exp^{\frac{\log 0.5}{h}}, &amp; \text{for half-life}\ h &gt; 0
\end{cases}\end{split}\]</div>
<p>One must specify precisely one of <strong>span</strong>, <strong>center of mass</strong>, <strong>half-life</strong>
and <strong>alpha</strong> to the EW functions:</p>
<ul class=""simple"">
<li><p><strong>Span</strong> corresponds to what is commonly called an “N-day EW moving average”.</p></li>
<li><p><strong>Center of mass</strong> has a more physical interpretation and can be thought of
in terms of span: <span class=""math notranslate nohighlight"">\(c = (s - 1) / 2\)</span>.</p></li>
<li><p><strong>Half-life</strong> is the period of time for the exponential weight to reduce to
one half.</p></li>
<li><p><strong>Alpha</strong> specifies the smoothing factor directly.</p></li>
</ul>
<p>You can also specify <code class=""docutils literal notranslate""><span class=""pre"">halflife</span></code> in terms of a timedelta convertible unit to specify the amount of
time it takes for an observation to decay to half its value when also specifying a sequence
of <code class=""docutils literal notranslate""><span class=""pre"">times</span></code>.</p>

<p>The following formula is used to compute exponentially weighted mean with an input vector of times:</p>
<div class=""math notranslate nohighlight"">
\[y_t = \frac{\sum_{i=0}^t 0.5^\frac{t_{t} - t_{i}}{\lambda} x_{t-i}}{\sum_{i=0}^t 0.5^\frac{t_{t} - t_{i}}{\lambda}},\]</div>
<p>ExponentialMovingWindow also has an <code class=""docutils literal notranslate""><span class=""pre"">ignore_na</span></code> argument, which determines how
intermediate null values affect the calculation of the weights.
When <code class=""docutils literal notranslate""><span class=""pre"">ignore_na=False</span></code> (the default), weights are calculated based on absolute
positions, so that intermediate null values affect the result.
When <code class=""docutils literal notranslate""><span class=""pre"">ignore_na=True</span></code>,
weights are calculated by ignoring intermediate null values.
For example, assuming <code class=""docutils literal notranslate""><span class=""pre"">adjust=True</span></code>, if <code class=""docutils literal notranslate""><span class=""pre"">ignore_na=False</span></code>, the weighted
average of <code class=""docutils literal notranslate""><span class=""pre"">3,</span> <span class=""pre"">NaN,</span> <span class=""pre"">5</span></code> would be calculated as</p>
<div class=""math notranslate nohighlight"">
\[\frac{(1-\alpha)^2 \cdot 3 + 1 \cdot 5}{(1-\alpha)^2 + 1}.\]</div>
<p>Whereas if <code class=""docutils literal notranslate""><span class=""pre"">ignore_na=True</span></code>, the weighted average would be calculated as</p>
<div class=""math notranslate nohighlight"">
\[\frac{(1-\alpha) \cdot 3 + 1 \cdot 5}{(1-\alpha) + 1}.\]</div>
<p>The <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">var()</span></code>, <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">std()</span></code>, and <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">cov()</span></code> functions have a <code class=""docutils literal notranslate""><span class=""pre"">bias</span></code> argument,
specifying whether the result should contain biased or unbiased statistics.
For example, if <code class=""docutils literal notranslate""><span class=""pre"">bias=True</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">ewmvar(x)</span></code> is calculated as
<code class=""docutils literal notranslate""><span class=""pre"">ewmvar(x)</span> <span class=""pre"">=</span> <span class=""pre"">ewma(x**2)</span> <span class=""pre"">-</span> <span class=""pre"">ewma(x)**2</span></code>;
whereas if <code class=""docutils literal notranslate""><span class=""pre"">bias=False</span></code> (the default), the biased variance statistics
are scaled by debiasing factors</p>
<div class=""math notranslate nohighlight"">
\[\frac{\left(\sum_{i=0}^t w_i\right)^2}{\left(\sum_{i=0}^t w_i\right)^2 - \sum_{i=0}^t w_i^2}.\]</div>
<p>(For <span class=""math notranslate nohighlight"">\(w_i = 1\)</span>, this reduces to the usual <span class=""math notranslate nohighlight"">\(N / (N - 1)\)</span> factor,
with <span class=""math notranslate nohighlight"">\(N = t + 1\)</span>.)
See <a class=""reference external"" href=""https://en.wikipedia.org/wiki/Weighted_arithmetic_mean#Weighted_sample_variance"">Weighted Sample Variance</a>
on Wikipedia for further details.</p>
</section>
</section>
</article>","Windowing operations # pandas contains a compact set of APIs for performing windowing operations - an operation that performs an aggregation over a sliding partition of values. The API functions similarly to the groupby API in that Series and DataFrame call the windowing method with necessary parameters and then subsequently call the aggregation function. The windows are comprised by looking back the length of the window from the current observation. The result above can be derived by taking the sum of the following windowed partitions of data: Overview # pandas supports 4 types of windowing operations: Rolling window: Generic fixed or variable sliding window over the values. Weighted window: Weighted, non-rectangular window supplied by the scipy.signal library. Expanding window: Accumulating window over the values. Exponentially Weighted window: Accumulating and exponentially weighted window over the values. As noted above, some operations support specifying a window based on a time offset: Additionally, some methods support chaining a groupby operation with a windowing operation which will first group the data by the specified keys and then perform a windowing operation per group. Note Windowing operations currently only support numeric data (integer and float) and will always return float64 values. Warning Some windowing aggregation, mean , sum , var and std methods may suffer from numerical imprecision due to the underlying windowing algorithms accumulating sums. When values differ with magnitude \(1/np.finfo(np.double).eps\) this results in truncation. It must be noted, that large values may have an impact on windows, which do not include these values. Kahan summation is used to compute the rolling sums to preserve accuracy as much as possible. New in version 1.3.0. Some windowing operations also support the method='table' option in the constructor which performs the windowing operation over an entire DataFrame instead of a single column or row at a time. This can provide a useful performance benefit for a DataFrame with many columns or rows (with the corresponding axis argument) or the ability to utilize other columns during the windowing operation. The method='table' option can only be used if engine='numba' is specified in the corresponding method call. For example, a weighted mean calculation can be calculated with apply() by specifying a separate column of weights. New in version 1.3. Some windowing operations also support an online method after constructing a windowing object which returns a new object that supports passing in new DataFrame or Series objects to continue the windowing calculation with the new values (i.e. online calculations). The methods on this new windowing objects must call the aggregation method first to “prime” the initial state of the online calculation. Then, new DataFrame or Series objects can be passed in the update argument to continue the windowing calculation. All windowing operations support a min_periods argument that dictates the minimum amount of non- np.nan values a window must have; otherwise, the resulting value is np.nan . min_periods defaults to 1 for time-based windows and window for fixed windows Additionally, all windowing operations supports the aggregate method for returning a result of multiple aggregations applied to a window. Rolling window # Generic rolling windows support specifying windows as a fixed number of observations or variable number of observations based on an offset. If a time based offset is provided, the corresponding time based index must be monotonic. For all supported aggregation functions, see Rolling window functions . Centering windows # By default the labels are set to the right edge of the window, but a center keyword is available so the labels can be set at the center. This can also be applied to datetime-like indices. New in version 1.3.0. Rolling window endpoints # The inclusion of the interval endpoints in rolling window calculations can be specified with the closed parameter: For example, having the right endpoint open is useful in many problems that require that there is no contamination from present information back to past information. This allows the rolling window to compute statistics “up to that point in time”, but not including that point in time. Custom window rolling # In addition to accepting an integer or offset as a window argument, rolling also accepts a BaseIndexer subclass that allows a user to define a custom method for calculating window bounds. The BaseIndexer subclass will need to define a get_window_bounds method that returns a tuple of two arrays, the first being the starting indices of the windows and second being the ending indices of the windows. Additionally, num_values , min_periods , center , closed and step will automatically be passed to get_window_bounds and the defined method must always accept these arguments. For example, if we have the following DataFrame and we want to use an expanding window where use_expanding is True otherwise a window of size 1, we can create the following BaseIndexer subclass: You can view other examples of BaseIndexer subclasses here One subclass of note within those examples is the VariableOffsetWindowIndexer that allows rolling operations over a non-fixed offset like a BusinessDay . For some problems knowledge of the future is available for analysis. For example, this occurs when each data point is a full time series read from an experiment, and the task is to extract underlying conditions. In these cases it can be useful to perform forward-looking rolling window computations. FixedForwardWindowIndexer class is available for this purpose. This BaseIndexer subclass implements a closed fixed-width forward-looking rolling window, and we can use it as follows: We can also achieve this by using slicing, applying rolling aggregation, and then flipping the result as shown in example below: Rolling apply # The apply() function takes an extra func argument and performs generic rolling computations. The func argument should be a single function that produces a single value from an ndarray input. raw specifies whether the windows are cast as Series objects ( raw=False ) or ndarray objects ( raw=True ). Numba engine # Additionally, apply() can leverage Numba if installed as an optional dependency. The apply aggregation can be executed using Numba by specifying engine='numba' and engine_kwargs arguments ( raw must also be set to True ). See enhancing performance with Numba for general usage of the arguments and performance considerations. Numba will be applied in potentially two routines: If func is a standard Python function, the engine will JIT the passed function. func can also be a JITed function in which case the engine will not JIT the function again. The engine will JIT the for loop where the apply function is applied to each window. The engine_kwargs argument is a dictionary of keyword arguments that will be passed into the numba.jit decorator . These keyword arguments will be applied to both the passed function (if a standard Python function) and the apply for loop over each window. New in version 1.3.0. mean , median , max , min , and sum also support the engine and engine_kwargs arguments. Binary window functions # cov() and corr() can compute moving window statistics about two Series or any combination of DataFrame / Series or DataFrame / DataFrame . Here is the behavior in each case: two Series : compute the statistic for the pairing. DataFrame / Series : compute the statistics for each column of the DataFrame with the passed Series, thus returning a DataFrame. DataFrame / DataFrame : by default compute the statistic for matching column names, returning a DataFrame. If the keyword argument pairwise=True is passed then computes the statistic for each pair of columns, returning a DataFrame with a MultiIndex whose values are the dates in question (see the next section ). For example: Computing rolling pairwise covariances and correlations # In financial data analysis and other fields it’s common to compute covariance and correlation matrices for a collection of time series. Often one is also interested in moving-window covariance and correlation matrices. This can be done by passing the pairwise keyword argument, which in the case of DataFrame inputs will yield a MultiIndexed DataFrame whose index are the dates in question. In the case of a single DataFrame argument the pairwise argument can even be omitted: Note Missing values are ignored and each entry is computed using the pairwise complete observations. Assuming the missing data are missing at random this results in an estimate for the covariance matrix which is unbiased. However, for many applications this estimate may not be acceptable because the estimated covariance matrix is not guaranteed to be positive semi-definite. This could lead to estimated correlations having absolute values which are greater than one, and/or a non-invertible covariance matrix. See Estimation of covariance matrices for more details. Weighted window # The win_type argument in .rolling generates a weighted windows that are commonly used in filtering and spectral estimation. win_type must be string that corresponds to a scipy.signal window function . Scipy must be installed in order to use these windows, and supplementary arguments that the Scipy window methods take must be specified in the aggregation function. For all supported aggregation functions, see Weighted window functions . Expanding window # An expanding window yields the value of an aggregation statistic with all the data available up to that point in time. Since these calculations are a special case of rolling statistics, they are implemented in pandas such that the following two calls are equivalent: For all supported aggregation functions, see Expanding window functions . Exponentially weighted window # An exponentially weighted window is similar to an expanding window but with each prior point being exponentially weighted down relative to the current point. In general, a weighted moving average is calculated as \[y_t = \frac{\sum_{i=0}^t w_i x_{t-i}}{\sum_{i=0}^t w_i},\] where \(x_t\) is the input, \(y_t\) is the result and the \(w_i\) are the weights. For all supported aggregation functions, see Exponentially-weighted window functions . The EW functions support two variants of exponential weights. The default, adjust=True , uses the weights \(w_i = (1 - \alpha)^i\) which gives \[y_t = \frac{x_t + (1 - \alpha)x_{t-1} + (1 - \alpha)^2 x_{t-2} + ... + (1 - \alpha)^t x_{0}}{1 + (1 - \alpha) + (1 - \alpha)^2 + ... + (1 - \alpha)^t}\] When adjust=False is specified, moving averages are calculated as \[\begin{split}y_0 &= x_0 \\ y_t &= (1 - \alpha) y_{t-1} + \alpha x_t,\end{split}\] which is equivalent to using weights \[\begin{split}w_i = \begin{cases} \alpha (1 - \alpha)^i & \text{if } i < t \\ (1 - \alpha)^i & \text{if } i = t. \end{cases}\end{split}\] Note These equations are sometimes written in terms of \(\alpha' = 1 - \alpha\) , e.g. \[y_t = \alpha' y_{t-1} + (1 - \alpha') x_t.\] The difference between the above two variants arises because we are dealing with series which have finite history. Consider a series of infinite history, with adjust=True : \[y_t = \frac{x_t + (1 - \alpha)x_{t-1} + (1 - \alpha)^2 x_{t-2} + ...} {1 + (1 - \alpha) + (1 - \alpha)^2 + ...}\] Noting that the denominator is a geometric series with initial term equal to 1 and a ratio of \(1 - \alpha\) we have \[\begin{split}y_t &= \frac{x_t + (1 - \alpha)x_{t-1} + (1 - \alpha)^2 x_{t-2} + ...} {\frac{1}{1 - (1 - \alpha)}}\\ &= [x_t + (1 - \alpha)x_{t-1} + (1 - \alpha)^2 x_{t-2} + ...] \alpha \\ &= \alpha x_t + [(1-\alpha)x_{t-1} + (1 - \alpha)^2 x_{t-2} + ...]\alpha \\ &= \alpha x_t + (1 - \alpha)[x_{t-1} + (1 - \alpha) x_{t-2} + ...]\alpha\\ &= \alpha x_t + (1 - \alpha) y_{t-1}\end{split}\] which is the same expression as adjust=False above and therefore shows the equivalence of the two variants for infinite series. When adjust=False , we have \(y_0 = x_0\) and \(y_t = \alpha x_t + (1 - \alpha) y_{t-1}\) . Therefore, there is an assumption that \(x_0\) is not an ordinary value but rather an exponentially weighted moment of the infinite series up to that point. One must have \(0 < \alpha \leq 1\) , and while it is possible to pass \(\alpha\) directly, it’s often easier to think about either the span , center of mass (com) or half-life of an EW moment: \[\begin{split}\alpha = \begin{cases} \frac{2}{s + 1}, & \text{for span}\ s \geq 1\\ \frac{1}{1 + c}, & \text{for center of mass}\ c \geq 0\\ 1 - \exp^{\frac{\log 0.5}{h}}, & \text{for half-life}\ h > 0 \end{cases}\end{split}\] One must specify precisely one of span , center of mass , half-life and alpha to the EW functions: Span corresponds to what is commonly called an “N-day EW moving average”. Center of mass has a more physical interpretation and can be thought of in terms of span: \(c = (s - 1) / 2\) . Half-life is the period of time for the exponential weight to reduce to one half. Alpha specifies the smoothing factor directly. You can also specify halflife in terms of a timedelta convertible unit to specify the amount of time it takes for an observation to decay to half its value when also specifying a sequence of times . The following formula is used to compute exponentially weighted mean with an input vector of times: \[y_t = \frac{\sum_{i=0}^t 0.5^\frac{t_{t} - t_{i}}{\lambda} x_{t-i}}{\sum_{i=0}^t 0.5^\frac{t_{t} - t_{i}}{\lambda}},\] ExponentialMovingWindow also has an ignore_na argument, which determines how intermediate null values affect the calculation of the weights. When ignore_na=False (the default), weights are calculated based on absolute positions, so that intermediate null values affect the result. When ignore_na=True , weights are calculated by ignoring intermediate null values. For example, assuming adjust=True , if ignore_na=False , the weighted average of 3, NaN, 5 would be calculated as \[\frac{(1-\alpha)^2 \cdot 3 + 1 \cdot 5}{(1-\alpha)^2 + 1}.\] Whereas if ignore_na=True , the weighted average would be calculated as \[\frac{(1-\alpha) \cdot 3 + 1 \cdot 5}{(1-\alpha) + 1}.\] The var() , std() , and cov() functions have a bias argument, specifying whether the result should contain biased or unbiased statistics. For example, if bias=True , ewmvar(x) is calculated as ewmvar(x) = ewma(x**2) - ewma(x)**2 ; whereas if bias=False (the default), the biased variance statistics are scaled by debiasing factors \[\frac{\left(\sum_{i=0}^t w_i\right)^2}{\left(\sum_{i=0}^t w_i\right)^2 - \sum_{i=0}^t w_i^2}.\] (For \(w_i = 1\) , this reduces to the usual \(N / (N - 1)\) factor, with \(N = t + 1\) .) See Weighted Sample Variance on Wikipedia for further details."
https://pandas.pydata.org/docs/user_guide/timeseries.html,Time series / date functionality,"<article class=""bd-article"" role=""main"">
<section id=""time-series-date-functionality"">
<span id=""timeseries""></span><h1>Time series / date functionality<a class=""headerlink"" href=""#time-series-date-functionality"" title=""Link to this heading"">#</a></h1>
<p>pandas contains extensive capabilities and features for working with time series data for all domains.
Using the NumPy <code class=""docutils literal notranslate""><span class=""pre"">datetime64</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">timedelta64</span></code> dtypes, pandas has consolidated a large number of
features from other Python libraries like <code class=""docutils literal notranslate""><span class=""pre"">scikits.timeseries</span></code> as well as created
a tremendous amount of new functionality for manipulating time series data.</p>
<p>For example, pandas supports:</p>
<p>Parsing time series information from various sources and formats</p>

<p>Generate sequences of fixed-frequency dates and time spans</p>

<p>Manipulating and converting date times with timezone information</p>

<p>Resampling or converting a time series to a particular frequency</p>

<p>Performing date and time arithmetic with absolute or relative time increments</p>

<p>pandas provides a relatively compact and self-contained set of tools for
performing the above tasks and more.</p>
<section id=""overview"">
<span id=""timeseries-overview""></span><h2>Overview<a class=""headerlink"" href=""#overview"" title=""Link to this heading"">#</a></h2>
<p>pandas captures 4 general time related concepts:</p>
<ol class=""arabic simple"">
<li><p>Date times: A specific date and time with timezone support. Similar to <code class=""docutils literal notranslate""><span class=""pre"">datetime.datetime</span></code> from the standard library.</p></li>
<li><p>Time deltas: An absolute time duration. Similar to <code class=""docutils literal notranslate""><span class=""pre"">datetime.timedelta</span></code> from the standard library.</p></li>
<li><p>Time spans: A span of time defined by a point in time and its associated frequency.</p></li>
<li><p>Date offsets: A relative time duration that respects calendar arithmetic. Similar to <code class=""docutils literal notranslate""><span class=""pre"">dateutil.relativedelta.relativedelta</span></code> from the <code class=""docutils literal notranslate""><span class=""pre"">dateutil</span></code> package.</p></li>
</ol>

<p>For time series data, it’s conventional to represent the time component in the index of a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>
so manipulations can be performed with respect to the time element.</p>

<p>However, <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> can directly also support the time component as data itself.</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> have extended data type support and functionality for <code class=""docutils literal notranslate""><span class=""pre"">datetime</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">timedelta</span></code>
and <code class=""docutils literal notranslate""><span class=""pre"">Period</span></code> data when passed into those constructors. <code class=""docutils literal notranslate""><span class=""pre"">DateOffset</span></code>
data however will be stored as <code class=""docutils literal notranslate""><span class=""pre"">object</span></code> data.</p>

<p>Lastly, pandas represents null date times, time deltas, and time spans as <code class=""docutils literal notranslate""><span class=""pre"">NaT</span></code> which
is useful for representing missing or null date like values and behaves similar
as <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code> does for float data.</p>

</section>
<section id=""timestamps-vs-time-spans"">
<span id=""timeseries-representation""></span><h2>Timestamps vs. time spans<a class=""headerlink"" href=""#timestamps-vs-time-spans"" title=""Link to this heading"">#</a></h2>
<p>Timestamped data is the most basic type of time series data that associates
values with points in time. For pandas objects it means using the points in
time.</p>

<p>However, in many cases it is more natural to associate things like change
variables with a time span instead. The span represented by <code class=""docutils literal notranslate""><span class=""pre"">Period</span></code> can be
specified explicitly, or inferred from datetime string format.</p>
<p>For example:</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.Timestamp.html#pandas.Timestamp"" title=""pandas.Timestamp""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Timestamp</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.Period.html#pandas.Period"" title=""pandas.Period""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Period</span></code></a> can serve as an index. Lists of
<code class=""docutils literal notranslate""><span class=""pre"">Timestamp</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">Period</span></code> are automatically coerced to <a class=""reference internal"" href=""../reference/api/pandas.DatetimeIndex.html#pandas.DatetimeIndex"" title=""pandas.DatetimeIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code></a>
and <a class=""reference internal"" href=""../reference/api/pandas.PeriodIndex.html#pandas.PeriodIndex"" title=""pandas.PeriodIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code></a> respectively.</p>

<p>pandas allows you to capture both representations and
convert between them. Under the hood, pandas represents timestamps using
instances of <code class=""docutils literal notranslate""><span class=""pre"">Timestamp</span></code> and sequences of timestamps using instances of
<code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code>. For regular time spans, pandas uses <code class=""docutils literal notranslate""><span class=""pre"">Period</span></code> objects for
scalar values and <code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code> for sequences of spans. Better support for
irregular intervals with arbitrary start and end points are forth-coming in
future releases.</p>
</section>
<section id=""converting-to-timestamps"">
<span id=""timeseries-converting""></span><h2>Converting to timestamps<a class=""headerlink"" href=""#converting-to-timestamps"" title=""Link to this heading"">#</a></h2>
<p>To convert a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or list-like object of date-like objects e.g. strings,
epochs, or a mixture, you can use the <code class=""docutils literal notranslate""><span class=""pre"">to_datetime</span></code> function. When passed
a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>, this returns a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> (with the same index), while a list-like
is converted to a <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code>:</p>

<p>If you use dates which start with the day first (i.e. European style),
you can pass the <code class=""docutils literal notranslate""><span class=""pre"">dayfirst</span></code> flag:</p>

<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>You see in the above example that <code class=""docutils literal notranslate""><span class=""pre"">dayfirst</span></code> isn’t strict. If a date
can’t be parsed with the day being first it will be parsed as if
<code class=""docutils literal notranslate""><span class=""pre"">dayfirst</span></code> were <code class=""docutils literal notranslate""><span class=""pre"">False</span></code> and a warning will also be raised.</p>
</div>
<p>If you pass a single string to <code class=""docutils literal notranslate""><span class=""pre"">to_datetime</span></code>, it returns a single <code class=""docutils literal notranslate""><span class=""pre"">Timestamp</span></code>.
<code class=""docutils literal notranslate""><span class=""pre"">Timestamp</span></code> can also accept string input, but it doesn’t accept string parsing
options like <code class=""docutils literal notranslate""><span class=""pre"">dayfirst</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">format</span></code>, so use <code class=""docutils literal notranslate""><span class=""pre"">to_datetime</span></code> if these are required.</p>

<p>You can also use the <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> constructor directly:</p>

<p>The string ‘infer’ can be passed in order to set the frequency of the index as the
inferred frequency upon creation:</p>

<section id=""providing-a-format-argument"">
<span id=""timeseries-converting-format""></span><h3>Providing a format argument<a class=""headerlink"" href=""#providing-a-format-argument"" title=""Link to this heading"">#</a></h3>
<p>In addition to the required datetime string, a <code class=""docutils literal notranslate""><span class=""pre"">format</span></code> argument can be passed to ensure specific parsing.
This could also potentially speed up the conversion considerably.</p>

<p>For more information on the choices available when specifying the <code class=""docutils literal notranslate""><span class=""pre"">format</span></code>
option, see the Python <a class=""reference external"" href=""https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior"">datetime documentation</a>.</p>
</section>
<section id=""assembling-datetime-from-multiple-dataframe-columns"">
<h3>Assembling datetime from multiple DataFrame columns<a class=""headerlink"" href=""#assembling-datetime-from-multiple-dataframe-columns"" title=""Link to this heading"">#</a></h3>
<p>You can also pass a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> of integer or string columns to assemble into a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> of <code class=""docutils literal notranslate""><span class=""pre"">Timestamps</span></code>.</p>

<p>You can pass only the columns that you need to assemble.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">pd.to_datetime</span></code> looks for standard designations of the datetime component in the column names, including:</p>
<ul class=""simple"">
<li><p>required: <code class=""docutils literal notranslate""><span class=""pre"">year</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">month</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">day</span></code></p></li>
<li><p>optional: <code class=""docutils literal notranslate""><span class=""pre"">hour</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">minute</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">second</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">millisecond</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">microsecond</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">nanosecond</span></code></p></li>
</ul>
</section>
<section id=""invalid-data"">
<h3>Invalid data<a class=""headerlink"" href=""#invalid-data"" title=""Link to this heading"">#</a></h3>
<p>The default behavior, <code class=""docutils literal notranslate""><span class=""pre"">errors='raise'</span></code>, is to raise when unparsable:</p>

<p>Pass <code class=""docutils literal notranslate""><span class=""pre"">errors='coerce'</span></code> to convert unparsable data to <code class=""docutils literal notranslate""><span class=""pre"">NaT</span></code> (not a time):</p>

</section>
<section id=""epoch-timestamps"">
<span id=""timeseries-converting-epoch""></span><h3>Epoch timestamps<a class=""headerlink"" href=""#epoch-timestamps"" title=""Link to this heading"">#</a></h3>
<p>pandas supports converting integer or float epoch times to <code class=""docutils literal notranslate""><span class=""pre"">Timestamp</span></code> and
<code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code>. The default unit is nanoseconds, since that is how <code class=""docutils literal notranslate""><span class=""pre"">Timestamp</span></code>
objects are stored internally. However, epochs are often stored in another <code class=""docutils literal notranslate""><span class=""pre"">unit</span></code>
which can be specified. These are computed from the starting point specified by the
<code class=""docutils literal notranslate""><span class=""pre"">origin</span></code> parameter.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">unit</span></code> parameter does not use the same strings as the <code class=""docutils literal notranslate""><span class=""pre"">format</span></code> parameter
that was discussed <a class=""reference internal"" href=""#timeseries-converting-format""><span class=""std std-ref"">above</span></a>). The
available units are listed on the documentation for <a class=""reference internal"" href=""../reference/api/pandas.to_datetime.html#pandas.to_datetime"" title=""pandas.to_datetime""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.to_datetime()</span></code></a>.</p>
</div>
<p>Constructing a <a class=""reference internal"" href=""../reference/api/pandas.Timestamp.html#pandas.Timestamp"" title=""pandas.Timestamp""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Timestamp</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DatetimeIndex.html#pandas.DatetimeIndex"" title=""pandas.DatetimeIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code></a> with an epoch timestamp
with the <code class=""docutils literal notranslate""><span class=""pre"">tz</span></code> argument specified will raise a ValueError. If you have
epochs in wall time in another timezone, you can read the epochs
as timezone-naive timestamps and then localize to the appropriate timezone:</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Epoch times will be rounded to the nearest nanosecond.</p>
</div>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Conversion of float epoch times can lead to inaccurate and unexpected results.
<a class=""reference external"" href=""https://docs.python.org/3/tutorial/floatingpoint.html#tut-fp-issues"" title=""(in Python v3.12)""><span class=""xref std std-ref"">Python floats</span></a> have about 15 digits precision in
decimal. Rounding during conversion from float to high precision <code class=""docutils literal notranslate""><span class=""pre"">Timestamp</span></code> is
unavoidable. The only way to achieve exact precision is to use a fixed-width
types (e.g. an int64).</p>

</div>
<div class=""admonition seealso"">
<p class=""admonition-title"">See also</p>
<p><a class=""reference internal"" href=""#timeseries-origin""><span class=""std std-ref"">Using the origin parameter</span></a></p>
</div>
</section>
<section id=""from-timestamps-to-epoch"">
<span id=""timeseries-converting-epoch-inverse""></span><h3>From timestamps to epoch<a class=""headerlink"" href=""#from-timestamps-to-epoch"" title=""Link to this heading"">#</a></h3>
<p>To invert the operation from above, namely, to convert from a <code class=""docutils literal notranslate""><span class=""pre"">Timestamp</span></code> to a ‘unix’ epoch:</p>

<p>We subtract the epoch (midnight at January 1, 1970 UTC) and then floor divide by the
“unit” (1 second).</p>

</section>
<section id=""using-the-origin-parameter"">
<span id=""timeseries-origin""></span><h3>Using the <code class=""docutils literal notranslate""><span class=""pre"">origin</span></code> parameter<a class=""headerlink"" href=""#using-the-origin-parameter"" title=""Link to this heading"">#</a></h3>
<p>Using the <code class=""docutils literal notranslate""><span class=""pre"">origin</span></code> parameter, one can specify an alternative starting point for creation
of a <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code>. For example, to use 1960-01-01 as the starting date:</p>

<p>The default is set at <code class=""docutils literal notranslate""><span class=""pre"">origin='unix'</span></code>, which defaults to <code class=""docutils literal notranslate""><span class=""pre"">1970-01-01</span> <span class=""pre"">00:00:00</span></code>.
Commonly called ‘unix epoch’ or POSIX time.</p>

</section>
</section>
<section id=""generating-ranges-of-timestamps"">
<span id=""timeseries-daterange""></span><h2>Generating ranges of timestamps<a class=""headerlink"" href=""#generating-ranges-of-timestamps"" title=""Link to this heading"">#</a></h2>
<p>To generate an index with timestamps, you can use either the <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> or
<code class=""docutils literal notranslate""><span class=""pre"">Index</span></code> constructor and pass in a list of datetime objects:</p>

<p>In practice this becomes very cumbersome because we often need a very long
index with a large number of timestamps. If we need timestamps on a regular
frequency, we can use the <a class=""reference internal"" href=""../reference/api/pandas.date_range.html#pandas.date_range"" title=""pandas.date_range""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">date_range()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.bdate_range.html#pandas.bdate_range"" title=""pandas.bdate_range""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">bdate_range()</span></code></a> functions
to create a <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code>. The default frequency for <code class=""docutils literal notranslate""><span class=""pre"">date_range</span></code> is a
<strong>calendar day</strong> while the default for <code class=""docutils literal notranslate""><span class=""pre"">bdate_range</span></code> is a <strong>business day</strong>:</p>

<p>Convenience functions like <code class=""docutils literal notranslate""><span class=""pre"">date_range</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">bdate_range</span></code> can utilize a
variety of <a class=""reference internal"" href=""#timeseries-offset-aliases""><span class=""std std-ref"">frequency aliases</span></a>:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">date_range</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">bdate_range</span></code> make it easy to generate a range of dates
using various combinations of parameters like <code class=""docutils literal notranslate""><span class=""pre"">start</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">end</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">periods</span></code>,
and <code class=""docutils literal notranslate""><span class=""pre"">freq</span></code>. The start and end dates are strictly inclusive, so dates outside
of those specified will not be generated:</p>

<p>Specifying <code class=""docutils literal notranslate""><span class=""pre"">start</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">end</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">periods</span></code> will generate a range of evenly spaced
dates from <code class=""docutils literal notranslate""><span class=""pre"">start</span></code> to <code class=""docutils literal notranslate""><span class=""pre"">end</span></code> inclusively, with <code class=""docutils literal notranslate""><span class=""pre"">periods</span></code> number of elements in the
resulting <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code>:</p>

<section id=""custom-frequency-ranges"">
<span id=""timeseries-custom-freq-ranges""></span><h3>Custom frequency ranges<a class=""headerlink"" href=""#custom-frequency-ranges"" title=""Link to this heading"">#</a></h3>
<p><code class=""docutils literal notranslate""><span class=""pre"">bdate_range</span></code> can also generate a range of custom frequency dates by using
the <code class=""docutils literal notranslate""><span class=""pre"">weekmask</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">holidays</span></code> parameters. These parameters will only be
used if a custom frequency string is passed.</p>

<div class=""admonition seealso"">
<p class=""admonition-title"">See also</p>
<p><a class=""reference internal"" href=""#timeseries-custombusinessdays""><span class=""std std-ref"">Custom business days</span></a></p>
</div>
</section>
</section>
<section id=""timestamp-limitations"">
<span id=""timeseries-timestamp-limits""></span><h2>Timestamp limitations<a class=""headerlink"" href=""#timestamp-limitations"" title=""Link to this heading"">#</a></h2>
<p>The limits of timestamp representation depend on the chosen resolution. For
nanosecond resolution, the time span that
can be represented using a 64-bit integer is limited to approximately 584 years:</p>

<p>When choosing second-resolution, the available range grows to <code class=""docutils literal notranslate""><span class=""pre"">+/-</span> <span class=""pre"">2.9e11</span> <span class=""pre"">years</span></code>.
Different resolutions can be converted to each other through <code class=""docutils literal notranslate""><span class=""pre"">as_unit</span></code>.</p>
<div class=""admonition seealso"">
<p class=""admonition-title"">See also</p>
<p><a class=""reference internal"" href=""#timeseries-oob""><span class=""std std-ref"">Representing out-of-bounds spans</span></a></p>
</div>
</section>
<section id=""indexing"">
<span id=""timeseries-datetimeindex""></span><h2>Indexing<a class=""headerlink"" href=""#indexing"" title=""Link to this heading"">#</a></h2>
<p>One of the main uses for <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> is as an index for pandas objects.
The <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> class contains many time series related optimizations:</p>
<ul class=""simple"">
<li><p>A large range of dates for various offsets are pre-computed and cached
under the hood in order to make generating subsequent date ranges very fast
(just have to grab a slice).</p></li>
<li><p>Fast shifting using the <code class=""docutils literal notranslate""><span class=""pre"">shift</span></code> method on pandas objects.</p></li>
<li><p>Unioning of overlapping <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> objects with the same frequency is
very fast (important for fast data alignment).</p></li>
<li><p>Quick access to date fields via properties such as <code class=""docutils literal notranslate""><span class=""pre"">year</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">month</span></code>, etc.</p></li>
<li><p>Regularization functions like <code class=""docutils literal notranslate""><span class=""pre"">snap</span></code> and very fast <code class=""docutils literal notranslate""><span class=""pre"">asof</span></code> logic.</p></li>
</ul>
<p><code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> objects have all the basic functionality of regular <code class=""docutils literal notranslate""><span class=""pre"">Index</span></code>
objects, and a smorgasbord of advanced time series specific methods for easy
frequency processing.</p>
<div class=""admonition seealso"">
<p class=""admonition-title"">See also</p>
<p><a class=""reference internal"" href=""basics.html#basics-reindexing""><span class=""std std-ref"">Reindexing methods</span></a></p>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>While pandas does not force you to have a sorted date index, some of these
methods may have unexpected or incorrect behavior if the dates are unsorted.</p>
</div>
<p><code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> can be used like a regular index and offers all of its
intelligent functionality like selection, slicing, etc.</p>

<section id=""partial-string-indexing"">
<span id=""timeseries-partialindexing""></span><h3>Partial string indexing<a class=""headerlink"" href=""#partial-string-indexing"" title=""Link to this heading"">#</a></h3>
<p>Dates and strings that parse to timestamps can be passed as indexing parameters:</p>

<p>To provide convenience for accessing longer time series, you can also pass in
the year or year and month as strings:</p>

<p>This type of slicing will work on a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> with a <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> as well. Since the
partial string selection is a form of label slicing, the endpoints <strong>will be</strong> included. This
would include matching times on an included date:</p>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Indexing <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> rows with a <em>single</em> string with getitem (e.g. <code class=""docutils literal notranslate""><span class=""pre"">frame[dtstring]</span></code>)
is deprecated starting with pandas 1.2.0 (given the ambiguity whether it is indexing
the rows or selecting a column) and will be removed in a future version. The equivalent
with <code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code> (e.g. <code class=""docutils literal notranslate""><span class=""pre"">frame.loc[dtstring]</span></code>) is still supported.</p>
</div>

<p>This starts on the very first time in the month, and includes the last date and
time for the month:</p>

<p>This specifies a stop time <strong>that includes all of the times on the last day</strong>:</p>

<p>This specifies an <strong>exact</strong> stop time (and is not the same as the above):</p>

<p>We are stopping on the included end-point as it is part of the index:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> partial string indexing also works on a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> with a <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code>:</p>

<p>Slicing with string indexing also honors UTC offset.</p>

</section>
<section id=""slice-vs-exact-match"">
<span id=""timeseries-slice-vs-exact-match""></span><h3>Slice vs. exact match<a class=""headerlink"" href=""#slice-vs-exact-match"" title=""Link to this heading"">#</a></h3>
<p>The same string used as an indexing parameter can be treated either as a slice or as an exact match depending on the resolution of the index. If the string is less accurate than the index, it will be treated as a slice, otherwise as an exact match.</p>
<p>Consider a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> object with a minute resolution index:</p>

<p>A timestamp string less accurate than a minute gives a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> object.</p>

<p>A timestamp string with minute resolution (or more accurate), gives a scalar instead, i.e. it is not casted to a slice.</p>

<p>If index resolution is second, then the minute-accurate timestamp gives a
<code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>.</p>

<p>If the timestamp string is treated as a slice, it can be used to index <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> with <code class=""docutils literal notranslate""><span class=""pre"">.loc[]</span></code> as well.</p>

<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>However, if the string is treated as an exact match, the selection in <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>’s <code class=""docutils literal notranslate""><span class=""pre"">[]</span></code> will be column-wise and not row-wise, see <a class=""reference internal"" href=""indexing.html#indexing-basics""><span class=""std std-ref"">Indexing Basics</span></a>. For example <code class=""docutils literal notranslate""><span class=""pre"">dft_minute['2011-12-31</span> <span class=""pre"">23:59']</span></code> will raise <code class=""docutils literal notranslate""><span class=""pre"">KeyError</span></code> as <code class=""docutils literal notranslate""><span class=""pre"">'2012-12-31</span> <span class=""pre"">23:59'</span></code> has the same resolution as the index and there is no column with such name:</p>
<p>To <em>always</em> have unambiguous selection, whether the row is treated as a slice or a single selection, use <code class=""docutils literal notranslate""><span class=""pre"">.loc</span></code>.</p>

</div>
<p>Note also that <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> resolution cannot be less precise than day.</p>

</section>
<section id=""exact-indexing"">
<h3>Exact indexing<a class=""headerlink"" href=""#exact-indexing"" title=""Link to this heading"">#</a></h3>
<p>As discussed in previous section, indexing a <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> with a partial string depends on the “accuracy” of the period, in other words how specific the interval is in relation to the resolution of the index. In contrast, indexing with <code class=""docutils literal notranslate""><span class=""pre"">Timestamp</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">datetime</span></code> objects is exact, because the objects have exact meaning. These also follow the semantics of <em>including both endpoints</em>.</p>
<p>These <code class=""docutils literal notranslate""><span class=""pre"">Timestamp</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">datetime</span></code> objects have exact <code class=""docutils literal notranslate""><span class=""pre"">hours,</span> <span class=""pre"">minutes,</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">seconds</span></code>, even though they were not explicitly specified (they are <code class=""docutils literal notranslate""><span class=""pre"">0</span></code>).</p>

<p>With no defaults.</p>

</section>
<section id=""truncating-fancy-indexing"">
<h3>Truncating &amp; fancy indexing<a class=""headerlink"" href=""#truncating-fancy-indexing"" title=""Link to this heading"">#</a></h3>
<p>A <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.truncate.html#pandas.DataFrame.truncate"" title=""pandas.DataFrame.truncate""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">truncate()</span></code></a> convenience function is provided that is similar
to slicing. Note that <code class=""docutils literal notranslate""><span class=""pre"">truncate</span></code> assumes a 0 value for any unspecified date
component in a <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> in contrast to slicing which returns any
partially matching dates:</p>

<p>Even complicated fancy indexing that breaks the <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> frequency
regularity will result in a <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code>, although frequency is lost:</p>

</section>
</section>
<section id=""time-date-components"">
<span id=""timeseries-components""></span><h2>Time/date components<a class=""headerlink"" href=""#time-date-components"" title=""Link to this heading"">#</a></h2>
<p>There are several time/date properties that one can access from <code class=""docutils literal notranslate""><span class=""pre"">Timestamp</span></code> or a collection of timestamps like a <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code>.</p>

<p>Furthermore, if you have a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> with datetimelike values, then you can
access these properties via the <code class=""docutils literal notranslate""><span class=""pre"">.dt</span></code> accessor, as detailed in the section
on <a class=""reference internal"" href=""basics.html#basics-dt-accessors""><span class=""std std-ref"">.dt accessors</span></a>.</p>
<p>You may obtain the year, week and day components of the ISO year from the ISO 8601 standard:</p>

</section>
<section id=""dateoffset-objects"">
<span id=""timeseries-offsets""></span><h2>DateOffset objects<a class=""headerlink"" href=""#dateoffset-objects"" title=""Link to this heading"">#</a></h2>
<p>In the preceding examples, frequency strings (e.g. <code class=""docutils literal notranslate""><span class=""pre"">'D'</span></code>) were used to specify
a frequency that defined:</p>
<ul class=""simple"">
<li><p>how the date times in <a class=""reference internal"" href=""../reference/api/pandas.DatetimeIndex.html#pandas.DatetimeIndex"" title=""pandas.DatetimeIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code></a> were spaced when using <a class=""reference internal"" href=""../reference/api/pandas.date_range.html#pandas.date_range"" title=""pandas.date_range""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">date_range()</span></code></a></p></li>
<li><p>the frequency of a <a class=""reference internal"" href=""../reference/api/pandas.Period.html#pandas.Period"" title=""pandas.Period""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Period</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.PeriodIndex.html#pandas.PeriodIndex"" title=""pandas.PeriodIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code></a></p></li>
</ul>
<p>These frequency strings map to a <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DateOffset</span></code> object and its subclasses. A <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DateOffset</span></code>
is similar to a <a class=""reference internal"" href=""../reference/api/pandas.Timedelta.html#pandas.Timedelta"" title=""pandas.Timedelta""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Timedelta</span></code></a> that represents a duration of time but follows specific calendar duration rules.
For example, a <a class=""reference internal"" href=""../reference/api/pandas.Timedelta.html#pandas.Timedelta"" title=""pandas.Timedelta""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Timedelta</span></code></a> day will always increment <code class=""docutils literal notranslate""><span class=""pre"">datetimes</span></code> by 24 hours, while a <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DateOffset</span></code> day
will increment <code class=""docutils literal notranslate""><span class=""pre"">datetimes</span></code> to the same time the next day whether a day represents 23, 24 or 25 hours due to daylight
savings time. However, all <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DateOffset</span></code> subclasses that are an hour or smaller
(<code class=""docutils literal notranslate""><span class=""pre"">Hour</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">Minute</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">Second</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">Milli</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">Micro</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">Nano</span></code>) behave like
<a class=""reference internal"" href=""../reference/api/pandas.Timedelta.html#pandas.Timedelta"" title=""pandas.Timedelta""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Timedelta</span></code></a> and respect absolute time.</p>
<p>The basic <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DateOffset</span></code> acts similar to <code class=""docutils literal notranslate""><span class=""pre"">dateutil.relativedelta</span></code> (<a class=""reference external"" href=""https://dateutil.readthedocs.io/en/stable/relativedelta.html"">relativedelta documentation</a>)
that shifts a date time by the corresponding calendar duration specified. The
arithmetic operator (<code class=""docutils literal notranslate""><span class=""pre"">+</span></code>) can be used to perform the shift.</p>

<p>Most <code class=""docutils literal notranslate""><span class=""pre"">DateOffsets</span></code> have associated frequencies strings, or offset aliases, that can be passed
into <code class=""docutils literal notranslate""><span class=""pre"">freq</span></code> keyword arguments. The available date offsets and associated frequency strings can be found below:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">DateOffsets</span></code> additionally have <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">rollforward()</span></code> and <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">rollback()</span></code>
methods for moving a date forward or backward respectively to a valid offset
date relative to the offset. For example, business offsets will roll dates
that land on the weekends (Saturday and Sunday) forward to Monday since
business offsets operate on the weekdays.</p>

<p>These operations preserve time (hour, minute, etc) information by default.
To reset time to midnight, use <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">normalize()</span></code> before or after applying
the operation (depending on whether you want the time information included
in the operation).</p>

<section id=""parametric-offsets"">
<h3>Parametric offsets<a class=""headerlink"" href=""#parametric-offsets"" title=""Link to this heading"">#</a></h3>
<p>Some of the offsets can be “parameterized” when created to result in different
behaviors. For example, the <code class=""docutils literal notranslate""><span class=""pre"">Week</span></code> offset for generating weekly data accepts a
<code class=""docutils literal notranslate""><span class=""pre"">weekday</span></code> parameter which results in the generated dates always lying on a
particular day of the week:</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">normalize</span></code> option will be effective for addition and subtraction.</p>

<p>Another example is parameterizing <code class=""docutils literal notranslate""><span class=""pre"">YearEnd</span></code> with the specific ending month:</p>

</section>
<section id=""using-offsets-with-series-datetimeindex"">
<span id=""timeseries-offsetseries""></span><h3>Using offsets with <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> / <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code><a class=""headerlink"" href=""#using-offsets-with-series-datetimeindex"" title=""Link to this heading"">#</a></h3>
<p>Offsets can be used with either a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> to
apply the offset to each element.</p>

<p>If the offset class maps directly to a <code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code> (<code class=""docutils literal notranslate""><span class=""pre"">Day</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">Hour</span></code>,
<code class=""docutils literal notranslate""><span class=""pre"">Minute</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">Second</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">Micro</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">Milli</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">Nano</span></code>) it can be
used exactly like a <code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code> - see the
<a class=""reference internal"" href=""timedeltas.html#timedeltas-operations""><span class=""std std-ref"">Timedelta section</span></a> for more examples.</p>

<p>Note that some offsets (such as <code class=""docutils literal notranslate""><span class=""pre"">BQuarterEnd</span></code>) do not have a
vectorized implementation. They can still be used but may
calculate significantly slower and will show a <code class=""docutils literal notranslate""><span class=""pre"">PerformanceWarning</span></code></p>

</section>
<section id=""custom-business-days"">
<span id=""timeseries-custombusinessdays""></span><h3>Custom business days<a class=""headerlink"" href=""#custom-business-days"" title=""Link to this heading"">#</a></h3>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">CDay</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">CustomBusinessDay</span></code> class provides a parametric
<code class=""docutils literal notranslate""><span class=""pre"">BusinessDay</span></code> class which can be used to create customized business day
calendars which account for local holidays and local weekend conventions.</p>
<p>As an interesting example, let’s look at Egypt where a Friday-Saturday weekend is observed.</p>

<p>Let’s map to the weekday names:</p>

<p>Holiday calendars can be used to provide the list of holidays. See the
<a class=""reference internal"" href=""#timeseries-holiday""><span class=""std std-ref"">holiday calendar</span></a> section for more information.</p>

<p>Monthly offsets that respect a certain holiday calendar can be defined
in the usual way.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The frequency string ‘C’ is used to indicate that a CustomBusinessDay
DateOffset is used, it is important to note that since CustomBusinessDay is
a parameterised type, instances of CustomBusinessDay may differ and this is
not detectable from the ‘C’ frequency string. The user therefore needs to
ensure that the ‘C’ frequency string is used consistently within the user’s
application.</p>
</div>
</section>
<section id=""business-hour"">
<span id=""timeseries-businesshour""></span><h3>Business hour<a class=""headerlink"" href=""#business-hour"" title=""Link to this heading"">#</a></h3>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">BusinessHour</span></code> class provides a business hour representation on <code class=""docutils literal notranslate""><span class=""pre"">BusinessDay</span></code>,
allowing to use specific start and end times.</p>
<p>By default, <code class=""docutils literal notranslate""><span class=""pre"">BusinessHour</span></code> uses 9:00 - 17:00 as business hours.
Adding <code class=""docutils literal notranslate""><span class=""pre"">BusinessHour</span></code> will increment <code class=""docutils literal notranslate""><span class=""pre"">Timestamp</span></code> by hourly frequency.
If target <code class=""docutils literal notranslate""><span class=""pre"">Timestamp</span></code> is out of business hours, move to the next business hour
then increment it. If the result exceeds the business hours end, the remaining
hours are added to the next business day.</p>

<p>You can also specify <code class=""docutils literal notranslate""><span class=""pre"">start</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">end</span></code> time by keywords. The argument must
be a <code class=""docutils literal notranslate""><span class=""pre"">str</span></code> with an <code class=""docutils literal notranslate""><span class=""pre"">hour:minute</span></code> representation or a <code class=""docutils literal notranslate""><span class=""pre"">datetime.time</span></code>
instance. Specifying seconds, microseconds and nanoseconds as business hour
results in <code class=""docutils literal notranslate""><span class=""pre"">ValueError</span></code>.</p>

<p>Passing <code class=""docutils literal notranslate""><span class=""pre"">start</span></code> time later than <code class=""docutils literal notranslate""><span class=""pre"">end</span></code> represents midnight business hour.
In this case, business hour exceeds midnight and overlap to the next day.
Valid business hours are distinguished by whether it started from valid <code class=""docutils literal notranslate""><span class=""pre"">BusinessDay</span></code>.</p>

<p>Applying <code class=""docutils literal notranslate""><span class=""pre"">BusinessHour.rollforward</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">rollback</span></code> to out of business hours results in
the next business hour start or previous day’s end. Different from other offsets, <code class=""docutils literal notranslate""><span class=""pre"">BusinessHour.rollforward</span></code>
may output different results from <code class=""docutils literal notranslate""><span class=""pre"">apply</span></code> by definition.</p>
<p>This is because one day’s business hour end is equal to next day’s business hour start. For example,
under the default business hours (9:00 - 17:00), there is no gap (0 minutes) between <code class=""docutils literal notranslate""><span class=""pre"">2014-08-01</span> <span class=""pre"">17:00</span></code> and
<code class=""docutils literal notranslate""><span class=""pre"">2014-08-04</span> <span class=""pre"">09:00</span></code>.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">BusinessHour</span></code> regards Saturday and Sunday as holidays. To use arbitrary
holidays, you can use <code class=""docutils literal notranslate""><span class=""pre"">CustomBusinessHour</span></code> offset, as explained in the
following subsection.</p>
</section>
<section id=""custom-business-hour"">
<span id=""timeseries-custombusinesshour""></span><h3>Custom business hour<a class=""headerlink"" href=""#custom-business-hour"" title=""Link to this heading"">#</a></h3>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">CustomBusinessHour</span></code> is a mixture of <code class=""docutils literal notranslate""><span class=""pre"">BusinessHour</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">CustomBusinessDay</span></code> which
allows you to specify arbitrary holidays. <code class=""docutils literal notranslate""><span class=""pre"">CustomBusinessHour</span></code> works as the same
as <code class=""docutils literal notranslate""><span class=""pre"">BusinessHour</span></code> except that it skips specified custom holidays.</p>

<p>You can use keyword arguments supported by either <code class=""docutils literal notranslate""><span class=""pre"">BusinessHour</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">CustomBusinessDay</span></code>.</p>

</section>
<section id=""offset-aliases"">
<span id=""timeseries-offset-aliases""></span><h3>Offset aliases<a class=""headerlink"" href=""#offset-aliases"" title=""Link to this heading"">#</a></h3>
<p>A number of string aliases are given to useful common time series
frequencies. We will refer to these aliases as <em>offset aliases</em>.</p>

<div class=""deprecated"">
<p><span class=""versionmodified deprecated"">Deprecated since version 2.2.0: </span>Aliases <code class=""docutils literal notranslate""><span class=""pre"">H</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">BH</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">CBH</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">T</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">S</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">L</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">U</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">N</span></code>
are deprecated in favour of the aliases <code class=""docutils literal notranslate""><span class=""pre"">h</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">bh</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">cbh</span></code>,
<code class=""docutils literal notranslate""><span class=""pre"">min</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">s</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">ms</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">us</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">ns</span></code>.</p>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<blockquote>
<div><p>When using the offset aliases above, it should be noted that functions
such as <a class=""reference internal"" href=""../reference/api/pandas.date_range.html#pandas.date_range"" title=""pandas.date_range""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">date_range()</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.bdate_range.html#pandas.bdate_range"" title=""pandas.bdate_range""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">bdate_range()</span></code></a>, will only return
timestamps that are in the interval defined by <code class=""docutils literal notranslate""><span class=""pre"">start_date</span></code> and
<code class=""docutils literal notranslate""><span class=""pre"">end_date</span></code>. If the <code class=""docutils literal notranslate""><span class=""pre"">start_date</span></code> does not correspond to the frequency,
the returned timestamps will start at the next valid timestamp, same for
<code class=""docutils literal notranslate""><span class=""pre"">end_date</span></code>, the returned timestamps will stop at the previous valid
timestamp.</p>
</div></blockquote>
<p>For example, for the offset <code class=""docutils literal notranslate""><span class=""pre"">MS</span></code>, if the <code class=""docutils literal notranslate""><span class=""pre"">start_date</span></code> is not the first
of the month, the returned timestamps will start with the first day of the
next month. If <code class=""docutils literal notranslate""><span class=""pre"">end_date</span></code> is not the first day of a month, the last
returned timestamp will be the first day of the corresponding month.</p>

<p>We can see in the above example <a class=""reference internal"" href=""../reference/api/pandas.date_range.html#pandas.date_range"" title=""pandas.date_range""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">date_range()</span></code></a> and
<a class=""reference internal"" href=""../reference/api/pandas.bdate_range.html#pandas.bdate_range"" title=""pandas.bdate_range""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">bdate_range()</span></code></a> will only return the valid timestamps between the
<code class=""docutils literal notranslate""><span class=""pre"">start_date</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">end_date</span></code>. If these are not valid timestamps for the
given frequency it will roll to the next value for <code class=""docutils literal notranslate""><span class=""pre"">start_date</span></code>
(respectively previous for the <code class=""docutils literal notranslate""><span class=""pre"">end_date</span></code>)</p>
</div>
</section>
<section id=""period-aliases"">
<span id=""timeseries-period-aliases""></span><h3>Period aliases<a class=""headerlink"" href=""#period-aliases"" title=""Link to this heading"">#</a></h3>
<p>A number of string aliases are given to useful common time series
frequencies. We will refer to these aliases as <em>period aliases</em>.</p>

<div class=""deprecated"">
<p><span class=""versionmodified deprecated"">Deprecated since version 2.2.0: </span>Aliases <code class=""docutils literal notranslate""><span class=""pre"">A</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">H</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">T</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">S</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">L</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">U</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">N</span></code> are deprecated in favour of the aliases
<code class=""docutils literal notranslate""><span class=""pre"">Y</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">h</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">min</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">s</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">ms</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">us</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">ns</span></code>.</p>
</div>
</section>
<section id=""combining-aliases"">
<h3>Combining aliases<a class=""headerlink"" href=""#combining-aliases"" title=""Link to this heading"">#</a></h3>
<p>As we have seen previously, the alias and the offset instance are fungible in
most functions:</p>

<p>You can combine together day and intraday offsets:</p>

</section>
<section id=""anchored-offsets"">
<h3>Anchored offsets<a class=""headerlink"" href=""#anchored-offsets"" title=""Link to this heading"">#</a></h3>
<p>For some frequencies you can specify an anchoring suffix:</p>

<p>These can be used as arguments to <code class=""docutils literal notranslate""><span class=""pre"">date_range</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">bdate_range</span></code>, constructors
for <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code>, as well as various other timeseries-related functions
in pandas.</p>
</section>
<section id=""anchored-offset-semantics"">
<h3>Anchored offset semantics<a class=""headerlink"" href=""#anchored-offset-semantics"" title=""Link to this heading"">#</a></h3>
<p>For those offsets that are anchored to the start or end of specific
frequency (<code class=""docutils literal notranslate""><span class=""pre"">MonthEnd</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">MonthBegin</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">WeekEnd</span></code>, etc), the following
rules apply to rolling forward and backwards.</p>
<p>When <code class=""docutils literal notranslate""><span class=""pre"">n</span></code> is not 0, if the given date is not on an anchor point, it snapped to the next(previous)
anchor point, and moved <code class=""docutils literal notranslate""><span class=""pre"">|n|-1</span></code> additional steps forwards or backwards.</p>

<p>If the given date <em>is</em> on an anchor point, it is moved <code class=""docutils literal notranslate""><span class=""pre"">|n|</span></code> points forwards
or backwards.</p>

<p>For the case when <code class=""docutils literal notranslate""><span class=""pre"">n=0</span></code>, the date is not moved if on an anchor point, otherwise
it is rolled forward to the next anchor point.</p>

</section>
<section id=""holidays-holiday-calendars"">
<span id=""timeseries-holiday""></span><h3>Holidays / holiday calendars<a class=""headerlink"" href=""#holidays-holiday-calendars"" title=""Link to this heading"">#</a></h3>
<p>Holidays and calendars provide a simple way to define holiday rules to be used
with <code class=""docutils literal notranslate""><span class=""pre"">CustomBusinessDay</span></code> or in other analysis that requires a predefined
set of holidays. The <code class=""docutils literal notranslate""><span class=""pre"">AbstractHolidayCalendar</span></code> class provides all the necessary
methods to return a list of holidays and only <code class=""docutils literal notranslate""><span class=""pre"">rules</span></code> need to be defined
in a specific holiday calendar class. Furthermore, the <code class=""docutils literal notranslate""><span class=""pre"">start_date</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">end_date</span></code>
class attributes determine over what date range holidays are generated. These
should be overwritten on the <code class=""docutils literal notranslate""><span class=""pre"">AbstractHolidayCalendar</span></code> class to have the range
apply to all calendar subclasses. <code class=""docutils literal notranslate""><span class=""pre"">USFederalHolidayCalendar</span></code> is the
only calendar that exists and primarily serves as an example for developing
other calendars.</p>
<p>For holidays that occur on fixed dates (e.g., US Memorial Day or July 4th) an
observance rule determines when that holiday is observed if it falls on a weekend
or some other non-observed day. Defined observance rules are:</p>

<p>An example of how holidays and holiday calendars are defined:</p>

<dl class=""field-list simple"">
<dt class=""field-odd"">hint<span class=""colon"">:</span></dt>
<dd class=""field-odd""><p><strong>weekday=MO(2)</strong> is same as <strong>2 * Week(weekday=2)</strong></p>
</dd>
</dl>
<p>Using this calendar, creating an index or doing offset arithmetic skips weekends
and holidays (i.e., Memorial Day/July 4th). For example, the below defines
a custom business day offset using the <code class=""docutils literal notranslate""><span class=""pre"">ExampleCalendar</span></code>. Like any other offset,
it can be used to create a <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> or added to <code class=""docutils literal notranslate""><span class=""pre"">datetime</span></code>
or <code class=""docutils literal notranslate""><span class=""pre"">Timestamp</span></code> objects.</p>

<p>Ranges are defined by the <code class=""docutils literal notranslate""><span class=""pre"">start_date</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">end_date</span></code> class attributes
of <code class=""docutils literal notranslate""><span class=""pre"">AbstractHolidayCalendar</span></code>. The defaults are shown below.</p>

<p>These dates can be overwritten by setting the attributes as
datetime/Timestamp/string.</p>

<p>Every calendar class is accessible by name using the <code class=""docutils literal notranslate""><span class=""pre"">get_calendar</span></code> function
which returns a holiday class instance. Any imported calendar class will
automatically be available by this function. Also, <code class=""docutils literal notranslate""><span class=""pre"">HolidayCalendarFactory</span></code>
provides an easy interface to create calendars that are combinations of calendars
or calendars with additional rules.</p>

</section>
</section>
<section id=""time-series-related-instance-methods"">
<span id=""timeseries-advanced-datetime""></span><h2>Time Series-related instance methods<a class=""headerlink"" href=""#time-series-related-instance-methods"" title=""Link to this heading"">#</a></h2>
<section id=""shifting-lagging"">
<h3>Shifting / lagging<a class=""headerlink"" href=""#shifting-lagging"" title=""Link to this heading"">#</a></h3>
<p>One may want to <em>shift</em> or <em>lag</em> the values in a time series back and forward in
time. The method for this is <a class=""reference internal"" href=""../reference/api/pandas.Series.shift.html#pandas.Series.shift"" title=""pandas.Series.shift""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">shift()</span></code></a>, which is available on all of
the pandas objects.</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">shift</span></code> method accepts an <code class=""docutils literal notranslate""><span class=""pre"">freq</span></code> argument which can accept a
<code class=""docutils literal notranslate""><span class=""pre"">DateOffset</span></code> class or other <code class=""docutils literal notranslate""><span class=""pre"">timedelta</span></code>-like object or also an
<a class=""reference internal"" href=""#timeseries-offset-aliases""><span class=""std std-ref"">offset alias</span></a>.</p>
<p>When <code class=""docutils literal notranslate""><span class=""pre"">freq</span></code> is specified, <code class=""docutils literal notranslate""><span class=""pre"">shift</span></code> method changes all the dates in the index
rather than changing the alignment of the data and the index:</p>

<p>Note that with when <code class=""docutils literal notranslate""><span class=""pre"">freq</span></code> is specified, the leading entry is no longer NaN
because the data is not being realigned.</p>
</section>
<section id=""frequency-conversion"">
<h3>Frequency conversion<a class=""headerlink"" href=""#frequency-conversion"" title=""Link to this heading"">#</a></h3>
<p>The primary function for changing frequencies is the <a class=""reference internal"" href=""../reference/api/pandas.Series.asfreq.html#pandas.Series.asfreq"" title=""pandas.Series.asfreq""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">asfreq()</span></code></a>
method. For a <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code>, this is basically just a thin, but convenient
wrapper around <a class=""reference internal"" href=""../reference/api/pandas.Series.reindex.html#pandas.Series.reindex"" title=""pandas.Series.reindex""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">reindex()</span></code></a> which generates a <code class=""docutils literal notranslate""><span class=""pre"">date_range</span></code> and
calls <code class=""docutils literal notranslate""><span class=""pre"">reindex</span></code>.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">asfreq</span></code> provides a further convenience so you can specify an interpolation
method for any gaps that may appear after the frequency conversion.</p>

</section>
<section id=""filling-forward-backward"">
<h3>Filling forward / backward<a class=""headerlink"" href=""#filling-forward-backward"" title=""Link to this heading"">#</a></h3>
<p>Related to <code class=""docutils literal notranslate""><span class=""pre"">asfreq</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">reindex</span></code> is <a class=""reference internal"" href=""../reference/api/pandas.Series.fillna.html#pandas.Series.fillna"" title=""pandas.Series.fillna""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">fillna()</span></code></a>, which is
documented in the <a class=""reference internal"" href=""missing_data.html#missing-data-fillna""><span class=""std std-ref"">missing data section</span></a>.</p>
</section>
<section id=""converting-to-python-datetimes"">
<h3>Converting to Python datetimes<a class=""headerlink"" href=""#converting-to-python-datetimes"" title=""Link to this heading"">#</a></h3>
<p><code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> can be converted to an array of Python native
<a class=""reference external"" href=""https://docs.python.org/3/library/datetime.html#datetime.datetime"" title=""(in Python v3.12)""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">datetime.datetime</span></code></a> objects using the <code class=""docutils literal notranslate""><span class=""pre"">to_pydatetime</span></code> method.</p>
</section>
</section>
<section id=""resampling"">
<span id=""timeseries-resampling""></span><h2>Resampling<a class=""headerlink"" href=""#resampling"" title=""Link to this heading"">#</a></h2>
<p>pandas has a simple, powerful, and efficient functionality for performing
resampling operations during frequency conversion (e.g., converting secondly
data into 5-minutely data). This is extremely common in, but not limited to,
financial applications.</p>
<p><a class=""reference internal"" href=""../reference/api/pandas.Series.resample.html#pandas.Series.resample"" title=""pandas.Series.resample""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">resample()</span></code></a> is a time-based groupby, followed by a reduction method
on each of its groups. See some <a class=""reference internal"" href=""cookbook.html#cookbook-resample""><span class=""std std-ref"">cookbook examples</span></a> for
some advanced strategies.</p>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">resample()</span></code> method can be used directly from <code class=""docutils literal notranslate""><span class=""pre"">DataFrameGroupBy</span></code> objects,
see the <a class=""reference internal"" href=""groupby.html#groupby-transform-window-resample""><span class=""std std-ref"">groupby docs</span></a>.</p>
<section id=""basics"">
<h3>Basics<a class=""headerlink"" href=""#basics"" title=""Link to this heading"">#</a></h3>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">resample</span></code> function is very flexible and allows you to specify many
different parameters to control the frequency conversion and resampling
operation.</p>
<p>Any built-in method available via <a class=""reference internal"" href=""../reference/groupby.html#api-groupby""><span class=""std std-ref"">GroupBy</span></a> is available as
a method of the returned object, including <code class=""docutils literal notranslate""><span class=""pre"">sum</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">mean</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">std</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">sem</span></code>,
<code class=""docutils literal notranslate""><span class=""pre"">max</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">min</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">median</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">first</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">last</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">ohlc</span></code>:</p>

<p>For downsampling, <code class=""docutils literal notranslate""><span class=""pre"">closed</span></code> can be set to ‘left’ or ‘right’ to specify which
end of the interval is closed:</p>

<p>Parameters like <code class=""docutils literal notranslate""><span class=""pre"">label</span></code> are used to manipulate the resulting labels.
<code class=""docutils literal notranslate""><span class=""pre"">label</span></code> specifies whether the result is labeled with the beginning or
the end of the interval.</p>

<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>The default values for <code class=""docutils literal notranslate""><span class=""pre"">label</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">closed</span></code> is ‘<strong>left</strong>’ for all
frequency offsets except for ‘ME’, ‘YE’, ‘QE’, ‘BME’, ‘BYE’, ‘BQE’, and ‘W’
which all have a default of ‘right’.</p>
<p>This might unintendedly lead to looking ahead, where the value for a later
time is pulled back to a previous time as in the following example with
the <a class=""reference internal"" href=""../reference/api/pandas.tseries.offsets.BusinessDay.html#pandas.tseries.offsets.BusinessDay"" title=""pandas.tseries.offsets.BusinessDay""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">BusinessDay</span></code></a> frequency:</p>

<p>Notice how the value for Sunday got pulled back to the previous Friday.
To get the behavior where the value for Sunday is pushed to Monday, use
instead</p>

</div>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">axis</span></code> parameter can be set to 0 or 1 and allows you to resample the
specified axis for a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>.</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">kind</span></code> can be set to ‘timestamp’ or ‘period’ to convert the resulting index
to/from timestamp and time span representations. By default <code class=""docutils literal notranslate""><span class=""pre"">resample</span></code>
retains the input representation.</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">convention</span></code> can be set to ‘start’ or ‘end’ when resampling period data
(detail below). It specifies how low frequency periods are converted to higher
frequency periods.</p>
</section>
<section id=""upsampling"">
<h3>Upsampling<a class=""headerlink"" href=""#upsampling"" title=""Link to this heading"">#</a></h3>
<p>For upsampling, you can specify a way to upsample and the <code class=""docutils literal notranslate""><span class=""pre"">limit</span></code> parameter to interpolate over the gaps that are created:</p>

</section>
<section id=""sparse-resampling"">
<h3>Sparse resampling<a class=""headerlink"" href=""#sparse-resampling"" title=""Link to this heading"">#</a></h3>
<p>Sparse timeseries are the ones where you have a lot fewer points relative
to the amount of time you are looking to resample. Naively upsampling a sparse
series can potentially generate lots of intermediate values. When you don’t want
to use a method to fill these values, e.g. <code class=""docutils literal notranslate""><span class=""pre"">fill_method</span></code> is <code class=""docutils literal notranslate""><span class=""pre"">None</span></code>, then
intermediate values will be filled with <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>.</p>
<p>Since <code class=""docutils literal notranslate""><span class=""pre"">resample</span></code> is a time-based groupby, the following is a method to efficiently
resample only the groups that are not all <code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code>.</p>

<p>If we want to resample to the full range of the series:</p>

<p>We can instead only resample those groups where we have points as follows:</p>

</section>
<section id=""aggregation"">
<span id=""timeseries-aggregate""></span><h3>Aggregation<a class=""headerlink"" href=""#aggregation"" title=""Link to this heading"">#</a></h3>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">resample()</span></code> method returns a <code class=""docutils literal notranslate""><span class=""pre"">pandas.api.typing.Resampler</span></code> instance. Similar to
the <a class=""reference internal"" href=""basics.html#basics-aggregate""><span class=""std std-ref"">aggregating API</span></a>, <a class=""reference internal"" href=""groupby.html#groupby-aggregate""><span class=""std std-ref"">groupby API</span></a>,
and the <a class=""reference internal"" href=""window.html#window-overview""><span class=""std std-ref"">window API</span></a>, a <code class=""docutils literal notranslate""><span class=""pre"">Resampler</span></code> can be selectively resampled.</p>
<p>Resampling a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>, the default will be to act on all columns with the same function.</p>

<p>We can select a specific column or columns using standard getitem.</p>

<p>You can pass a list or dict of functions to do aggregation with, outputting a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>:</p>

<p>On a resampled <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>, you can pass a list of functions to apply to each
column, which produces an aggregated result with a hierarchical index:</p>

<p>By passing a dict to <code class=""docutils literal notranslate""><span class=""pre"">aggregate</span></code> you can apply a different aggregation to the
columns of a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>:</p>

<p>The function names can also be strings. In order for a string to be valid it
must be implemented on the resampled object:</p>

<p>Furthermore, you can also specify multiple aggregation functions for each column separately.</p>

<p>If a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> does not have a datetimelike index, but instead you want
to resample based on datetimelike column in the frame, it can passed to the
<code class=""docutils literal notranslate""><span class=""pre"">on</span></code> keyword.</p>

<p>Similarly, if you instead want to resample by a datetimelike
level of <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code>, its name or location can be passed to the
<code class=""docutils literal notranslate""><span class=""pre"">level</span></code> keyword.</p>

</section>
<section id=""iterating-through-groups"">
<span id=""timeseries-iterating-label""></span><h3>Iterating through groups<a class=""headerlink"" href=""#iterating-through-groups"" title=""Link to this heading"">#</a></h3>
<p>With the <code class=""docutils literal notranslate""><span class=""pre"">Resampler</span></code> object in hand, iterating through the grouped data is very
natural and functions similarly to <a class=""reference external"" href=""https://docs.python.org/3/library/itertools.html#itertools.groupby"" title=""(in Python v3.12)""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">itertools.groupby()</span></code></a>:</p>

<p>See <a class=""reference internal"" href=""groupby.html#groupby-iterating-label""><span class=""std std-ref"">Iterating through groups</span></a> or <code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Resampler.__iter__</span></code> for more.</p>
</section>
<section id=""use-origin-or-offset-to-adjust-the-start-of-the-bins"">
<span id=""timeseries-adjust-the-start-of-the-bins""></span><h3>Use <code class=""docutils literal notranslate""><span class=""pre"">origin</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">offset</span></code> to adjust the start of the bins<a class=""headerlink"" href=""#use-origin-or-offset-to-adjust-the-start-of-the-bins"" title=""Link to this heading"">#</a></h3>
<p>The bins of the grouping are adjusted based on the beginning of the day of the time series starting point. This works well with frequencies that are multiples of a day (like <code class=""docutils literal notranslate""><span class=""pre"">30D</span></code>) or that divide a day evenly (like <code class=""docutils literal notranslate""><span class=""pre"">90s</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">1min</span></code>). This can create inconsistencies with some frequencies that do not meet this criteria. To change this behavior you can specify a fixed Timestamp with the argument <code class=""docutils literal notranslate""><span class=""pre"">origin</span></code>.</p>
<p>For example:</p>

<p>Here we can see that, when using <code class=""docutils literal notranslate""><span class=""pre"">origin</span></code> with its default value (<code class=""docutils literal notranslate""><span class=""pre"">'start_day'</span></code>), the result after <code class=""docutils literal notranslate""><span class=""pre"">'2000-10-02</span> <span class=""pre"">00:00:00'</span></code> are not identical depending on the start of time series:</p>

<p>Here we can see that, when setting <code class=""docutils literal notranslate""><span class=""pre"">origin</span></code> to <code class=""docutils literal notranslate""><span class=""pre"">'epoch'</span></code>, the result after <code class=""docutils literal notranslate""><span class=""pre"">'2000-10-02</span> <span class=""pre"">00:00:00'</span></code> are identical depending on the start of time series:</p>

<p>If needed you can use a custom timestamp for <code class=""docutils literal notranslate""><span class=""pre"">origin</span></code>:</p>

<p>If needed you can just adjust the bins with an <code class=""docutils literal notranslate""><span class=""pre"">offset</span></code> Timedelta that would be added to the default <code class=""docutils literal notranslate""><span class=""pre"">origin</span></code>.
Those two examples are equivalent for this time series:</p>

<p>Note the use of <code class=""docutils literal notranslate""><span class=""pre"">'start'</span></code> for <code class=""docutils literal notranslate""><span class=""pre"">origin</span></code> on the last example. In that case, <code class=""docutils literal notranslate""><span class=""pre"">origin</span></code> will be set to the first value of the timeseries.</p>
</section>
<section id=""backward-resample"">
<h3>Backward resample<a class=""headerlink"" href=""#backward-resample"" title=""Link to this heading"">#</a></h3>
<div class=""versionadded"">
<p><span class=""versionmodified added"">New in version 1.3.0.</span></p>
</div>
<p>Instead of adjusting the beginning of bins, sometimes we need to fix the end of the bins to make a backward resample with a given <code class=""docutils literal notranslate""><span class=""pre"">freq</span></code>. The backward resample sets <code class=""docutils literal notranslate""><span class=""pre"">closed</span></code> to <code class=""docutils literal notranslate""><span class=""pre"">'right'</span></code> by default since the last value should be considered as the edge point for the last bin.</p>
<p>We can set <code class=""docutils literal notranslate""><span class=""pre"">origin</span></code> to <code class=""docutils literal notranslate""><span class=""pre"">'end'</span></code>. The value for a specific <code class=""docutils literal notranslate""><span class=""pre"">Timestamp</span></code> index stands for the resample result from the current <code class=""docutils literal notranslate""><span class=""pre"">Timestamp</span></code> minus <code class=""docutils literal notranslate""><span class=""pre"">freq</span></code> to the current <code class=""docutils literal notranslate""><span class=""pre"">Timestamp</span></code> with a right close.</p>

<p>Besides, in contrast with the <code class=""docutils literal notranslate""><span class=""pre"">'start_day'</span></code> option, <code class=""docutils literal notranslate""><span class=""pre"">end_day</span></code> is supported. This will set the origin as the ceiling midnight of the largest <code class=""docutils literal notranslate""><span class=""pre"">Timestamp</span></code>.</p>

<p>The above result uses <code class=""docutils literal notranslate""><span class=""pre"">2000-10-02</span> <span class=""pre"">00:29:00</span></code> as the last bin’s right edge since the following computation.</p>

</section>
</section>
<section id=""time-span-representation"">
<span id=""timeseries-periods""></span><h2>Time span representation<a class=""headerlink"" href=""#time-span-representation"" title=""Link to this heading"">#</a></h2>
<p>Regular intervals of time are represented by <code class=""docutils literal notranslate""><span class=""pre"">Period</span></code> objects in pandas while
sequences of <code class=""docutils literal notranslate""><span class=""pre"">Period</span></code> objects are collected in a <code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code>, which can
be created with the convenience function <code class=""docutils literal notranslate""><span class=""pre"">period_range</span></code>.</p>
<section id=""period"">
<h3>Period<a class=""headerlink"" href=""#period"" title=""Link to this heading"">#</a></h3>
<p>A <code class=""docutils literal notranslate""><span class=""pre"">Period</span></code> represents a span of time (e.g., a day, a month, a quarter, etc).
You can specify the span via <code class=""docutils literal notranslate""><span class=""pre"">freq</span></code> keyword using a frequency alias like below.
Because <code class=""docutils literal notranslate""><span class=""pre"">freq</span></code> represents a span of <code class=""docutils literal notranslate""><span class=""pre"">Period</span></code>, it cannot be negative like “-3D”.</p>

<p>Adding and subtracting integers from periods shifts the period by its own
frequency. Arithmetic is not allowed between <code class=""docutils literal notranslate""><span class=""pre"">Period</span></code> with different <code class=""docutils literal notranslate""><span class=""pre"">freq</span></code> (span).</p>

<p>If <code class=""docutils literal notranslate""><span class=""pre"">Period</span></code> freq is daily or higher (<code class=""docutils literal notranslate""><span class=""pre"">D</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">h</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">min</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">s</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">ms</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">us</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">ns</span></code>), <code class=""docutils literal notranslate""><span class=""pre"">offsets</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">timedelta</span></code>-like can be added if the result can have the same freq. Otherwise, <code class=""docutils literal notranslate""><span class=""pre"">ValueError</span></code> will be raised.</p>


<p>If <code class=""docutils literal notranslate""><span class=""pre"">Period</span></code> has other frequencies, only the same <code class=""docutils literal notranslate""><span class=""pre"">offsets</span></code> can be added. Otherwise, <code class=""docutils literal notranslate""><span class=""pre"">ValueError</span></code> will be raised.</p>


<p>Taking the difference of <code class=""docutils literal notranslate""><span class=""pre"">Period</span></code> instances with the same frequency will
return the number of frequency units between them:</p>

</section>
<section id=""periodindex-and-period-range"">
<h3>PeriodIndex and period_range<a class=""headerlink"" href=""#periodindex-and-period-range"" title=""Link to this heading"">#</a></h3>
<p>Regular sequences of <code class=""docutils literal notranslate""><span class=""pre"">Period</span></code> objects can be collected in a <code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code>,
which can be constructed using the <code class=""docutils literal notranslate""><span class=""pre"">period_range</span></code> convenience function:</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code> constructor can also be used directly:</p>

<p>Passing multiplied frequency outputs a sequence of <code class=""docutils literal notranslate""><span class=""pre"">Period</span></code> which
has multiplied span.</p>

<p>If <code class=""docutils literal notranslate""><span class=""pre"">start</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">end</span></code> are <code class=""docutils literal notranslate""><span class=""pre"">Period</span></code> objects, they will be used as anchor
endpoints for a <code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code> with frequency matching that of the
<code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code> constructor.</p>

<p>Just like <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code>, a <code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code> can also be used to index pandas
objects:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code> supports addition and subtraction with the same rule as <code class=""docutils literal notranslate""><span class=""pre"">Period</span></code>.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code> has its own dtype named <code class=""docutils literal notranslate""><span class=""pre"">period</span></code>, refer to <a class=""reference internal"" href=""#timeseries-period-dtype""><span class=""std std-ref"">Period Dtypes</span></a>.</p>
</section>
<section id=""period-dtypes"">
<span id=""timeseries-period-dtype""></span><h3>Period dtypes<a class=""headerlink"" href=""#period-dtypes"" title=""Link to this heading"">#</a></h3>
<p><code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code> has a custom <code class=""docutils literal notranslate""><span class=""pre"">period</span></code> dtype. This is a pandas extension
dtype similar to the <a class=""reference internal"" href=""#timeseries-timezone-series""><span class=""std std-ref"">timezone aware dtype</span></a> (<code class=""docutils literal notranslate""><span class=""pre"">datetime64[ns,</span> <span class=""pre"">tz]</span></code>).</p>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">period</span></code> dtype holds the <code class=""docutils literal notranslate""><span class=""pre"">freq</span></code> attribute and is represented with
<code class=""docutils literal notranslate""><span class=""pre"">period[freq]</span></code> like <code class=""docutils literal notranslate""><span class=""pre"">period[D]</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">period[M]</span></code>, using <a class=""reference internal"" href=""#timeseries-period-aliases""><span class=""std std-ref"">frequency strings</span></a>.</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">period</span></code> dtype can be used in <code class=""docutils literal notranslate""><span class=""pre"">.astype(...)</span></code>. It allows one to change the
<code class=""docutils literal notranslate""><span class=""pre"">freq</span></code> of a <code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code> like <code class=""docutils literal notranslate""><span class=""pre"">.asfreq()</span></code> and convert a
<code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> to <code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code> like <code class=""docutils literal notranslate""><span class=""pre"">to_period()</span></code>:</p>

</section>
<section id=""periodindex-partial-string-indexing"">
<h3>PeriodIndex partial string indexing<a class=""headerlink"" href=""#periodindex-partial-string-indexing"" title=""Link to this heading"">#</a></h3>
<p>PeriodIndex now supports partial string slicing with non-monotonic indexes.</p>
<p>You can pass in dates and strings to <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> with <code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code>, in the same manner as <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code>. For details, refer to <a class=""reference internal"" href=""#timeseries-partialindexing""><span class=""std std-ref"">DatetimeIndex Partial String Indexing</span></a>.</p>

<p>Passing a string representing a lower frequency than <code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code> returns partial sliced data.</p>

<p>As with <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code>, the endpoints will be included in the result. The example below slices data starting from 10:00 to 11:59.</p>

</section>
<section id=""frequency-conversion-and-resampling-with-periodindex"">
<h3>Frequency conversion and resampling with PeriodIndex<a class=""headerlink"" href=""#frequency-conversion-and-resampling-with-periodindex"" title=""Link to this heading"">#</a></h3>
<p>The frequency of <code class=""docutils literal notranslate""><span class=""pre"">Period</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code> can be converted via the <code class=""docutils literal notranslate""><span class=""pre"">asfreq</span></code>
method. Let’s start with the fiscal year 2011, ending in December:</p>

<p>We can convert it to a monthly frequency. Using the <code class=""docutils literal notranslate""><span class=""pre"">how</span></code> parameter, we can
specify whether to return the starting or ending month:</p>

<p>The shorthands ‘s’ and ‘e’ are provided for convenience:</p>

<p>Converting to a “super-period” (e.g., annual frequency is a super-period of
quarterly frequency) automatically returns the super-period that includes the
input period:</p>

<p>Note that since we converted to an annual frequency that ends the year in
November, the monthly period of December 2011 is actually in the 2012 Y-NOV
period.</p>
<p id=""timeseries-quarterly"">Period conversions with anchored frequencies are particularly useful for
working with various quarterly data common to economics, business, and other
fields. Many organizations define quarters relative to the month in which their
fiscal year starts and ends. Thus, first quarter of 2011 could start in 2010 or
a few months into 2011. Via anchored frequencies, pandas works for all quarterly
frequencies <code class=""docutils literal notranslate""><span class=""pre"">Q-JAN</span></code> through <code class=""docutils literal notranslate""><span class=""pre"">Q-DEC</span></code>.</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">Q-DEC</span></code> define regular calendar quarters:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">Q-MAR</span></code> defines fiscal year end in March:</p>

</section>
</section>
<section id=""converting-between-representations"">
<span id=""timeseries-interchange""></span><h2>Converting between representations<a class=""headerlink"" href=""#converting-between-representations"" title=""Link to this heading"">#</a></h2>
<p>Timestamped data can be converted to PeriodIndex-ed data using <code class=""docutils literal notranslate""><span class=""pre"">to_period</span></code>
and vice-versa using <code class=""docutils literal notranslate""><span class=""pre"">to_timestamp</span></code>:</p>

<p>Remember that ‘s’ and ‘e’ can be used to return the timestamps at the start or
end of the period:</p>

<p>Converting between period and timestamp enables some convenient arithmetic
functions to be used. In the following example, we convert a quarterly
frequency with year ending in November to 9am of the end of the month following
the quarter end:</p>

</section>
<section id=""representing-out-of-bounds-spans"">
<span id=""timeseries-oob""></span><h2>Representing out-of-bounds spans<a class=""headerlink"" href=""#representing-out-of-bounds-spans"" title=""Link to this heading"">#</a></h2>
<p>If you have data that is outside of the <code class=""docutils literal notranslate""><span class=""pre"">Timestamp</span></code> bounds, see <a class=""reference internal"" href=""#timeseries-timestamp-limits""><span class=""std std-ref"">Timestamp limitations</span></a>,
then you can use a <code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code> and/or <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> of <code class=""docutils literal notranslate""><span class=""pre"">Periods</span></code> to do computations.</p>

<p>To convert from an <code class=""docutils literal notranslate""><span class=""pre"">int64</span></code> based YYYYMMDD representation.</p>

<p>These can easily be converted to a <code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code>:</p>

</section>
<section id=""time-zone-handling"">
<span id=""timeseries-timezone""></span><h2>Time zone handling<a class=""headerlink"" href=""#time-zone-handling"" title=""Link to this heading"">#</a></h2>
<p>pandas provides rich support for working with timestamps in different time
zones using the <code class=""docutils literal notranslate""><span class=""pre"">pytz</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">dateutil</span></code> libraries or <a class=""reference external"" href=""https://docs.python.org/3/library/datetime.html#datetime.timezone"" title=""(in Python v3.12)""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">datetime.timezone</span></code></a>
objects from the standard library.</p>
<section id=""working-with-time-zones"">
<h3>Working with time zones<a class=""headerlink"" href=""#working-with-time-zones"" title=""Link to this heading"">#</a></h3>
<p>By default, pandas objects are time zone unaware:</p>

<p>To localize these dates to a time zone (assign a particular time zone to a naive date),
you can use the <code class=""docutils literal notranslate""><span class=""pre"">tz_localize</span></code> method or the <code class=""docutils literal notranslate""><span class=""pre"">tz</span></code> keyword argument in
<a class=""reference internal"" href=""../reference/api/pandas.date_range.html#pandas.date_range"" title=""pandas.date_range""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">date_range()</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.Timestamp.html#pandas.Timestamp"" title=""pandas.Timestamp""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Timestamp</span></code></a>, or <a class=""reference internal"" href=""../reference/api/pandas.DatetimeIndex.html#pandas.DatetimeIndex"" title=""pandas.DatetimeIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code></a>.
You can either pass <code class=""docutils literal notranslate""><span class=""pre"">pytz</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">dateutil</span></code> time zone objects or Olson time zone database strings.
Olson time zone strings will return <code class=""docutils literal notranslate""><span class=""pre"">pytz</span></code> time zone objects by default.
To return <code class=""docutils literal notranslate""><span class=""pre"">dateutil</span></code> time zone objects, append <code class=""docutils literal notranslate""><span class=""pre"">dateutil/</span></code> before the string.</p>
<ul class=""simple"">
<li><p>In <code class=""docutils literal notranslate""><span class=""pre"">pytz</span></code> you can find a list of common (and less common) time zones using
<code class=""docutils literal notranslate""><span class=""pre"">from</span> <span class=""pre"">pytz</span> <span class=""pre"">import</span> <span class=""pre"">common_timezones,</span> <span class=""pre"">all_timezones</span></code>.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">dateutil</span></code> uses the OS time zones so there isn’t a fixed list available. For
common zones, the names are the same as <code class=""docutils literal notranslate""><span class=""pre"">pytz</span></code>.</p></li>
</ul>


<p>Note that the <code class=""docutils literal notranslate""><span class=""pre"">UTC</span></code> time zone is a special case in <code class=""docutils literal notranslate""><span class=""pre"">dateutil</span></code> and should be constructed explicitly
as an instance of <code class=""docutils literal notranslate""><span class=""pre"">dateutil.tz.tzutc</span></code>. You can also construct other time
zones objects explicitly first.</p>

<p>To convert a time zone aware pandas object from one time zone to another,
you can use the <code class=""docutils literal notranslate""><span class=""pre"">tz_convert</span></code> method.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>When using <code class=""docutils literal notranslate""><span class=""pre"">pytz</span></code> time zones, <a class=""reference internal"" href=""../reference/api/pandas.DatetimeIndex.html#pandas.DatetimeIndex"" title=""pandas.DatetimeIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code></a> will construct a different
time zone object than a <a class=""reference internal"" href=""../reference/api/pandas.Timestamp.html#pandas.Timestamp"" title=""pandas.Timestamp""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Timestamp</span></code></a> for the same time zone input. A <a class=""reference internal"" href=""../reference/api/pandas.DatetimeIndex.html#pandas.DatetimeIndex"" title=""pandas.DatetimeIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code></a>
can hold a collection of <a class=""reference internal"" href=""../reference/api/pandas.Timestamp.html#pandas.Timestamp"" title=""pandas.Timestamp""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Timestamp</span></code></a> objects that may have different UTC offsets and cannot be
succinctly represented by one <code class=""docutils literal notranslate""><span class=""pre"">pytz</span></code> time zone instance while one <a class=""reference internal"" href=""../reference/api/pandas.Timestamp.html#pandas.Timestamp"" title=""pandas.Timestamp""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Timestamp</span></code></a>
represents one point in time with a specific UTC offset.</p>

</div>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Be wary of conversions between libraries. For some time zones, <code class=""docutils literal notranslate""><span class=""pre"">pytz</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">dateutil</span></code> have different
definitions of the zone. This is more of a problem for unusual time zones than for
‘standard’ zones like <code class=""docutils literal notranslate""><span class=""pre"">US/Eastern</span></code>.</p>
</div>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Be aware that a time zone definition across versions of time zone libraries may not
be considered equal. This may cause problems when working with stored data that
is localized using one version and operated on with a different version.
See <a class=""reference internal"" href=""io.html#io-hdf5-notes""><span class=""std std-ref"">here</span></a> for how to handle such a situation.</p>
</div>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>For <code class=""docutils literal notranslate""><span class=""pre"">pytz</span></code> time zones, it is incorrect to pass a time zone object directly into
the <code class=""docutils literal notranslate""><span class=""pre"">datetime.datetime</span></code> constructor
(e.g., <code class=""docutils literal notranslate""><span class=""pre"">datetime.datetime(2011,</span> <span class=""pre"">1,</span> <span class=""pre"">1,</span> <span class=""pre"">tzinfo=pytz.timezone('US/Eastern'))</span></code>.
Instead, the datetime needs to be localized using the <code class=""docutils literal notranslate""><span class=""pre"">localize</span></code> method
on the <code class=""docutils literal notranslate""><span class=""pre"">pytz</span></code> time zone object.</p>
</div>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Be aware that for times in the future, correct conversion between time zones
(and UTC) cannot be guaranteed by any time zone library because a timezone’s
offset from UTC may be changed by the respective government.</p>
</div>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>If you are using dates beyond 2038-01-18, due to current deficiencies
in the underlying libraries caused by the year 2038 problem, daylight saving time (DST) adjustments
to timezone aware dates will not be applied. If and when the underlying libraries are fixed,
the DST transitions will be applied.</p>
<p>For example, for two dates that are in British Summer Time (and so would normally be GMT+1), both the following asserts evaluate as true:</p>

</div>
<p>Under the hood, all timestamps are stored in UTC. Values from a time zone aware
<a class=""reference internal"" href=""../reference/api/pandas.DatetimeIndex.html#pandas.DatetimeIndex"" title=""pandas.DatetimeIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.Timestamp.html#pandas.Timestamp"" title=""pandas.Timestamp""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Timestamp</span></code></a> will have their fields (day, hour, minute, etc.)
localized to the time zone. However, timestamps with the same UTC value are
still considered to be equal even if they are in different time zones:</p>

<p>Operations between <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> in different time zones will yield UTC
<a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>, aligning the data on the UTC timestamps:</p>

<p>To remove time zone information, use <code class=""docutils literal notranslate""><span class=""pre"">tz_localize(None)</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">tz_convert(None)</span></code>.
<code class=""docutils literal notranslate""><span class=""pre"">tz_localize(None)</span></code> will remove the time zone yielding the local time representation.
<code class=""docutils literal notranslate""><span class=""pre"">tz_convert(None)</span></code> will remove the time zone after converting to UTC time.</p>

</section>
<section id=""fold"">
<span id=""timeseries-fold""></span><h3>Fold<a class=""headerlink"" href=""#fold"" title=""Link to this heading"">#</a></h3>
<p>For ambiguous times, pandas supports explicitly specifying the keyword-only fold argument.
Due to daylight saving time, one wall clock time can occur twice when shifting
from summer to winter time; fold describes whether the datetime-like corresponds
to the first (0) or the second time (1) the wall clock hits the ambiguous time.
Fold is supported only for constructing from naive <code class=""docutils literal notranslate""><span class=""pre"">datetime.datetime</span></code>
(see <a class=""reference external"" href=""https://docs.python.org/3/library/datetime.html"">datetime documentation</a> for details) or from <a class=""reference internal"" href=""../reference/api/pandas.Timestamp.html#pandas.Timestamp"" title=""pandas.Timestamp""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Timestamp</span></code></a>
or for constructing from components (see below). Only <code class=""docutils literal notranslate""><span class=""pre"">dateutil</span></code> timezones are supported
(see <a class=""reference external"" href=""https://dateutil.readthedocs.io/en/stable/tz.html#dateutil.tz.enfold"">dateutil documentation</a>
for <code class=""docutils literal notranslate""><span class=""pre"">dateutil</span></code> methods that deal with ambiguous datetimes) as <code class=""docutils literal notranslate""><span class=""pre"">pytz</span></code>
timezones do not support fold (see <a class=""reference external"" href=""http://pytz.sourceforge.net/index.html"">pytz documentation</a>
for details on how <code class=""docutils literal notranslate""><span class=""pre"">pytz</span></code> deals with ambiguous datetimes). To localize an ambiguous datetime
with <code class=""docutils literal notranslate""><span class=""pre"">pytz</span></code>, please use <a class=""reference internal"" href=""../reference/api/pandas.Timestamp.tz_localize.html#pandas.Timestamp.tz_localize"" title=""pandas.Timestamp.tz_localize""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Timestamp.tz_localize()</span></code></a>. In general, we recommend to rely
on <a class=""reference internal"" href=""../reference/api/pandas.Timestamp.tz_localize.html#pandas.Timestamp.tz_localize"" title=""pandas.Timestamp.tz_localize""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Timestamp.tz_localize()</span></code></a> when localizing ambiguous datetimes if you need direct
control over how they are handled.</p>

</section>
<section id=""ambiguous-times-when-localizing"">
<span id=""timeseries-timezone-ambiguous""></span><h3>Ambiguous times when localizing<a class=""headerlink"" href=""#ambiguous-times-when-localizing"" title=""Link to this heading"">#</a></h3>
<p><code class=""docutils literal notranslate""><span class=""pre"">tz_localize</span></code> may not be able to determine the UTC offset of a timestamp
because daylight savings time (DST) in a local time zone causes some times to occur
twice within one day (“clocks fall back”). The following options are available:</p>
<ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">'raise'</span></code>: Raises a <code class=""docutils literal notranslate""><span class=""pre"">pytz.AmbiguousTimeError</span></code> (the default behavior)</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">'infer'</span></code>: Attempt to determine the correct offset base on the monotonicity of the timestamps</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">'NaT'</span></code>: Replaces ambiguous times with <code class=""docutils literal notranslate""><span class=""pre"">NaT</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">bool</span></code>: <code class=""docutils literal notranslate""><span class=""pre"">True</span></code> represents a DST time, <code class=""docutils literal notranslate""><span class=""pre"">False</span></code> represents non-DST time. An array-like of <code class=""docutils literal notranslate""><span class=""pre"">bool</span></code> values is supported for a sequence of times.</p></li>
</ul>

<p>This will fail as there are ambiguous times (<code class=""docutils literal notranslate""><span class=""pre"">'11/06/2011</span> <span class=""pre"">01:00'</span></code>)</p>

<p>Handle these ambiguous times by specifying the following.</p>

</section>
<section id=""nonexistent-times-when-localizing"">
<span id=""timeseries-timezone-nonexistent""></span><h3>Nonexistent times when localizing<a class=""headerlink"" href=""#nonexistent-times-when-localizing"" title=""Link to this heading"">#</a></h3>
<p>A DST transition may also shift the local time ahead by 1 hour creating nonexistent
local times (“clocks spring forward”). The behavior of localizing a timeseries with nonexistent times
can be controlled by the <code class=""docutils literal notranslate""><span class=""pre"">nonexistent</span></code> argument. The following options are available:</p>
<ul class=""simple"">
<li><p><code class=""docutils literal notranslate""><span class=""pre"">'raise'</span></code>: Raises a <code class=""docutils literal notranslate""><span class=""pre"">pytz.NonExistentTimeError</span></code> (the default behavior)</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">'NaT'</span></code>: Replaces nonexistent times with <code class=""docutils literal notranslate""><span class=""pre"">NaT</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">'shift_forward'</span></code>: Shifts nonexistent times forward to the closest real time</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">'shift_backward'</span></code>: Shifts nonexistent times backward to the closest real time</p></li>
<li><p>timedelta object: Shifts nonexistent times by the timedelta duration</p></li>
</ul>

<p>Localization of nonexistent times will raise an error by default.</p>

<p>Transform nonexistent times to <code class=""docutils literal notranslate""><span class=""pre"">NaT</span></code> or shift the times.</p>

</section>
<section id=""time-zone-series-operations"">
<span id=""timeseries-timezone-series""></span><h3>Time zone Series operations<a class=""headerlink"" href=""#time-zone-series-operations"" title=""Link to this heading"">#</a></h3>
<p>A <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> with time zone <strong>naive</strong> values is
represented with a dtype of <code class=""docutils literal notranslate""><span class=""pre"">datetime64[ns]</span></code>.</p>

<p>A <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> with a time zone <strong>aware</strong> values is
represented with a dtype of <code class=""docutils literal notranslate""><span class=""pre"">datetime64[ns,</span> <span class=""pre"">tz]</span></code> where <code class=""docutils literal notranslate""><span class=""pre"">tz</span></code> is the time zone</p>

<p>Both of these <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> time zone information
can be manipulated via the <code class=""docutils literal notranslate""><span class=""pre"">.dt</span></code> accessor, see <a class=""reference internal"" href=""basics.html#basics-dt-accessors""><span class=""std std-ref"">the dt accessor section</span></a>.</p>
<p>For example, to localize and convert a naive stamp to time zone aware.</p>

<p>Time zone information can also be manipulated using the <code class=""docutils literal notranslate""><span class=""pre"">astype</span></code> method.
This method can convert between different timezone-aware dtypes.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Using <a class=""reference internal"" href=""../reference/api/pandas.Series.to_numpy.html#pandas.Series.to_numpy"" title=""pandas.Series.to_numpy""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.to_numpy()</span></code></a> on a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>, returns a NumPy array of the data.
NumPy does not currently support time zones (even though it is <em>printing</em> in the local time zone!),
therefore an object array of Timestamps is returned for time zone aware data:</p>

<p>By converting to an object array of Timestamps, it preserves the time zone
information. For example, when converting back to a Series:</p>

<p>However, if you want an actual NumPy <code class=""docutils literal notranslate""><span class=""pre"">datetime64[ns]</span></code> array (with the values
converted to UTC) instead of an array of objects, you can specify the
<code class=""docutils literal notranslate""><span class=""pre"">dtype</span></code> argument:</p>

</div>
</section>
</section>
</section>
</article>","Time series / date functionality # pandas contains extensive capabilities and features for working with time series data for all domains. Using the NumPy datetime64 and timedelta64 dtypes, pandas has consolidated a large number of features from other Python libraries like scikits.timeseries as well as created a tremendous amount of new functionality for manipulating time series data. For example, pandas supports: Parsing time series information from various sources and formats Generate sequences of fixed-frequency dates and time spans Manipulating and converting date times with timezone information Resampling or converting a time series to a particular frequency Performing date and time arithmetic with absolute or relative time increments pandas provides a relatively compact and self-contained set of tools for performing the above tasks and more. Overview # pandas captures 4 general time related concepts: Date times: A specific date and time with timezone support. Similar to datetime.datetime from the standard library. Time deltas: An absolute time duration. Similar to datetime.timedelta from the standard library. Time spans: A span of time defined by a point in time and its associated frequency. Date offsets: A relative time duration that respects calendar arithmetic. Similar to dateutil.relativedelta.relativedelta from the dateutil package. For time series data, it’s conventional to represent the time component in the index of a Series or DataFrame so manipulations can be performed with respect to the time element. However, Series and DataFrame can directly also support the time component as data itself. Series and DataFrame have extended data type support and functionality for datetime , timedelta and Period data when passed into those constructors. DateOffset data however will be stored as object data. Lastly, pandas represents null date times, time deltas, and time spans as NaT which is useful for representing missing or null date like values and behaves similar as np.nan does for float data. Timestamps vs. time spans # Timestamped data is the most basic type of time series data that associates values with points in time. For pandas objects it means using the points in time. However, in many cases it is more natural to associate things like change variables with a time span instead. The span represented by Period can be specified explicitly, or inferred from datetime string format. For example: Timestamp and Period can serve as an index. Lists of Timestamp and Period are automatically coerced to DatetimeIndex and PeriodIndex respectively. pandas allows you to capture both representations and convert between them. Under the hood, pandas represents timestamps using instances of Timestamp and sequences of timestamps using instances of DatetimeIndex . For regular time spans, pandas uses Period objects for scalar values and PeriodIndex for sequences of spans. Better support for irregular intervals with arbitrary start and end points are forth-coming in future releases. Converting to timestamps # To convert a Series or list-like object of date-like objects e.g. strings, epochs, or a mixture, you can use the to_datetime function. When passed a Series , this returns a Series (with the same index), while a list-like is converted to a DatetimeIndex : If you use dates which start with the day first (i.e. European style), you can pass the dayfirst flag: Warning You see in the above example that dayfirst isn’t strict. If a date can’t be parsed with the day being first it will be parsed as if dayfirst were False and a warning will also be raised. If you pass a single string to to_datetime , it returns a single Timestamp . Timestamp can also accept string input, but it doesn’t accept string parsing options like dayfirst or format , so use to_datetime if these are required. You can also use the DatetimeIndex constructor directly: The string ‘infer’ can be passed in order to set the frequency of the index as the inferred frequency upon creation: Providing a format argument # In addition to the required datetime string, a format argument can be passed to ensure specific parsing. This could also potentially speed up the conversion considerably. For more information on the choices available when specifying the format option, see the Python datetime documentation . Assembling datetime from multiple DataFrame columns # You can also pass a DataFrame of integer or string columns to assemble into a Series of Timestamps . You can pass only the columns that you need to assemble. pd.to_datetime looks for standard designations of the datetime component in the column names, including: required: year , month , day optional: hour , minute , second , millisecond , microsecond , nanosecond Invalid data # The default behavior, errors='raise' , is to raise when unparsable: Pass errors='coerce' to convert unparsable data to NaT (not a time): Epoch timestamps # pandas supports converting integer or float epoch times to Timestamp and DatetimeIndex . The default unit is nanoseconds, since that is how Timestamp objects are stored internally. However, epochs are often stored in another unit which can be specified. These are computed from the starting point specified by the origin parameter. Note The unit parameter does not use the same strings as the format parameter that was discussed above ). The available units are listed on the documentation for pandas.to_datetime() . Constructing a Timestamp or DatetimeIndex with an epoch timestamp with the tz argument specified will raise a ValueError. If you have epochs in wall time in another timezone, you can read the epochs as timezone-naive timestamps and then localize to the appropriate timezone: Note Epoch times will be rounded to the nearest nanosecond. Warning Conversion of float epoch times can lead to inaccurate and unexpected results. Python floats have about 15 digits precision in decimal. Rounding during conversion from float to high precision Timestamp is unavoidable. The only way to achieve exact precision is to use a fixed-width types (e.g. an int64). See also Using the origin parameter From timestamps to epoch # To invert the operation from above, namely, to convert from a Timestamp to a ‘unix’ epoch: We subtract the epoch (midnight at January 1, 1970 UTC) and then floor divide by the “unit” (1 second). Using the origin parameter # Using the origin parameter, one can specify an alternative starting point for creation of a DatetimeIndex . For example, to use 1960-01-01 as the starting date: The default is set at origin='unix' , which defaults to 1970-01-01 00:00:00 . Commonly called ‘unix epoch’ or POSIX time. Generating ranges of timestamps # To generate an index with timestamps, you can use either the DatetimeIndex or Index constructor and pass in a list of datetime objects: In practice this becomes very cumbersome because we often need a very long index with a large number of timestamps. If we need timestamps on a regular frequency, we can use the date_range() and bdate_range() functions to create a DatetimeIndex . The default frequency for date_range is a calendar day while the default for bdate_range is a business day : Convenience functions like date_range and bdate_range can utilize a variety of frequency aliases : date_range and bdate_range make it easy to generate a range of dates using various combinations of parameters like start , end , periods , and freq . The start and end dates are strictly inclusive, so dates outside of those specified will not be generated: Specifying start , end , and periods will generate a range of evenly spaced dates from start to end inclusively, with periods number of elements in the resulting DatetimeIndex : Custom frequency ranges # bdate_range can also generate a range of custom frequency dates by using the weekmask and holidays parameters. These parameters will only be used if a custom frequency string is passed. See also Custom business days Timestamp limitations # The limits of timestamp representation depend on the chosen resolution. For nanosecond resolution, the time span that can be represented using a 64-bit integer is limited to approximately 584 years: When choosing second-resolution, the available range grows to +/- 2.9e11 years . Different resolutions can be converted to each other through as_unit . See also Representing out-of-bounds spans Indexing # One of the main uses for DatetimeIndex is as an index for pandas objects. The DatetimeIndex class contains many time series related optimizations: A large range of dates for various offsets are pre-computed and cached under the hood in order to make generating subsequent date ranges very fast (just have to grab a slice). Fast shifting using the shift method on pandas objects. Unioning of overlapping DatetimeIndex objects with the same frequency is very fast (important for fast data alignment). Quick access to date fields via properties such as year , month , etc. Regularization functions like snap and very fast asof logic. DatetimeIndex objects have all the basic functionality of regular Index objects, and a smorgasbord of advanced time series specific methods for easy frequency processing. See also Reindexing methods Note While pandas does not force you to have a sorted date index, some of these methods may have unexpected or incorrect behavior if the dates are unsorted. DatetimeIndex can be used like a regular index and offers all of its intelligent functionality like selection, slicing, etc. Partial string indexing # Dates and strings that parse to timestamps can be passed as indexing parameters: To provide convenience for accessing longer time series, you can also pass in the year or year and month as strings: This type of slicing will work on a DataFrame with a DatetimeIndex as well. Since the partial string selection is a form of label slicing, the endpoints will be included. This would include matching times on an included date: Warning Indexing DataFrame rows with a single string with getitem (e.g. frame[dtstring] ) is deprecated starting with pandas 1.2.0 (given the ambiguity whether it is indexing the rows or selecting a column) and will be removed in a future version. The equivalent with .loc (e.g. frame.loc[dtstring] ) is still supported. This starts on the very first time in the month, and includes the last date and time for the month: This specifies a stop time that includes all of the times on the last day : This specifies an exact stop time (and is not the same as the above): We are stopping on the included end-point as it is part of the index: DatetimeIndex partial string indexing also works on a DataFrame with a MultiIndex : Slicing with string indexing also honors UTC offset. Slice vs. exact match # The same string used as an indexing parameter can be treated either as a slice or as an exact match depending on the resolution of the index. If the string is less accurate than the index, it will be treated as a slice, otherwise as an exact match. Consider a Series object with a minute resolution index: A timestamp string less accurate than a minute gives a Series object. A timestamp string with minute resolution (or more accurate), gives a scalar instead, i.e. it is not casted to a slice. If index resolution is second, then the minute-accurate timestamp gives a Series . If the timestamp string is treated as a slice, it can be used to index DataFrame with .loc[] as well. Warning However, if the string is treated as an exact match, the selection in DataFrame ’s [] will be column-wise and not row-wise, see Indexing Basics . For example dft_minute['2011-12-31 23:59'] will raise KeyError as '2012-12-31 23:59' has the same resolution as the index and there is no column with such name: To always have unambiguous selection, whether the row is treated as a slice or a single selection, use .loc . Note also that DatetimeIndex resolution cannot be less precise than day. Exact indexing # As discussed in previous section, indexing a DatetimeIndex with a partial string depends on the “accuracy” of the period, in other words how specific the interval is in relation to the resolution of the index. In contrast, indexing with Timestamp or datetime objects is exact, because the objects have exact meaning. These also follow the semantics of including both endpoints . These Timestamp and datetime objects have exact hours, minutes, and seconds , even though they were not explicitly specified (they are 0 ). With no defaults. Truncating & fancy indexing # A truncate() convenience function is provided that is similar to slicing. Note that truncate assumes a 0 value for any unspecified date component in a DatetimeIndex in contrast to slicing which returns any partially matching dates: Even complicated fancy indexing that breaks the DatetimeIndex frequency regularity will result in a DatetimeIndex , although frequency is lost: Time/date components # There are several time/date properties that one can access from Timestamp or a collection of timestamps like a DatetimeIndex . Furthermore, if you have a Series with datetimelike values, then you can access these properties via the .dt accessor, as detailed in the section on .dt accessors . You may obtain the year, week and day components of the ISO year from the ISO 8601 standard: DateOffset objects # In the preceding examples, frequency strings (e.g. 'D' ) were used to specify a frequency that defined: how the date times in DatetimeIndex were spaced when using date_range() the frequency of a Period or PeriodIndex These frequency strings map to a DateOffset object and its subclasses. A DateOffset is similar to a Timedelta that represents a duration of time but follows specific calendar duration rules. For example, a Timedelta day will always increment datetimes by 24 hours, while a DateOffset day will increment datetimes to the same time the next day whether a day represents 23, 24 or 25 hours due to daylight savings time. However, all DateOffset subclasses that are an hour or smaller ( Hour , Minute , Second , Milli , Micro , Nano ) behave like Timedelta and respect absolute time. The basic DateOffset acts similar to dateutil.relativedelta ( relativedelta documentation ) that shifts a date time by the corresponding calendar duration specified. The arithmetic operator ( + ) can be used to perform the shift. Most DateOffsets have associated frequencies strings, or offset aliases, that can be passed into freq keyword arguments. The available date offsets and associated frequency strings can be found below: DateOffsets additionally have rollforward() and rollback() methods for moving a date forward or backward respectively to a valid offset date relative to the offset. For example, business offsets will roll dates that land on the weekends (Saturday and Sunday) forward to Monday since business offsets operate on the weekdays. These operations preserve time (hour, minute, etc) information by default. To reset time to midnight, use normalize() before or after applying the operation (depending on whether you want the time information included in the operation). Parametric offsets # Some of the offsets can be “parameterized” when created to result in different behaviors. For example, the Week offset for generating weekly data accepts a weekday parameter which results in the generated dates always lying on a particular day of the week: The normalize option will be effective for addition and subtraction. Another example is parameterizing YearEnd with the specific ending month: Using offsets with Series / DatetimeIndex # Offsets can be used with either a Series or DatetimeIndex to apply the offset to each element. If the offset class maps directly to a Timedelta ( Day , Hour , Minute , Second , Micro , Milli , Nano ) it can be used exactly like a Timedelta - see the Timedelta section for more examples. Note that some offsets (such as BQuarterEnd ) do not have a vectorized implementation. They can still be used but may calculate significantly slower and will show a PerformanceWarning Custom business days # The CDay or CustomBusinessDay class provides a parametric BusinessDay class which can be used to create customized business day calendars which account for local holidays and local weekend conventions. As an interesting example, let’s look at Egypt where a Friday-Saturday weekend is observed. Let’s map to the weekday names: Holiday calendars can be used to provide the list of holidays. See the holiday calendar section for more information. Monthly offsets that respect a certain holiday calendar can be defined in the usual way. Note The frequency string ‘C’ is used to indicate that a CustomBusinessDay DateOffset is used, it is important to note that since CustomBusinessDay is a parameterised type, instances of CustomBusinessDay may differ and this is not detectable from the ‘C’ frequency string. The user therefore needs to ensure that the ‘C’ frequency string is used consistently within the user’s application. Business hour # The BusinessHour class provides a business hour representation on BusinessDay , allowing to use specific start and end times. By default, BusinessHour uses 9:00 - 17:00 as business hours. Adding BusinessHour will increment Timestamp by hourly frequency. If target Timestamp is out of business hours, move to the next business hour then increment it. If the result exceeds the business hours end, the remaining hours are added to the next business day. You can also specify start and end time by keywords. The argument must be a str with an hour:minute representation or a datetime.time instance. Specifying seconds, microseconds and nanoseconds as business hour results in ValueError . Passing start time later than end represents midnight business hour. In this case, business hour exceeds midnight and overlap to the next day. Valid business hours are distinguished by whether it started from valid BusinessDay . Applying BusinessHour.rollforward and rollback to out of business hours results in the next business hour start or previous day’s end. Different from other offsets, BusinessHour.rollforward may output different results from apply by definition. This is because one day’s business hour end is equal to next day’s business hour start. For example, under the default business hours (9:00 - 17:00), there is no gap (0 minutes) between 2014-08-01 17:00 and 2014-08-04 09:00 . BusinessHour regards Saturday and Sunday as holidays. To use arbitrary holidays, you can use CustomBusinessHour offset, as explained in the following subsection. Custom business hour # The CustomBusinessHour is a mixture of BusinessHour and CustomBusinessDay which allows you to specify arbitrary holidays. CustomBusinessHour works as the same as BusinessHour except that it skips specified custom holidays. You can use keyword arguments supported by either BusinessHour and CustomBusinessDay . Offset aliases # A number of string aliases are given to useful common time series frequencies. We will refer to these aliases as offset aliases . Deprecated since version 2.2.0: Aliases H , BH , CBH , T , S , L , U , and N are deprecated in favour of the aliases h , bh , cbh , min , s , ms , us , and ns . Note When using the offset aliases above, it should be noted that functions such as date_range() , bdate_range() , will only return timestamps that are in the interval defined by start_date and end_date . If the start_date does not correspond to the frequency, the returned timestamps will start at the next valid timestamp, same for end_date , the returned timestamps will stop at the previous valid timestamp. For example, for the offset MS , if the start_date is not the first of the month, the returned timestamps will start with the first day of the next month. If end_date is not the first day of a month, the last returned timestamp will be the first day of the corresponding month. We can see in the above example date_range() and bdate_range() will only return the valid timestamps between the start_date and end_date . If these are not valid timestamps for the given frequency it will roll to the next value for start_date (respectively previous for the end_date ) Period aliases # A number of string aliases are given to useful common time series frequencies. We will refer to these aliases as period aliases . Deprecated since version 2.2.0: Aliases A , H , T , S , L , U , and N are deprecated in favour of the aliases Y , h , min , s , ms , us , and ns . Combining aliases # As we have seen previously, the alias and the offset instance are fungible in most functions: You can combine together day and intraday offsets: Anchored offsets # For some frequencies you can specify an anchoring suffix: These can be used as arguments to date_range , bdate_range , constructors for DatetimeIndex , as well as various other timeseries-related functions in pandas. Anchored offset semantics # For those offsets that are anchored to the start or end of specific frequency ( MonthEnd , MonthBegin , WeekEnd , etc), the following rules apply to rolling forward and backwards. When n is not 0, if the given date is not on an anchor point, it snapped to the next(previous) anchor point, and moved |n|-1 additional steps forwards or backwards. If the given date is on an anchor point, it is moved |n| points forwards or backwards. For the case when n=0 , the date is not moved if on an anchor point, otherwise it is rolled forward to the next anchor point. Holidays / holiday calendars # Holidays and calendars provide a simple way to define holiday rules to be used with CustomBusinessDay or in other analysis that requires a predefined set of holidays. The AbstractHolidayCalendar class provides all the necessary methods to return a list of holidays and only rules need to be defined in a specific holiday calendar class. Furthermore, the start_date and end_date class attributes determine over what date range holidays are generated. These should be overwritten on the AbstractHolidayCalendar class to have the range apply to all calendar subclasses. USFederalHolidayCalendar is the only calendar that exists and primarily serves as an example for developing other calendars. For holidays that occur on fixed dates (e.g., US Memorial Day or July 4th) an observance rule determines when that holiday is observed if it falls on a weekend or some other non-observed day. Defined observance rules are: An example of how holidays and holiday calendars are defined: hint : weekday=MO(2) is same as 2 * Week(weekday=2) Using this calendar, creating an index or doing offset arithmetic skips weekends and holidays (i.e., Memorial Day/July 4th). For example, the below defines a custom business day offset using the ExampleCalendar . Like any other offset, it can be used to create a DatetimeIndex or added to datetime or Timestamp objects. Ranges are defined by the start_date and end_date class attributes of AbstractHolidayCalendar . The defaults are shown below. These dates can be overwritten by setting the attributes as datetime/Timestamp/string. Every calendar class is accessible by name using the get_calendar function which returns a holiday class instance. Any imported calendar class will automatically be available by this function. Also, HolidayCalendarFactory provides an easy interface to create calendars that are combinations of calendars or calendars with additional rules. Time Series-related instance methods # Shifting / lagging # One may want to shift or lag the values in a time series back and forward in time. The method for this is shift() , which is available on all of the pandas objects. The shift method accepts an freq argument which can accept a DateOffset class or other timedelta -like object or also an offset alias . When freq is specified, shift method changes all the dates in the index rather than changing the alignment of the data and the index: Note that with when freq is specified, the leading entry is no longer NaN because the data is not being realigned. Frequency conversion # The primary function for changing frequencies is the asfreq() method. For a DatetimeIndex , this is basically just a thin, but convenient wrapper around reindex() which generates a date_range and calls reindex . asfreq provides a further convenience so you can specify an interpolation method for any gaps that may appear after the frequency conversion. Filling forward / backward # Related to asfreq and reindex is fillna() , which is documented in the missing data section . Converting to Python datetimes # DatetimeIndex can be converted to an array of Python native datetime.datetime objects using the to_pydatetime method. Resampling # pandas has a simple, powerful, and efficient functionality for performing resampling operations during frequency conversion (e.g., converting secondly data into 5-minutely data). This is extremely common in, but not limited to, financial applications. resample() is a time-based groupby, followed by a reduction method on each of its groups. See some cookbook examples for some advanced strategies. The resample() method can be used directly from DataFrameGroupBy objects, see the groupby docs . Basics # The resample function is very flexible and allows you to specify many different parameters to control the frequency conversion and resampling operation. Any built-in method available via GroupBy is available as a method of the returned object, including sum , mean , std , sem , max , min , median , first , last , ohlc : For downsampling, closed can be set to ‘left’ or ‘right’ to specify which end of the interval is closed: Parameters like label are used to manipulate the resulting labels. label specifies whether the result is labeled with the beginning or the end of the interval. Warning The default values for label and closed is ‘ left ’ for all frequency offsets except for ‘ME’, ‘YE’, ‘QE’, ‘BME’, ‘BYE’, ‘BQE’, and ‘W’ which all have a default of ‘right’. This might unintendedly lead to looking ahead, where the value for a later time is pulled back to a previous time as in the following example with the BusinessDay frequency: Notice how the value for Sunday got pulled back to the previous Friday. To get the behavior where the value for Sunday is pushed to Monday, use instead The axis parameter can be set to 0 or 1 and allows you to resample the specified axis for a DataFrame . kind can be set to ‘timestamp’ or ‘period’ to convert the resulting index to/from timestamp and time span representations. By default resample retains the input representation. convention can be set to ‘start’ or ‘end’ when resampling period data (detail below). It specifies how low frequency periods are converted to higher frequency periods. Upsampling # For upsampling, you can specify a way to upsample and the limit parameter to interpolate over the gaps that are created: Sparse resampling # Sparse timeseries are the ones where you have a lot fewer points relative to the amount of time you are looking to resample. Naively upsampling a sparse series can potentially generate lots of intermediate values. When you don’t want to use a method to fill these values, e.g. fill_method is None , then intermediate values will be filled with NaN . Since resample is a time-based groupby, the following is a method to efficiently resample only the groups that are not all NaN . If we want to resample to the full range of the series: We can instead only resample those groups where we have points as follows: Aggregation # The resample() method returns a pandas.api.typing.Resampler instance. Similar to the aggregating API , groupby API , and the window API , a Resampler can be selectively resampled. Resampling a DataFrame , the default will be to act on all columns with the same function. We can select a specific column or columns using standard getitem. You can pass a list or dict of functions to do aggregation with, outputting a DataFrame : On a resampled DataFrame , you can pass a list of functions to apply to each column, which produces an aggregated result with a hierarchical index: By passing a dict to aggregate you can apply a different aggregation to the columns of a DataFrame : The function names can also be strings. In order for a string to be valid it must be implemented on the resampled object: Furthermore, you can also specify multiple aggregation functions for each column separately. If a DataFrame does not have a datetimelike index, but instead you want to resample based on datetimelike column in the frame, it can passed to the on keyword. Similarly, if you instead want to resample by a datetimelike level of MultiIndex , its name or location can be passed to the level keyword. Iterating through groups # With the Resampler object in hand, iterating through the grouped data is very natural and functions similarly to itertools.groupby() : See Iterating through groups or Resampler.__iter__ for more. Use origin or offset to adjust the start of the bins # The bins of the grouping are adjusted based on the beginning of the day of the time series starting point. This works well with frequencies that are multiples of a day (like 30D ) or that divide a day evenly (like 90s or 1min ). This can create inconsistencies with some frequencies that do not meet this criteria. To change this behavior you can specify a fixed Timestamp with the argument origin . For example: Here we can see that, when using origin with its default value ( 'start_day' ), the result after '2000-10-02 00:00:00' are not identical depending on the start of time series: Here we can see that, when setting origin to 'epoch' , the result after '2000-10-02 00:00:00' are identical depending on the start of time series: If needed you can use a custom timestamp for origin : If needed you can just adjust the bins with an offset Timedelta that would be added to the default origin . Those two examples are equivalent for this time series: Note the use of 'start' for origin on the last example. In that case, origin will be set to the first value of the timeseries. Backward resample # New in version 1.3.0. Instead of adjusting the beginning of bins, sometimes we need to fix the end of the bins to make a backward resample with a given freq . The backward resample sets closed to 'right' by default since the last value should be considered as the edge point for the last bin. We can set origin to 'end' . The value for a specific Timestamp index stands for the resample result from the current Timestamp minus freq to the current Timestamp with a right close. Besides, in contrast with the 'start_day' option, end_day is supported. This will set the origin as the ceiling midnight of the largest Timestamp . The above result uses 2000-10-02 00:29:00 as the last bin’s right edge since the following computation. Time span representation # Regular intervals of time are represented by Period objects in pandas while sequences of Period objects are collected in a PeriodIndex , which can be created with the convenience function period_range . Period # A Period represents a span of time (e.g., a day, a month, a quarter, etc). You can specify the span via freq keyword using a frequency alias like below. Because freq represents a span of Period , it cannot be negative like “-3D”. Adding and subtracting integers from periods shifts the period by its own frequency. Arithmetic is not allowed between Period with different freq (span). If Period freq is daily or higher ( D , h , min , s , ms , us , and ns ), offsets and timedelta -like can be added if the result can have the same freq. Otherwise, ValueError will be raised. If Period has other frequencies, only the same offsets can be added. Otherwise, ValueError will be raised. Taking the difference of Period instances with the same frequency will return the number of frequency units between them: PeriodIndex and period_range # Regular sequences of Period objects can be collected in a PeriodIndex , which can be constructed using the period_range convenience function: The PeriodIndex constructor can also be used directly: Passing multiplied frequency outputs a sequence of Period which has multiplied span. If start or end are Period objects, they will be used as anchor endpoints for a PeriodIndex with frequency matching that of the PeriodIndex constructor. Just like DatetimeIndex , a PeriodIndex can also be used to index pandas objects: PeriodIndex supports addition and subtraction with the same rule as Period . PeriodIndex has its own dtype named period , refer to Period Dtypes . Period dtypes # PeriodIndex has a custom period dtype. This is a pandas extension dtype similar to the timezone aware dtype ( datetime64[ns, tz] ). The period dtype holds the freq attribute and is represented with period[freq] like period[D] or period[M] , using frequency strings . The period dtype can be used in .astype(...) . It allows one to change the freq of a PeriodIndex like .asfreq() and convert a DatetimeIndex to PeriodIndex like to_period() : PeriodIndex partial string indexing # PeriodIndex now supports partial string slicing with non-monotonic indexes. You can pass in dates and strings to Series and DataFrame with PeriodIndex , in the same manner as DatetimeIndex . For details, refer to DatetimeIndex Partial String Indexing . Passing a string representing a lower frequency than PeriodIndex returns partial sliced data. As with DatetimeIndex , the endpoints will be included in the result. The example below slices data starting from 10:00 to 11:59. Frequency conversion and resampling with PeriodIndex # The frequency of Period and PeriodIndex can be converted via the asfreq method. Let’s start with the fiscal year 2011, ending in December: We can convert it to a monthly frequency. Using the how parameter, we can specify whether to return the starting or ending month: The shorthands ‘s’ and ‘e’ are provided for convenience: Converting to a “super-period” (e.g., annual frequency is a super-period of quarterly frequency) automatically returns the super-period that includes the input period: Note that since we converted to an annual frequency that ends the year in November, the monthly period of December 2011 is actually in the 2012 Y-NOV period. Period conversions with anchored frequencies are particularly useful for working with various quarterly data common to economics, business, and other fields. Many organizations define quarters relative to the month in which their fiscal year starts and ends. Thus, first quarter of 2011 could start in 2010 or a few months into 2011. Via anchored frequencies, pandas works for all quarterly frequencies Q-JAN through Q-DEC . Q-DEC define regular calendar quarters: Q-MAR defines fiscal year end in March: Converting between representations # Timestamped data can be converted to PeriodIndex-ed data using to_period and vice-versa using to_timestamp : Remember that ‘s’ and ‘e’ can be used to return the timestamps at the start or end of the period: Converting between period and timestamp enables some convenient arithmetic functions to be used. In the following example, we convert a quarterly frequency with year ending in November to 9am of the end of the month following the quarter end: Representing out-of-bounds spans # If you have data that is outside of the Timestamp bounds, see Timestamp limitations , then you can use a PeriodIndex and/or Series of Periods to do computations. To convert from an int64 based YYYYMMDD representation. These can easily be converted to a PeriodIndex : Time zone handling # pandas provides rich support for working with timestamps in different time zones using the pytz and dateutil libraries or datetime.timezone objects from the standard library. Working with time zones # By default, pandas objects are time zone unaware: To localize these dates to a time zone (assign a particular time zone to a naive date), you can use the tz_localize method or the tz keyword argument in date_range() , Timestamp , or DatetimeIndex . You can either pass pytz or dateutil time zone objects or Olson time zone database strings. Olson time zone strings will return pytz time zone objects by default. To return dateutil time zone objects, append dateutil/ before the string. In pytz you can find a list of common (and less common) time zones using from pytz import common_timezones, all_timezones . dateutil uses the OS time zones so there isn’t a fixed list available. For common zones, the names are the same as pytz . Note that the UTC time zone is a special case in dateutil and should be constructed explicitly as an instance of dateutil.tz.tzutc . You can also construct other time zones objects explicitly first. To convert a time zone aware pandas object from one time zone to another, you can use the tz_convert method. Note When using pytz time zones, DatetimeIndex will construct a different time zone object than a Timestamp for the same time zone input. A DatetimeIndex can hold a collection of Timestamp objects that may have different UTC offsets and cannot be succinctly represented by one pytz time zone instance while one Timestamp represents one point in time with a specific UTC offset. Warning Be wary of conversions between libraries. For some time zones, pytz and dateutil have different definitions of the zone. This is more of a problem for unusual time zones than for ‘standard’ zones like US/Eastern . Warning Be aware that a time zone definition across versions of time zone libraries may not be considered equal. This may cause problems when working with stored data that is localized using one version and operated on with a different version. See here for how to handle such a situation. Warning For pytz time zones, it is incorrect to pass a time zone object directly into the datetime.datetime constructor (e.g., datetime.datetime(2011, 1, 1, tzinfo=pytz.timezone('US/Eastern')) . Instead, the datetime needs to be localized using the localize method on the pytz time zone object. Warning Be aware that for times in the future, correct conversion between time zones (and UTC) cannot be guaranteed by any time zone library because a timezone’s offset from UTC may be changed by the respective government. Warning If you are using dates beyond 2038-01-18, due to current deficiencies in the underlying libraries caused by the year 2038 problem, daylight saving time (DST) adjustments to timezone aware dates will not be applied. If and when the underlying libraries are fixed, the DST transitions will be applied. For example, for two dates that are in British Summer Time (and so would normally be GMT+1), both the following asserts evaluate as true: Under the hood, all timestamps are stored in UTC. Values from a time zone aware DatetimeIndex or Timestamp will have their fields (day, hour, minute, etc.) localized to the time zone. However, timestamps with the same UTC value are still considered to be equal even if they are in different time zones: Operations between Series in different time zones will yield UTC Series , aligning the data on the UTC timestamps: To remove time zone information, use tz_localize(None) or tz_convert(None) . tz_localize(None) will remove the time zone yielding the local time representation. tz_convert(None) will remove the time zone after converting to UTC time. Fold # For ambiguous times, pandas supports explicitly specifying the keyword-only fold argument. Due to daylight saving time, one wall clock time can occur twice when shifting from summer to winter time; fold describes whether the datetime-like corresponds to the first (0) or the second time (1) the wall clock hits the ambiguous time. Fold is supported only for constructing from naive datetime.datetime (see datetime documentation for details) or from Timestamp or for constructing from components (see below). Only dateutil timezones are supported (see dateutil documentation for dateutil methods that deal with ambiguous datetimes) as pytz timezones do not support fold (see pytz documentation for details on how pytz deals with ambiguous datetimes). To localize an ambiguous datetime with pytz , please use Timestamp.tz_localize() . In general, we recommend to rely on Timestamp.tz_localize() when localizing ambiguous datetimes if you need direct control over how they are handled. Ambiguous times when localizing # tz_localize may not be able to determine the UTC offset of a timestamp because daylight savings time (DST) in a local time zone causes some times to occur twice within one day (“clocks fall back”). The following options are available: 'raise' : Raises a pytz.AmbiguousTimeError (the default behavior) 'infer' : Attempt to determine the correct offset base on the monotonicity of the timestamps 'NaT' : Replaces ambiguous times with NaT bool : True represents a DST time, False represents non-DST time. An array-like of bool values is supported for a sequence of times. This will fail as there are ambiguous times ( '11/06/2011 01:00' ) Handle these ambiguous times by specifying the following. Nonexistent times when localizing # A DST transition may also shift the local time ahead by 1 hour creating nonexistent local times (“clocks spring forward”). The behavior of localizing a timeseries with nonexistent times can be controlled by the nonexistent argument. The following options are available: 'raise' : Raises a pytz.NonExistentTimeError (the default behavior) 'NaT' : Replaces nonexistent times with NaT 'shift_forward' : Shifts nonexistent times forward to the closest real time 'shift_backward' : Shifts nonexistent times backward to the closest real time timedelta object: Shifts nonexistent times by the timedelta duration Localization of nonexistent times will raise an error by default. Transform nonexistent times to NaT or shift the times. Time zone Series operations # A Series with time zone naive values is represented with a dtype of datetime64[ns] . A Series with a time zone aware values is represented with a dtype of datetime64[ns, tz] where tz is the time zone Both of these Series time zone information can be manipulated via the .dt accessor, see the dt accessor section . For example, to localize and convert a naive stamp to time zone aware. Time zone information can also be manipulated using the astype method. This method can convert between different timezone-aware dtypes. Note Using Series.to_numpy() on a Series , returns a NumPy array of the data. NumPy does not currently support time zones (even though it is printing in the local time zone!), therefore an object array of Timestamps is returned for time zone aware data: By converting to an object array of Timestamps, it preserves the time zone information. For example, when converting back to a Series: However, if you want an actual NumPy datetime64[ns] array (with the values converted to UTC) instead of an array of objects, you can specify the dtype argument:"
https://pandas.pydata.org/docs/user_guide/timedeltas.html,Time deltas,"<article class=""bd-article"" role=""main"">
<section id=""time-deltas"">
<span id=""timedeltas-timedeltas""></span><span id=""timedeltas""></span><h1>Time deltas<a class=""headerlink"" href=""#time-deltas"" title=""Link to this heading"">#</a></h1>
<p>Timedeltas are differences in times, expressed in difference units, e.g. days, hours, minutes,
seconds. They can be both positive and negative.</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code> is a subclass of <code class=""docutils literal notranslate""><span class=""pre"">datetime.timedelta</span></code>, and behaves in a similar manner,
but allows compatibility with <code class=""docutils literal notranslate""><span class=""pre"">np.timedelta64</span></code> types as well as a host of custom representation,
parsing, and attributes.</p>
<section id=""parsing"">
<h2>Parsing<a class=""headerlink"" href=""#parsing"" title=""Link to this heading"">#</a></h2>
<p>You can construct a <code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code> scalar through various arguments, including <a class=""reference external"" href=""https://en.wikipedia.org/wiki/ISO_8601#Durations"">ISO 8601 Duration</a> strings.</p>

<p><a class=""reference internal"" href=""timeseries.html#timeseries-offsets""><span class=""std std-ref"">DateOffsets</span></a> (<code class=""docutils literal notranslate""><span class=""pre"">Day,</span> <span class=""pre"">Hour,</span> <span class=""pre"">Minute,</span> <span class=""pre"">Second,</span> <span class=""pre"">Milli,</span> <span class=""pre"">Micro,</span> <span class=""pre"">Nano</span></code>) can also be used in construction.</p>

<p>Further, operations among the scalars yield another scalar <code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code>.</p>

<section id=""to-timedelta"">
<h3>to_timedelta<a class=""headerlink"" href=""#to-timedelta"" title=""Link to this heading"">#</a></h3>
<p>Using the top-level <code class=""docutils literal notranslate""><span class=""pre"">pd.to_timedelta</span></code>, you can convert a scalar, array, list,
or Series from a recognized timedelta format / value into a <code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code> type.
It will construct Series if the input is a Series, a scalar if the input is
scalar-like, otherwise it will output a <code class=""docutils literal notranslate""><span class=""pre"">TimedeltaIndex</span></code>.</p>
<p>You can parse a single string to a Timedelta:</p>

<p>or a list/array of strings:</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">unit</span></code> keyword argument specifies the unit of the Timedelta if the input
is numeric:</p>

<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>If a string or array of strings is passed as an input then the <code class=""docutils literal notranslate""><span class=""pre"">unit</span></code> keyword
argument will be ignored. If a string without units is passed then the default
unit of nanoseconds is assumed.</p>
</div>
</section>
<section id=""timedelta-limitations"">
<span id=""timedeltas-limitations""></span><h3>Timedelta limitations<a class=""headerlink"" href=""#timedelta-limitations"" title=""Link to this heading"">#</a></h3>
<p>pandas represents <code class=""docutils literal notranslate""><span class=""pre"">Timedeltas</span></code> in nanosecond resolution using
64 bit integers. As such, the 64 bit integer limits determine
the <code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code> limits.</p>

</section>
</section>
<section id=""operations"">
<span id=""timedeltas-operations""></span><h2>Operations<a class=""headerlink"" href=""#operations"" title=""Link to this heading"">#</a></h2>
<p>You can operate on Series/DataFrames and construct <code class=""docutils literal notranslate""><span class=""pre"">timedelta64[ns]</span></code> Series through
subtraction operations on <code class=""docutils literal notranslate""><span class=""pre"">datetime64[ns]</span></code> Series, or <code class=""docutils literal notranslate""><span class=""pre"">Timestamps</span></code>.</p>

<p>Operations with scalars from a <code class=""docutils literal notranslate""><span class=""pre"">timedelta64[ns]</span></code> series:</p>

<p>Series of timedeltas with <code class=""docutils literal notranslate""><span class=""pre"">NaT</span></code> values are supported:</p>

<p>Elements can be set to <code class=""docutils literal notranslate""><span class=""pre"">NaT</span></code> using <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code> analogously to datetimes:</p>

<p>Operands can also appear in a reversed order (a singular object operated with a Series):</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">min,</span> <span class=""pre"">max</span></code> and the corresponding <code class=""docutils literal notranslate""><span class=""pre"">idxmin,</span> <span class=""pre"">idxmax</span></code> operations are supported on frames:</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">min,</span> <span class=""pre"">max,</span> <span class=""pre"">idxmin,</span> <span class=""pre"">idxmax</span></code> operations are supported on Series as well. A scalar result will be a <code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code>.</p>

<p>You can fillna on timedeltas, passing a timedelta to get a particular value.</p>

<p>You can also negate, multiply and use <code class=""docutils literal notranslate""><span class=""pre"">abs</span></code> on <code class=""docutils literal notranslate""><span class=""pre"">Timedeltas</span></code>:</p>

</section>
<section id=""reductions"">
<span id=""timedeltas-timedeltas-reductions""></span><h2>Reductions<a class=""headerlink"" href=""#reductions"" title=""Link to this heading"">#</a></h2>
<p>Numeric reduction operation for <code class=""docutils literal notranslate""><span class=""pre"">timedelta64[ns]</span></code> will return <code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code> objects. As usual
<code class=""docutils literal notranslate""><span class=""pre"">NaT</span></code> are skipped during evaluation.</p>

</section>
<section id=""frequency-conversion"">
<span id=""timedeltas-timedeltas-convert""></span><h2>Frequency conversion<a class=""headerlink"" href=""#frequency-conversion"" title=""Link to this heading"">#</a></h2>
<p>Timedelta Series and <code class=""docutils literal notranslate""><span class=""pre"">TimedeltaIndex</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code> can be converted to other frequencies by astyping to a specific timedelta dtype.</p>

<p>For timedelta64 resolutions other than the supported “s”, “ms”, “us”, “ns”,
an alternative is to divide by another timedelta object. Note that division by the NumPy scalar is true division, while astyping is equivalent of floor division.</p>

<p>Dividing or multiplying a <code class=""docutils literal notranslate""><span class=""pre"">timedelta64[ns]</span></code> Series by an integer or integer Series
yields another <code class=""docutils literal notranslate""><span class=""pre"">timedelta64[ns]</span></code> dtypes Series.</p>

<p>Rounded division (floor-division) of a <code class=""docutils literal notranslate""><span class=""pre"">timedelta64[ns]</span></code> Series by a scalar
<code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code> gives a series of integers.</p>

<p id=""timedeltas-mod-divmod"">The mod (%) and divmod operations are defined for <code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code> when operating with another timedelta-like or with a numeric argument.</p>

</section>
<section id=""attributes"">
<h2>Attributes<a class=""headerlink"" href=""#attributes"" title=""Link to this heading"">#</a></h2>
<p>You can access various components of the <code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">TimedeltaIndex</span></code> directly using the attributes <code class=""docutils literal notranslate""><span class=""pre"">days,seconds,microseconds,nanoseconds</span></code>. These are identical to the values returned by <code class=""docutils literal notranslate""><span class=""pre"">datetime.timedelta</span></code>, in that, for example, the <code class=""docutils literal notranslate""><span class=""pre"">.seconds</span></code> attribute represents the number of seconds &gt;= 0 and &lt; 1 day. These are signed according to whether the <code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code> is signed.</p>
<p>These operations can also be directly accessed via the <code class=""docutils literal notranslate""><span class=""pre"">.dt</span></code> property of the <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> as well.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Note that the attributes are NOT the displayed values of the <code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code>. Use <code class=""docutils literal notranslate""><span class=""pre"">.components</span></code> to retrieve the displayed values.</p>
</div>
<p>For a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>:</p>

<p>You can access the value of the fields for a scalar <code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code> directly.</p>

<p>You can use the <code class=""docutils literal notranslate""><span class=""pre"">.components</span></code> property to access a reduced form of the timedelta. This returns a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> indexed
similarly to the <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code>. These are the <em>displayed</em> values of the <code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code>.</p>

<p id=""timedeltas-isoformat"">You can convert a <code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code> to an <a class=""reference external"" href=""https://en.wikipedia.org/wiki/ISO_8601#Durations"">ISO 8601 Duration</a> string with the
<code class=""docutils literal notranslate""><span class=""pre"">.isoformat</span></code> method</p>

</section>
<section id=""timedeltaindex"">
<span id=""timedeltas-index""></span><h2>TimedeltaIndex<a class=""headerlink"" href=""#timedeltaindex"" title=""Link to this heading"">#</a></h2>
<p>To generate an index with time delta, you can use either the <a class=""reference internal"" href=""../reference/api/pandas.TimedeltaIndex.html#pandas.TimedeltaIndex"" title=""pandas.TimedeltaIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">TimedeltaIndex</span></code></a> or
the <a class=""reference internal"" href=""../reference/api/pandas.timedelta_range.html#pandas.timedelta_range"" title=""pandas.timedelta_range""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">timedelta_range()</span></code></a> constructor.</p>
<p>Using <code class=""docutils literal notranslate""><span class=""pre"">TimedeltaIndex</span></code> you can pass string-like, <code class=""docutils literal notranslate""><span class=""pre"">Timedelta</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">timedelta</span></code>,
or <code class=""docutils literal notranslate""><span class=""pre"">np.timedelta64</span></code> objects. Passing <code class=""docutils literal notranslate""><span class=""pre"">np.nan/pd.NaT/nat</span></code> will represent missing values.</p>

<p>The string ‘infer’ can be passed in order to set the frequency of the index as the
inferred frequency upon creation:</p>

<section id=""generating-ranges-of-time-deltas"">
<h3>Generating ranges of time deltas<a class=""headerlink"" href=""#generating-ranges-of-time-deltas"" title=""Link to this heading"">#</a></h3>
<p>Similar to <a class=""reference internal"" href=""../reference/api/pandas.date_range.html#pandas.date_range"" title=""pandas.date_range""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">date_range()</span></code></a>, you can construct regular ranges of a <code class=""docutils literal notranslate""><span class=""pre"">TimedeltaIndex</span></code>
using <a class=""reference internal"" href=""../reference/api/pandas.timedelta_range.html#pandas.timedelta_range"" title=""pandas.timedelta_range""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">timedelta_range()</span></code></a>. The default frequency for <code class=""docutils literal notranslate""><span class=""pre"">timedelta_range</span></code> is
calendar day:</p>

<p>Various combinations of <code class=""docutils literal notranslate""><span class=""pre"">start</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">end</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">periods</span></code> can be used with
<code class=""docutils literal notranslate""><span class=""pre"">timedelta_range</span></code>:</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">freq</span></code> parameter can passed a variety of <a class=""reference internal"" href=""timeseries.html#timeseries-offset-aliases""><span class=""std std-ref"">frequency aliases</span></a>:</p>

<p>Specifying <code class=""docutils literal notranslate""><span class=""pre"">start</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">end</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">periods</span></code> will generate a range of evenly spaced
timedeltas from <code class=""docutils literal notranslate""><span class=""pre"">start</span></code> to <code class=""docutils literal notranslate""><span class=""pre"">end</span></code> inclusively, with <code class=""docutils literal notranslate""><span class=""pre"">periods</span></code> number of elements
in the resulting <code class=""docutils literal notranslate""><span class=""pre"">TimedeltaIndex</span></code>:</p>

</section>
<section id=""using-the-timedeltaindex"">
<h3>Using the TimedeltaIndex<a class=""headerlink"" href=""#using-the-timedeltaindex"" title=""Link to this heading"">#</a></h3>
<p>Similarly to other of the datetime-like indices, <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">PeriodIndex</span></code>, you can use
<code class=""docutils literal notranslate""><span class=""pre"">TimedeltaIndex</span></code> as the index of pandas objects.</p>

<p>Selections work similarly, with coercion on string-likes and slices:</p>

<p>Furthermore you can use partial string selection and the range will be inferred:</p>

</section>
<section id=""id1"">
<h3>Operations<a class=""headerlink"" href=""#id1"" title=""Link to this heading"">#</a></h3>
<p>Finally, the combination of <code class=""docutils literal notranslate""><span class=""pre"">TimedeltaIndex</span></code> with <code class=""docutils literal notranslate""><span class=""pre"">DatetimeIndex</span></code> allow certain combination operations that are NaT preserving:</p>

</section>
<section id=""conversions"">
<h3>Conversions<a class=""headerlink"" href=""#conversions"" title=""Link to this heading"">#</a></h3>
<p>Similarly to frequency conversion on a <code class=""docutils literal notranslate""><span class=""pre"">Series</span></code> above, you can convert these indices to yield another Index.</p>

<p>Scalars type ops work as well. These can potentially return a <em>different</em> type of index.</p>

</section>
</section>
<section id=""resampling"">
<span id=""timedeltas-resampling""></span><h2>Resampling<a class=""headerlink"" href=""#resampling"" title=""Link to this heading"">#</a></h2>
<p>Similar to <a class=""reference internal"" href=""timeseries.html#timeseries-resampling""><span class=""std std-ref"">timeseries resampling</span></a>, we can resample with a <code class=""docutils literal notranslate""><span class=""pre"">TimedeltaIndex</span></code>.</p>

</section>
</section>
</article>","Time deltas # Timedeltas are differences in times, expressed in difference units, e.g. days, hours, minutes, seconds. They can be both positive and negative. Timedelta is a subclass of datetime.timedelta , and behaves in a similar manner, but allows compatibility with np.timedelta64 types as well as a host of custom representation, parsing, and attributes. Parsing # You can construct a Timedelta scalar through various arguments, including ISO 8601 Duration strings. DateOffsets ( Day, Hour, Minute, Second, Milli, Micro, Nano ) can also be used in construction. Further, operations among the scalars yield another scalar Timedelta . to_timedelta # Using the top-level pd.to_timedelta , you can convert a scalar, array, list, or Series from a recognized timedelta format / value into a Timedelta type. It will construct Series if the input is a Series, a scalar if the input is scalar-like, otherwise it will output a TimedeltaIndex . You can parse a single string to a Timedelta: or a list/array of strings: The unit keyword argument specifies the unit of the Timedelta if the input is numeric: Warning If a string or array of strings is passed as an input then the unit keyword argument will be ignored. If a string without units is passed then the default unit of nanoseconds is assumed. Timedelta limitations # pandas represents Timedeltas in nanosecond resolution using 64 bit integers. As such, the 64 bit integer limits determine the Timedelta limits. Operations # You can operate on Series/DataFrames and construct timedelta64[ns] Series through subtraction operations on datetime64[ns] Series, or Timestamps . Operations with scalars from a timedelta64[ns] series: Series of timedeltas with NaT values are supported: Elements can be set to NaT using np.nan analogously to datetimes: Operands can also appear in a reversed order (a singular object operated with a Series): min, max and the corresponding idxmin, idxmax operations are supported on frames: min, max, idxmin, idxmax operations are supported on Series as well. A scalar result will be a Timedelta . You can fillna on timedeltas, passing a timedelta to get a particular value. You can also negate, multiply and use abs on Timedeltas : Reductions # Numeric reduction operation for timedelta64[ns] will return Timedelta objects. As usual NaT are skipped during evaluation. Frequency conversion # Timedelta Series and TimedeltaIndex , and Timedelta can be converted to other frequencies by astyping to a specific timedelta dtype. For timedelta64 resolutions other than the supported “s”, “ms”, “us”, “ns”, an alternative is to divide by another timedelta object. Note that division by the NumPy scalar is true division, while astyping is equivalent of floor division. Dividing or multiplying a timedelta64[ns] Series by an integer or integer Series yields another timedelta64[ns] dtypes Series. Rounded division (floor-division) of a timedelta64[ns] Series by a scalar Timedelta gives a series of integers. The mod (%) and divmod operations are defined for Timedelta when operating with another timedelta-like or with a numeric argument. Attributes # You can access various components of the Timedelta or TimedeltaIndex directly using the attributes days,seconds,microseconds,nanoseconds . These are identical to the values returned by datetime.timedelta , in that, for example, the .seconds attribute represents the number of seconds >= 0 and < 1 day. These are signed according to whether the Timedelta is signed. These operations can also be directly accessed via the .dt property of the Series as well. Note Note that the attributes are NOT the displayed values of the Timedelta . Use .components to retrieve the displayed values. For a Series : You can access the value of the fields for a scalar Timedelta directly. You can use the .components property to access a reduced form of the timedelta. This returns a DataFrame indexed similarly to the Series . These are the displayed values of the Timedelta . You can convert a Timedelta to an ISO 8601 Duration string with the .isoformat method TimedeltaIndex # To generate an index with time delta, you can use either the TimedeltaIndex or the timedelta_range() constructor. Using TimedeltaIndex you can pass string-like, Timedelta , timedelta , or np.timedelta64 objects. Passing np.nan/pd.NaT/nat will represent missing values. The string ‘infer’ can be passed in order to set the frequency of the index as the inferred frequency upon creation: Generating ranges of time deltas # Similar to date_range() , you can construct regular ranges of a TimedeltaIndex using timedelta_range() . The default frequency for timedelta_range is calendar day: Various combinations of start , end , and periods can be used with timedelta_range : The freq parameter can passed a variety of frequency aliases : Specifying start , end , and periods will generate a range of evenly spaced timedeltas from start to end inclusively, with periods number of elements in the resulting TimedeltaIndex : Using the TimedeltaIndex # Similarly to other of the datetime-like indices, DatetimeIndex and PeriodIndex , you can use TimedeltaIndex as the index of pandas objects. Selections work similarly, with coercion on string-likes and slices: Furthermore you can use partial string selection and the range will be inferred: Operations # Finally, the combination of TimedeltaIndex with DatetimeIndex allow certain combination operations that are NaT preserving: Conversions # Similarly to frequency conversion on a Series above, you can convert these indices to yield another Index. Scalars type ops work as well. These can potentially return a different type of index. Resampling # Similar to timeseries resampling , we can resample with a TimedeltaIndex ."
https://pandas.pydata.org/docs/user_guide/options.html,Options and settings,"<article class=""bd-article"" role=""main"">
<section id=""options-and-settings"">
<span id=""options""></span><h1>Options and settings<a class=""headerlink"" href=""#options-and-settings"" title=""Link to this heading"">#</a></h1>
<section id=""overview"">
<h2>Overview<a class=""headerlink"" href=""#overview"" title=""Link to this heading"">#</a></h2>
<p>pandas has an options API configure and customize global behavior related to
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> display, data behavior and more.</p>
<p>Options have a full “dotted-style”, case-insensitive name (e.g. <code class=""docutils literal notranslate""><span class=""pre"">display.max_rows</span></code>).
You can get/set options directly as attributes of the top-level <code class=""docutils literal notranslate""><span class=""pre"">options</span></code> attribute:</p>

<p>The API is composed of 5 relevant functions, available directly from the <code class=""docutils literal notranslate""><span class=""pre"">pandas</span></code>
namespace:</p>
<ul class=""simple"">
<li><p><a class=""reference internal"" href=""../reference/api/pandas.get_option.html#pandas.get_option"" title=""pandas.get_option""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">get_option()</span></code></a> / <a class=""reference internal"" href=""../reference/api/pandas.set_option.html#pandas.set_option"" title=""pandas.set_option""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">set_option()</span></code></a> - get/set the value of a single option.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.reset_option.html#pandas.reset_option"" title=""pandas.reset_option""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">reset_option()</span></code></a> - reset one or more options to their default value.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.describe_option.html#pandas.describe_option"" title=""pandas.describe_option""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">describe_option()</span></code></a> - print the descriptions of one or more options.</p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.option_context.html#pandas.option_context"" title=""pandas.option_context""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">option_context()</span></code></a> - execute a codeblock with a set of options
that revert to prior settings after execution.</p></li>
</ul>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Developers can check out <a class=""reference external"" href=""https://github.com/pandas-dev/pandas/blob/main/pandas/core/config_init.py"">pandas/core/config_init.py</a> for more information.</p>
</div>
<p>All of the functions above accept a regexp pattern (<code class=""docutils literal notranslate""><span class=""pre"">re.search</span></code> style) as an argument,
to match an unambiguous substring:</p>

<p>The following will <strong>not work</strong> because it matches multiple option names, e.g.
<code class=""docutils literal notranslate""><span class=""pre"">display.max_colwidth</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">display.max_rows</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">display.max_columns</span></code>:</p>

<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Using this form of shorthand may cause your code to break if new options with similar names are added in future versions.</p>
</div>
</section>
<section id=""available-options"">
<span id=""options-available""></span><h2>Available options<a class=""headerlink"" href=""#available-options"" title=""Link to this heading"">#</a></h2>
<p>You can get a list of available options and their descriptions with <a class=""reference internal"" href=""../reference/api/pandas.describe_option.html#pandas.describe_option"" title=""pandas.describe_option""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">describe_option()</span></code></a>. When called
with no argument <a class=""reference internal"" href=""../reference/api/pandas.describe_option.html#pandas.describe_option"" title=""pandas.describe_option""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">describe_option()</span></code></a> will print out the descriptions for all available options.</p>

</section>
<section id=""getting-and-setting-options"">
<h2>Getting and setting options<a class=""headerlink"" href=""#getting-and-setting-options"" title=""Link to this heading"">#</a></h2>
<p>As described above, <a class=""reference internal"" href=""../reference/api/pandas.get_option.html#pandas.get_option"" title=""pandas.get_option""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">get_option()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.set_option.html#pandas.set_option"" title=""pandas.set_option""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">set_option()</span></code></a>
are available from the pandas namespace. To change an option, call
<code class=""docutils literal notranslate""><span class=""pre"">set_option('option</span> <span class=""pre"">regex',</span> <span class=""pre"">new_value)</span></code>.</p>

<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The option <code class=""docutils literal notranslate""><span class=""pre"">'mode.sim_interactive'</span></code> is mostly used for debugging purposes.</p>
</div>
<p>You can use <a class=""reference internal"" href=""../reference/api/pandas.reset_option.html#pandas.reset_option"" title=""pandas.reset_option""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">reset_option()</span></code></a> to revert to a setting’s default value</p>

<p>It’s also possible to reset multiple options at once (using a regex):</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.option_context.html#pandas.option_context"" title=""pandas.option_context""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">option_context()</span></code></a> context manager has been exposed through
the top-level API, allowing you to execute code with given option values. Option values
are restored automatically when you exit the <code class=""docutils literal notranslate""><span class=""pre"">with</span></code> block:</p>

</section>
<section id=""setting-startup-options-in-python-ipython-environment"">
<h2>Setting startup options in Python/IPython environment<a class=""headerlink"" href=""#setting-startup-options-in-python-ipython-environment"" title=""Link to this heading"">#</a></h2>
<p>Using startup scripts for the Python/IPython environment to import pandas and set options makes working with pandas more efficient.
To do this, create a <code class=""docutils literal notranslate""><span class=""pre"">.py</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">.ipy</span></code> script in the startup directory of the desired profile.
An example where the startup folder is in a default IPython profile can be found at:</p>
<div class=""highlight-none notranslate""><div class=""highlight""><pre><span></span>$IPYTHONDIR/profile_default/startup
</pre></div>
</div>
<p>More information can be found in the <a class=""reference external"" href=""https://ipython.org/ipython-doc/stable/interactive/tutorial.html#startup-files"">IPython documentation</a>. An example startup script for pandas is displayed below:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">pandas</span> <span class=""k"">as</span> <span class=""nn"">pd</span>

<span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">set_option</span><span class=""p"">(</span><span class=""s2"">""display.max_rows""</span><span class=""p"">,</span> <span class=""mi"">999</span><span class=""p"">)</span>
<span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">set_option</span><span class=""p"">(</span><span class=""s2"">""display.precision""</span><span class=""p"">,</span> <span class=""mi"">5</span><span class=""p"">)</span>
</pre></div>
</div>
</section>
<section id=""frequently-used-options"">
<span id=""options-frequently-used""></span><h2>Frequently used options<a class=""headerlink"" href=""#frequently-used-options"" title=""Link to this heading"">#</a></h2>
<p>The following is a demonstrates the more frequently used display options.</p>
<p><code class=""docutils literal notranslate""><span class=""pre"">display.max_rows</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">display.max_columns</span></code> sets the maximum number
of rows and columns displayed when a frame is pretty-printed. Truncated
lines are replaced by an ellipsis.</p>

<p>Once the <code class=""docutils literal notranslate""><span class=""pre"">display.max_rows</span></code> is exceeded, the <code class=""docutils literal notranslate""><span class=""pre"">display.min_rows</span></code> options
determines how many rows are shown in the truncated repr.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">display.expand_frame_repr</span></code> allows for the representation of a
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> to stretch across pages, wrapped over the all the columns.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">display.large_repr</span></code> displays a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> that exceed
<code class=""docutils literal notranslate""><span class=""pre"">max_columns</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">max_rows</span></code> as a truncated frame or summary.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">display.max_colwidth</span></code> sets the maximum width of columns. Cells
of this length or longer will be truncated with an ellipsis.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">display.max_info_columns</span></code> sets a threshold for the number of columns
displayed when calling <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.info.html#pandas.DataFrame.info"" title=""pandas.DataFrame.info""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">info()</span></code></a>.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">display.max_info_rows</span></code>: <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.info.html#pandas.DataFrame.info"" title=""pandas.DataFrame.info""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">info()</span></code></a> will usually show null-counts for each column.
For a large <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>, this can be quite slow. <code class=""docutils literal notranslate""><span class=""pre"">max_info_rows</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">max_info_cols</span></code>
limit this null check to the specified rows and columns respectively. The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.info.html#pandas.DataFrame.info"" title=""pandas.DataFrame.info""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">info()</span></code></a>
keyword argument <code class=""docutils literal notranslate""><span class=""pre"">show_counts=True</span></code> will override this.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">display.precision</span></code> sets the output display precision in terms of decimal places.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">display.chop_threshold</span></code> sets the rounding threshold to zero when displaying a
<a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>. This setting does not change the
precision at which the number is stored.</p>

<p><code class=""docutils literal notranslate""><span class=""pre"">display.colheader_justify</span></code> controls the justification of the headers.
The options are <code class=""docutils literal notranslate""><span class=""pre"">'right'</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">'left'</span></code>.</p>

</section>
<section id=""number-formatting"">
<span id=""basics-console-output""></span><h2>Number formatting<a class=""headerlink"" href=""#number-formatting"" title=""Link to this heading"">#</a></h2>
<p>pandas also allows you to set how numbers are displayed in the console.
This option is not set through the <code class=""docutils literal notranslate""><span class=""pre"">set_options</span></code> API.</p>
<p>Use the <code class=""docutils literal notranslate""><span class=""pre"">set_eng_float_format</span></code> function
to alter the floating-point formatting of pandas objects to produce a particular
format.</p>

<p>Use <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.round.html#pandas.DataFrame.round"" title=""pandas.DataFrame.round""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">round()</span></code></a> to specifically control rounding of an individual <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a></p>
</section>
<section id=""unicode-formatting"">
<span id=""options-east-asian-width""></span><h2>Unicode formatting<a class=""headerlink"" href=""#unicode-formatting"" title=""Link to this heading"">#</a></h2>
<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p>Enabling this option will affect the performance for printing of DataFrame and Series (about 2 times slower).
Use only when it is actually required.</p>
</div>
<p>Some East Asian countries use Unicode characters whose width corresponds to two Latin characters.
If a DataFrame or Series contains these characters, the default output mode may not align them properly.</p>

<p>Enabling <code class=""docutils literal notranslate""><span class=""pre"">display.unicode.east_asian_width</span></code> allows pandas to check each character’s “East Asian Width” property.
These characters can be aligned properly by setting this option to <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>. However, this will result in longer render
times than the standard <code class=""docutils literal notranslate""><span class=""pre"">len</span></code> function.</p>

<p>In addition, Unicode characters whose width is “ambiguous” can either be 1 or 2 characters wide depending on the
terminal setting or encoding. The option <code class=""docutils literal notranslate""><span class=""pre"">display.unicode.ambiguous_as_wide</span></code> can be used to handle the ambiguity.</p>
<p>By default, an “ambiguous” character’s width, such as “¡” (inverted exclamation) in the example below, is taken to be 1.</p>

<p>Enabling <code class=""docutils literal notranslate""><span class=""pre"">display.unicode.ambiguous_as_wide</span></code> makes pandas interpret these characters’ widths to be 2.
(Note that this option will only be effective when <code class=""docutils literal notranslate""><span class=""pre"">display.unicode.east_asian_width</span></code> is enabled.)</p>
<p>However, setting this option incorrectly for your terminal will cause these characters to be aligned incorrectly:</p>

</section>
<section id=""table-schema-display"">
<span id=""options-table-schema""></span><h2>Table schema display<a class=""headerlink"" href=""#table-schema-display"" title=""Link to this heading"">#</a></h2>
<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> will publish a Table Schema representation
by default. This can be enabled globally with the
<code class=""docutils literal notranslate""><span class=""pre"">display.html.table_schema</span></code> option:</p>

<p>Only <code class=""docutils literal notranslate""><span class=""pre"">'display.max_rows'</span></code> are serialized and published.</p>
</section>
</section>
</article>","Options and settings # Overview # pandas has an options API configure and customize global behavior related to DataFrame display, data behavior and more. Options have a full “dotted-style”, case-insensitive name (e.g. display.max_rows ). You can get/set options directly as attributes of the top-level options attribute: The API is composed of 5 relevant functions, available directly from the pandas namespace: get_option() / set_option() - get/set the value of a single option. reset_option() - reset one or more options to their default value. describe_option() - print the descriptions of one or more options. option_context() - execute a codeblock with a set of options that revert to prior settings after execution. Note Developers can check out pandas/core/config_init.py for more information. All of the functions above accept a regexp pattern ( re.search style) as an argument, to match an unambiguous substring: The following will not work because it matches multiple option names, e.g. display.max_colwidth , display.max_rows , display.max_columns : Warning Using this form of shorthand may cause your code to break if new options with similar names are added in future versions. Available options # You can get a list of available options and their descriptions with describe_option() . When called with no argument describe_option() will print out the descriptions for all available options. Getting and setting options # As described above, get_option() and set_option() are available from the pandas namespace. To change an option, call set_option('option regex', new_value) . Note The option 'mode.sim_interactive' is mostly used for debugging purposes. You can use reset_option() to revert to a setting’s default value It’s also possible to reset multiple options at once (using a regex): option_context() context manager has been exposed through the top-level API, allowing you to execute code with given option values. Option values are restored automatically when you exit the with block: Setting startup options in Python/IPython environment # Using startup scripts for the Python/IPython environment to import pandas and set options makes working with pandas more efficient. To do this, create a .py or .ipy script in the startup directory of the desired profile. An example where the startup folder is in a default IPython profile can be found at: $IPYTHONDIR/profile_default/startup More information can be found in the IPython documentation . An example startup script for pandas is displayed below: import pandas as pd pd . set_option ( ""display.max_rows"" , 999 ) pd . set_option ( ""display.precision"" , 5 ) Frequently used options # The following is a demonstrates the more frequently used display options. display.max_rows and display.max_columns sets the maximum number of rows and columns displayed when a frame is pretty-printed. Truncated lines are replaced by an ellipsis. Once the display.max_rows is exceeded, the display.min_rows options determines how many rows are shown in the truncated repr. display.expand_frame_repr allows for the representation of a DataFrame to stretch across pages, wrapped over the all the columns. display.large_repr displays a DataFrame that exceed max_columns or max_rows as a truncated frame or summary. display.max_colwidth sets the maximum width of columns. Cells of this length or longer will be truncated with an ellipsis. display.max_info_columns sets a threshold for the number of columns displayed when calling info() . display.max_info_rows : info() will usually show null-counts for each column. For a large DataFrame , this can be quite slow. max_info_rows and max_info_cols limit this null check to the specified rows and columns respectively. The info() keyword argument show_counts=True will override this. display.precision sets the output display precision in terms of decimal places. display.chop_threshold sets the rounding threshold to zero when displaying a Series or DataFrame . This setting does not change the precision at which the number is stored. display.colheader_justify controls the justification of the headers. The options are 'right' , and 'left' . Number formatting # pandas also allows you to set how numbers are displayed in the console. This option is not set through the set_options API. Use the set_eng_float_format function to alter the floating-point formatting of pandas objects to produce a particular format. Use round() to specifically control rounding of an individual DataFrame Unicode formatting # Warning Enabling this option will affect the performance for printing of DataFrame and Series (about 2 times slower). Use only when it is actually required. Some East Asian countries use Unicode characters whose width corresponds to two Latin characters. If a DataFrame or Series contains these characters, the default output mode may not align them properly. Enabling display.unicode.east_asian_width allows pandas to check each character’s “East Asian Width” property. These characters can be aligned properly by setting this option to True . However, this will result in longer render times than the standard len function. In addition, Unicode characters whose width is “ambiguous” can either be 1 or 2 characters wide depending on the terminal setting or encoding. The option display.unicode.ambiguous_as_wide can be used to handle the ambiguity. By default, an “ambiguous” character’s width, such as “¡” (inverted exclamation) in the example below, is taken to be 1. Enabling display.unicode.ambiguous_as_wide makes pandas interpret these characters’ widths to be 2. (Note that this option will only be effective when display.unicode.east_asian_width is enabled.) However, setting this option incorrectly for your terminal will cause these characters to be aligned incorrectly: Table schema display # DataFrame and Series will publish a Table Schema representation by default. This can be enabled globally with the display.html.table_schema option: Only 'display.max_rows' are serialized and published."
https://pandas.pydata.org/docs/user_guide/enhancingperf.html,Enhancing performance,"<article class=""bd-article"" role=""main"">
<section id=""enhancing-performance"">
<span id=""enhancingperf""></span><h1>Enhancing performance<a class=""headerlink"" href=""#enhancing-performance"" title=""Link to this heading"">#</a></h1>
<p>In this part of the tutorial, we will investigate how to speed up certain
functions operating on pandas <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> using Cython, Numba and <a class=""reference internal"" href=""../reference/api/pandas.eval.html#pandas.eval"" title=""pandas.eval""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.eval()</span></code></a>.
Generally, using Cython and Numba can offer a larger speedup than using <a class=""reference internal"" href=""../reference/api/pandas.eval.html#pandas.eval"" title=""pandas.eval""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.eval()</span></code></a>
but will require a lot more code.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>In addition to following the steps in this tutorial, users interested in enhancing
performance are highly encouraged to install the
<a class=""reference internal"" href=""../getting_started/install.html#install-recommended-dependencies""><span class=""std std-ref"">recommended dependencies</span></a> for pandas.
These dependencies are often not installed by default, but will offer speed
improvements if present.</p>
</div>
<section id=""cython-writing-c-extensions-for-pandas"">
<span id=""enhancingperf-cython""></span><h2>Cython (writing C extensions for pandas)<a class=""headerlink"" href=""#cython-writing-c-extensions-for-pandas"" title=""Link to this heading"">#</a></h2>
<p>For many use cases writing pandas in pure Python and NumPy is sufficient. In some
computationally heavy applications however, it can be possible to achieve sizable
speed-ups by offloading work to <a class=""reference external"" href=""https://cython.org/"">cython</a>.</p>
<p>This tutorial assumes you have refactored as much as possible in Python, for example
by trying to remove for-loops and making use of NumPy vectorization. It’s always worth
optimising in Python first.</p>
<p>This tutorial walks through a “typical” process of cythonizing a slow computation.
We use an <a class=""reference external"" href=""https://docs.cython.org/en/latest/src/quickstart/cythonize.html"">example from the Cython documentation</a>
but in the context of pandas. Our final cythonized solution is around 100 times
faster than the pure Python solution.</p>
<section id=""pure-python"">
<span id=""enhancingperf-pure""></span><h3>Pure Python<a class=""headerlink"" href=""#pure-python"" title=""Link to this heading"">#</a></h3>
<p>We have a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> to which we want to apply a function row-wise.</p>

<p>Here’s the function in pure Python:</p>

<p>We achieve our result by using <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply"" title=""pandas.DataFrame.apply""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.apply()</span></code></a> (row-wise):</p>

<p>Let’s take a look and see where the time is spent during this operation
using the <a class=""reference external"" href=""https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-prun"">prun ipython magic function</a>:</p>

<p>By far the majority of time is spend inside either <code class=""docutils literal notranslate""><span class=""pre"">integrate_f</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">f</span></code>,
hence we’ll concentrate our efforts cythonizing these two functions.</p>
</section>
<section id=""plain-cython"">
<span id=""enhancingperf-plain""></span><h3>Plain Cython<a class=""headerlink"" href=""#plain-cython"" title=""Link to this heading"">#</a></h3>
<p>First we’re going to need to import the Cython magic function to IPython:</p>

<p>Now, let’s simply copy our functions over to Cython:</p>


<p>This has improved the performance compared to the pure Python approach by one-third.</p>
</section>
<section id=""declaring-c-types"">
<span id=""enhancingperf-type""></span><h3>Declaring C types<a class=""headerlink"" href=""#declaring-c-types"" title=""Link to this heading"">#</a></h3>
<p>We can annotate the function variables and return types as well as use <code class=""docutils literal notranslate""><span class=""pre"">cdef</span></code>
and <code class=""docutils literal notranslate""><span class=""pre"">cpdef</span></code> to improve performance:</p>


<p>Annotating the functions with C types yields an over ten times performance improvement compared to
the original Python implementation.</p>
</section>
<section id=""using-ndarray"">
<span id=""enhancingperf-ndarray""></span><h3>Using ndarray<a class=""headerlink"" href=""#using-ndarray"" title=""Link to this heading"">#</a></h3>
<p>When re-profiling, time is spent creating a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> from each row, and calling <code class=""docutils literal notranslate""><span class=""pre"">__getitem__</span></code> from both
the index and the series (three times for each row). These Python function calls are expensive and
can be improved by passing an <code class=""docutils literal notranslate""><span class=""pre"">np.ndarray</span></code>.</p>


<p>This implementation creates an array of zeros and inserts the result
of <code class=""docutils literal notranslate""><span class=""pre"">integrate_f_typed</span></code> applied over each row. Looping over an <code class=""docutils literal notranslate""><span class=""pre"">ndarray</span></code> is faster
in Cython than looping over a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> object.</p>
<p>Since <code class=""docutils literal notranslate""><span class=""pre"">apply_integrate_f</span></code> is typed to accept an <code class=""docutils literal notranslate""><span class=""pre"">np.ndarray</span></code>, <a class=""reference internal"" href=""../reference/api/pandas.Series.to_numpy.html#pandas.Series.to_numpy"" title=""pandas.Series.to_numpy""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.to_numpy()</span></code></a>
calls are needed to utilize this function.</p>

<p>Performance has improved from the prior implementation by almost ten times.</p>
</section>
<section id=""disabling-compiler-directives"">
<span id=""enhancingperf-boundswrap""></span><h3>Disabling compiler directives<a class=""headerlink"" href=""#disabling-compiler-directives"" title=""Link to this heading"">#</a></h3>
<p>The majority of the time is now spent in <code class=""docutils literal notranslate""><span class=""pre"">apply_integrate_f</span></code>. Disabling Cython’s <code class=""docutils literal notranslate""><span class=""pre"">boundscheck</span></code>
and <code class=""docutils literal notranslate""><span class=""pre"">wraparound</span></code> checks can yield more performance.</p>



<p>However, a loop indexer <code class=""docutils literal notranslate""><span class=""pre"">i</span></code> accessing an invalid location in an array would cause a segfault because memory access isn’t checked.
For more about <code class=""docutils literal notranslate""><span class=""pre"">boundscheck</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">wraparound</span></code>, see the Cython docs on
<a class=""reference external"" href=""https://cython.readthedocs.io/en/latest/src/userguide/source_files_and_compilation.html#compiler-directives"">compiler directives</a>.</p>
</section>
</section>
<section id=""numba-jit-compilation"">
<span id=""enhancingperf-numba""></span><h2>Numba (JIT compilation)<a class=""headerlink"" href=""#numba-jit-compilation"" title=""Link to this heading"">#</a></h2>
<p>An alternative to statically compiling Cython code is to use a dynamic just-in-time (JIT) compiler with <a class=""reference external"" href=""https://numba.pydata.org/"">Numba</a>.</p>
<p>Numba allows you to write a pure Python function which can be JIT compiled to native machine instructions, similar in performance to C, C++ and Fortran,
by decorating your function with <code class=""docutils literal notranslate""><span class=""pre"">@jit</span></code>.</p>
<p>Numba works by generating optimized machine code using the LLVM compiler infrastructure at import time, runtime, or statically (using the included pycc tool).
Numba supports compilation of Python to run on either CPU or GPU hardware and is designed to integrate with the Python scientific software stack.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">@jit</span></code> compilation will add overhead to the runtime of the function, so performance benefits may not be realized especially when using small data sets.
Consider <a class=""reference external"" href=""https://numba.readthedocs.io/en/stable/developer/caching.html"">caching</a> your function to avoid compilation overhead each time your function is run.</p>
</div>
<p>Numba can be used in 2 ways with pandas:</p>
<ol class=""arabic simple"">
<li><p>Specify the <code class=""docutils literal notranslate""><span class=""pre"">engine=""numba""</span></code> keyword in select pandas methods</p></li>
<li><p>Define your own Python function decorated with <code class=""docutils literal notranslate""><span class=""pre"">@jit</span></code> and pass the underlying NumPy array of <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> (using <a class=""reference internal"" href=""../reference/api/pandas.Series.to_numpy.html#pandas.Series.to_numpy"" title=""pandas.Series.to_numpy""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.to_numpy()</span></code></a>) into the function</p></li>
</ol>
<section id=""pandas-numba-engine"">
<h3>pandas Numba Engine<a class=""headerlink"" href=""#pandas-numba-engine"" title=""Link to this heading"">#</a></h3>
<p>If Numba is installed, one can specify <code class=""docutils literal notranslate""><span class=""pre"">engine=""numba""</span></code> in select pandas methods to execute the method using Numba.
Methods that support <code class=""docutils literal notranslate""><span class=""pre"">engine=""numba""</span></code> will also have an <code class=""docutils literal notranslate""><span class=""pre"">engine_kwargs</span></code> keyword that accepts a dictionary that allows one to specify
<code class=""docutils literal notranslate""><span class=""pre"">""nogil""</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">""nopython""</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">""parallel""</span></code> keys with boolean values to pass into the <code class=""docutils literal notranslate""><span class=""pre"">@jit</span></code> decorator.
If <code class=""docutils literal notranslate""><span class=""pre"">engine_kwargs</span></code> is not specified, it defaults to <code class=""docutils literal notranslate""><span class=""pre"">{""nogil"":</span> <span class=""pre"">False,</span> <span class=""pre"">""nopython"":</span> <span class=""pre"">True,</span> <span class=""pre"">""parallel"":</span> <span class=""pre"">False}</span></code> unless otherwise specified.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>In terms of performance, <strong>the first time a function is run using the Numba engine will be slow</strong>
as Numba will have some function compilation overhead. However, the JIT compiled functions are cached,
and subsequent calls will be fast. In general, the Numba engine is performant with
a larger amount of data points (e.g. 1+ million).</p>

</div>
<p>If your compute hardware contains multiple CPUs, the largest performance gain can be realized by setting <code class=""docutils literal notranslate""><span class=""pre"">parallel</span></code> to <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>
to leverage more than 1 CPU. Internally, pandas leverages numba to parallelize computations over the columns of a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>;
therefore, this performance benefit is only beneficial for a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> with a large number of columns.</p>

</section>
<section id=""custom-function-examples"">
<h3>Custom Function Examples<a class=""headerlink"" href=""#custom-function-examples"" title=""Link to this heading"">#</a></h3>
<p>A custom Python function decorated with <code class=""docutils literal notranslate""><span class=""pre"">@jit</span></code> can be used with pandas objects by passing their NumPy array
representations with <a class=""reference internal"" href=""../reference/api/pandas.Series.to_numpy.html#pandas.Series.to_numpy"" title=""pandas.Series.to_numpy""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.to_numpy()</span></code></a>.</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">numba</span>


<span class=""nd"">@numba</span><span class=""o"">.</span><span class=""n"">jit</span>
<span class=""k"">def</span> <span class=""nf"">f_plain</span><span class=""p"">(</span><span class=""n"">x</span><span class=""p"">):</span>
    <span class=""k"">return</span> <span class=""n"">x</span> <span class=""o"">*</span> <span class=""p"">(</span><span class=""n"">x</span> <span class=""o"">-</span> <span class=""mi"">1</span><span class=""p"">)</span>


<span class=""nd"">@numba</span><span class=""o"">.</span><span class=""n"">jit</span>
<span class=""k"">def</span> <span class=""nf"">integrate_f_numba</span><span class=""p"">(</span><span class=""n"">a</span><span class=""p"">,</span> <span class=""n"">b</span><span class=""p"">,</span> <span class=""n"">N</span><span class=""p"">):</span>
    <span class=""n"">s</span> <span class=""o"">=</span> <span class=""mi"">0</span>
    <span class=""n"">dx</span> <span class=""o"">=</span> <span class=""p"">(</span><span class=""n"">b</span> <span class=""o"">-</span> <span class=""n"">a</span><span class=""p"">)</span> <span class=""o"">/</span> <span class=""n"">N</span>
    <span class=""k"">for</span> <span class=""n"">i</span> <span class=""ow"">in</span> <span class=""nb"">range</span><span class=""p"">(</span><span class=""n"">N</span><span class=""p"">):</span>
        <span class=""n"">s</span> <span class=""o"">+=</span> <span class=""n"">f_plain</span><span class=""p"">(</span><span class=""n"">a</span> <span class=""o"">+</span> <span class=""n"">i</span> <span class=""o"">*</span> <span class=""n"">dx</span><span class=""p"">)</span>
    <span class=""k"">return</span> <span class=""n"">s</span> <span class=""o"">*</span> <span class=""n"">dx</span>


<span class=""nd"">@numba</span><span class=""o"">.</span><span class=""n"">jit</span>
<span class=""k"">def</span> <span class=""nf"">apply_integrate_f_numba</span><span class=""p"">(</span><span class=""n"">col_a</span><span class=""p"">,</span> <span class=""n"">col_b</span><span class=""p"">,</span> <span class=""n"">col_N</span><span class=""p"">):</span>
    <span class=""n"">n</span> <span class=""o"">=</span> <span class=""nb"">len</span><span class=""p"">(</span><span class=""n"">col_N</span><span class=""p"">)</span>
    <span class=""n"">result</span> <span class=""o"">=</span> <span class=""n"">np</span><span class=""o"">.</span><span class=""n"">empty</span><span class=""p"">(</span><span class=""n"">n</span><span class=""p"">,</span> <span class=""n"">dtype</span><span class=""o"">=</span><span class=""s2"">""float64""</span><span class=""p"">)</span>
    <span class=""k"">assert</span> <span class=""nb"">len</span><span class=""p"">(</span><span class=""n"">col_a</span><span class=""p"">)</span> <span class=""o"">==</span> <span class=""nb"">len</span><span class=""p"">(</span><span class=""n"">col_b</span><span class=""p"">)</span> <span class=""o"">==</span> <span class=""n"">n</span>
    <span class=""k"">for</span> <span class=""n"">i</span> <span class=""ow"">in</span> <span class=""nb"">range</span><span class=""p"">(</span><span class=""n"">n</span><span class=""p"">):</span>
        <span class=""n"">result</span><span class=""p"">[</span><span class=""n"">i</span><span class=""p"">]</span> <span class=""o"">=</span> <span class=""n"">integrate_f_numba</span><span class=""p"">(</span><span class=""n"">col_a</span><span class=""p"">[</span><span class=""n"">i</span><span class=""p"">],</span> <span class=""n"">col_b</span><span class=""p"">[</span><span class=""n"">i</span><span class=""p"">],</span> <span class=""n"">col_N</span><span class=""p"">[</span><span class=""n"">i</span><span class=""p"">])</span>
    <span class=""k"">return</span> <span class=""n"">result</span>


<span class=""k"">def</span> <span class=""nf"">compute_numba</span><span class=""p"">(</span><span class=""n"">df</span><span class=""p"">):</span>
    <span class=""n"">result</span> <span class=""o"">=</span> <span class=""n"">apply_integrate_f_numba</span><span class=""p"">(</span>
        <span class=""n"">df</span><span class=""p"">[</span><span class=""s2"">""a""</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">to_numpy</span><span class=""p"">(),</span> <span class=""n"">df</span><span class=""p"">[</span><span class=""s2"">""b""</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">to_numpy</span><span class=""p"">(),</span> <span class=""n"">df</span><span class=""p"">[</span><span class=""s2"">""N""</span><span class=""p"">]</span><span class=""o"">.</span><span class=""n"">to_numpy</span><span class=""p"">()</span>
    <span class=""p"">)</span>
    <span class=""k"">return</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">Series</span><span class=""p"">(</span><span class=""n"">result</span><span class=""p"">,</span> <span class=""n"">index</span><span class=""o"">=</span><span class=""n"">df</span><span class=""o"">.</span><span class=""n"">index</span><span class=""p"">,</span> <span class=""n"">name</span><span class=""o"">=</span><span class=""s2"">""result""</span><span class=""p"">)</span>
</pre></div>
</div>

<p>In this example, using Numba was faster than Cython.</p>
<p>Numba can also be used to write vectorized functions that do not require the user to explicitly
loop over the observations of a vector; a vectorized function will be applied to each row automatically.
Consider the following example of doubling each observation:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""kn"">import</span> <span class=""nn"">numba</span>


<span class=""k"">def</span> <span class=""nf"">double_every_value_nonumba</span><span class=""p"">(</span><span class=""n"">x</span><span class=""p"">):</span>
    <span class=""k"">return</span> <span class=""n"">x</span> <span class=""o"">*</span> <span class=""mi"">2</span>


<span class=""nd"">@numba</span><span class=""o"">.</span><span class=""n"">vectorize</span>
<span class=""k"">def</span> <span class=""nf"">double_every_value_withnumba</span><span class=""p"">(</span><span class=""n"">x</span><span class=""p"">):</span>  <span class=""c1""># noqa E501</span>
    <span class=""k"">return</span> <span class=""n"">x</span> <span class=""o"">*</span> <span class=""mi"">2</span>
</pre></div>
</div>

</section>
<section id=""caveats"">
<h3>Caveats<a class=""headerlink"" href=""#caveats"" title=""Link to this heading"">#</a></h3>
<p>Numba is best at accelerating functions that apply numerical functions to NumPy
arrays. If you try to <code class=""docutils literal notranslate""><span class=""pre"">@jit</span></code> a function that contains unsupported <a class=""reference external"" href=""https://numba.readthedocs.io/en/stable/reference/pysupported.html"">Python</a>
or <a class=""reference external"" href=""https://numba.readthedocs.io/en/stable/reference/numpysupported.html"">NumPy</a>
code, compilation will revert <a class=""reference external"" href=""https://numba.readthedocs.io/en/stable/glossary.html#term-object-mode"">object mode</a> which
will mostly likely not speed up your function. If you would
prefer that Numba throw an error if it cannot compile a function in a way that
speeds up your code, pass Numba the argument
<code class=""docutils literal notranslate""><span class=""pre"">nopython=True</span></code> (e.g. <code class=""docutils literal notranslate""><span class=""pre"">@jit(nopython=True)</span></code>). For more on
troubleshooting Numba modes, see the <a class=""reference external"" href=""https://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#the-compiled-code-is-too-slow"">Numba troubleshooting page</a>.</p>
<p>Using <code class=""docutils literal notranslate""><span class=""pre"">parallel=True</span></code> (e.g. <code class=""docutils literal notranslate""><span class=""pre"">@jit(parallel=True)</span></code>) may result in a <code class=""docutils literal notranslate""><span class=""pre"">SIGABRT</span></code> if the threading layer leads to unsafe
behavior. You can first <a class=""reference external"" href=""https://numba.readthedocs.io/en/stable/user/threading-layer.html#selecting-a-threading-layer-for-safe-parallel-execution"">specify a safe threading layer</a>
before running a JIT function with <code class=""docutils literal notranslate""><span class=""pre"">parallel=True</span></code>.</p>
<p>Generally if the you encounter a segfault (<code class=""docutils literal notranslate""><span class=""pre"">SIGSEGV</span></code>) while using Numba, please report the issue
to the <a class=""reference external"" href=""https://github.com/numba/numba/issues/new/choose"">Numba issue tracker.</a></p>
</section>
</section>
<section id=""expression-evaluation-via-eval"">
<span id=""enhancingperf-eval""></span><h2>Expression evaluation via <a class=""reference internal"" href=""../reference/api/pandas.eval.html#pandas.eval"" title=""pandas.eval""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">eval()</span></code></a><a class=""headerlink"" href=""#expression-evaluation-via-eval"" title=""Link to this heading"">#</a></h2>
<p>The top-level function <a class=""reference internal"" href=""../reference/api/pandas.eval.html#pandas.eval"" title=""pandas.eval""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.eval()</span></code></a> implements performant expression evaluation of
<a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>. Expression evaluation allows operations
to be expressed as strings and can potentially provide a performance improvement
by evaluate arithmetic and boolean expression all at once for large <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>You should not use <a class=""reference internal"" href=""../reference/api/pandas.eval.html#pandas.eval"" title=""pandas.eval""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">eval()</span></code></a> for simple
expressions or for expressions involving small DataFrames. In fact,
<a class=""reference internal"" href=""../reference/api/pandas.eval.html#pandas.eval"" title=""pandas.eval""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">eval()</span></code></a> is many orders of magnitude slower for
smaller expressions or objects than plain Python. A good rule of thumb is
to only use <a class=""reference internal"" href=""../reference/api/pandas.eval.html#pandas.eval"" title=""pandas.eval""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">eval()</span></code></a> when you have a
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> with more than 10,000 rows.</p>
</div>
<section id=""supported-syntax"">
<h3>Supported syntax<a class=""headerlink"" href=""#supported-syntax"" title=""Link to this heading"">#</a></h3>
<p>These operations are supported by <a class=""reference internal"" href=""../reference/api/pandas.eval.html#pandas.eval"" title=""pandas.eval""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.eval()</span></code></a>:</p>
<ul class=""simple"">
<li><p>Arithmetic operations except for the left shift (<code class=""docutils literal notranslate""><span class=""pre"">&lt;&lt;</span></code>) and right shift
(<code class=""docutils literal notranslate""><span class=""pre"">&gt;&gt;</span></code>) operators, e.g., <code class=""docutils literal notranslate""><span class=""pre"">df</span> <span class=""pre"">+</span> <span class=""pre"">2</span> <span class=""pre"">*</span> <span class=""pre"">pi</span> <span class=""pre"">/</span> <span class=""pre"">s</span> <span class=""pre"">**</span> <span class=""pre"">4</span> <span class=""pre"">%</span> <span class=""pre"">42</span> <span class=""pre"">-</span> <span class=""pre"">the_golden_ratio</span></code></p></li>
<li><p>Comparison operations, including chained comparisons, e.g., <code class=""docutils literal notranslate""><span class=""pre"">2</span> <span class=""pre"">&lt;</span> <span class=""pre"">df</span> <span class=""pre"">&lt;</span> <span class=""pre"">df2</span></code></p></li>
<li><p>Boolean operations, e.g., <code class=""docutils literal notranslate""><span class=""pre"">df</span> <span class=""pre"">&lt;</span> <span class=""pre"">df2</span> <span class=""pre"">and</span> <span class=""pre"">df3</span> <span class=""pre"">&lt;</span> <span class=""pre"">df4</span> <span class=""pre"">or</span> <span class=""pre"">not</span> <span class=""pre"">df_bool</span></code></p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">list</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">tuple</span></code> literals, e.g., <code class=""docutils literal notranslate""><span class=""pre"">[1,</span> <span class=""pre"">2]</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">(1,</span> <span class=""pre"">2)</span></code></p></li>
<li><p>Attribute access, e.g., <code class=""docutils literal notranslate""><span class=""pre"">df.a</span></code></p></li>
<li><p>Subscript expressions, e.g., <code class=""docutils literal notranslate""><span class=""pre"">df[0]</span></code></p></li>
<li><p>Simple variable evaluation, e.g., <code class=""docutils literal notranslate""><span class=""pre"">pd.eval(""df"")</span></code> (this is not very useful)</p></li>
<li><p>Math functions: <code class=""docutils literal notranslate""><span class=""pre"">sin</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">cos</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">exp</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">log</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">expm1</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">log1p</span></code>,
<code class=""docutils literal notranslate""><span class=""pre"">sqrt</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">sinh</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">cosh</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">tanh</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">arcsin</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">arccos</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">arctan</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">arccosh</span></code>,
<code class=""docutils literal notranslate""><span class=""pre"">arcsinh</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">arctanh</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">abs</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">arctan2</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">log10</span></code>.</p></li>
</ul>
<p>The following Python syntax is <strong>not</strong> allowed:</p>
<ul>
<li><p>Expressions</p>
<blockquote>
<div><ul class=""simple"">
<li><p>Function calls other than math functions.</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">is</span></code>/<code class=""docutils literal notranslate""><span class=""pre"">is</span> <span class=""pre"">not</span></code> operations</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">if</span></code> expressions</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">lambda</span></code> expressions</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">list</span></code>/<code class=""docutils literal notranslate""><span class=""pre"">set</span></code>/<code class=""docutils literal notranslate""><span class=""pre"">dict</span></code> comprehensions</p></li>
<li><p>Literal <code class=""docutils literal notranslate""><span class=""pre"">dict</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">set</span></code> expressions</p></li>
<li><p><code class=""docutils literal notranslate""><span class=""pre"">yield</span></code> expressions</p></li>
<li><p>Generator expressions</p></li>
<li><p>Boolean expressions consisting of only scalar values</p></li>
</ul>
</div></blockquote>
</li>
<li><p>Statements</p>
<blockquote>
<div><ul class=""simple"">
<li><p>Neither <a class=""reference external"" href=""https://docs.python.org/3/reference/simple_stmts.html"">simple</a>
or <a class=""reference external"" href=""https://docs.python.org/3/reference/compound_stmts.html"">compound</a>
statements are allowed. This includes <code class=""docutils literal notranslate""><span class=""pre"">for</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">while</span></code>, and
<code class=""docutils literal notranslate""><span class=""pre"">if</span></code>.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</section>
<section id=""local-variables"">
<h3>Local variables<a class=""headerlink"" href=""#local-variables"" title=""Link to this heading"">#</a></h3>
<p>You must <em>explicitly reference</em> any local variable that you want to use in an
expression by placing the <code class=""docutils literal notranslate""><span class=""pre"">@</span></code> character in front of the name. This mechanism is
the same for both <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.query.html#pandas.DataFrame.query"" title=""pandas.DataFrame.query""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.query()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.eval.html#pandas.DataFrame.eval"" title=""pandas.DataFrame.eval""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.eval()</span></code></a>. For example,</p>

<p>If you don’t prefix the local variable with <code class=""docutils literal notranslate""><span class=""pre"">@</span></code>, pandas will raise an
exception telling you the variable is undefined.</p>
<p>When using <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.eval.html#pandas.DataFrame.eval"" title=""pandas.DataFrame.eval""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.eval()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.query.html#pandas.DataFrame.query"" title=""pandas.DataFrame.query""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.query()</span></code></a>, this allows you
to have a local variable and a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> column with the same
name in an expression.</p>

<div class=""admonition warning"">
<p class=""admonition-title"">Warning</p>
<p><a class=""reference internal"" href=""../reference/api/pandas.eval.html#pandas.eval"" title=""pandas.eval""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.eval()</span></code></a> will raise an exception if you cannot use the <code class=""docutils literal notranslate""><span class=""pre"">@</span></code> prefix because it
isn’t defined in that context.</p>

<p>In this case, you should simply refer to the variables like you would in
standard Python.</p>

</div>
</section>
<section id=""pandas-eval-parsers"">
<h3><a class=""reference internal"" href=""../reference/api/pandas.eval.html#pandas.eval"" title=""pandas.eval""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.eval()</span></code></a> parsers<a class=""headerlink"" href=""#pandas-eval-parsers"" title=""Link to this heading"">#</a></h3>
<p>There are two different expression syntax parsers.</p>
<p>The default <code class=""docutils literal notranslate""><span class=""pre"">'pandas'</span></code> parser allows a more intuitive syntax for expressing
query-like operations (comparisons, conjunctions and disjunctions). In
particular, the precedence of the <code class=""docutils literal notranslate""><span class=""pre"">&amp;</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">|</span></code> operators is made equal to
the precedence of the corresponding boolean operations <code class=""docutils literal notranslate""><span class=""pre"">and</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">or</span></code>.</p>
<p>For example, the above conjunction can be written without parentheses.
Alternatively, you can use the <code class=""docutils literal notranslate""><span class=""pre"">'python'</span></code> parser to enforce strict Python
semantics.</p>

<p>The same expression can be “anded” together with the word <a class=""reference external"" href=""https://docs.python.org/3/reference/expressions.html#and"" title=""(in Python v3.12)""><code class=""xref std std-keyword docutils literal notranslate""><span class=""pre"">and</span></code></a> as
well:</p>

<p>The <a class=""reference external"" href=""https://docs.python.org/3/reference/expressions.html#and"" title=""(in Python v3.12)""><code class=""xref std std-keyword docutils literal notranslate""><span class=""pre"">and</span></code></a> and <a class=""reference external"" href=""https://docs.python.org/3/reference/expressions.html#or"" title=""(in Python v3.12)""><code class=""xref std std-keyword docutils literal notranslate""><span class=""pre"">or</span></code></a> operators here have the same precedence that they would
in Python.</p>
</section>
<section id=""pandas-eval-engines"">
<h3><a class=""reference internal"" href=""../reference/api/pandas.eval.html#pandas.eval"" title=""pandas.eval""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.eval()</span></code></a> engines<a class=""headerlink"" href=""#pandas-eval-engines"" title=""Link to this heading"">#</a></h3>
<p>There are two different expression engines.</p>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">'numexpr'</span></code> engine is the more performant engine that can yield performance improvements
compared to standard Python syntax for large <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>. This engine requires the
optional dependency <code class=""docutils literal notranslate""><span class=""pre"">numexpr</span></code> to be installed.</p>
<p>The <code class=""docutils literal notranslate""><span class=""pre"">'python'</span></code> engine is generally <em>not</em> useful except for testing
other evaluation engines against it. You will achieve <strong>no</strong> performance
benefits using <a class=""reference internal"" href=""../reference/api/pandas.eval.html#pandas.eval"" title=""pandas.eval""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">eval()</span></code></a> with <code class=""docutils literal notranslate""><span class=""pre"">engine='python'</span></code> and may
incur a performance hit.</p>


</section>
<section id=""the-dataframe-eval-method"">
<h3>The <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.eval.html#pandas.DataFrame.eval"" title=""pandas.DataFrame.eval""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.eval()</span></code></a> method<a class=""headerlink"" href=""#the-dataframe-eval-method"" title=""Link to this heading"">#</a></h3>
<p>In addition to the top level <a class=""reference internal"" href=""../reference/api/pandas.eval.html#pandas.eval"" title=""pandas.eval""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.eval()</span></code></a> function you can also
evaluate an expression in the “context” of a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>.</p>

<p>Any expression that is a valid <a class=""reference internal"" href=""../reference/api/pandas.eval.html#pandas.eval"" title=""pandas.eval""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.eval()</span></code></a> expression is also a valid
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.eval.html#pandas.DataFrame.eval"" title=""pandas.DataFrame.eval""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.eval()</span></code></a> expression, with the added benefit that you don’t have to
prefix the name of the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> to the column(s) you’re
interested in evaluating.</p>
<p>In addition, you can perform assignment of columns within an expression.
This allows for <em>formulaic evaluation</em>. The assignment target can be a
new column name or an existing column name, and it must be a valid Python
identifier.</p>

<p>A copy of the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> with the
new or modified columns is returned, and the original frame is unchanged.</p>

<p>Multiple column assignments can be performed by using a multi-line string.</p>

<p>The equivalent in standard Python would be</p>

</section>
<section id=""eval-performance-comparison"">
<h3><a class=""reference internal"" href=""../reference/api/pandas.eval.html#pandas.eval"" title=""pandas.eval""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">eval()</span></code></a> performance comparison<a class=""headerlink"" href=""#eval-performance-comparison"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference internal"" href=""../reference/api/pandas.eval.html#pandas.eval"" title=""pandas.eval""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.eval()</span></code></a> works well with expressions containing large arrays.</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> arithmetic:</p>


<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> comparison:</p>


<p><a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> arithmetic with unaligned axes.</p>


<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Operations such as</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""mi"">1</span> <span class=""ow"">and</span> <span class=""mi"">2</span>  <span class=""c1""># would parse to 1 &amp; 2, but should evaluate to 2</span>
<span class=""mi"">3</span> <span class=""ow"">or</span> <span class=""mi"">4</span>  <span class=""c1""># would parse to 3 | 4, but should evaluate to 3</span>
<span class=""o"">~</span><span class=""mi"">1</span>  <span class=""c1""># this is okay, but slower when using eval</span>
</pre></div>
</div>
<p>should be performed in Python. An exception will be raised if you try to
perform any boolean/bitwise operations with scalar operands that are not
of type <code class=""docutils literal notranslate""><span class=""pre"">bool</span></code> or <code class=""docutils literal notranslate""><span class=""pre"">np.bool_</span></code>.</p>
</div>
<p>Here is a plot showing the running time of
<a class=""reference internal"" href=""../reference/api/pandas.eval.html#pandas.eval"" title=""pandas.eval""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.eval()</span></code></a> as function of the size of the frame involved in the
computation. The two lines are two different engines.</p>
<img alt=""../_images/eval-perf.png"" src=""../_images/eval-perf.png""/>
<p>You will only see the performance benefits of using the <code class=""docutils literal notranslate""><span class=""pre"">numexpr</span></code> engine with <a class=""reference internal"" href=""../reference/api/pandas.eval.html#pandas.eval"" title=""pandas.eval""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.eval()</span></code></a> if your <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>
has more than approximately 100,000 rows.</p>
<p>This plot was created using a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> with 3 columns each containing
floating point values generated using <code class=""docutils literal notranslate""><span class=""pre"">numpy.random.randn()</span></code>.</p>
</section>
<section id=""expression-evaluation-limitations-with-numexpr"">
<h3>Expression evaluation limitations with <code class=""docutils literal notranslate""><span class=""pre"">numexpr</span></code><a class=""headerlink"" href=""#expression-evaluation-limitations-with-numexpr"" title=""Link to this heading"">#</a></h3>
<p>Expressions that would result in an object dtype or involve datetime operations
because of <code class=""docutils literal notranslate""><span class=""pre"">NaT</span></code> must be evaluated in Python space, but part of an expression
can still be evaluated with <code class=""docutils literal notranslate""><span class=""pre"">numexpr</span></code>. For example:</p>

<p>The numeric part of the comparison (<code class=""docutils literal notranslate""><span class=""pre"">nums</span> <span class=""pre"">==</span> <span class=""pre"">1</span></code>) will be evaluated by
<code class=""docutils literal notranslate""><span class=""pre"">numexpr</span></code> and the object part of the comparison (<code class=""docutils literal notranslate""><span class=""pre"">""strings</span> <span class=""pre"">==</span> <span class=""pre"">'a'</span></code>) will
be evaluated by Python.</p>
</section>
</section>
</section>
</article>","Enhancing performance # In this part of the tutorial, we will investigate how to speed up certain functions operating on pandas DataFrame using Cython, Numba and pandas.eval() . Generally, using Cython and Numba can offer a larger speedup than using pandas.eval() but will require a lot more code. Note In addition to following the steps in this tutorial, users interested in enhancing performance are highly encouraged to install the recommended dependencies for pandas. These dependencies are often not installed by default, but will offer speed improvements if present. Cython (writing C extensions for pandas) # For many use cases writing pandas in pure Python and NumPy is sufficient. In some computationally heavy applications however, it can be possible to achieve sizable speed-ups by offloading work to cython . This tutorial assumes you have refactored as much as possible in Python, for example by trying to remove for-loops and making use of NumPy vectorization. It’s always worth optimising in Python first. This tutorial walks through a “typical” process of cythonizing a slow computation. We use an example from the Cython documentation but in the context of pandas. Our final cythonized solution is around 100 times faster than the pure Python solution. Pure Python # We have a DataFrame to which we want to apply a function row-wise. Here’s the function in pure Python: We achieve our result by using DataFrame.apply() (row-wise): Let’s take a look and see where the time is spent during this operation using the prun ipython magic function : By far the majority of time is spend inside either integrate_f or f , hence we’ll concentrate our efforts cythonizing these two functions. Plain Cython # First we’re going to need to import the Cython magic function to IPython: Now, let’s simply copy our functions over to Cython: This has improved the performance compared to the pure Python approach by one-third. Declaring C types # We can annotate the function variables and return types as well as use cdef and cpdef to improve performance: Annotating the functions with C types yields an over ten times performance improvement compared to the original Python implementation. Using ndarray # When re-profiling, time is spent creating a Series from each row, and calling __getitem__ from both the index and the series (three times for each row). These Python function calls are expensive and can be improved by passing an np.ndarray . This implementation creates an array of zeros and inserts the result of integrate_f_typed applied over each row. Looping over an ndarray is faster in Cython than looping over a Series object. Since apply_integrate_f is typed to accept an np.ndarray , Series.to_numpy() calls are needed to utilize this function. Performance has improved from the prior implementation by almost ten times. Disabling compiler directives # The majority of the time is now spent in apply_integrate_f . Disabling Cython’s boundscheck and wraparound checks can yield more performance. However, a loop indexer i accessing an invalid location in an array would cause a segfault because memory access isn’t checked. For more about boundscheck and wraparound , see the Cython docs on compiler directives . Numba (JIT compilation) # An alternative to statically compiling Cython code is to use a dynamic just-in-time (JIT) compiler with Numba . Numba allows you to write a pure Python function which can be JIT compiled to native machine instructions, similar in performance to C, C++ and Fortran, by decorating your function with @jit . Numba works by generating optimized machine code using the LLVM compiler infrastructure at import time, runtime, or statically (using the included pycc tool). Numba supports compilation of Python to run on either CPU or GPU hardware and is designed to integrate with the Python scientific software stack. Note The @jit compilation will add overhead to the runtime of the function, so performance benefits may not be realized especially when using small data sets. Consider caching your function to avoid compilation overhead each time your function is run. Numba can be used in 2 ways with pandas: Specify the engine=""numba"" keyword in select pandas methods Define your own Python function decorated with @jit and pass the underlying NumPy array of Series or DataFrame (using Series.to_numpy() ) into the function pandas Numba Engine # If Numba is installed, one can specify engine=""numba"" in select pandas methods to execute the method using Numba. Methods that support engine=""numba"" will also have an engine_kwargs keyword that accepts a dictionary that allows one to specify ""nogil"" , ""nopython"" and ""parallel"" keys with boolean values to pass into the @jit decorator. If engine_kwargs is not specified, it defaults to {""nogil"": False, ""nopython"": True, ""parallel"": False} unless otherwise specified. Note In terms of performance, the first time a function is run using the Numba engine will be slow as Numba will have some function compilation overhead. However, the JIT compiled functions are cached, and subsequent calls will be fast. In general, the Numba engine is performant with a larger amount of data points (e.g. 1+ million). If your compute hardware contains multiple CPUs, the largest performance gain can be realized by setting parallel to True to leverage more than 1 CPU. Internally, pandas leverages numba to parallelize computations over the columns of a DataFrame ; therefore, this performance benefit is only beneficial for a DataFrame with a large number of columns. Custom Function Examples # A custom Python function decorated with @jit can be used with pandas objects by passing their NumPy array representations with Series.to_numpy() . import numba @numba . jit def f_plain ( x ): return x * ( x - 1 ) @numba . jit def integrate_f_numba ( a , b , N ): s = 0 dx = ( b - a ) / N for i in range ( N ): s += f_plain ( a + i * dx ) return s * dx @numba . jit def apply_integrate_f_numba ( col_a , col_b , col_N ): n = len ( col_N ) result = np . empty ( n , dtype = ""float64"" ) assert len ( col_a ) == len ( col_b ) == n for i in range ( n ): result [ i ] = integrate_f_numba ( col_a [ i ], col_b [ i ], col_N [ i ]) return result def compute_numba ( df ): result = apply_integrate_f_numba ( df [ ""a"" ] . to_numpy (), df [ ""b"" ] . to_numpy (), df [ ""N"" ] . to_numpy () ) return pd . Series ( result , index = df . index , name = ""result"" ) In this example, using Numba was faster than Cython. Numba can also be used to write vectorized functions that do not require the user to explicitly loop over the observations of a vector; a vectorized function will be applied to each row automatically. Consider the following example of doubling each observation: import numba def double_every_value_nonumba ( x ): return x * 2 @numba . vectorize def double_every_value_withnumba ( x ): # noqa E501 return x * 2 Caveats # Numba is best at accelerating functions that apply numerical functions to NumPy arrays. If you try to @jit a function that contains unsupported Python or NumPy code, compilation will revert object mode which will mostly likely not speed up your function. If you would prefer that Numba throw an error if it cannot compile a function in a way that speeds up your code, pass Numba the argument nopython=True (e.g. @jit(nopython=True) ). For more on troubleshooting Numba modes, see the Numba troubleshooting page . Using parallel=True (e.g. @jit(parallel=True) ) may result in a SIGABRT if the threading layer leads to unsafe behavior. You can first specify a safe threading layer before running a JIT function with parallel=True . Generally if the you encounter a segfault ( SIGSEGV ) while using Numba, please report the issue to the Numba issue tracker. Expression evaluation via eval() # The top-level function pandas.eval() implements performant expression evaluation of Series and DataFrame . Expression evaluation allows operations to be expressed as strings and can potentially provide a performance improvement by evaluate arithmetic and boolean expression all at once for large DataFrame . Note You should not use eval() for simple expressions or for expressions involving small DataFrames. In fact, eval() is many orders of magnitude slower for smaller expressions or objects than plain Python. A good rule of thumb is to only use eval() when you have a DataFrame with more than 10,000 rows. Supported syntax # These operations are supported by pandas.eval() : Arithmetic operations except for the left shift ( << ) and right shift ( >> ) operators, e.g., df + 2 * pi / s ** 4 % 42 - the_golden_ratio Comparison operations, including chained comparisons, e.g., 2 < df < df2 Boolean operations, e.g., df < df2 and df3 < df4 or not df_bool list and tuple literals, e.g., [1, 2] or (1, 2) Attribute access, e.g., df.a Subscript expressions, e.g., df[0] Simple variable evaluation, e.g., pd.eval(""df"") (this is not very useful) Math functions: sin , cos , exp , log , expm1 , log1p , sqrt , sinh , cosh , tanh , arcsin , arccos , arctan , arccosh , arcsinh , arctanh , abs , arctan2 and log10 . The following Python syntax is not allowed: Expressions Function calls other than math functions. is / is not operations if expressions lambda expressions list / set / dict comprehensions Literal dict and set expressions yield expressions Generator expressions Boolean expressions consisting of only scalar values Statements Neither simple or compound statements are allowed. This includes for , while , and if . Local variables # You must explicitly reference any local variable that you want to use in an expression by placing the @ character in front of the name. This mechanism is the same for both DataFrame.query() and DataFrame.eval() . For example, If you don’t prefix the local variable with @ , pandas will raise an exception telling you the variable is undefined. When using DataFrame.eval() and DataFrame.query() , this allows you to have a local variable and a DataFrame column with the same name in an expression. Warning pandas.eval() will raise an exception if you cannot use the @ prefix because it isn’t defined in that context. In this case, you should simply refer to the variables like you would in standard Python. pandas.eval() parsers # There are two different expression syntax parsers. The default 'pandas' parser allows a more intuitive syntax for expressing query-like operations (comparisons, conjunctions and disjunctions). In particular, the precedence of the & and | operators is made equal to the precedence of the corresponding boolean operations and and or . For example, the above conjunction can be written without parentheses. Alternatively, you can use the 'python' parser to enforce strict Python semantics. The same expression can be “anded” together with the word and as well: The and and or operators here have the same precedence that they would in Python. pandas.eval() engines # There are two different expression engines. The 'numexpr' engine is the more performant engine that can yield performance improvements compared to standard Python syntax for large DataFrame . This engine requires the optional dependency numexpr to be installed. The 'python' engine is generally not useful except for testing other evaluation engines against it. You will achieve no performance benefits using eval() with engine='python' and may incur a performance hit. The DataFrame.eval() method # In addition to the top level pandas.eval() function you can also evaluate an expression in the “context” of a DataFrame . Any expression that is a valid pandas.eval() expression is also a valid DataFrame.eval() expression, with the added benefit that you don’t have to prefix the name of the DataFrame to the column(s) you’re interested in evaluating. In addition, you can perform assignment of columns within an expression. This allows for formulaic evaluation . The assignment target can be a new column name or an existing column name, and it must be a valid Python identifier. A copy of the DataFrame with the new or modified columns is returned, and the original frame is unchanged. Multiple column assignments can be performed by using a multi-line string. The equivalent in standard Python would be eval() performance comparison # pandas.eval() works well with expressions containing large arrays. DataFrame arithmetic: DataFrame comparison: DataFrame arithmetic with unaligned axes. Note Operations such as 1 and 2 # would parse to 1 & 2, but should evaluate to 2 3 or 4 # would parse to 3 | 4, but should evaluate to 3 ~ 1 # this is okay, but slower when using eval should be performed in Python. An exception will be raised if you try to perform any boolean/bitwise operations with scalar operands that are not of type bool or np.bool_ . Here is a plot showing the running time of pandas.eval() as function of the size of the frame involved in the computation. The two lines are two different engines. You will only see the performance benefits of using the numexpr engine with pandas.eval() if your DataFrame has more than approximately 100,000 rows. This plot was created using a DataFrame with 3 columns each containing floating point values generated using numpy.random.randn() . Expression evaluation limitations with numexpr # Expressions that would result in an object dtype or involve datetime operations because of NaT must be evaluated in Python space, but part of an expression can still be evaluated with numexpr . For example: The numeric part of the comparison ( nums == 1 ) will be evaluated by numexpr and the object part of the comparison ( ""strings == 'a' ) will be evaluated by Python."
https://pandas.pydata.org/docs/user_guide/scale.html,Scaling to large datasets,"<article class=""bd-article"" role=""main"">
<section id=""scaling-to-large-datasets"">
<span id=""scale""></span><h1>Scaling to large datasets<a class=""headerlink"" href=""#scaling-to-large-datasets"" title=""Link to this heading"">#</a></h1>
<p>pandas provides data structures for in-memory analytics, which makes using pandas
to analyze datasets that are larger than memory datasets somewhat tricky. Even datasets
that are a sizable fraction of memory become unwieldy, as some pandas operations need
to make intermediate copies.</p>
<p>This document provides a few recommendations for scaling your analysis to larger datasets.
It’s a complement to <a class=""reference internal"" href=""enhancingperf.html#enhancingperf""><span class=""std std-ref"">Enhancing performance</span></a>, which focuses on speeding up analysis
for datasets that fit in memory.</p>
<section id=""load-less-data"">
<h2>Load less data<a class=""headerlink"" href=""#load-less-data"" title=""Link to this heading"">#</a></h2>
<p>Suppose our raw dataset on disk has many columns.</p>

<p>To load the columns we want, we have two options.
Option 1 loads in all the data and then filters to what we need.</p>

<p>Option 2 only loads the columns we request.</p>

<p>If we were to measure the memory usage of the two calls, we’d see that specifying
<code class=""docutils literal notranslate""><span class=""pre"">columns</span></code> uses about 1/10th the memory in this case.</p>
<p>With <a class=""reference internal"" href=""../reference/api/pandas.read_csv.html#pandas.read_csv"" title=""pandas.read_csv""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.read_csv()</span></code></a>, you can specify <code class=""docutils literal notranslate""><span class=""pre"">usecols</span></code> to limit the columns
read into memory. Not all file formats that can be read by pandas provide an option
to read a subset of columns.</p>
</section>
<section id=""use-efficient-datatypes"">
<h2>Use efficient datatypes<a class=""headerlink"" href=""#use-efficient-datatypes"" title=""Link to this heading"">#</a></h2>
<p>The default pandas data types are not the most memory efficient. This is
especially true for text data columns with relatively few unique values (commonly
referred to as “low-cardinality” data). By using more efficient data types, you
can store larger datasets in memory.</p>

<p>Now, let’s inspect the data types and memory usage to see where we should focus our
attention.</p>


<p>The <code class=""docutils literal notranslate""><span class=""pre"">name</span></code> column is taking up much more memory than any other. It has just a
few unique values, so it’s a good candidate for converting to a
<a class=""reference internal"" href=""../reference/api/pandas.Categorical.html#pandas.Categorical"" title=""pandas.Categorical""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">pandas.Categorical</span></code></a>. With a <a class=""reference internal"" href=""../reference/api/pandas.Categorical.html#pandas.Categorical"" title=""pandas.Categorical""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">pandas.Categorical</span></code></a>, we store each unique name once and use
space-efficient integers to know which specific name is used in each row.</p>

<p>We can go a bit further and downcast the numeric columns to their smallest types
using <a class=""reference internal"" href=""../reference/api/pandas.to_numeric.html#pandas.to_numeric"" title=""pandas.to_numeric""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pandas.to_numeric()</span></code></a>.</p>



<p>In all, we’ve reduced the in-memory footprint of this dataset to 1/5 of its
original size.</p>
<p>See <a class=""reference internal"" href=""categorical.html#categorical""><span class=""std std-ref"">Categorical data</span></a> for more on <a class=""reference internal"" href=""../reference/api/pandas.Categorical.html#pandas.Categorical"" title=""pandas.Categorical""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">pandas.Categorical</span></code></a> and <a class=""reference internal"" href=""basics.html#basics-dtypes""><span class=""std std-ref"">dtypes</span></a>
for an overview of all of pandas’ dtypes.</p>
</section>
<section id=""use-chunking"">
<h2>Use chunking<a class=""headerlink"" href=""#use-chunking"" title=""Link to this heading"">#</a></h2>
<p>Some workloads can be achieved with chunking by splitting a large problem into a bunch of small problems. For example,
converting an individual CSV file into a Parquet file and repeating that for each file in a directory. As long as each chunk
fits in memory, you can work with datasets that are much larger than memory.</p>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>Chunking works well when the operation you’re performing requires zero or minimal
coordination between chunks. For more complicated workflows, you’re better off
<a class=""reference internal"" href=""#scale-other-libraries""><span class=""std std-ref"">using other libraries</span></a>.</p>
</div>
<p>Suppose we have an even larger “logical dataset” on disk that’s a directory of parquet
files. Each file in the directory represents a different year of the entire dataset.</p>

<div class=""highlight-default notranslate""><div class=""highlight""><pre><span></span>data
└── timeseries
    ├── ts-00.parquet
    ├── ts-01.parquet
    ├── ts-02.parquet
    ├── ts-03.parquet
    ├── ts-04.parquet
    ├── ts-05.parquet
    ├── ts-06.parquet
    ├── ts-07.parquet
    ├── ts-08.parquet
    ├── ts-09.parquet
    ├── ts-10.parquet
    └── ts-11.parquet
</pre></div>
</div>
<p>Now we’ll implement an out-of-core <a class=""reference internal"" href=""../reference/api/pandas.Series.value_counts.html#pandas.Series.value_counts"" title=""pandas.Series.value_counts""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">pandas.Series.value_counts()</span></code></a>. The peak memory usage of this
workflow is the single largest chunk, plus a small series storing the unique value
counts up to this point. As long as each individual file fits in memory, this will
work for arbitrary-sized datasets.</p>

<p>Some readers, like <a class=""reference internal"" href=""../reference/api/pandas.read_csv.html#pandas.read_csv"" title=""pandas.read_csv""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">pandas.read_csv()</span></code></a>, offer parameters to control the
<code class=""docutils literal notranslate""><span class=""pre"">chunksize</span></code> when reading a single file.</p>
<p>Manually chunking is an OK option for workflows that don’t
require too sophisticated of operations. Some operations, like <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.groupby.html#pandas.DataFrame.groupby"" title=""pandas.DataFrame.groupby""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">pandas.DataFrame.groupby()</span></code></a>, are
much harder to do chunkwise. In these cases, you may be better switching to a
different library that implements these out-of-core algorithms for you.</p>
</section>
<section id=""use-other-libraries"">
<span id=""scale-other-libraries""></span><h2>Use Other Libraries<a class=""headerlink"" href=""#use-other-libraries"" title=""Link to this heading"">#</a></h2>
<p>There are other libraries which provide similar APIs to pandas and work nicely with pandas DataFrame,
and can give you the ability to scale your large dataset processing and analytics
by parallel runtime, distributed memory, clustering, etc. You can find more information
in <a class=""reference external"" href=""https://pandas.pydata.org/community/ecosystem.html#out-of-core"">the ecosystem page</a>.</p>
</section>
</section>
</article>","Scaling to large datasets # pandas provides data structures for in-memory analytics, which makes using pandas to analyze datasets that are larger than memory datasets somewhat tricky. Even datasets that are a sizable fraction of memory become unwieldy, as some pandas operations need to make intermediate copies. This document provides a few recommendations for scaling your analysis to larger datasets. It’s a complement to Enhancing performance , which focuses on speeding up analysis for datasets that fit in memory. Load less data # Suppose our raw dataset on disk has many columns. To load the columns we want, we have two options. Option 1 loads in all the data and then filters to what we need. Option 2 only loads the columns we request. If we were to measure the memory usage of the two calls, we’d see that specifying columns uses about 1/10th the memory in this case. With pandas.read_csv() , you can specify usecols to limit the columns read into memory. Not all file formats that can be read by pandas provide an option to read a subset of columns. Use efficient datatypes # The default pandas data types are not the most memory efficient. This is especially true for text data columns with relatively few unique values (commonly referred to as “low-cardinality” data). By using more efficient data types, you can store larger datasets in memory. Now, let’s inspect the data types and memory usage to see where we should focus our attention. The name column is taking up much more memory than any other. It has just a few unique values, so it’s a good candidate for converting to a pandas.Categorical . With a pandas.Categorical , we store each unique name once and use space-efficient integers to know which specific name is used in each row. We can go a bit further and downcast the numeric columns to their smallest types using pandas.to_numeric() . In all, we’ve reduced the in-memory footprint of this dataset to 1/5 of its original size. See Categorical data for more on pandas.Categorical and dtypes for an overview of all of pandas’ dtypes. Use chunking # Some workloads can be achieved with chunking by splitting a large problem into a bunch of small problems. For example, converting an individual CSV file into a Parquet file and repeating that for each file in a directory. As long as each chunk fits in memory, you can work with datasets that are much larger than memory. Note Chunking works well when the operation you’re performing requires zero or minimal coordination between chunks. For more complicated workflows, you’re better off using other libraries . Suppose we have an even larger “logical dataset” on disk that’s a directory of parquet files. Each file in the directory represents a different year of the entire dataset. data └── timeseries     ├── ts-00.parquet     ├── ts-01.parquet     ├── ts-02.parquet     ├── ts-03.parquet     ├── ts-04.parquet     ├── ts-05.parquet     ├── ts-06.parquet     ├── ts-07.parquet     ├── ts-08.parquet     ├── ts-09.parquet     ├── ts-10.parquet     └── ts-11.parquet Now we’ll implement an out-of-core pandas.Series.value_counts() . The peak memory usage of this workflow is the single largest chunk, plus a small series storing the unique value counts up to this point. As long as each individual file fits in memory, this will work for arbitrary-sized datasets. Some readers, like pandas.read_csv() , offer parameters to control the chunksize when reading a single file. Manually chunking is an OK option for workflows that don’t require too sophisticated of operations. Some operations, like pandas.DataFrame.groupby() , are much harder to do chunkwise. In these cases, you may be better switching to a different library that implements these out-of-core algorithms for you. Use Other Libraries # There are other libraries which provide similar APIs to pandas and work nicely with pandas DataFrame, and can give you the ability to scale your large dataset processing and analytics by parallel runtime, distributed memory, clustering, etc. You can find more information in the ecosystem page ."
https://pandas.pydata.org/docs/user_guide/sparse.html,Sparse data structures,"<article class=""bd-article"" role=""main"">
<section id=""sparse-data-structures"">
<span id=""sparse""></span><h1>Sparse data structures<a class=""headerlink"" href=""#sparse-data-structures"" title=""Link to this heading"">#</a></h1>
<p>pandas provides data structures for efficiently storing sparse data.
These are not necessarily sparse in the typical “mostly 0”. Rather, you can view these
objects as being “compressed” where any data matching a specific value (<code class=""docutils literal notranslate""><span class=""pre"">NaN</span></code> / missing value, though any value
can be chosen, including 0) is omitted. The compressed values are not actually stored in the array.</p>

<p>Notice the dtype, <code class=""docutils literal notranslate""><span class=""pre"">Sparse[float64,</span> <span class=""pre"">nan]</span></code>. The <code class=""docutils literal notranslate""><span class=""pre"">nan</span></code> means that elements in the
array that are <code class=""docutils literal notranslate""><span class=""pre"">nan</span></code> aren’t actually stored, only the non-<code class=""docutils literal notranslate""><span class=""pre"">nan</span></code> elements are.
Those non-<code class=""docutils literal notranslate""><span class=""pre"">nan</span></code> elements have a <code class=""docutils literal notranslate""><span class=""pre"">float64</span></code> dtype.</p>
<p>The sparse objects exist for memory efficiency reasons. Suppose you had a
large, mostly NA <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>:</p>

<p>As you can see, the density (% of values that have not been “compressed”) is
extremely low. This sparse object takes up much less memory on disk (pickled)
and in the Python interpreter.</p>

<p>Functionally, their behavior should be nearly
identical to their dense counterparts.</p>
<section id=""sparsearray"">
<span id=""sparse-array""></span><h2>SparseArray<a class=""headerlink"" href=""#sparsearray"" title=""Link to this heading"">#</a></h2>
<p><a class=""reference internal"" href=""../reference/api/pandas.arrays.SparseArray.html#pandas.arrays.SparseArray"" title=""pandas.arrays.SparseArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">arrays.SparseArray</span></code></a> is a <a class=""reference internal"" href=""../reference/api/pandas.api.extensions.ExtensionArray.html#pandas.api.extensions.ExtensionArray"" title=""pandas.api.extensions.ExtensionArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">ExtensionArray</span></code></a>
for storing an array of sparse values (see <a class=""reference internal"" href=""basics.html#basics-dtypes""><span class=""std std-ref"">dtypes</span></a> for more
on extension arrays). It is a 1-dimensional ndarray-like object storing
only values distinct from the <code class=""docutils literal notranslate""><span class=""pre"">fill_value</span></code>:</p>

<p>A sparse array can be converted to a regular (dense) ndarray with <code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">numpy.asarray()</span></code></p>

</section>
<section id=""sparsedtype"">
<span id=""sparse-dtype""></span><h2>SparseDtype<a class=""headerlink"" href=""#sparsedtype"" title=""Link to this heading"">#</a></h2>
<p>The <code class=""xref py py-attr docutils literal notranslate""><span class=""pre"">SparseArray.dtype</span></code> property stores two pieces of information</p>
<ol class=""arabic simple"">
<li><p>The dtype of the non-sparse values</p></li>
<li><p>The scalar fill value</p></li>
</ol>

<p>A <a class=""reference internal"" href=""../reference/api/pandas.SparseDtype.html#pandas.SparseDtype"" title=""pandas.SparseDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">SparseDtype</span></code></a> may be constructed by passing only a dtype</p>

<p>in which case a default fill value will be used (for NumPy dtypes this is often the
“missing” value for that dtype). To override this default an explicit fill value may be
passed instead</p>

<p>Finally, the string alias <code class=""docutils literal notranslate""><span class=""pre"">'Sparse[dtype]'</span></code> may be used to specify a sparse dtype
in many places</p>

</section>
<section id=""sparse-accessor"">
<span id=""id1""></span><h2>Sparse accessor<a class=""headerlink"" href=""#sparse-accessor"" title=""Link to this heading"">#</a></h2>
<p>pandas provides a <code class=""docutils literal notranslate""><span class=""pre"">.sparse</span></code> accessor, similar to <code class=""docutils literal notranslate""><span class=""pre"">.str</span></code> for string data, <code class=""docutils literal notranslate""><span class=""pre"">.cat</span></code>
for categorical data, and <code class=""docutils literal notranslate""><span class=""pre"">.dt</span></code> for datetime-like data. This namespace provides
attributes and methods that are specific to sparse data.</p>

<p>This accessor is available only on data with <code class=""docutils literal notranslate""><span class=""pre"">SparseDtype</span></code>, and on the <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>
class itself for creating a Series with sparse data from a scipy COO matrix with.</p>
<p>A <code class=""docutils literal notranslate""><span class=""pre"">.sparse</span></code> accessor has been added for <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> as well.
See <a class=""reference internal"" href=""../reference/frame.html#api-frame-sparse""><span class=""std std-ref"">Sparse accessor</span></a> for more.</p>
</section>
<section id=""sparse-calculation"">
<span id=""id2""></span><h2>Sparse calculation<a class=""headerlink"" href=""#sparse-calculation"" title=""Link to this heading"">#</a></h2>
<p>You can apply NumPy <a class=""reference external"" href=""https://numpy.org/doc/stable/reference/ufuncs.html"">ufuncs</a>
to <a class=""reference internal"" href=""../reference/api/pandas.arrays.SparseArray.html#pandas.arrays.SparseArray"" title=""pandas.arrays.SparseArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">arrays.SparseArray</span></code></a> and get a <a class=""reference internal"" href=""../reference/api/pandas.arrays.SparseArray.html#pandas.arrays.SparseArray"" title=""pandas.arrays.SparseArray""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">arrays.SparseArray</span></code></a> as a result.</p>

<p>The <em>ufunc</em> is also applied to <code class=""docutils literal notranslate""><span class=""pre"">fill_value</span></code>. This is needed to get
the correct dense result.</p>

<p><strong>Conversion</strong></p>
<p>To convert data from sparse to dense, use the <code class=""docutils literal notranslate""><span class=""pre"">.sparse</span></code> accessors</p>

<p>From dense to sparse, use <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.astype.html#pandas.DataFrame.astype"" title=""pandas.DataFrame.astype""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.astype()</span></code></a> with a <a class=""reference internal"" href=""../reference/api/pandas.SparseDtype.html#pandas.SparseDtype"" title=""pandas.SparseDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">SparseDtype</span></code></a>.</p>

</section>
<section id=""interaction-with-scipy-sparse"">
<span id=""sparse-scipysparse""></span><h2>Interaction with <em>scipy.sparse</em><a class=""headerlink"" href=""#interaction-with-scipy-sparse"" title=""Link to this heading"">#</a></h2>
<p>Use <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.sparse.from_spmatrix.html#pandas.DataFrame.sparse.from_spmatrix"" title=""pandas.DataFrame.sparse.from_spmatrix""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.sparse.from_spmatrix()</span></code></a> to create a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> with sparse values from a sparse matrix.</p>

<p>All sparse formats are supported, but matrices that are not in <a class=""reference external"" href=""https://docs.scipy.org/doc/scipy/reference/sparse.html#module-scipy.sparse"" title=""(in SciPy v1.13.0)""><code class=""xref py py-mod docutils literal notranslate""><span class=""pre"">COOrdinate</span></code></a> format will be converted, copying data as needed.
To convert back to sparse SciPy matrix in COO format, you can use the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.sparse.to_coo.html#pandas.DataFrame.sparse.to_coo"" title=""pandas.DataFrame.sparse.to_coo""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.sparse.to_coo()</span></code></a> method:</p>

<p><a class=""reference internal"" href=""../reference/api/pandas.Series.sparse.to_coo.html#pandas.Series.sparse.to_coo"" title=""pandas.Series.sparse.to_coo""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.sparse.to_coo()</span></code></a> is implemented for transforming a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> with sparse values indexed by a <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a> to a <a class=""reference external"" href=""https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html#scipy.sparse.coo_matrix"" title=""(in SciPy v1.13.0)""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">scipy.sparse.coo_matrix</span></code></a>.</p>
<p>The method requires a <a class=""reference internal"" href=""../reference/api/pandas.MultiIndex.html#pandas.MultiIndex"" title=""pandas.MultiIndex""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">MultiIndex</span></code></a> with two or more levels.</p>

<p>In the example below, we transform the <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> to a sparse representation of a 2-d array by specifying that the first and second <code class=""docutils literal notranslate""><span class=""pre"">MultiIndex</span></code> levels define labels for the rows and the third and fourth levels define labels for the columns. We also specify that the column and row labels should be sorted in the final sparse representation.</p>

<p>Specifying different row and column labels (and not sorting them) yields a different sparse matrix:</p>

<p>A convenience method <a class=""reference internal"" href=""../reference/api/pandas.Series.sparse.from_coo.html#pandas.Series.sparse.from_coo"" title=""pandas.Series.sparse.from_coo""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">Series.sparse.from_coo()</span></code></a> is implemented for creating a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> with sparse values from a <code class=""docutils literal notranslate""><span class=""pre"">scipy.sparse.coo_matrix</span></code>.</p>

<p>The default behaviour (with <code class=""docutils literal notranslate""><span class=""pre"">dense_index=False</span></code>) simply returns a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> containing
only the non-null entries.</p>

<p>Specifying <code class=""docutils literal notranslate""><span class=""pre"">dense_index=True</span></code> will result in an index that is the Cartesian product of the
row and columns coordinates of the matrix. Note that this will consume a significant amount of memory
(relative to <code class=""docutils literal notranslate""><span class=""pre"">dense_index=False</span></code>) if the sparse matrix is large (and sparse) enough.</p>

</section>
</section>
</article>","Sparse data structures # pandas provides data structures for efficiently storing sparse data. These are not necessarily sparse in the typical “mostly 0”. Rather, you can view these objects as being “compressed” where any data matching a specific value ( NaN / missing value, though any value can be chosen, including 0) is omitted. The compressed values are not actually stored in the array. Notice the dtype, Sparse[float64, nan] . The nan means that elements in the array that are nan aren’t actually stored, only the non- nan elements are. Those non- nan elements have a float64 dtype. The sparse objects exist for memory efficiency reasons. Suppose you had a large, mostly NA DataFrame : As you can see, the density (% of values that have not been “compressed”) is extremely low. This sparse object takes up much less memory on disk (pickled) and in the Python interpreter. Functionally, their behavior should be nearly identical to their dense counterparts. SparseArray # arrays.SparseArray is a ExtensionArray for storing an array of sparse values (see dtypes for more on extension arrays). It is a 1-dimensional ndarray-like object storing only values distinct from the fill_value : A sparse array can be converted to a regular (dense) ndarray with numpy.asarray() SparseDtype # The SparseArray.dtype property stores two pieces of information The dtype of the non-sparse values The scalar fill value A SparseDtype may be constructed by passing only a dtype in which case a default fill value will be used (for NumPy dtypes this is often the “missing” value for that dtype). To override this default an explicit fill value may be passed instead Finally, the string alias 'Sparse[dtype]' may be used to specify a sparse dtype in many places Sparse accessor # pandas provides a .sparse accessor, similar to .str for string data, .cat for categorical data, and .dt for datetime-like data. This namespace provides attributes and methods that are specific to sparse data. This accessor is available only on data with SparseDtype , and on the Series class itself for creating a Series with sparse data from a scipy COO matrix with. A .sparse accessor has been added for DataFrame as well. See Sparse accessor for more. Sparse calculation # You can apply NumPy ufuncs to arrays.SparseArray and get a arrays.SparseArray as a result. The ufunc is also applied to fill_value . This is needed to get the correct dense result. Conversion To convert data from sparse to dense, use the .sparse accessors From dense to sparse, use DataFrame.astype() with a SparseDtype . Interaction with scipy.sparse # Use DataFrame.sparse.from_spmatrix() to create a DataFrame with sparse values from a sparse matrix. All sparse formats are supported, but matrices that are not in COOrdinate format will be converted, copying data as needed. To convert back to sparse SciPy matrix in COO format, you can use the DataFrame.sparse.to_coo() method: Series.sparse.to_coo() is implemented for transforming a Series with sparse values indexed by a MultiIndex to a scipy.sparse.coo_matrix . The method requires a MultiIndex with two or more levels. In the example below, we transform the Series to a sparse representation of a 2-d array by specifying that the first and second MultiIndex levels define labels for the rows and the third and fourth levels define labels for the columns. We also specify that the column and row labels should be sorted in the final sparse representation. Specifying different row and column labels (and not sorting them) yields a different sparse matrix: A convenience method Series.sparse.from_coo() is implemented for creating a Series with sparse values from a scipy.sparse.coo_matrix . The default behaviour (with dense_index=False ) simply returns a Series containing only the non-null entries. Specifying dense_index=True will result in an index that is the Cartesian product of the row and columns coordinates of the matrix. Note that this will consume a significant amount of memory (relative to dense_index=False ) if the sparse matrix is large (and sparse) enough."
https://pandas.pydata.org/docs/user_guide/gotchas.html,Frequently Asked Questions (FAQ),"<article class=""bd-article"" role=""main"">
<section id=""frequently-asked-questions-faq"">
<span id=""gotchas""></span><h1>Frequently Asked Questions (FAQ)<a class=""headerlink"" href=""#frequently-asked-questions-faq"" title=""Link to this heading"">#</a></h1>
<section id=""dataframe-memory-usage"">
<span id=""df-memory-usage""></span><h2>DataFrame memory usage<a class=""headerlink"" href=""#dataframe-memory-usage"" title=""Link to this heading"">#</a></h2>
<p>The memory usage of a <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> (including the index) is shown when calling
the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.info.html#pandas.DataFrame.info"" title=""pandas.DataFrame.info""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">info()</span></code></a>. A configuration option, <code class=""docutils literal notranslate""><span class=""pre"">display.memory_usage</span></code>
(see <a class=""reference internal"" href=""options.html#options-available""><span class=""std std-ref"">the list of options</span></a>), specifies if the
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> memory usage will be displayed when invoking the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.info.html#pandas.DataFrame.info"" title=""pandas.DataFrame.info""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">info()</span></code></a>
method.</p>
<p>For example, the memory usage of the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> below is shown
when calling <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.info.html#pandas.DataFrame.info"" title=""pandas.DataFrame.info""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">info()</span></code></a>:</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">+</span></code> symbol indicates that the true memory usage could be higher, because
pandas does not count the memory used by values in columns with
<code class=""docutils literal notranslate""><span class=""pre"">dtype=object</span></code>.</p>
<p>Passing <code class=""docutils literal notranslate""><span class=""pre"">memory_usage='deep'</span></code> will enable a more accurate memory usage report,
accounting for the full usage of the contained objects. This is optional
as it can be expensive to do this deeper introspection.</p>

<p>By default the display option is set to <code class=""docutils literal notranslate""><span class=""pre"">True</span></code> but can be explicitly
overridden by passing the <code class=""docutils literal notranslate""><span class=""pre"">memory_usage</span></code> argument when invoking <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.info.html#pandas.DataFrame.info"" title=""pandas.DataFrame.info""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">info()</span></code></a>.</p>
<p>The memory usage of each column can be found by calling the
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.memory_usage.html#pandas.DataFrame.memory_usage"" title=""pandas.DataFrame.memory_usage""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">memory_usage()</span></code></a> method. This returns a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> with an index
represented by column names and memory usage of each column shown in bytes. For
the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> above, the memory usage of each column and the total memory
usage can be found with the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.memory_usage.html#pandas.DataFrame.memory_usage"" title=""pandas.DataFrame.memory_usage""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">memory_usage()</span></code></a> method:</p>

<p>By default the memory usage of the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> index is shown in the
returned <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>, the memory usage of the index can be suppressed by passing
the <code class=""docutils literal notranslate""><span class=""pre"">index=False</span></code> argument:</p>

<p>The memory usage displayed by the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.info.html#pandas.DataFrame.info"" title=""pandas.DataFrame.info""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">info()</span></code></a> method utilizes the
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.memory_usage.html#pandas.DataFrame.memory_usage"" title=""pandas.DataFrame.memory_usage""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">memory_usage()</span></code></a> method to determine the memory usage of a
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> while also formatting the output in human-readable units (base-2
representation; i.e. 1KB = 1024 bytes).</p>
<p>See also <a class=""reference internal"" href=""categorical.html#categorical-memory""><span class=""std std-ref"">Categorical Memory Usage</span></a>.</p>
</section>
<section id=""using-if-truth-statements-with-pandas"">
<span id=""gotchas-truth""></span><h2>Using if/truth statements with pandas<a class=""headerlink"" href=""#using-if-truth-statements-with-pandas"" title=""Link to this heading"">#</a></h2>
<p>pandas follows the NumPy convention of raising an error when you try to convert
something to a <code class=""docutils literal notranslate""><span class=""pre"">bool</span></code>. This happens in an <code class=""docutils literal notranslate""><span class=""pre"">if</span></code>-statement or when using the
boolean operations: <code class=""docutils literal notranslate""><span class=""pre"">and</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">or</span></code>, and <code class=""docutils literal notranslate""><span class=""pre"">not</span></code>. It is not clear what the result
of the following code should be:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""gp"">&gt;&gt;&gt; </span><span class=""k"">if</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">Series</span><span class=""p"">([</span><span class=""kc"">False</span><span class=""p"">,</span> <span class=""kc"">True</span><span class=""p"">,</span> <span class=""kc"">False</span><span class=""p"">]):</span>
<span class=""gp"">... </span>    <span class=""k"">pass</span>
</pre></div>
</div>
<p>Should it be <code class=""docutils literal notranslate""><span class=""pre"">True</span></code> because it’s not zero-length, or <code class=""docutils literal notranslate""><span class=""pre"">False</span></code> because there
are <code class=""docutils literal notranslate""><span class=""pre"">False</span></code> values? It is unclear, so instead, pandas raises a <code class=""docutils literal notranslate""><span class=""pre"">ValueError</span></code>:</p>

<p>You need to explicitly choose what you want to do with the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>, e.g.
use <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.any.html#pandas.DataFrame.any"" title=""pandas.DataFrame.any""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">any()</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.all.html#pandas.DataFrame.all"" title=""pandas.DataFrame.all""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">all()</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.empty.html#pandas.DataFrame.empty"" title=""pandas.DataFrame.empty""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">empty()</span></code></a>.
Alternatively, you might want to compare if the pandas object is <code class=""docutils literal notranslate""><span class=""pre"">None</span></code>:</p>

<p>Below is how to check if any of the values are <code class=""docutils literal notranslate""><span class=""pre"">True</span></code>:</p>

<section id=""bitwise-boolean"">
<h3>Bitwise boolean<a class=""headerlink"" href=""#bitwise-boolean"" title=""Link to this heading"">#</a></h3>
<p>Bitwise boolean operators like <code class=""docutils literal notranslate""><span class=""pre"">==</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">!=</span></code> return a boolean <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a>
which performs an element-wise comparison when compared to a scalar.</p>

<p>See <a class=""reference internal"" href=""basics.html#basics-compare""><span class=""std std-ref"">boolean comparisons</span></a> for more examples.</p>
</section>
<section id=""using-the-in-operator"">
<h3>Using the <code class=""docutils literal notranslate""><span class=""pre"">in</span></code> operator<a class=""headerlink"" href=""#using-the-in-operator"" title=""Link to this heading"">#</a></h3>
<p>Using the Python <code class=""docutils literal notranslate""><span class=""pre"">in</span></code> operator on a <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> tests for membership in the
<strong>index</strong>, not membership among the values.</p>

<p>If this behavior is surprising, keep in mind that using <code class=""docutils literal notranslate""><span class=""pre"">in</span></code> on a Python
dictionary tests keys, not values, and <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> are dict-like.
To test for membership in the values, use the method <a class=""reference internal"" href=""../reference/api/pandas.Series.isin.html#pandas.Series.isin"" title=""pandas.Series.isin""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">isin()</span></code></a>:</p>

<p>For <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>, likewise, <code class=""docutils literal notranslate""><span class=""pre"">in</span></code> applies to the column axis,
testing for membership in the list of column names.</p>
</section>
</section>
<section id=""mutating-with-user-defined-function-udf-methods"">
<span id=""gotchas-udf-mutation""></span><h2>Mutating with User Defined Function (UDF) methods<a class=""headerlink"" href=""#mutating-with-user-defined-function-udf-methods"" title=""Link to this heading"">#</a></h2>
<p>This section applies to pandas methods that take a UDF. In particular, the methods
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply"" title=""pandas.DataFrame.apply""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.apply()</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.aggregate.html#pandas.DataFrame.aggregate"" title=""pandas.DataFrame.aggregate""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.aggregate()</span></code></a>, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.transform.html#pandas.DataFrame.transform"" title=""pandas.DataFrame.transform""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.transform()</span></code></a>, and
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.filter.html#pandas.DataFrame.filter"" title=""pandas.DataFrame.filter""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.filter()</span></code></a>.</p>
<p>It is a general rule in programming that one should not mutate a container
while it is being iterated over. Mutation will invalidate the iterator,
causing unexpected behavior. Consider the example:</p>

<p>One probably would have expected that the result would be <code class=""docutils literal notranslate""><span class=""pre"">[1,</span> <span class=""pre"">3,</span> <span class=""pre"">5]</span></code>.
When using a pandas method that takes a UDF, internally pandas is often
iterating over the
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> or other pandas object. Therefore, if the UDF mutates (changes)
the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>, unexpected behavior can arise.</p>
<p>Here is a similar example with <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply"" title=""pandas.DataFrame.apply""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.apply()</span></code></a>:</p>

<p>To resolve this issue, one can make a copy so that the mutation does
not apply to the container being iterated over.</p>


</section>
<section id=""missing-value-representation-for-numpy-types"">
<h2>Missing value representation for NumPy types<a class=""headerlink"" href=""#missing-value-representation-for-numpy-types"" title=""Link to this heading"">#</a></h2>
<section id=""np-nan-as-the-na-representation-for-numpy-types"">
<h3><code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code> as the <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> representation for NumPy types<a class=""headerlink"" href=""#np-nan-as-the-na-representation-for-numpy-types"" title=""Link to this heading"">#</a></h3>
<p>For lack of <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> (missing) support from the ground up in NumPy and Python in
general, <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> could have been represented with:</p>
<ul class=""simple"">
<li><p>A <em>masked array</em> solution: an array of data and an array of boolean values
indicating whether a value is there or is missing.</p></li>
<li><p>Using a special sentinel value, bit pattern, or set of sentinel values to
denote <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> across the dtypes.</p></li>
</ul>
<p>The special value <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code> (Not-A-Number) was chosen as the <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> value for NumPy types, and there are API
functions like <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.isna.html#pandas.DataFrame.isna"" title=""pandas.DataFrame.isna""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.isna()</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.notna.html#pandas.DataFrame.notna"" title=""pandas.DataFrame.notna""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">DataFrame.notna()</span></code></a> which can be used across the dtypes to
detect NA values. However, this choice has a downside of coercing missing integer data as float types as
shown in <a class=""reference internal"" href=""#gotchas-intna""><span class=""std std-ref"">Support for integer NA</span></a>.</p>
</section>
<section id=""na-type-promotions-for-numpy-types"">
<h3><code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> type promotions for NumPy types<a class=""headerlink"" href=""#na-type-promotions-for-numpy-types"" title=""Link to this heading"">#</a></h3>
<p>When introducing NAs into an existing <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> via
<a class=""reference internal"" href=""../reference/api/pandas.Series.reindex.html#pandas.Series.reindex"" title=""pandas.Series.reindex""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">reindex()</span></code></a> or some other means, boolean and integer types will be
promoted to a different dtype in order to store the NAs. The promotions are
summarized in this table:</p>

</section>
<section id=""support-for-integer-na"">
<span id=""gotchas-intna""></span><h3>Support for integer <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code><a class=""headerlink"" href=""#support-for-integer-na"" title=""Link to this heading"">#</a></h3>
<p>In the absence of high performance <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> support being built into NumPy from
the ground up, the primary casualty is the ability to represent NAs in integer
arrays. For example:</p>

<p>This trade-off is made largely for memory and performance reasons, and also so
that the resulting <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> continues to be “numeric”.</p>
<p>If you need to represent integers with possibly missing values, use one of
the nullable-integer extension dtypes provided by pandas or pyarrow</p>
<ul class=""simple"">
<li><p><a class=""reference internal"" href=""../reference/api/pandas.Int8Dtype.html#pandas.Int8Dtype"" title=""pandas.Int8Dtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Int8Dtype</span></code></a></p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.Int16Dtype.html#pandas.Int16Dtype"" title=""pandas.Int16Dtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Int16Dtype</span></code></a></p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.Int32Dtype.html#pandas.Int32Dtype"" title=""pandas.Int32Dtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Int32Dtype</span></code></a></p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.Int64Dtype.html#pandas.Int64Dtype"" title=""pandas.Int64Dtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Int64Dtype</span></code></a></p></li>
<li><p><a class=""reference internal"" href=""../reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"" title=""pandas.ArrowDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">ArrowDtype</span></code></a></p></li>
</ul>

<p>See <a class=""reference internal"" href=""integer_na.html#integer-na""><span class=""std std-ref"">Nullable integer data type</span></a> and <a class=""reference internal"" href=""pyarrow.html#pyarrow""><span class=""std std-ref"">PyArrow Functionality</span></a> for more.</p>
</section>
<section id=""why-not-make-numpy-like-r"">
<h3>Why not make NumPy like R?<a class=""headerlink"" href=""#why-not-make-numpy-like-r"" title=""Link to this heading"">#</a></h3>
<p>Many people have suggested that NumPy should simply emulate the <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> support
present in the more domain-specific statistical programming language <a class=""reference external"" href=""https://www.r-project.org/"">R</a>. Part of the reason is the NumPy type hierarchy:</p>

<p>The R language, by contrast, only has a handful of built-in data types:
<code class=""docutils literal notranslate""><span class=""pre"">integer</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">numeric</span></code> (floating-point), <code class=""docutils literal notranslate""><span class=""pre"">character</span></code>, and
<code class=""docutils literal notranslate""><span class=""pre"">boolean</span></code>. <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> types are implemented by reserving special bit patterns for
each type to be used as the missing value. While doing this with the full NumPy
type hierarchy would be possible, it would be a more substantial trade-off
(especially for the 8- and 16-bit data types) and implementation undertaking.</p>
<p>However, R <code class=""docutils literal notranslate""><span class=""pre"">NA</span></code> semantics are now available by using masked NumPy types such as <a class=""reference internal"" href=""../reference/api/pandas.Int64Dtype.html#pandas.Int64Dtype"" title=""pandas.Int64Dtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Int64Dtype</span></code></a>
or PyArrow types (<a class=""reference internal"" href=""../reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"" title=""pandas.ArrowDtype""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">ArrowDtype</span></code></a>).</p>
</section>
</section>
<section id=""differences-with-numpy"">
<h2>Differences with NumPy<a class=""headerlink"" href=""#differences-with-numpy"" title=""Link to this heading"">#</a></h2>
<p>For <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> and <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> objects, <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.var.html#pandas.DataFrame.var"" title=""pandas.DataFrame.var""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">var()</span></code></a> normalizes by
<code class=""docutils literal notranslate""><span class=""pre"">N-1</span></code> to produce <a class=""reference external"" href=""https://en.wikipedia.org/wiki/Bias_of_an_estimator"">unbiased estimates of the population variance</a>, while NumPy’s
<code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">numpy.var()</span></code> normalizes by N, which measures the variance of the sample. Note that
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.cov.html#pandas.DataFrame.cov"" title=""pandas.DataFrame.cov""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">cov()</span></code></a> normalizes by <code class=""docutils literal notranslate""><span class=""pre"">N-1</span></code> in both pandas and NumPy.</p>
</section>
<section id=""thread-safety"">
<span id=""gotchas-thread-safety""></span><h2>Thread-safety<a class=""headerlink"" href=""#thread-safety"" title=""Link to this heading"">#</a></h2>
<p>pandas is not 100% thread safe. The known issues relate to
the <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.copy.html#pandas.DataFrame.copy"" title=""pandas.DataFrame.copy""><code class=""xref py py-meth docutils literal notranslate""><span class=""pre"">copy()</span></code></a> method. If you are doing a lot of copying of
<a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a> objects shared among threads, we recommend holding locks inside
the threads where the data copying occurs.</p>
<p>See <a class=""reference external"" href=""https://stackoverflow.com/questions/13592618/python-pandas-dataframe-thread-safe"">this link</a>
for more information.</p>
</section>
<section id=""byte-ordering-issues"">
<h2>Byte-ordering issues<a class=""headerlink"" href=""#byte-ordering-issues"" title=""Link to this heading"">#</a></h2>
<p>Occasionally you may have to deal with data that were created on a machine with
a different byte order than the one on which you are running Python. A common
symptom of this issue is an error like:</p>
<div class=""highlight-default notranslate""><div class=""highlight""><pre><span></span><span class=""n"">Traceback</span>
    <span class=""o"">...</span>
<span class=""ne"">ValueError</span><span class=""p"">:</span> <span class=""n"">Big</span><span class=""o"">-</span><span class=""n"">endian</span> <span class=""n"">buffer</span> <span class=""ow"">not</span> <span class=""n"">supported</span> <span class=""n"">on</span> <span class=""n"">little</span><span class=""o"">-</span><span class=""n"">endian</span> <span class=""n"">compiler</span>
</pre></div>
</div>
<p>To deal
with this issue you should convert the underlying NumPy array to the native
system byte order <em>before</em> passing it to <a class=""reference internal"" href=""../reference/api/pandas.Series.html#pandas.Series"" title=""pandas.Series""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">Series</span></code></a> or <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.html#pandas.DataFrame"" title=""pandas.DataFrame""><code class=""xref py py-class docutils literal notranslate""><span class=""pre"">DataFrame</span></code></a>
constructors using something similar to the following:</p>

<p>See <a class=""reference external"" href=""https://numpy.org/doc/stable/user/basics.byteswapping.html"">the NumPy documentation on byte order</a> for more
details.</p>
</section>
</section>
</article>","Frequently Asked Questions (FAQ) # DataFrame memory usage # The memory usage of a DataFrame (including the index) is shown when calling the info() . A configuration option, display.memory_usage (see the list of options ), specifies if the DataFrame memory usage will be displayed when invoking the info() method. For example, the memory usage of the DataFrame below is shown when calling info() : The + symbol indicates that the true memory usage could be higher, because pandas does not count the memory used by values in columns with dtype=object . Passing memory_usage='deep' will enable a more accurate memory usage report, accounting for the full usage of the contained objects. This is optional as it can be expensive to do this deeper introspection. By default the display option is set to True but can be explicitly overridden by passing the memory_usage argument when invoking info() . The memory usage of each column can be found by calling the memory_usage() method. This returns a Series with an index represented by column names and memory usage of each column shown in bytes. For the DataFrame above, the memory usage of each column and the total memory usage can be found with the memory_usage() method: By default the memory usage of the DataFrame index is shown in the returned Series , the memory usage of the index can be suppressed by passing the index=False argument: The memory usage displayed by the info() method utilizes the memory_usage() method to determine the memory usage of a DataFrame while also formatting the output in human-readable units (base-2 representation; i.e. 1KB = 1024 bytes). See also Categorical Memory Usage . Using if/truth statements with pandas # pandas follows the NumPy convention of raising an error when you try to convert something to a bool . This happens in an if -statement or when using the boolean operations: and , or , and not . It is not clear what the result of the following code should be: >>> if pd . Series ([ False , True , False ]): ... pass Should it be True because it’s not zero-length, or False because there are False values? It is unclear, so instead, pandas raises a ValueError : You need to explicitly choose what you want to do with the DataFrame , e.g. use any() , all() or empty() . Alternatively, you might want to compare if the pandas object is None : Below is how to check if any of the values are True : Bitwise boolean # Bitwise boolean operators like == and != return a boolean Series which performs an element-wise comparison when compared to a scalar. See boolean comparisons for more examples. Using the in operator # Using the Python in operator on a Series tests for membership in the index , not membership among the values. If this behavior is surprising, keep in mind that using in on a Python dictionary tests keys, not values, and Series are dict-like. To test for membership in the values, use the method isin() : For DataFrame , likewise, in applies to the column axis, testing for membership in the list of column names. Mutating with User Defined Function (UDF) methods # This section applies to pandas methods that take a UDF. In particular, the methods DataFrame.apply() , DataFrame.aggregate() , DataFrame.transform() , and DataFrame.filter() . It is a general rule in programming that one should not mutate a container while it is being iterated over. Mutation will invalidate the iterator, causing unexpected behavior. Consider the example: One probably would have expected that the result would be [1, 3, 5] . When using a pandas method that takes a UDF, internally pandas is often iterating over the DataFrame or other pandas object. Therefore, if the UDF mutates (changes) the DataFrame , unexpected behavior can arise. Here is a similar example with DataFrame.apply() : To resolve this issue, one can make a copy so that the mutation does not apply to the container being iterated over. Missing value representation for NumPy types # np.nan as the NA representation for NumPy types # For lack of NA (missing) support from the ground up in NumPy and Python in general, NA could have been represented with: A masked array solution: an array of data and an array of boolean values indicating whether a value is there or is missing. Using a special sentinel value, bit pattern, or set of sentinel values to denote NA across the dtypes. The special value np.nan (Not-A-Number) was chosen as the NA value for NumPy types, and there are API functions like DataFrame.isna() and DataFrame.notna() which can be used across the dtypes to detect NA values. However, this choice has a downside of coercing missing integer data as float types as shown in Support for integer NA . NA type promotions for NumPy types # When introducing NAs into an existing Series or DataFrame via reindex() or some other means, boolean and integer types will be promoted to a different dtype in order to store the NAs. The promotions are summarized in this table: Support for integer NA # In the absence of high performance NA support being built into NumPy from the ground up, the primary casualty is the ability to represent NAs in integer arrays. For example: This trade-off is made largely for memory and performance reasons, and also so that the resulting Series continues to be “numeric”. If you need to represent integers with possibly missing values, use one of the nullable-integer extension dtypes provided by pandas or pyarrow Int8Dtype Int16Dtype Int32Dtype Int64Dtype ArrowDtype See Nullable integer data type and PyArrow Functionality for more. Why not make NumPy like R? # Many people have suggested that NumPy should simply emulate the NA support present in the more domain-specific statistical programming language R . Part of the reason is the NumPy type hierarchy: The R language, by contrast, only has a handful of built-in data types: integer , numeric (floating-point), character , and boolean . NA types are implemented by reserving special bit patterns for each type to be used as the missing value. While doing this with the full NumPy type hierarchy would be possible, it would be a more substantial trade-off (especially for the 8- and 16-bit data types) and implementation undertaking. However, R NA semantics are now available by using masked NumPy types such as Int64Dtype or PyArrow types ( ArrowDtype ). Differences with NumPy # For Series and DataFrame objects, var() normalizes by N-1 to produce unbiased estimates of the population variance , while NumPy’s numpy.var() normalizes by N, which measures the variance of the sample. Note that cov() normalizes by N-1 in both pandas and NumPy. Thread-safety # pandas is not 100% thread safe. The known issues relate to the copy() method. If you are doing a lot of copying of DataFrame objects shared among threads, we recommend holding locks inside the threads where the data copying occurs. See this link for more information. Byte-ordering issues # Occasionally you may have to deal with data that were created on a machine with a different byte order than the one on which you are running Python. A common symptom of this issue is an error like: Traceback ... ValueError : Big - endian buffer not supported on little - endian compiler To deal with this issue you should convert the underlying NumPy array to the native system byte order before passing it to Series or DataFrame constructors using something similar to the following: See the NumPy documentation on byte order for more details."
https://pandas.pydata.org/docs/user_guide/cookbook.html,Cookbook,"<article class=""bd-article"" role=""main"">
<section id=""cookbook"">
<span id=""id1""></span><h1>Cookbook<a class=""headerlink"" href=""#cookbook"" title=""Link to this heading"">#</a></h1>
<p>This is a repository for <em>short and sweet</em> examples and links for useful pandas recipes.
We encourage users to add to this documentation.</p>
<p>Adding interesting links and/or inline examples to this section is a great <em>First Pull Request</em>.</p>
<p>Simplified, condensed, new-user friendly, in-line examples have been inserted where possible to
augment the Stack-Overflow and GitHub links. Many of the links contain expanded information,
above what the in-line examples offer.</p>
<p>pandas (pd) and NumPy (np) are the only two abbreviated imported modules. The rest are kept
explicitly imported for newer users.</p>
<section id=""idioms"">
<h2>Idioms<a class=""headerlink"" href=""#idioms"" title=""Link to this heading"">#</a></h2>
<p id=""cookbook-idioms"">These are some neat pandas <code class=""docutils literal notranslate""><span class=""pre"">idioms</span></code></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/17128302/python-pandas-idiom-for-if-then-else"">if-then/if-then-else on one column, and assignment to another one or more columns:</a></p>

<section id=""if-then"">
<h3>if-then…<a class=""headerlink"" href=""#if-then"" title=""Link to this heading"">#</a></h3>
<p>An if-then on one column</p>

<p>An if-then with assignment to 2 columns:</p>

<p>Add another line with different logic, to do the -else</p>

<p>Or use pandas where after you’ve set up a mask</p>

<p><a class=""reference external"" href=""https://stackoverflow.com/questions/19913659/pandas-conditional-creation-of-a-series-dataframe-column"">if-then-else using NumPy’s where()</a></p>

</section>
<section id=""splitting"">
<h3>Splitting<a class=""headerlink"" href=""#splitting"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/14957116/how-to-split-a-dataframe-according-to-a-boolean-criterion"">Split a frame with a boolean criterion</a></p>

</section>
<section id=""building-criteria"">
<h3>Building criteria<a class=""headerlink"" href=""#building-criteria"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/15315452/selecting-with-complex-criteria-from-pandas-dataframe"">Select with multi-column criteria</a></p>

<p>…and (without assignment returns a Series)</p>

<p>…or (without assignment returns a Series)</p>

<p>…or (with assignment modifies the DataFrame.)</p>

<p><a class=""reference external"" href=""https://stackoverflow.com/questions/17758023/return-rows-in-a-dataframe-closest-to-a-user-defined-number"">Select rows with data closest to certain value using argsort</a></p>

<p><a class=""reference external"" href=""https://stackoverflow.com/questions/21058254/pandas-boolean-operation-in-a-python-list/21058331"">Dynamically reduce a list of criteria using a binary operators</a></p>

<p>One could hard code:</p>

<p>…Or it can be done with a list of dynamically built criteria</p>

</section>
</section>
<section id=""selection"">
<span id=""cookbook-selection""></span><h2>Selection<a class=""headerlink"" href=""#selection"" title=""Link to this heading"">#</a></h2>
<section id=""dataframes"">
<h3>Dataframes<a class=""headerlink"" href=""#dataframes"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""indexing.html#indexing""><span class=""std std-ref"">indexing</span></a> docs.</p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/14725068/pandas-using-row-labels-in-boolean-indexing"">Using both row labels and value conditionals</a></p>

<p>Use loc for label-oriented slicing and iloc positional slicing <a class=""reference external"" href=""https://github.com/pandas-dev/pandas/issues/2904"">GH 2904</a></p>

<p>There are 2 explicit slicing methods, with a third general case</p>
<ol class=""arabic simple"">
<li><p>Positional-oriented (Python slicing style : exclusive of end)</p></li>
<li><p>Label-oriented (Non-Python slicing style : inclusive of end)</p></li>
<li><p>General (Either slicing style : depends on if the slice contains labels or positions)</p></li>
</ol>

<p>Ambiguity arises when an index consists of integers with a non-zero start or non-unit increment.</p>

<p><a class=""reference external"" href=""https://stackoverflow.com/q/14986510"">Using inverse operator (~) to take the complement of a mask</a></p>

</section>
<section id=""new-columns"">
<h3>New columns<a class=""headerlink"" href=""#new-columns"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/16575868/efficiently-creating-additional-columns-in-a-pandas-dataframe-using-map"">Efficiently and dynamically creating new columns using DataFrame.map (previously named applymap)</a></p>

<p><a class=""reference external"" href=""https://stackoverflow.com/q/23394476"">Keep other columns when using min() with groupby</a></p>

<p>Method 1 : idxmin() to get the index of the minimums</p>

<p>Method 2 : sort then take first of each</p>

<p>Notice the same results, with the exception of the index.</p>
</section>
</section>
<section id=""multiindexing"">
<span id=""cookbook-multi-index""></span><h2>Multiindexing<a class=""headerlink"" href=""#multiindexing"" title=""Link to this heading"">#</a></h2>
<p>The <a class=""reference internal"" href=""advanced.html#advanced-hierarchical""><span class=""std std-ref"">multindexing</span></a> docs.</p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/14916358/reshaping-dataframes-in-pandas-based-on-column-labels"">Creating a MultiIndex from a labeled frame</a></p>

<section id=""arithmetic"">
<h3>Arithmetic<a class=""headerlink"" href=""#arithmetic"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/19501510/divide-entire-pandas-multiindex-dataframe-by-dataframe-variable/19502176#19502176"">Performing arithmetic with a MultiIndex that needs broadcasting</a></p>

</section>
<section id=""slicing"">
<h3>Slicing<a class=""headerlink"" href=""#slicing"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/12590131/how-to-slice-multindex-columns-in-pandas-dataframes"">Slicing a MultiIndex with xs</a></p>

<p>To take the cross section of the 1st level and 1st axis the index:</p>

<p>…and now the 2nd level of the 1st axis.</p>

<p><a class=""reference external"" href=""https://stackoverflow.com/questions/14964493/multiindex-based-indexing-in-pandas"">Slicing a MultiIndex with xs, method #2</a></p>

<p><a class=""reference external"" href=""https://stackoverflow.com/questions/19319432/pandas-selecting-a-lower-level-in-a-dataframe-to-do-a-ffill"">Setting portions of a MultiIndex with xs</a></p>
</section>
<section id=""sorting"">
<h3>Sorting<a class=""headerlink"" href=""#sorting"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference external"" href=""https://stackoverflow.com/q/14733871"">Sort by specific column or an ordered list of columns, with a MultiIndex</a></p>

<p>Partial selection, the need for sortedness <a class=""reference external"" href=""https://github.com/pandas-dev/pandas/issues/2995"">GH 2995</a></p>
</section>
<section id=""levels"">
<h3>Levels<a class=""headerlink"" href=""#levels"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/14744068/prepend-a-level-to-a-pandas-multiindex"">Prepending a level to a multiindex</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/q/14507794"">Flatten Hierarchical columns</a></p>
</section>
</section>
<section id=""missing-data"">
<span id=""cookbook-missing-data""></span><h2>Missing data<a class=""headerlink"" href=""#missing-data"" title=""Link to this heading"">#</a></h2>
<p>The <a class=""reference internal"" href=""missing_data.html#missing-data""><span class=""std std-ref"">missing data</span></a> docs.</p>
<p>Fill forward a reversed timeseries</p>

<p><a class=""reference external"" href=""https://stackoverflow.com/questions/18196811/cumsum-reset-at-nan"">cumsum reset at NaN values</a></p>
<section id=""replace"">
<h3>Replace<a class=""headerlink"" href=""#replace"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/16818871/extracting-value-and-creating-new-column-out-of-it"">Using replace with backrefs</a></p>
</section>
</section>
<section id=""grouping"">
<span id=""cookbook-grouping""></span><h2>Grouping<a class=""headerlink"" href=""#grouping"" title=""Link to this heading"">#</a></h2>
<p>The <a class=""reference internal"" href=""groupby.html#groupby""><span class=""std std-ref"">grouping</span></a> docs.</p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/15322632/python-pandas-df-groupy-agg-column-reference-in-agg"">Basic grouping with apply</a></p>
<p>Unlike agg, apply’s callable is passed a sub-DataFrame which gives you access to all the columns</p>

<p><a class=""reference external"" href=""https://stackoverflow.com/questions/14734533/how-to-access-pandas-groupby-dataframe-by-key"">Using get_group</a></p>

<p><a class=""reference external"" href=""https://stackoverflow.com/questions/15262134/apply-different-functions-to-different-items-in-group-object-python-pandas"">Apply to different items in a group</a></p>

<p><a class=""reference external"" href=""https://stackoverflow.com/questions/14542145/reductions-down-a-column-in-pandas"">Expanding apply</a></p>

<p><a class=""reference external"" href=""https://stackoverflow.com/questions/14760757/replacing-values-with-groupby-means"">Replacing some values with mean of the rest of a group</a></p>

<p><a class=""reference external"" href=""https://stackoverflow.com/questions/14941366/pandas-sort-by-group-aggregate-and-column"">Sort groups by aggregated data</a></p>

<p><a class=""reference external"" href=""https://stackoverflow.com/questions/14897100/create-multiple-columns-in-pandas-aggregation-function"">Create multiple aggregated columns</a></p>

<p><a class=""reference external"" href=""https://stackoverflow.com/q/17709270"">Create a value counts column and reassign back to the DataFrame</a></p>

<p><a class=""reference external"" href=""https://stackoverflow.com/q/23198053/190597"">Shift groups of the values in a column based on the index</a></p>

<p><a class=""reference external"" href=""https://stackoverflow.com/q/26701849/190597"">Select row with maximum value from each group</a></p>

<p><a class=""reference external"" href=""https://stackoverflow.com/q/29142487/846892"">Grouping like Python’s itertools.groupby</a></p>

<section id=""expanding-data"">
<h3>Expanding data<a class=""headerlink"" href=""#expanding-data"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/15489011/python-time-series-alignment-and-to-date-functions"">Alignment and to-date</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/14300768/pandas-rolling-computation-with-window-based-on-values-instead-of-counts"">Rolling Computation window based on values instead of counts</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/15771472/pandas-rolling-mean-by-time-interval"">Rolling Mean by Time Interval</a></p>
</section>
<section id=""id2"">
<h3>Splitting<a class=""headerlink"" href=""#id2"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/13353233/best-way-to-split-a-dataframe-given-an-edge/15449992#15449992"">Splitting a frame</a></p>
<p>Create a list of dataframes, split using a delineation based on logic included in rows.</p>

</section>
<section id=""pivot"">
<span id=""cookbook-pivot""></span><h3>Pivot<a class=""headerlink"" href=""#pivot"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""reshaping.html#reshaping-pivot""><span class=""std std-ref"">Pivot</span></a> docs.</p>
<p><a class=""reference external"" href=""https://stackoverflow.com/a/15574875"">Partial sums and subtotals</a></p>

<p><a class=""reference external"" href=""https://stackoverflow.com/questions/15589354/frequency-tables-in-pandas-like-plyr-in-r"">Frequency table like plyr in R</a></p>

<p><a class=""reference external"" href=""https://stackoverflow.com/questions/30379789/plot-pandas-data-frame-with-year-over-year-data"">Plot pandas DataFrame with year over year data</a></p>
<p>To create year and month cross tabulation:</p>

</section>
<section id=""apply"">
<h3>Apply<a class=""headerlink"" href=""#apply"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/17349981/converting-pandas-dataframe-with-categorical-values-into-binary-values"">Rolling apply to organize - Turning embedded lists into a MultiIndex frame</a></p>

<p><a class=""reference external"" href=""https://stackoverflow.com/questions/19121854/using-rolling-apply-on-a-dataframe-object"">Rolling apply with a DataFrame returning a Series</a></p>
<p>Rolling Apply to multiple columns where function calculates a Series before a Scalar from the Series is returned</p>

<p><a class=""reference external"" href=""https://stackoverflow.com/questions/21040766/python-pandas-rolling-apply-two-column-input-into-function/21045831#21045831"">Rolling apply with a DataFrame returning a Scalar</a></p>
<p>Rolling Apply to multiple columns where function returns a Scalar (Volume Weighted Average Price)</p>

</section>
</section>
<section id=""timeseries"">
<h2>Timeseries<a class=""headerlink"" href=""#timeseries"" title=""Link to this heading"">#</a></h2>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/14539992/pandas-drop-rows-outside-of-time-range"">Between times</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/17559885/pandas-dataframe-mask-based-on-index"">Using indexer between time</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/a/24014440"">Constructing a datetime range that excludes weekends and includes only certain times</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/13893227/vectorized-look-up-of-values-in-pandas-dataframe"">Vectorized Lookup</a></p>
<p><a class=""reference external"" href=""https://nipunbatra.github.io/blog/visualisation/2013/05/01/aggregation-timeseries.html"">Aggregation and plotting time series</a></p>
<p>Turn a matrix with hours in columns and days in rows into a continuous row sequence in the form of a time series.
<a class=""reference external"" href=""https://stackoverflow.com/questions/15432659/how-to-rearrange-a-python-pandas-dataframe"">How to rearrange a Python pandas DataFrame?</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/22244383/pandas-df-refill-adding-two-columns-of-different-shape"">Dealing with duplicates when reindexing a timeseries to a specified frequency</a></p>
<p>Calculate the first day of the month for each entry in a DatetimeIndex</p>

<section id=""resampling"">
<span id=""cookbook-resample""></span><h3>Resampling<a class=""headerlink"" href=""#resampling"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""timeseries.html#timeseries-resampling""><span class=""std std-ref"">Resample</span></a> docs.</p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/15297053/how-can-i-divide-single-values-of-a-dataframe-by-monthly-averages"">Using Grouper instead of TimeGrouper for time grouping of values</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/33637312/pandas-grouper-by-frequency-with-completeness-requirement"">Time grouping with some missing values</a></p>
<p>Valid frequency arguments to Grouper <a class=""reference internal"" href=""timeseries.html#timeseries-offset-aliases""><span class=""std std-ref"">Timeseries</span></a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/41483763/pandas-timegrouper-on-multiindex"">Grouping using a MultiIndex</a></p>
<p>Using TimeGrouper and another grouping to create subgroups, then apply a custom function <a class=""reference external"" href=""https://github.com/pandas-dev/pandas/issues/3791"">GH 3791</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/15408156/resampling-with-custom-periods"">Resampling with custom periods</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/14898574/resample-intrday-pandas-dataframe-without-add-new-days"">Resample intraday frame without adding new days</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/14861023/resampling-minute-data"">Resample minute data</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/q/18677271/564538"">Resample with groupby</a></p>
</section>
</section>
<section id=""merge"">
<span id=""cookbook-merge""></span><h2>Merge<a class=""headerlink"" href=""#merge"" title=""Link to this heading"">#</a></h2>
<p>The <a class=""reference internal"" href=""merging.html#merging-join""><span class=""std std-ref"">Join</span></a> docs.</p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/14988480/pandas-version-of-rbind"">Concatenate two dataframes with overlapping index (emulate R rbind)</a></p>

<p>Depending on df construction, <code class=""docutils literal notranslate""><span class=""pre"">ignore_index</span></code> may be needed</p>

<p>Self Join of a DataFrame <a class=""reference external"" href=""https://github.com/pandas-dev/pandas/issues/2996"">GH 2996</a></p>

<p><a class=""reference external"" href=""https://stackoverflow.com/questions/14341805/pandas-merge-pd-merge-how-to-set-the-index-and-join"">How to set the index and join</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/12322289/kdb-like-asof-join-for-timeseries-data-in-pandas/12336039#12336039"">KDB like asof join</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/15581829/how-to-perform-an-inner-or-outer-join-of-dataframes-with-pandas-on-non-simplisti"">Join with a criteria based on the values</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/25125626/pandas-merge-with-logic/2512764"">Using searchsorted to merge based on values inside a range</a></p>
</section>
<section id=""plotting"">
<span id=""cookbook-plotting""></span><h2>Plotting<a class=""headerlink"" href=""#plotting"" title=""Link to this heading"">#</a></h2>
<p>The <a class=""reference internal"" href=""visualization.html#visualization""><span class=""std std-ref"">Plotting</span></a> docs.</p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/14349055/making-matplotlib-graphs-look-like-r-by-default"">Make Matplotlib look like R</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/12945971/pandas-timeseries-plot-setting-x-axis-major-and-minor-ticks-and-labels"">Setting x-axis major and minor labels</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/16392921/make-more-than-one-chart-in-same-ipython-notebook-cell"">Plotting multiple charts in an IPython Jupyter notebook</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/16568964/make-a-multiline-plot-from-csv-file-in-matplotlib"">Creating a multi-line plot</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/17050202/plot-timeseries-of-histograms-in-python"">Plotting a heatmap</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/11067368/annotate-time-series-plot-in-matplotlib"">Annotate a time-series plot</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/17891493/annotating-points-from-a-pandas-dataframe-in-matplotlib-plot"">Annotate a time-series plot #2</a></p>
<p><a class=""reference external"" href=""https://pandas-xlsxwriter-charts.readthedocs.io/"">Generate Embedded plots in excel files using Pandas, Vincent and xlsxwriter</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/23232989/boxplot-stratified-by-column-in-python-pandas"">Boxplot for each quartile of a stratifying variable</a></p>

<img alt=""../_images/quartile_boxplot.png"" src=""../_images/quartile_boxplot.png""/>
</section>
<section id=""data-in-out"">
<h2>Data in/out<a class=""headerlink"" href=""#data-in-out"" title=""Link to this heading"">#</a></h2>
<p><a class=""reference external"" href=""https://stackoverflow.com/q/16628329"">Performance comparison of SQL vs HDF5</a></p>
<section id=""csv"">
<span id=""cookbook-csv""></span><h3>CSV<a class=""headerlink"" href=""#csv"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""io.html#io-read-csv-table""><span class=""std std-ref"">CSV</span></a> docs</p>
<p><a class=""reference external"" href=""https://wesmckinney.com/blog/update-on-upcoming-pandas-v0-10-new-file-parser-other-performance-wins/"">read_csv in action</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/17134942/pandas-dataframe-output-end-of-csv"">appending to a csv</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/11622652/large-persistent-dataframe-in-pandas/12193309#12193309"">Reading a csv chunk-by-chunk</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/19674212/pandas-data-frame-select-rows-and-clear-memory"">Reading only certain rows of a csv chunk-by-chunk</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/15008970/way-to-read-first-few-lines-for-pandas-dataframe"">Reading the first few lines of a frame</a></p>
<p>Reading a file that is compressed but not by <code class=""docutils literal notranslate""><span class=""pre"">gzip/bz2</span></code> (the native compressed formats which <code class=""docutils literal notranslate""><span class=""pre"">read_csv</span></code> understands).
This example shows a <code class=""docutils literal notranslate""><span class=""pre"">WinZipped</span></code> file, but is a general application of opening the file within a context manager and
using that handle to read.
<a class=""reference external"" href=""https://stackoverflow.com/questions/17789907/pandas-convert-winzipped-csv-file-to-data-frame"">See here</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/15555005/get-inferred-dataframe-types-iteratively-using-chunksize"">Inferring dtypes from a file</a></p>
<p>Dealing with bad lines <a class=""reference external"" href=""https://github.com/pandas-dev/pandas/issues/2886"">GH 2886</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/17349574/pandas-write-multiindex-rows-with-to-csv"">Write a multi-row index CSV without writing duplicates</a></p>
<section id=""reading-multiple-files-to-create-a-single-dataframe"">
<span id=""cookbook-csv-multiple-files""></span><h4>Reading multiple files to create a single DataFrame<a class=""headerlink"" href=""#reading-multiple-files-to-create-a-single-dataframe"" title=""Link to this heading"">#</a></h4>
<p>The best way to combine multiple files into a single DataFrame is to read the individual frames one by one, put all
of the individual frames into a list, and then combine the frames in the list using <code class=""xref py py-func docutils literal notranslate""><span class=""pre"">pd.concat()</span></code>:</p>

<p>You can use the same approach to read all files matching a pattern. Here is an example using <code class=""docutils literal notranslate""><span class=""pre"">glob</span></code>:</p>

<p>Finally, this strategy will work with the other <code class=""docutils literal notranslate""><span class=""pre"">pd.read_*(...)</span></code> functions described in the <a class=""reference internal"" href=""io.html#io""><span class=""std std-ref"">io docs</span></a>.</p>
</section>
<section id=""parsing-date-components-in-multi-columns"">
<h4>Parsing date components in multi-columns<a class=""headerlink"" href=""#parsing-date-components-in-multi-columns"" title=""Link to this heading"">#</a></h4>
<p>Parsing date components in multi-columns is faster with a format</p>

</section>
<section id=""skip-row-between-header-and-data"">
<h4>Skip row between header and data<a class=""headerlink"" href=""#skip-row-between-header-and-data"" title=""Link to this heading"">#</a></h4>

<section id=""option-1-pass-rows-explicitly-to-skip-rows"">
<h5>Option 1: pass rows explicitly to skip rows<a class=""headerlink"" href=""#option-1-pass-rows-explicitly-to-skip-rows"" title=""Link to this heading"">#</a></h5>

</section>
<section id=""option-2-read-column-names-and-then-data"">
<h5>Option 2: read column names and then data<a class=""headerlink"" href=""#option-2-read-column-names-and-then-data"" title=""Link to this heading"">#</a></h5>

</section>
</section>
</section>
<section id=""sql"">
<span id=""cookbook-sql""></span><h3>SQL<a class=""headerlink"" href=""#sql"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""io.html#io-sql""><span class=""std std-ref"">SQL</span></a> docs</p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/10065051/python-pandas-and-databases-like-mysql"">Reading from databases with SQL</a></p>
</section>
<section id=""excel"">
<span id=""cookbook-excel""></span><h3>Excel<a class=""headerlink"" href=""#excel"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""io.html#io-excel""><span class=""std std-ref"">Excel</span></a> docs</p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/15588713/sheets-of-excel-workbook-from-a-url-into-a-pandas-dataframe"">Reading from a filelike handle</a></p>
<p><a class=""reference external"" href=""https://pbpython.com/improve-pandas-excel-output.html"">Modifying formatting in XlsxWriter output</a></p>
<p>Loading only visible sheets <a class=""reference external"" href=""https://github.com/pandas-dev/pandas/issues/19842#issuecomment-892150745"">GH 19842#issuecomment-892150745</a></p>
</section>
<section id=""html"">
<span id=""cookbook-html""></span><h3>HTML<a class=""headerlink"" href=""#html"" title=""Link to this heading"">#</a></h3>
<p><a class=""reference external"" href=""https://stackoverflow.com/a/18939272/564538"">Reading HTML tables from a server that cannot handle the default request
header</a></p>
</section>
<section id=""hdfstore"">
<span id=""cookbook-hdf""></span><h3>HDFStore<a class=""headerlink"" href=""#hdfstore"" title=""Link to this heading"">#</a></h3>
<p>The <a class=""reference internal"" href=""io.html#io-hdf5""><span class=""std std-ref"">HDFStores</span></a> docs</p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/13926089/selecting-columns-from-pandas-hdfstore-table"">Simple queries with a Timestamp Index</a></p>
<p>Managing heterogeneous data using a linked multiple table hierarchy <a class=""reference external"" href=""https://github.com/pandas-dev/pandas/issues/3032"">GH 3032</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/14614512/merging-two-tables-with-millions-of-rows-in-python/14617925#14617925"">Merging on-disk tables with millions of rows</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/a/29014295/2858145"">Avoiding inconsistencies when writing to a store from multiple processes/threads</a></p>
<p>De-duplicating a large store by chunks, essentially a recursive reduction operation. Shows a function for taking in data from
csv file and creating a store by chunks, with date parsing as well.
<a class=""reference external"" href=""https://stackoverflow.com/questions/16110252/need-to-compare-very-large-files-around-1-5gb-in-python/16110391#16110391"">See here</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/20428355/appending-column-to-frame-of-hdf-file-in-pandas/20428786#20428786"">Creating a store chunk-by-chunk from a csv file</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/16997048/how-does-one-append-large-amounts-of-data-to-a-pandas-hdfstore-and-get-a-natural/16999397#16999397"">Appending to a store, while creating a unique index</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/q/14262433"">Large Data work flows</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/16997048/how-does-one-append-large-amounts-of-data-to-a-pandas-hdfstore-and-get-a-natural"">Reading in a sequence of files, then providing a global unique index to a store while appending</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/15798209/pandas-group-by-query-on-large-data-in-hdfstore"">Groupby on a HDFStore with low group density</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/25459982/trouble-with-grouby-on-millions-of-keys-on-a-chunked-file-in-python-pandas/25471765#25471765"">Groupby on a HDFStore with high group density</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/22777284/improve-query-performance-from-a-large-hdfstore-table-with-pandas/22820780#22820780"">Hierarchical queries on a HDFStore</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/20497897/converting-dict-of-dicts-into-pandas-dataframe-memory-issues"">Counting with a HDFStore</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/15488809/how-to-trouble-shoot-hdfstore-exception-cannot-find-the-correct-atom-type"">Troubleshoot HDFStore exceptions</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/15988871/hdfstore-appendstring-dataframe-fails-when-string-column-contents-are-longer"">Setting min_itemsize with strings</a></p>
<p><a class=""reference external"" href=""https://stackoverflow.com/questions/17893370/ptrepack-sortby-needs-full-index"">Using ptrepack to create a completely-sorted-index on a store</a></p>
<p>Storing Attributes to a group node</p>

<p>You can create or load a HDFStore in-memory by passing the <code class=""docutils literal notranslate""><span class=""pre"">driver</span></code>
parameter to PyTables. Changes are only written to disk when the HDFStore
is closed.</p>

</section>
<section id=""binary-files"">
<span id=""cookbook-binary""></span><h3>Binary files<a class=""headerlink"" href=""#binary-files"" title=""Link to this heading"">#</a></h3>
<p>pandas readily accepts NumPy record arrays, if you need to read in a binary
file consisting of an array of C structs. For example, given this C program
in a file called <code class=""docutils literal notranslate""><span class=""pre"">main.c</span></code> compiled with <code class=""docutils literal notranslate""><span class=""pre"">gcc</span> <span class=""pre"">main.c</span> <span class=""pre"">-std=gnu99</span></code> on a
64-bit machine,</p>
<div class=""highlight-c notranslate""><div class=""highlight""><pre><span></span><span class=""cp"">#include</span><span class=""w""> </span><span class=""cpf"">&lt;stdio.h&gt;</span>
<span class=""cp"">#include</span><span class=""w""> </span><span class=""cpf"">&lt;stdint.h&gt;</span>

<span class=""k"">typedef</span><span class=""w""> </span><span class=""k"">struct</span><span class=""w""> </span><span class=""nc"">_Data</span>
<span class=""p"">{</span>
<span class=""w"">    </span><span class=""kt"">int32_t</span><span class=""w""> </span><span class=""n"">count</span><span class=""p"">;</span>
<span class=""w"">    </span><span class=""kt"">double</span><span class=""w""> </span><span class=""n"">avg</span><span class=""p"">;</span>
<span class=""w"">    </span><span class=""kt"">float</span><span class=""w""> </span><span class=""n"">scale</span><span class=""p"">;</span>
<span class=""p"">}</span><span class=""w""> </span><span class=""n"">Data</span><span class=""p"">;</span>

<span class=""kt"">int</span><span class=""w""> </span><span class=""nf"">main</span><span class=""p"">(</span><span class=""kt"">int</span><span class=""w""> </span><span class=""n"">argc</span><span class=""p"">,</span><span class=""w""> </span><span class=""k"">const</span><span class=""w""> </span><span class=""kt"">char</span><span class=""w""> </span><span class=""o"">*</span><span class=""n"">argv</span><span class=""p"">[])</span>
<span class=""p"">{</span>
<span class=""w"">    </span><span class=""kt"">size_t</span><span class=""w""> </span><span class=""n"">n</span><span class=""w""> </span><span class=""o"">=</span><span class=""w""> </span><span class=""mi"">10</span><span class=""p"">;</span>
<span class=""w"">    </span><span class=""n"">Data</span><span class=""w""> </span><span class=""n"">d</span><span class=""p"">[</span><span class=""n"">n</span><span class=""p"">];</span>

<span class=""w"">    </span><span class=""k"">for</span><span class=""w""> </span><span class=""p"">(</span><span class=""kt"">int</span><span class=""w""> </span><span class=""n"">i</span><span class=""w""> </span><span class=""o"">=</span><span class=""w""> </span><span class=""mi"">0</span><span class=""p"">;</span><span class=""w""> </span><span class=""n"">i</span><span class=""w""> </span><span class=""o"">&lt;</span><span class=""w""> </span><span class=""n"">n</span><span class=""p"">;</span><span class=""w""> </span><span class=""o"">++</span><span class=""n"">i</span><span class=""p"">)</span>
<span class=""w"">    </span><span class=""p"">{</span>
<span class=""w"">        </span><span class=""n"">d</span><span class=""p"">[</span><span class=""n"">i</span><span class=""p"">].</span><span class=""n"">count</span><span class=""w""> </span><span class=""o"">=</span><span class=""w""> </span><span class=""n"">i</span><span class=""p"">;</span>
<span class=""w"">        </span><span class=""n"">d</span><span class=""p"">[</span><span class=""n"">i</span><span class=""p"">].</span><span class=""n"">avg</span><span class=""w""> </span><span class=""o"">=</span><span class=""w""> </span><span class=""n"">i</span><span class=""w""> </span><span class=""o"">+</span><span class=""w""> </span><span class=""mf"">1.0</span><span class=""p"">;</span>
<span class=""w"">        </span><span class=""n"">d</span><span class=""p"">[</span><span class=""n"">i</span><span class=""p"">].</span><span class=""n"">scale</span><span class=""w""> </span><span class=""o"">=</span><span class=""w""> </span><span class=""p"">(</span><span class=""kt"">float</span><span class=""p"">)</span><span class=""w""> </span><span class=""n"">i</span><span class=""w""> </span><span class=""o"">+</span><span class=""w""> </span><span class=""mf"">2.0f</span><span class=""p"">;</span>
<span class=""w"">    </span><span class=""p"">}</span>

<span class=""w"">    </span><span class=""kt"">FILE</span><span class=""w""> </span><span class=""o"">*</span><span class=""n"">file</span><span class=""w""> </span><span class=""o"">=</span><span class=""w""> </span><span class=""n"">fopen</span><span class=""p"">(</span><span class=""s"">""binary.dat""</span><span class=""p"">,</span><span class=""w""> </span><span class=""s"">""wb""</span><span class=""p"">);</span>
<span class=""w"">    </span><span class=""n"">fwrite</span><span class=""p"">(</span><span class=""o"">&amp;</span><span class=""n"">d</span><span class=""p"">,</span><span class=""w""> </span><span class=""k"">sizeof</span><span class=""p"">(</span><span class=""n"">Data</span><span class=""p"">),</span><span class=""w""> </span><span class=""n"">n</span><span class=""p"">,</span><span class=""w""> </span><span class=""n"">file</span><span class=""p"">);</span>
<span class=""w"">    </span><span class=""n"">fclose</span><span class=""p"">(</span><span class=""n"">file</span><span class=""p"">);</span>

<span class=""w"">    </span><span class=""k"">return</span><span class=""w""> </span><span class=""mi"">0</span><span class=""p"">;</span>
<span class=""p"">}</span>
</pre></div>
</div>
<p>the following Python code will read the binary file <code class=""docutils literal notranslate""><span class=""pre"">'binary.dat'</span></code> into a
pandas <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code>, where each element of the struct corresponds to a column
in the frame:</p>
<div class=""highlight-python notranslate""><div class=""highlight""><pre><span></span><span class=""n"">names</span> <span class=""o"">=</span> <span class=""s2"">""count""</span><span class=""p"">,</span> <span class=""s2"">""avg""</span><span class=""p"">,</span> <span class=""s2"">""scale""</span>

<span class=""c1""># note that the offsets are larger than the size of the type because of</span>
<span class=""c1""># struct padding</span>
<span class=""n"">offsets</span> <span class=""o"">=</span> <span class=""mi"">0</span><span class=""p"">,</span> <span class=""mi"">8</span><span class=""p"">,</span> <span class=""mi"">16</span>
<span class=""n"">formats</span> <span class=""o"">=</span> <span class=""s2"">""i4""</span><span class=""p"">,</span> <span class=""s2"">""f8""</span><span class=""p"">,</span> <span class=""s2"">""f4""</span>
<span class=""n"">dt</span> <span class=""o"">=</span> <span class=""n"">np</span><span class=""o"">.</span><span class=""n"">dtype</span><span class=""p"">({</span><span class=""s2"">""names""</span><span class=""p"">:</span> <span class=""n"">names</span><span class=""p"">,</span> <span class=""s2"">""offsets""</span><span class=""p"">:</span> <span class=""n"">offsets</span><span class=""p"">,</span> <span class=""s2"">""formats""</span><span class=""p"">:</span> <span class=""n"">formats</span><span class=""p"">},</span> <span class=""n"">align</span><span class=""o"">=</span><span class=""kc"">True</span><span class=""p"">)</span>
<span class=""n"">df</span> <span class=""o"">=</span> <span class=""n"">pd</span><span class=""o"">.</span><span class=""n"">DataFrame</span><span class=""p"">(</span><span class=""n"">np</span><span class=""o"">.</span><span class=""n"">fromfile</span><span class=""p"">(</span><span class=""s2"">""binary.dat""</span><span class=""p"">,</span> <span class=""n"">dt</span><span class=""p"">))</span>
</pre></div>
</div>
<div class=""admonition note"">
<p class=""admonition-title"">Note</p>
<p>The offsets of the structure elements may be different depending on the
architecture of the machine on which the file was created. Using a raw
binary file format like this for general data storage is not recommended, as
it is not cross platform. We recommended either HDF5 or parquet, both of
which are supported by pandas’ IO facilities.</p>
</div>
</section>
</section>
<section id=""computation"">
<h2>Computation<a class=""headerlink"" href=""#computation"" title=""Link to this heading"">#</a></h2>
<p><a class=""reference external"" href=""https://nbviewer.ipython.org/gist/metakermit/5720498"">Numerical integration (sample-based) of a time series</a></p>
<section id=""correlation"">
<h3>Correlation<a class=""headerlink"" href=""#correlation"" title=""Link to this heading"">#</a></h3>
<p>Often it’s useful to obtain the lower (or upper) triangular form of a correlation matrix calculated from <a class=""reference internal"" href=""../reference/api/pandas.DataFrame.corr.html#pandas.DataFrame.corr"" title=""pandas.DataFrame.corr""><code class=""xref py py-func docutils literal notranslate""><span class=""pre"">DataFrame.corr()</span></code></a>. This can be achieved by passing a boolean mask to <code class=""docutils literal notranslate""><span class=""pre"">where</span></code> as follows:</p>

<p>The <code class=""docutils literal notranslate""><span class=""pre"">method</span></code> argument within <code class=""docutils literal notranslate""><span class=""pre"">DataFrame.corr</span></code> can accept a callable in addition to the named correlation types. Here we compute the <a class=""reference external"" href=""https://en.wikipedia.org/wiki/Distance_correlation"">distance correlation</a> matrix for a <code class=""docutils literal notranslate""><span class=""pre"">DataFrame</span></code> object.</p>

</section>
</section>
<section id=""timedeltas"">
<h2>Timedeltas<a class=""headerlink"" href=""#timedeltas"" title=""Link to this heading"">#</a></h2>
<p>The <a class=""reference internal"" href=""timedeltas.html#timedeltas-timedeltas""><span class=""std std-ref"">Timedeltas</span></a> docs.</p>
<p><a class=""reference external"" href=""https://github.com/pandas-dev/pandas/pull/2899"">Using timedeltas</a></p>

<p><a class=""reference external"" href=""https://stackoverflow.com/questions/16385785/add-days-to-dates-in-dataframe"">Adding and subtracting deltas and dates</a></p>

<p><a class=""reference external"" href=""https://stackoverflow.com/questions/15683588/iterating-through-a-pandas-dataframe"">Another example</a></p>
<p>Values can be set to NaT using np.nan, similar to datetime</p>

</section>
<section id=""creating-example-data"">
<h2>Creating example data<a class=""headerlink"" href=""#creating-example-data"" title=""Link to this heading"">#</a></h2>
<p>To create a dataframe from every combination of some given values, like R’s <code class=""docutils literal notranslate""><span class=""pre"">expand.grid()</span></code>
function, we can create a dict where the keys are column names and the values are lists
of the data values:</p>

</section>
<section id=""constant-series"">
<h2>Constant series<a class=""headerlink"" href=""#constant-series"" title=""Link to this heading"">#</a></h2>
<p>To assess if a series has a constant value, we can check if <code class=""docutils literal notranslate""><span class=""pre"">series.nunique()</span> <span class=""pre"">&lt;=</span> <span class=""pre"">1</span></code>.
However, a more performant approach, that does not count all unique values first, is:</p>

<p>This approach assumes that the series does not contain missing values.
For the case that we would drop NA values, we can simply remove those values first:</p>

<p>If missing values are considered distinct from any other value, then one could use:</p>

<p>(Note that this example does not disambiguate between <code class=""docutils literal notranslate""><span class=""pre"">np.nan</span></code>, <code class=""docutils literal notranslate""><span class=""pre"">pd.NA</span></code> and <code class=""docutils literal notranslate""><span class=""pre"">None</span></code>)</p>
</section>
</section>
</article>","Cookbook # This is a repository for short and sweet examples and links for useful pandas recipes. We encourage users to add to this documentation. Adding interesting links and/or inline examples to this section is a great First Pull Request . Simplified, condensed, new-user friendly, in-line examples have been inserted where possible to augment the Stack-Overflow and GitHub links. Many of the links contain expanded information, above what the in-line examples offer. pandas (pd) and NumPy (np) are the only two abbreviated imported modules. The rest are kept explicitly imported for newer users. Idioms # These are some neat pandas idioms if-then/if-then-else on one column, and assignment to another one or more columns: if-then… # An if-then on one column An if-then with assignment to 2 columns: Add another line with different logic, to do the -else Or use pandas where after you’ve set up a mask if-then-else using NumPy’s where() Splitting # Split a frame with a boolean criterion Building criteria # Select with multi-column criteria …and (without assignment returns a Series) …or (without assignment returns a Series) …or (with assignment modifies the DataFrame.) Select rows with data closest to certain value using argsort Dynamically reduce a list of criteria using a binary operators One could hard code: …Or it can be done with a list of dynamically built criteria Selection # Dataframes # The indexing docs. Using both row labels and value conditionals Use loc for label-oriented slicing and iloc positional slicing GH 2904 There are 2 explicit slicing methods, with a third general case Positional-oriented (Python slicing style : exclusive of end) Label-oriented (Non-Python slicing style : inclusive of end) General (Either slicing style : depends on if the slice contains labels or positions) Ambiguity arises when an index consists of integers with a non-zero start or non-unit increment. Using inverse operator (~) to take the complement of a mask New columns # Efficiently and dynamically creating new columns using DataFrame.map (previously named applymap) Keep other columns when using min() with groupby Method 1 : idxmin() to get the index of the minimums Method 2 : sort then take first of each Notice the same results, with the exception of the index. Multiindexing # The multindexing docs. Creating a MultiIndex from a labeled frame Arithmetic # Performing arithmetic with a MultiIndex that needs broadcasting Slicing # Slicing a MultiIndex with xs To take the cross section of the 1st level and 1st axis the index: …and now the 2nd level of the 1st axis. Slicing a MultiIndex with xs, method #2 Setting portions of a MultiIndex with xs Sorting # Sort by specific column or an ordered list of columns, with a MultiIndex Partial selection, the need for sortedness GH 2995 Levels # Prepending a level to a multiindex Flatten Hierarchical columns Missing data # The missing data docs. Fill forward a reversed timeseries cumsum reset at NaN values Replace # Using replace with backrefs Grouping # The grouping docs. Basic grouping with apply Unlike agg, apply’s callable is passed a sub-DataFrame which gives you access to all the columns Using get_group Apply to different items in a group Expanding apply Replacing some values with mean of the rest of a group Sort groups by aggregated data Create multiple aggregated columns Create a value counts column and reassign back to the DataFrame Shift groups of the values in a column based on the index Select row with maximum value from each group Grouping like Python’s itertools.groupby Expanding data # Alignment and to-date Rolling Computation window based on values instead of counts Rolling Mean by Time Interval Splitting # Splitting a frame Create a list of dataframes, split using a delineation based on logic included in rows. Pivot # The Pivot docs. Partial sums and subtotals Frequency table like plyr in R Plot pandas DataFrame with year over year data To create year and month cross tabulation: Apply # Rolling apply to organize - Turning embedded lists into a MultiIndex frame Rolling apply with a DataFrame returning a Series Rolling Apply to multiple columns where function calculates a Series before a Scalar from the Series is returned Rolling apply with a DataFrame returning a Scalar Rolling Apply to multiple columns where function returns a Scalar (Volume Weighted Average Price) Timeseries # Between times Using indexer between time Constructing a datetime range that excludes weekends and includes only certain times Vectorized Lookup Aggregation and plotting time series Turn a matrix with hours in columns and days in rows into a continuous row sequence in the form of a time series. How to rearrange a Python pandas DataFrame? Dealing with duplicates when reindexing a timeseries to a specified frequency Calculate the first day of the month for each entry in a DatetimeIndex Resampling # The Resample docs. Using Grouper instead of TimeGrouper for time grouping of values Time grouping with some missing values Valid frequency arguments to Grouper Timeseries Grouping using a MultiIndex Using TimeGrouper and another grouping to create subgroups, then apply a custom function GH 3791 Resampling with custom periods Resample intraday frame without adding new days Resample minute data Resample with groupby Merge # The Join docs. Concatenate two dataframes with overlapping index (emulate R rbind) Depending on df construction, ignore_index may be needed Self Join of a DataFrame GH 2996 How to set the index and join KDB like asof join Join with a criteria based on the values Using searchsorted to merge based on values inside a range Plotting # The Plotting docs. Make Matplotlib look like R Setting x-axis major and minor labels Plotting multiple charts in an IPython Jupyter notebook Creating a multi-line plot Plotting a heatmap Annotate a time-series plot Annotate a time-series plot #2 Generate Embedded plots in excel files using Pandas, Vincent and xlsxwriter Boxplot for each quartile of a stratifying variable Data in/out # Performance comparison of SQL vs HDF5 CSV # The CSV docs read_csv in action appending to a csv Reading a csv chunk-by-chunk Reading only certain rows of a csv chunk-by-chunk Reading the first few lines of a frame Reading a file that is compressed but not by gzip/bz2 (the native compressed formats which read_csv understands). This example shows a WinZipped file, but is a general application of opening the file within a context manager and using that handle to read. See here Inferring dtypes from a file Dealing with bad lines GH 2886 Write a multi-row index CSV without writing duplicates Reading multiple files to create a single DataFrame # The best way to combine multiple files into a single DataFrame is to read the individual frames one by one, put all of the individual frames into a list, and then combine the frames in the list using pd.concat() : You can use the same approach to read all files matching a pattern. Here is an example using glob : Finally, this strategy will work with the other pd.read_*(...) functions described in the io docs . Parsing date components in multi-columns # Parsing date components in multi-columns is faster with a format Skip row between header and data # Option 1: pass rows explicitly to skip rows # Option 2: read column names and then data # SQL # The SQL docs Reading from databases with SQL Excel # The Excel docs Reading from a filelike handle Modifying formatting in XlsxWriter output Loading only visible sheets GH 19842#issuecomment-892150745 HTML # Reading HTML tables from a server that cannot handle the default request header HDFStore # The HDFStores docs Simple queries with a Timestamp Index Managing heterogeneous data using a linked multiple table hierarchy GH 3032 Merging on-disk tables with millions of rows Avoiding inconsistencies when writing to a store from multiple processes/threads De-duplicating a large store by chunks, essentially a recursive reduction operation. Shows a function for taking in data from csv file and creating a store by chunks, with date parsing as well. See here Creating a store chunk-by-chunk from a csv file Appending to a store, while creating a unique index Large Data work flows Reading in a sequence of files, then providing a global unique index to a store while appending Groupby on a HDFStore with low group density Groupby on a HDFStore with high group density Hierarchical queries on a HDFStore Counting with a HDFStore Troubleshoot HDFStore exceptions Setting min_itemsize with strings Using ptrepack to create a completely-sorted-index on a store Storing Attributes to a group node You can create or load a HDFStore in-memory by passing the driver parameter to PyTables. Changes are only written to disk when the HDFStore is closed. Binary files # pandas readily accepts NumPy record arrays, if you need to read in a binary file consisting of an array of C structs. For example, given this C program in a file called main.c compiled with gcc main.c -std=gnu99 on a 64-bit machine, #include <stdio.h> #include <stdint.h> typedef struct _Data { int32_t count ; double avg ; float scale ; } Data ; int main ( int argc , const char * argv []) { size_t n = 10 ; Data d [ n ]; for ( int i = 0 ; i < n ; ++ i ) { d [ i ]. count = i ; d [ i ]. avg = i + 1.0 ; d [ i ]. scale = ( float ) i + 2.0f ; } FILE * file = fopen ( ""binary.dat"" , ""wb"" ); fwrite ( & d , sizeof ( Data ), n , file ); fclose ( file ); return 0 ; } the following Python code will read the binary file 'binary.dat' into a pandas DataFrame , where each element of the struct corresponds to a column in the frame: names = ""count"" , ""avg"" , ""scale"" # note that the offsets are larger than the size of the type because of # struct padding offsets = 0 , 8 , 16 formats = ""i4"" , ""f8"" , ""f4"" dt = np . dtype ({ ""names"" : names , ""offsets"" : offsets , ""formats"" : formats }, align = True ) df = pd . DataFrame ( np . fromfile ( ""binary.dat"" , dt )) Note The offsets of the structure elements may be different depending on the architecture of the machine on which the file was created. Using a raw binary file format like this for general data storage is not recommended, as it is not cross platform. We recommended either HDF5 or parquet, both of which are supported by pandas’ IO facilities. Computation # Numerical integration (sample-based) of a time series Correlation # Often it’s useful to obtain the lower (or upper) triangular form of a correlation matrix calculated from DataFrame.corr() . This can be achieved by passing a boolean mask to where as follows: The method argument within DataFrame.corr can accept a callable in addition to the named correlation types. Here we compute the distance correlation matrix for a DataFrame object. Timedeltas # The Timedeltas docs. Using timedeltas Adding and subtracting deltas and dates Another example Values can be set to NaT using np.nan, similar to datetime Creating example data # To create a dataframe from every combination of some given values, like R’s expand.grid() function, we can create a dict where the keys are column names and the values are lists of the data values: Constant series # To assess if a series has a constant value, we can check if series.nunique() <= 1 . However, a more performant approach, that does not count all unique values first, is: This approach assumes that the series does not contain missing values. For the case that we would drop NA values, we can simply remove those values first: If missing values are considered distinct from any other value, then one could use: (Note that this example does not disambiguate between np.nan , pd.NA and None )"
